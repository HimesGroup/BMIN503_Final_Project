---
title: 'EPID600 FINAL PROJECT, SEDENTARY BEHAVIOR AND 30-YEAR FULL CVD RISK'
author: Alexandra L. Hanlon, PhD
output:
  html_document:
  toc: false 
depth: 3 
theme: paper 
highlight: tango
---
  ***
  
#### Importing and wrangling with data

```{r, eval=TRUE}


library(dplyr)
library(ggplot2)

temp1 <- read.csv(file = "Q:/Alex Hanlon/sedentary_data_for_R.csv", header = TRUE)
temp2 <- dplyr::rename (temp1, TOTAL_PHYS_ACTIVITY_N =  TOTAL_PHYS, BLOOD_PRESSURE_N = SYS_BP_AUTO, 
          FRUITVEG_N = FRUIT_VEG, BMI_N = BMI, BODY_FAT_N = BODY_FAT
                ) 

temp3 <- dplyr::mutate(temp2, GENDER = factor(SEX, labels=c("Female", "Male")),
           RACE = factor(RACE_NEW, labels=c("Mixed/Other", "Asian","Black","White")),
           COLLEGE_C = factor(COLLEGE,labels = c("No", "Yes")),
           EMPLOYMENT_C = factor(EMPLOYMENT, labels = c("Employed",
                                                        "Unemployed",
                                                        "Retired")),
           SHIFT_WORK_C = factor(SHIFT_WORK, labels = c("No", "Yes")),
           RESIDENCE_C = factor(RESIDENCE, labels = c("Urban", "Rural")),
           DEPRESSION_C = factor(MH_STATUS, labels = c("No", "Yes")),
           SEASON_ASSESS_C = factor(SEASON_ASSESS, labels = c("Fall", 
                                                    "Winter",
                                                    "Spring",
                                                    "Summer")),
           CHRONO_C = factor(CHRONO_4_CAT, labels = c("Definitely morning", 
                                                    "More morning than evening",
                                                    "More evening than morning",
                                                    "Definitely evening")),
           SLEEP_C = factor(SLEEP, labels = c("Short", "Long", "Adequate")),
           DIABETES_C = factor(DIABETES, labels = c("No", "Yes")),
           SMOKE_C = factor(SMOKE, labels = c("No", "Yes")),
           HYPERTENSION_MEDS_C = factor(BP_MEDS_ALL, labels = c("No", "Yes")),
           PHYSICAL_ACTIVITY_C = factor(PHYSACT_REC, labels = c("No", "Yes")),
           FRUITVEG_RECOMMEND_MET_C = factor(FRUITVEG_REC, labels = c("No", "Yes")),
           ALCOHOL_INTAKE_C = factor(ALCOHOL_INTAKE, labels = c("Daily or almost daily", 
                                                    "Three or four times a week",
                                                    "Once or twice a week",
                                                    "One to three times a month",
                                                    "Special occasions only",
                                                    "Never")),
           CVD_RISK_C = factor(FULL_CVD_RISK >= 0.4, labels = c("Low", "High"))
           )
          
## Keep only the variables that are needed for the analysis  
temp4 <- dplyr::select(temp3, TV_HRS, COMP_HRS, DRIVE_HRS, AGE, GENDER, CHRONO_C,SLEEP_C,DIABETES_C,SMOKE_C,HYPERTENSION_MEDS_C,PHYSICAL_ACTIVITY_C,FRUITVEG_RECOMMEND_MET_C,
                       ALCOHOL_INTAKE_C,CVD_RISK_C,BLOOD_PRESSURE_N, BMI_N , BODY_FAT_N,TOTAL_PHYS_ACTIVITY_N, 
          FRUITVEG_N)

## Keep only the observations with nonomissing values for all variables of interest
data <- temp4[complete.cases(temp4),]
str(data)
write.csv(data, file = "data_for_Alex.csv")
```

#### Descriptive Statistics
1. Summary of CVD risk dummy 

```{r, eval=TRUE}
ggplot(data=data, aes(x=CVD_RISK_C)) + 
    geom_bar()
summary(data$CVD_RISK_C)
```

2. Summary of risk score components and compare them by CVD risk group

```{r, eval=TRUE}
#Age
qplot(AGE, data=data, geom="histogram", binwidth=1, col=I("blue"), fill=I("blue"), alpha=I(0.5))
summary(data$AGE)

ggplot(data = data, aes(CVD_RISK_C, AGE)) +
  geom_boxplot()

t.test(AGE~CVD_RISK_C, data = data)

#Blood pressure
qplot(BLOOD_PRESSURE_N, data=data, geom="histogram", binwidth=1, col=I("blue"), fill=I("blue"), alpha=I(0.5))
summary(data$BLOOD_PRESSURE_N)

ggplot(data = data, aes(CVD_RISK_C, BLOOD_PRESSURE_N)) +
  geom_boxplot()

t.test(BLOOD_PRESSURE_N~CVD_RISK_C, data = data)

#BMI
qplot(BMI_N, data=data, geom="histogram", binwidth=1, col=I("blue"), fill=I("blue"), alpha=I(0.5))
summary(data$BMI_N)

ggplot(data = data, aes(CVD_RISK_C, BMI_N)) +
  geom_boxplot()

t.test(BMI_N~CVD_RISK_C, data = data)

#Gender

prop.table(table(data$GENDER))
ggplot(data=data, aes(x=GENDER)) + 
    geom_bar()

ggplot(data = data, aes(fill = CVD_RISK_C, x = GENDER)) +
  geom_bar(position = "dodge")
chisq.test(table(data$CVD_RISK_C, data$GENDER))

#Smoking status

prop.table(table(data$SMOKE_C))
ggplot(data=data, aes(x=SMOKE_C)) + 
    geom_bar()

ggplot(data = data, aes(fill = CVD_RISK_C, x = SMOKE_C)) +
  geom_bar(position = "dodge")
chisq.test(table(data$CVD_RISK_C, data$SMOKE_C))

#Diabetes
prop.table(table(data$DIABETES_C))
ggplot(data=data, aes(x=DIABETES_C)) + 
    geom_bar()

ggplot(data = data, aes(fill = CVD_RISK_C, x = DIABETES_C)) +
  geom_bar(position = "dodge")
chisq.test(table(data$CVD_RISK_C, data$DIABETES_C))

# Treatment of hypertensionn

prop.table(table(data$HYPERTENSION_MEDS_C))
ggplot(data=data, aes(x=HYPERTENSION_MEDS_C)) + 
    geom_bar()

ggplot(data = data, aes(fill = CVD_RISK_C, x = HYPERTENSION_MEDS_C)) +
  geom_bar(position = "dodge")
chisq.test(table(data$CVD_RISK_C, data$HYPERTENSION_MEDS_C))
```

3. Summary of sedentary behavior variables and compare them by CVD risk group

```{r, eval=TRUE}
#TV hours
qplot(TV_HRS, data=data, geom="histogram", binwidth=1, col=I("blue"), fill=I("blue"), alpha=I(0.5))
summary(data$TV_HRS)

ggplot(data = data, aes(CVD_RISK_C, TV_HRS)) +
  geom_boxplot()

t.test(TV_HRS~CVD_RISK_C, data = data)

#Computer hours

qplot(COMP_HRS, data=data, geom="histogram", binwidth=1, col=I("blue"), fill=I("blue"), alpha=I(0.5))
summary(data$COMP_HRS)

ggplot(data = data, aes(CVD_RISK_C, COMP_HRS)) +
  geom_boxplot()

t.test(COMP_HRS~CVD_RISK_C, data = data)

#Drive hours

qplot(DRIVE_HRS, data=data, geom="histogram", binwidth=1, col=I("blue"), fill=I("blue"), alpha=I(0.5))
summary(data$DRIVE_HRS)

ggplot(data = data, aes(CVD_RISK_C, DRIVE_HRS)) +
  geom_boxplot()

t.test(DRIVE_HRS~CVD_RISK_C, data = data)
```

4. Summary of covariates and compare them by CVD risk group

```{r, eval=TRUE}
#Total physical activity (continuous)

ggplot(data = data, aes(CVD_RISK_C, TOTAL_PHYS_ACTIVITY_N)) +
  geom_boxplot()
t.test(TOTAL_PHYS_ACTIVITY_N~CVD_RISK_C, data = data)

#Total physical activity (categorical)

ggplot(data = data, aes(fill = CVD_RISK_C, x = PHYSICAL_ACTIVITY_C)) +
  geom_bar(position = "dodge") 
chisq.test(table(data$CVD_RISK_C, data$PHYSICAL_ACTIVITY_C))

#Fruit and Vegetable Intake (continuous)

ggplot(data = data, aes(CVD_RISK_C, FRUITVEG_N)) +
  geom_boxplot()
t.test(FRUITVEG_N~CVD_RISK_C, data = data)

#Fruit and Vegetable Intake (categorical)

ggplot(data = data, aes(fill = CVD_RISK_C, x = FRUITVEG_RECOMMEND_MET_C)) +
  geom_bar(position = "dodge") 
chisq.test(table(data$CVD_RISK_C, data$FRUITVEG_RECOMMEND_MET_C))

#Alcohol intake (categorical)

ggplot(data = data, aes(fill = CVD_RISK_C, x = ALCOHOL_INTAKE_C)) +
  geom_bar(position = "dodge") 
chisq.test(table(data$CVD_RISK_C, data$ALCOHOL_INTAKE_C))

#Sleep duration (categorical)

ggplot(data = data, aes(fill = CVD_RISK_C, x = SLEEP_C)) +
  geom_bar(position = "dodge") 
chisq.test(table(data$CVD_RISK_C, data$SLEEP_C))

#Sleep timing preference (categorical)

ggplot(data = data, aes(fill = CVD_RISK_C, x = CHRONO_C)) +
  geom_bar(position = "dodge") 
chisq.test(table(data$CVD_RISK_C, data$CHRONO_C))

#Body fat percentage (continuous)

ggplot(data = data, aes(CVD_RISK_C, BODY_FAT_N)) +
  geom_boxplot()
t.test(BODY_FAT_N~CVD_RISK_C, data = data)
```

4. Decision tree

```{r, eval=TRUE}

library(rpart)
library(partykit)
library(rpart.plot)
library(caret) 
set.seed(101)
train <- sample(1:nrow(data), nrow(data)*0.6)
test <- data[-train, "CVD_RISK_C"]
tree_cvd <- rpart(CVD_RISK_C~TV_HRS+COMP_HRS+DRIVE_HRS+
                    PHYSICAL_ACTIVITY_C+FRUITVEG_RECOMMEND_MET_C+
                    ALCOHOL_INTAKE_C+SLEEP_C+
                    CHRONO_C+BODY_FAT_N,  method="class", data=data, subset=train)
plot(as.party(tree_cvd), type="simple")
#plot(as.party(tree1), type="extended")
summary(tree_cvd)
yhat <- predict(tree_cvd, data[-train,], type="class")
nonmissing <- !is.na(test)
conf <- table(yhat[nonmissing], test[nonmissing])

f.conf <- confusionMatrix(conf)
print(f.conf)
```

5. Logistic regression and random forest modeling

    + Distriution of subjects by CVD risk (low/moderate vs high)

```{r, eval=TRUE}
data2 <- dplyr::select(data, CVD_RISK_C, 
                       TV_HRS,COMP_HRS,DRIVE_HRS,
                       PHYSICAL_ACTIVITY_C,FRUITVEG_RECOMMEND_MET_C,
                       ALCOHOL_INTAKE_C,SLEEP_C,CHRONO_C,BODY_FAT_N)
str(data2)
table(data2$CVD_RISK_C)
```
    
    + Univariate logistic regression models to examine variables  individually associated with CVD risk at a significance level <0.05. 

```{r, eval=TRUE}
pvalues <- sapply( data2[,2:10], function(w) {
glm.fit <- glm(data$CVD_RISK_C ~ w, family=binomial)
summary(glm.fit)$coefficients[2,4]
})
pvalues[pvalues<0.05]

```

TV hours, driving hours, physical activity, alcohol intake, sleep duration, sleep timing preference, and body fat percentage are all statistically significant at p<0.05.


    + Generating a plot to visualize how TV hours (the values of the individual variable with lowest p-value) differ by risk group.


```{r, eval=TRUE}
ggplot(data2, aes(CVD_RISK_C, TV_HRS)) +
    geom_boxplot(aes(fill=CVD_RISK_C)) +
    labs(title="Most Significantly Associated Variable")
```

   + Comparing the predictive accuracy of 1) Logistic regression and 2) Random forest multivariate models of CVD risk regressed on all independent variables simultaneously.
   
```{r, eval=TRUE}
#Logistic regression
full.glm <- glm(CVD_RISK_C~., data=data2, family=binomial(logit))
summary(full.glm)
glm.pred <- predict(full.glm, data2, type="response")


#Random Forest
library(randomForest)
rf <- randomForest(CVD_RISK_C~., data=data2, ntree=100, importance=TRUE)
rf
imp <- rf$importance
sort(imp[,4], decreasing=TRUE)
rf.pred <- predict(rf, data2, type="prob")
```

All independent variables in the multivariate logistic regression are significant. In the random forest model, body fat percentage is the most important predictor, while the fruit and vegetable intake is the least important predictor.

   + Obtain 10-fold cross validation classification vectors for each model. Obtain AUC values and make an ROC plot that shows ROC curves corresponding to predictive accuracy using the training data as well as the 10-fold cross-validations. 
   
```{r, eval=TRUE}
#10-fold cross-validation
library(dplyr)
N = nrow(data2)
K = 10
set.seed(1234)
s = sample(1:K, size=N, replace=T)
pred_outputs.glm <- vector(mode="numeric", length=N)
pred_outputs.rf <- vector(mode="numeric", length=N)
obs_outputs <- vector(mode="numeric", length=N)
offset <- 0
for(i in 1:K){
    train <- filter(data2, s != i)
    test <- filter(data2, s == i)
    obs_outputs[1:length(s[s==i]) + offset] <- test$CVD_RISK_C
    #GLM train/test
    glm <- glm(CVD_RISK_C~., data=train, family=binomial(logit))
    glm.pred.curr <- predict(glm, test, type="response")
    pred_outputs.glm[1:length(s[s==i]) + offset] <- glm.pred.curr

    #RF train/test
    rf <- randomForest(CVD_RISK_C~., data=train, ntree=100)
    rf.pred.curr <- predict(rf, newdata=test, type="prob") 
    pred_outputs.rf[1:length(s[s==i]) + offset] <- rf.pred.curr[,2]

    offset <- offset + length(s[s==i])
}

#ROC curves - one plot of the four tests
library(pROC)
plot.roc(data$CVD_RISK_C, glm.pred, ci=TRUE)
plot.roc(obs_outputs, pred_outputs.glm, ci=TRUE, col="darkblue", add=TRUE)
plot.roc(data$CVD_RISK_C, rf.pred[, 2], ci=TRUE, col="darkgreen", add=TRUE)
plot.roc(obs_outputs, pred_outputs.rf, ci=TRUE, col="red", add=TRUE) 
legend("bottomright",  legend=c("GLM Training", "GLM Cross-Validation", "RF Training", "RF Cross-Validation"), col=c("black", "darkblue", "darkgreen", "red"), lwd=1)
```

AUC values are is 0.8963, 0.6727, 0.6477, 0.6476 for the RF training set, RF with 10-fold CV,  MV LR training set, and MV LR with 10-fold CV, respectively. Random forest models are superior to logistic regression for this data set in terms of predictionn accuracy.

   + Create logistic regression and random forest predictive models using the "best" variables according to each method.

```{r, eval=TRUE}
best.glm <- pvalues[pvalues<1E-10]
names(best.glm)
best.rf <- imp[, 4][imp[, 4]>10]
names(best.rf)
```

The significant ariables in the univariate logistic regression models are TV hours, driving hours, alcohol intake, sleep duration, and sleep timing preference. 

All 9 independnet variables emerged significant in the RF model.

```{r, eval=TRUE}

#Logistic regression
top.glm <- glm(CVD_RISK_C~TV_HRS+DRIVE_HRS+ALCOHOL_INTAKE_C+SLEEP_C+CHRONO_C, data=data2, family=binomial(logit))
summary(top.glm)
glm.top.pred <- predict(top.glm, data2, type="response")


#10-fold cross-validation
N = nrow(data2)
K = 10
set.seed(1234)
s = sample(1:K, size=N, replace=T)
pred_outputs.glm <- vector(mode="numeric", length=N)
obs_outputs <- vector(mode="numeric", length=N)
offset <- 0
for(i in 1:K){
    train <- filter(data2, s != i)
    test <- filter(data2, s == i)
    obs_outputs[1:length(s[s==i]) + offset] <- test$CVD_RISK_C
    #GLM train/test
    glm <- glm(CVD_RISK_C~TV_HRS+DRIVE_HRS+ALCOHOL_INTAKE_C+SLEEP_C+CHRONO_C, data=train, family=binomial(logit))
    glm.pred.curr <- predict(glm, test, type="response")
    pred_outputs.glm[1:length(s[s==i]) + offset] <- glm.pred.curr

    
    offset <- offset + length(s[s==i])
}

#ROC Curves
plot.roc(data2$CVD_RISK_C, glm.top.pred, ci=TRUE, main="Using Top-Ranking Variables") 
plot.roc(obs_outputs, pred_outputs.glm, ci=TRUE, col="darkblue", add=TRUE)
plot.roc(data2$CVD_RISK_C, rf.pred[, 2], ci=TRUE, col="darkgreen", add=TRUE)
plot.roc(obs_outputs, pred_outputs.rf, ci=TRUE, col="red", add=TRUE) 
legend("bottomright", legend=c("GLM Training", "GLM Cross-Validation", "RF Training", "RF Cross-Validation"), col=c("black", "darkblue", "darkgreen", "red"), lwd=1)
```
No suprisingly similar to above -- AUC values are is 0.8963, 0.6727, 0.6467, 0.6466 for the RF training set, RF with 10-fold CV,  MV LR training set, and MV LR with 10-fold CV, respectively. Using the top ranking variables, random forests are again superior to logistic regression for this data set in terms of predictionn accuracy. The models did not change for RF as all variables were significant from the start.

#### Odds ratios for logistic models


```{r, eval=TRUE}
# odds ratios for the full logistic model
exp(cbind(OR = coef(full.glm), confint(full.glm)))
# odds ratios for the logstic model with top ranking predictors
exp(cbind(OR = coef(top.glm), confint(top.glm)))
```

In the full LR model, the odds of high CVD risk (versus low/model) increased by 38% for each additional hour of TV viewing, by 1% with each additional hour of computer use, by 5% with each additioanl hour of driving, by 3% for participants meeting PA recommendations, by 4% for participants meeting vegetable and fruit intake recommendations, by 22% for participants with long vs short sleep duration. Additionally, the odds of high CVD risk were greater among those with daily drinking, as compared to the other groups. The odds of high CVD risk also decreased by a factor of 0.105 for participants who slept adequately as compared to short, decreased by a factor of 0.112 for participants whose sleep timing preference was more morning than evening vs definitely morning, decreased by a factor of 0.209 for those with sleep timing preference more evening than morning vs definitely morning, decreased by a factor of 0.208 for those with a sleep timing preference as definitely evening vs definitely morning, and decreased by a factor of 0.006 for each percentage increase in body fat.
