---
title: "BMIN503: Conceptualizing Actionability in Medicine and Clinical Genomics"
author: "Kellie Owens"
output: 
  html_document:
    toc: false 
    depth: 3 
    theme: paper 
    highlight: tango
---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 400)
```  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(pubmed.mineR)
library(knitr)
library(ggplot2)
library(bibliometrix)
library(RISmed)
library(dplyr)
library(tm)
library(wordcloud)
library(RColorBrewer)
library(tidyverse)
library(tm)
library(NLP)
library(wordcloud)
library(slam)
library(reshape2)
library(topicmodels)
```

### Overview

The primary questions driving my research are: How and when did "actionability" become the primary framework to assess when genomic data is useful for patients? How can we conceptualize a more sophisticated, ethical, and effective method for determining when genomic tests are useful in a clinical setting? As a social scientist, my first step in answering these questions is to understand the context surrounding actionability as a concept. To help understand this context, I will perform a natural language processing analysis of all scientific abstracts mentioning "actionability" and related terms that are archived in PubMed and Web of Science. This natural language processing analysis can help answer the following pieces of this research: When did "actionability" first appear in published literature, and how did its use spread over time? What types of fields and journals use the concept of actionability? What words and concepts appear most frequently alongside "actionability?" In developing this project, I spoke with Dr. Pamela Sankar, who helped me understand the political landscape surrounding genomics research in the United States. I also spoke with Dr. Reed Pyeritz, who helped me understand the science and technical aspects of genomics research. Finally, I spoke with Dr. John Holmes, who helped me understand what types of research questions natural language processing can and cannot answer. Here is a link to my final project Github repository: [Final Project Repo](https://github.com/owenske3/BMIN503_Final_Project)

### Introduction 

Clinical genomic sequencing (CGS) is becoming more common, even in primary care settings (eg, Geisinger 2018, Vassi et al. 2017). By identifying pathogenic and highly penetrant variants in healthy individuals, providers can suggest treatments or lifestyle interventions to manage health risks and prevent poor health outcomes. But CGS is also expensive and not without potential harms (Vassy et al. 2017). Clinical genomic sequencing (CGS) produces large amounts of data, much of which is hard to characterize or may have a negligible influence on health. The concept of actionability is commonly used to help separate genomic information that may be useful from information that is likely irrelevant for patients (Berg et al 2013, Amendola et al 2015, Berg et al 2011, Jarvik et al 2014, Webber et al. 2018). Definitions of actionability generally include the following factors: the level of evidence regarding pathogenicity and penetrance of a variant; the efficacy, burden, and availability of interventions; and the severity of potential disease (Berg et al. 2016). Even with widely referenced guidelines on actionability from the American College of Medical Genetics and Genomics (ACMG) (Green et al. 2013, Kalia et al. 2017), there are still ongoing debates about what actionability means (eg. Chae et al. 2017, Burke et al 2013, Goddard et al 2013, Grove et al 2014, McCormick et al. 2014, Moret et al. 2017, Ramos et al. 2014, Institute of Medicine 2014) and significant variability in how laboratories and clinicians interpret the ACMG guidelines (eg. Ackerman and Koenig 2018, O’Daniel et al. 2017, Scheuner et al. 2018, Lázaro-Muñoz et al. 2017, Bland et al. 2017). Actionability directs attention to whether genomic information warrants action and reflects its initial development as a strategy to augment diagnosis and treatment in sick patients. As CGS expands towards healthy populations in primary care settings, actionability is still widely embraced without consensus regarding its definition and use. Despite its centrality in clinical genetics/genomics, there has been little research examining what actionability means and how it is used in published literature. This project will perform a natural language processing analysis to examine how actionability emerged and proliferated in published literature archived in PubMed and Web of Science.

I am a sociologist and bioethicist who primarily works with qualitative data. I usually read documents (like published abstracts) myself and annotate them to look for themes and patterns. This project serves as a proof of concept for me to see what kinds of qualitative work I could be automating. This project is interdisciplinary because it draws upon methodological and theoretical tools from a number of fields including: clinical genomics, bioethics, sociology, science and technology studies, and biomedical informatics. Social scientists and humanities scholars have many theoretical tools to assess how a concept is taken up by a scientific or medical field and how this concept shapes clinical decision-making and practice. This theory can help guide policy related to the translation of research products into clinical settings. Most of this social science research is qualitative and based on small sample sizes. Biomedical informatics methods, such as natural language processing, can help analyze large amounts of textual data related to a given concept. This project will bridge the strengths of natural language processing with normative and conceptual theory from the social sciences and bioethics.

### Methods and Results

The data for this project are scientific articles with abstracts archived in PubMed and Web of Science that include the words "actionable" or "actionability." I conducted searches on the PubMed and Web of Science websites and saved results as text files (or, when using the RISmed package, searched PubMed abstracts directly in RStudio). I tried a variety of search terms but, in the end, decided to keep my main dataset as big as possible (with the search term "actionab*" appearing in the title or abstract of an article). I used three R packages to pull this data into RStudio: pubmed.mineR, bibiometrix, and RISmed. Below, I've shown how I loaded data for the three packages:

```{r eval=TRUE, message=FALSE, warning=FALSE}
#Find and read Pubmed Abstracts via pubmed.mineR
pubmed.actionab = readabs("/Users/knowens/Desktop/BMIN503_Final_Project/Data/PubMed.Actionab.txt")
printabs(pubmed.actionab)
```

```{r eval=TRUE, message=FALSE, warning=FALSE}
#Find and read Web of Science abstracts via bibliometrix
WebOfScience <- readFiles("/Users/knowens/Desktop/BMIN503_Final_Project/Data/file1.txt", "/Users/knowens/Desktop/BMIN503_Final_Project/Data/file2.txt", "/Users/knowens/Desktop/BMIN503_Final_Project/Data/file3.txt", "/Users/knowens/Desktop/BMIN503_Final_Project/Data/file4.txt", "/Users/knowens/Desktop/BMIN503_Final_Project/Data/file5.txt", "/Users/knowens/Desktop/BMIN503_Final_Project/Data/file6.txt", "/Users/knowens/Desktop/BMIN503_Final_Project/Data/file7.txt", "/Users/knowens/Desktop/BMIN503_Final_Project/Data/file8.txt", "/Users/knowens/Desktop/BMIN503_Final_Project/Data/file9.txt", "/Users/knowens/Desktop/BMIN503_Final_Project/Data/file10.txt")
WS <- convert2df(WebOfScience, dbsource = "isi", format = "plaintext")
WSresults <- biblioAnalysis(WS, sep = ";")
```

```{r eval=TRUE, message=FALSE, warning=FALSE}
#Find and read PubMed abstracts via RISmed
search <- EUtilsSummary("actionab*", 
                      type = "esearch", 
                      db = "pubmed",
                      datetype = "pdat",
                      retmax = 12000,
                      mindate = 1960, 
                      maxdate = 2019)
fetch <- EUtilsGet(search, type = "efetch", db = "pubmed")
RISmed_abstracts <- data.frame(title = fetch@ArticleTitle,
                        abstract = fetch@AbstractText, 
                        journal = fetch@Title,
                        DOI = fetch@PMID, 
                        year = fetch@YearPubmed)
RISmed_abstracts <- RISmed_abstracts %>% mutate(abstract = as.character(abstract))
```

I started my analysis by looking for basic context about the dataset. First, I wanted to get some examples of where "actionable" occurs in the abstracts. The "pubmed.mineR" package will generate a list of sentences where a given search term, like "actionable," occurs. Below are five examples:

```{r eval=TRUE, message=FALSE, warning=FALSE}
sentence = Give_Sentences("actionable", abs = pubmed.actionab)
sentence[1:5]
```

To simplify things further, "pubmed.mineR" can also show just the words before and after "actionable" in a given abstract. Here are ten examples:

```{r eval=TRUE, message=FALSE, warning=FALSE}
# Find words before and after "actionable"
associations = word_associations("actionable", pubmed.actionab)
associations[1:10]
```

These two steps show me that references to actionability often occur near discussions of a particular intervention, often related to pharmacogenomics. Next, I wanted to identify the top frequency words in the dataset. I first made a wordcloud to help visualize word frequency. To do this, I used the "tm" and "wordcloud" packages in R. I made a number of transformations to the text to remove words that would not be helpful to the analysis, like very common english words and the words "actionable" and "actionability" (because I already expect them to show up in every abstract).

```{r eval=TRUE, message=FALSE, warning=FALSE}
#Word Cloud
wordcloud_text <- WS$AB #convert list entries to text
wordcloud_corpus <- Corpus(VectorSource(wordcloud_text))
wordcloud_corpus <- tm_map(wordcloud_corpus,
                              content_transformer(function(x) iconv(x, to = 'UTF-8-MAC', sub =' byte'))
)

wordcloud_corpus <- tm_map(wordcloud_corpus, content_transformer(tolower))
wordcloud_corpus <- tm_map(wordcloud_corpus, removePunctuation)
wordcloud_corpus <- tm_map(wordcloud_corpus, removeNumbers)
wordcloud_corpus <- tm_map(wordcloud_corpus, removeWords, stopwords("english"))
myStopwords <- c(stopwords(), "actionable", "actionability")
wordcloud_corpus <- tm_map(wordcloud_corpus, function(x) removeWords(x, myStopwords))

wordcloud(wordcloud_corpus, min.freq = 10, max.words = 100, scale = c(4,.2), random.order = FALSE, colors = brewer.pal(8, "Dark2"))
```

While the wordcloud provides a nice visualization, I find it ultimately more useful to see the same data represented in table form.To do this, I can use "ggplot":

```{r eval=TRUE, message=FALSE, warning=FALSE}
tdm <- TermDocumentMatrix(wordcloud_corpus)
dtm <- DocumentTermMatrix(wordcloud_corpus)

word.freq = sort(rowSums(as.matrix(tdm)),decreasing = TRUE)
freq.df = data.frame(word=names(word.freq), freq=word.freq)
head(freq.df, 20)

ggplot(head(freq.df,15), aes(reorder(word,freq), freq)) +
  geom_bar(stat = "identity") + coord_flip() +
  xlab("Words") + ylab("Frequency") +
  ggtitle("Most Frequent Words")
```

The wordcloud and word frequency table show that "patient" is the most frequent word in the abstracts. This makes sense, because actionability is supposed to help us sort out when a test produces results that are useful to patients. While one-word keywords are useful, it would also be helpful to see which two-word phrases appear most often in the abstracts. To do this, I made a bi-gram word cloud. The bi-gram cloud required adding more stopwords, because phrases related to copyrights and nationality (e.g. United States) were showing up frequently.

```{r eval=TRUE, message=FALSE, warning=FALSE}
#Bi-gram Word Cloud
bigram_corpus <- VCorpus(VectorSource(wordcloud_text))
bigram_corpus <- tm_map(bigram_corpus,
                              content_transformer(function(x) iconv(x, to = 'UTF-8-MAC', sub =' byte'))
)

bigram_corpus <- tm_map(bigram_corpus, content_transformer(tolower))
bigram_corpus <- tm_map(bigram_corpus, removePunctuation)
bigram_corpus <- tm_map(bigram_corpus, removeNumbers)
bigram_corpus <- tm_map(bigram_corpus, removeWords, stopwords("english"))
myStopwords <- c(stopwords(), "actionable", "actionability", "copyright", "elsevier", "p", "inc", "reserved", "american", "united")
bigram_corpus <- tm_map(bigram_corpus, function(x) removeWords(x, myStopwords))

BigramTokenizer <- function(x) {
      unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
}

tdm.bigram <- TermDocumentMatrix(bigram_corpus, control = list(wordLengths=c(0,Inf), tokenize = BigramTokenizer))
tdm.bigram.nonsparse <- removeSparseTerms(tdm.bigram, 0.99)

freq2 = sort(rowSums(as.matrix(tdm.bigram.nonsparse)),decreasing = TRUE)
freq.df = data.frame(word=names(freq2), freq=freq2)

wordcloud(freq.df$word, freq.df$freq, scale = c(2, 0.1), max.words=30, random.order = F, colors = brewer.pal(8, "Dark2"))
```

These word frequency analyses show that many of the most frequently represented words are related to genomics and cancer, which I would have expected. Like word frequencies, it would also be helpful to know which journals are most frequently represented in the dataset. I can plot journal frequencies using "ggplot."

```{r eval=TRUE, message=FALSE, warning=FALSE}
simplified_journals <- str_trunc(WS$SO, 30, "right")
top_journals <- as.data.frame(sort(table(simplified_journals), decreasing = TRUE)[1:15])

ggplot(top_journals, aes(x = simplified_journals, y = Freq)) +
    geom_bar(stat = "identity") +
    labs(title = "Journal Frequency") +
    labs(x = "Journal", y = "Number of Articles") +
    theme(axis.text.x = element_text(angle = 90))
```

Again, the journal data shows that the most common journals publishing articles mentioning actionability are usually related to oncology or genomics. Because I am interested in how actionability emerged as a concept in the literature, it would be useful to know when actionability first appeared and how its use has spread over time. I can plot the number of abstracts mentioning actionability by year. This plot shows me that "actionability" became a common phrase over the past ten years, and that the number of articles mentioning actionability continues to grow:

```{r eval=TRUE, message=FALSE, warning=FALSE}
#Abstracts by Year
RISmed_abstracts %>%
group_by(year) %>%
count() %>%
ggplot(aes(year, n)) +
geom_point() +
geom_line() +
labs(title = "Pubmed Articles by Year", hjust = 0.5,
y = "Articles")
```

After performing these basic analyses, I would also like to identify relationships between words and themes in the abstracts. The "bibliometrix" package allows me to map keyword co-occurances from abstracts in Web of Science. The "keywords" refer to a small set of author-generated words attached to each article. The network layout is generated using the Fructerman-Reingold algorithm, which is a force-directed layout algorithm. The size of the circles represents how often that keyword is represented in the data. The proximity of the circles represents the strength of the keywords' relationship to each other. Circles that are closer together have a larger percentage of the data featuring co-occurences of those words. The color of the circle is the algorithm's attempt to place the keywords into relevant clusters.

```{r eval=TRUE, message=FALSE, warning=FALSE}
NetMatrix <- biblioNetwork(WS, analysis = "co-occurrences", network = "keywords", sep = ";")
net=networkPlot(NetMatrix, normalize="association", weighted=T, n=30, Title = "Keyword Co-occurences", type = "fruchterman", size=T,edgesize = 5,labelsize=0.7)
```

The most common keyword is "precision medicine. Other common keywords are "next-generation sequencing," "targeted therapy," and "cancer." These keywords are not surprising given the prior figures showing that most abstracts are related to genomics and cancer. The keyword map can help me understand why actionability has become such a popular concept over the past ten years. Actionability is closely linked with precision medicine, which has also become more popular over the past ten years. 

Finally, I spend a lot of time trying to sort documents into categories based on theme. Or, I try to identify which themes are most frequently represented in a text-based dataset. I can start to do this computationally using natural language processing techniques like topic modeling. Topic models "allow the probabilistic modeling of term frequency occurences in documents. The fitted model can be used to estimate the similarity between documents as well as between a set of specified keywords using  an additional layer of latent variables which are referred to as topics” (Grun and Hornik 2011).

The most common form of topic modeling, as far as I can tell, uses latent Dirichlet allocation (LDA). This method treats each document as a mixture of topics and each topic as a mixture of words. Documents can have overlapping content, rather than being separated into distinct groups. After testing a few models, I used a particular type of LDA called the correlated topics model (CTM) because I didn't want to assume that topics were uncorrelated for my particular dataset.

To perform the topic modeling analysis, I also calculated term frequency-inverse document frequency (tf-idf). Silge and Robinson explain that "the idea of tf-idf is to find the important words for the content of each document by decreasing the weight for commonly used words and increasing the weight for words not used much in a corpus of documents” (Silge and Robinson 2019). Each word gets a tf-idf value and then I excluded terms with really low values because that indicates that those words are too common to be helpful in generating topics.

After testing some options, I chose to sort the abstracts into 30 topics. For ease of reading the output, I have shown 5 topics as examples.

```{r eval=TRUE, message=FALSE, warning=FALSE}
#Topic Modeling
summary(col_sums(dtm))

#tf-idf
term_tfidf <- tapply(dtm$v/row_sums(dtm)[dtm$i], dtm$j, mean) *
  log2(nDocs(dtm)/col_sums(dtm > 0))
summary(term_tfidf)

dtm <- dtm[,term_tfidf >= 0.1]
dtm <- dtm[row_sums(dtm) > 0,]
summary(col_sums(dtm))
dim(dtm)

#Testing Models
k <- 30
SEED <- 2010
TM <-
   list(VEM = LDA(dtm, k = k, control = list(seed = SEED)),
     VEM_fixed = LDA(dtm, k = k,
       control = list(estimate.alpha = FALSE, seed = SEED)),
     Gibbs = LDA(dtm, k = k, method = "Gibbs",
       control = list(seed = SEED, burnin = 1000,
         thin = 100, iter = 1000)),
     CTM = CTM(dtm, k = k,
       control = list(seed = SEED,
         var = list(tol = 10^-4), em = list(tol = 10^-3))))

sapply(TM[1:2], slot, "alpha")

sapply(TM, function(x) +
  mean(apply(posterior(x)$topics, +
  1, function(z) - sum(z *log(z)))))

#Show sample of topics
words_per_topic <- 5
Terms <- terms(TM[["VEM"]], words_per_topic)
Terms[,c(3, 11, 18, 21, 22)]
```

This sample of topics shows that abstracts are related to a variety of themes such as prostate cancer, the microbiome, smoking, and radiology. I can also see how frequently a given topic appears in the dataset, shown using "ggplot" below. Or, I could sort through individual abstracts to see which topics are represented in that abstract (not shown).

```{r eval=TRUE, message=FALSE, warning=FALSE}
#Show Topic Frequency
Topic <- topics(TM[["VEM"]], 1)
Topic2 <- as.data.frame(sort(table(Topic), decreasing = TRUE))

ggplot(Topic2, aes(x = Topic, y = Freq)) +
    geom_bar(stat = "identity") +
    labs(title = "Topic Frequency") +
    labs(x = "Topic", y = "Frequency")
```

Some of the topics worked better than others, and if I were to use this in my published research I would need to refine my model with an actual informatician. But, topic modeleing still provides a useful starting point in a process that usually takes months to do by hand. NLP analyses are a fast and easy way to provide a crude analysis of topics and relevant keywords, but it does not replace my own reading of documents. I am still better at determining sentiment and trying to understand why there is disagreement about what counts as an actionable finding or result. But, this project showed me that NLP can be a nice first step to help me see some initial patterns in a given text-based dataset, and I will continue to use it in my research process.

### Bibliography
Ackerman SL, Koenig BA. Understanding variations in secondary findings reporting practices across U.S. genome sequencing laboratories. AJOB empirical bioethics. 2018;9(1):48-57.

Amendola LM, Dorschner MO, Robertson PD, et al. Actionable exomic incidental findings in 6503 participants: challenges of variant classification. Genome Research. 2015.

Berg JS, Khoury MJ, Evans JP. Deploying whole genome sequencing in clinical practice and public health: Meeting the challenge one bin at a time. Genetics In Medicine. 2011;13:499.

Berg JS, Amendola LM, Eng C, et al. Processes and preliminary outputs for identification of actionable genes as incidental findings in genomic sequence data in the Clinical Sequencing Exploratory Research Consortium. Genetics In Medicine. 2013;15:860.

Berg JS, Foreman AK, O'Daniel JM, et al. A semiquantitative metric for evaluating clinical actionability of incidental or secondary findings from genome-scale sequencing. Genet Med. 2016;18(5):467-75.

Bland A, Harrington EA, Dunn K, et al. Clinically impactful differences in variant interpretation between clinicians and testing laboratories: a single-center experience. Genetics In Medicine. 2017;20:369.

Burke W, Antommaria AHM, Bennett R, et al. Recommendations for returning genomic incidental findings? We need to talk! Genetics in medicine : official journal of the American College of Medical Genetics. 2013;15(11):854-859.

Chae YK, Pan AP, Davis AA, et al. Path toward Precision Oncology: Review of Targeted Therapy Studies and Tools to Aid in Defining "Actionability" of a Molecular Lesion and Patient Management Support. Molecular cancer therapeutics. 2017;16(12):2645-2655.

Geisinger. DNA sequencing to become part of Geisinger’s routine clinical care. May 7, 2018. <https://www.geisinger.org/about-geisinger/news-and-media/news-releases/2018/05/07/12/18/dna-sequencing-to-become-part-of-geisingers-routine-clinical-care>

Goddard KAB, Whitlock EP, Berg JS, et al. Description and pilot results from a novel method for evaluating return of incidental findings from next-generation sequencing technologies. Genetics in medicine : official journal of the American College of Medical Genetics. 2013;15(9):721-728.

Green RC, Berg JS, Grody WW, et al. ACMG recommendations for reporting of incidental findings in clinical exome and genome sequencing. Genetics in medicine : official journal of the American College of Medical Genetics. 2013;15(7):565-574.

Grove ME, Wolpert MN, Cho MK, Lee SS, Ormond KE. Views of genetics health professionals on the return of genomic results. Journal of genetic counseling. 2014;23(4):531-538.

Grün, B., & Hornik, K. (2011). topicmodels: An R Package for Fitting Topic Models. Journal of Statistical Software, 40(13), 1 - 30. doi:http://dx.doi.org/10.18637/jss.v040.i13

Institute of Medicine. Assessing genomic sequencing information for health care decision making:  Workshop summary.  Washington, DC:  The National Academies Press. 2014.

Jarvik GP, Amendola LM, Berg JS, et al. Return of Genomic Results to Research Participants: The Floor, the Ceiling, and the Choices In Between. The American Journal of Human Genetics. 2014;94(6):818-826.

Kalia SS, Adelman K, Bale SJ, et al. Recommendations for reporting of secondary findings in clinical exome and genome sequencing, 2016 update (ACMG SF v2.0): a policy statement of the American College of Medical Genetics and Genomics. Genetics In Medicine. 2016;19:249.

Lázaro-Muñoz G, Conley JM, Davis AM, Prince AE, Cadigan RJ. Which Results to Return: Subjective Judgments in Selecting Medically Actionable Genes. Genet Test Mol Biomarkers. 2017;21(3):184-194.

McCormick JB, Sharp RR, Farrugia G, et al. Genomic Medicine and Incidental Findings: Balancing Actionability and Patient Autonomy. Mayo Clinic Proceedings. 2014;89(6):718-721.

Moret C, Mauron A, Fokstuen S, Makrythanasis P, Hurst SA. Defining categories of actionability for secondary findings in next-generation sequencing. Journal of Medical Ethics. 2017;43(5):346-349.

O'Daniel JM, McLaughlin HM, Amendola LM, et al. A survey of current practices for genomic sequencing test interpretation and reporting processes in US laboratories. Genetics in medicine : official journal of the American College of Medical Genetics. 2017;19(5):575-582.

Ramos EM, Din-Lovinescu C, Berg JS, et al. Characterizing genetic variants for clinical action. American journal of medical genetics Part C, Seminars in medical genetics. 2014;166C(1):93-104.

Scheuner MT, Russell MM, Chanfreau-Coffinier C, et al. Stakeholders' views on the value of outcomes from clinical genetic and genomic interventions. Genetics in medicine : official journal of the American College of Medical Genetics. 2018.

Silge, Julia, and David Robinson. Text mining with R: A tidy approach. " O'Reilly Media, Inc.", 2019.

Vassy JL, Christensen KD, Schonman EF, Blout CL, Robinson JO, Krier JB, Diamond PM, Lebo M, Machini K, Azzariti DR, Dukhovny D, Bates DW, MacRae CA, Murray MF, Rehm HL, McGuire AL, and Green RC, for the MedSeq Project. Whole-genome sequencing in primary care. Annals of Internal Medicine. 2017;167(3):I-20-20.

Webber EM, Hunter JE, Biesecker LG, et al. Evidence-based assessments of clinical actionability in the context of secondary findings: Updates from ClinGen's Actionability Working Group. Human mutation. 2018;39(11):1677-1685.


  
  