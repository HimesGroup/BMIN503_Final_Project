---
title: "BMIN503/EPID600 Project Template"
author: "Danielle Kellier"
bibliography: references.bib
output: 
  bookdown::html_:
    toc: false 
    depth: 3 
    theme: paper 
    highlight: tango
    keep_md: true
---

```{r install-packages, eval=FALSE}

install.packages("renv")
renv::restore()

```


```{r set-options, message=FALSE, cache=FALSE}
options(width = 400)
library(tidyverse)
library(gtsummary)
# library(simstudy)
library(randomForest)
library(inTrees)
library(glue)
library(icd)
# library(fabricatr)
library(mgcv)
library(ranger)
library(magrittr)
library(tidytext)
# library(ggforce)

# Settings
refresh = F #When true, reads in raw CSV files and processes. When false, loads in already-processed feather files
nobs <- 6000 #num of observations included in dataset
missing_threshold <- 0.05 # level of missingness acceptable for an individual variable
test_to_train <- c(0.8, 0.2) #ratio of data used from training dataset compared to testing data set
num_randomforest_trees <- 500 # number of randomForest trees

source("load_data.R") #Loads in records from outpatient visits from a folder not included in git repository

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

Ranger2List <- function(rf_ranger)
{
  formatRanger <- function(tree){
    rownames(tree) <- 1:nrow(tree)
    tree$`status` <- ifelse(tree$`terminal`==TRUE,-1,1)
    tree$`left daughter` <- tree$`leftChild` + 1
    tree$`right daughter` <- tree$`rightChild` + 1
    tree$`split var` <- tree$`splitvarID`
    tree$`split point` <- tree$`splitval`
    tree$`prediction` <- tree$`prediction`
    tree <- tree[,c("left daughter","right daughter","split var","split point","status")]
    tree <- data.matrix(as.data.frame(tree))
    return(tree)
  }
  treeList <- NULL
  treeList$ntree <- rf_ranger$num.trees
  treeList$list <- vector("list",rf_ranger$num.trees)
  for(i in 1:rf_ranger$num.trees){
    treeList$list[[i]] <- formatRanger( treeInfo(rf_ranger, tree = i) )
  }
  return(treeList)
}

```  
***
Use this template to complete your project throughout the course. Your Final Project presentation will be based on the contents of this document. Replace the title/name above and text below with your own, but keep the headers.

1. Recall that you forked the [Final Project Repo](https://github.com/HimesGroup/BMIN503_Final_Project) and have downloaded it as a project to your local computer. Write the overview and introduction for your final project. The overview consists of 2-3 sentences summarizing the project and goals. For the introduction, the first paragraph describes the problem addressed, its significance, and some background to motivate the problem. In the second paragraph, explain why your problem is interdisciplinary, what fields can contribute to its understanding, and incorporate background related to what you learned from meeting with faculty/staff. Start working on the Methods/Results section, which consists of code and its output along with text describing what you are doing (Note: we will not check your code now, but you should have something in place before Assignment 6 is distributed).


### Overview
`Give a brief a description of your project and its goal(s), what data you are using to complete it, and what three faculty/staff in different fields you have spoken to about your project with a brief summary of what you learned from each person. Include a link to your final project GitHub repository.`

For children visiting the emergency department with a chief complaint of headache of migraine, are there features of their initial clinical presentation that can predict the presence of an intracranial abnormality? As a proof of concept, this study involves a retrospective cohort of children who visited the CHOP neurology outpatient clinic between 2012 and 2020 with the complaint of headache or migraine to predict risk of positive findings seen on imaging.

### Introduction 
`Describe the problem addressed, its significance, and some background to motivate the problem.`
`Explain why your problem is interdisciplinary, what fields can contribute to its understanding, and incorporate background related to what you learned from meeting with faculty/staff.`

Headache is a major cause of disability in children and a common chief complaint in the pediatric emergency room. Given the range of etiologies from primary to life-threatening, many children end up receiving imaging for ultimately benign which leads to excessive cost for both the patient and the healthcare system[@Cain2018; @Irwin2018; @Kan2000; @Young2018]. In addition, exposure to radiation from computed tomography scanning in children can greatly increase the risk of later malignancy[@Brenner2001; @Feng2010]. Using a nested case-control design within a larger cohort of ED visits for headache/migraine, we hope to establish whether there are particular features of a child's initial clinical presentation that can inform an emergency physicianâ€™s decision to order imaging for a child with headache.

Headache is consistently ranked as one of the top 10 chief complaints for an emergency room visit within the United States according to the National Hospital Ambulatory Medical Care Survey[@UnitedStatesDepartmentofHealthHumanServices-NationalCenterforHealthStatistics2019]. In fact, for over 1.7 million (5% overall) pediatric emergency visits in 2017, headache was listed as a reason for the visit[@UnitedStatesDepartmentofHealthHumanServices-NationalCenterforHealthStatistics2019]. Headache can be an alarming but highly nonspecific symptom in that it can be triggered by a disabling but ultimately benign primary disorder, a secondary but nonconcerning case of influenza, or act as the harbinger for a brain tumor or subarachnoid hemorrhage. Although a neurologist or headache subspecialist may focus on pinpointing a headache's etiology to direct treatment, an emergency room physician's goal is to look for "red flags" or signs of a serious etiology requiring urgent intervention. Still, a symptom's status as a "red flag" can be questionable: changes in vision or sensation can be associated with a stroke or simply be the aura of an incoming migraine. As a result, roughly 18-41% of children with headache end up receiving some form of neuroimaging of which only 4-10% had new abnormal findings seen on imaging[@Cain2018; @Kan2000; @Sheridan2013]. The high rate of children undergoing unnecessary imaging, especially the additional exposure risks of computed tomography, demonstrate a gap in the knowledge base that is made available to physicians within the emergency room who must deal with a high volume of patients diverse in their clinical presentations and acuity. 

Due to bottlenecks in the data acquisition process, electronic medical record data from emergency room visits has yet to be acquired. As a result, this paper will use already available medical record data from children visiting the outpatient neurology clinic with the complaint of headache or migraine as a proof of concept. This study aims to use machine learning to 1) select features of the clinical presentation that influence the risk of an abnormal finding on imaging and 2)  simplify the predictive model generated into an algorithm that can be disseminated and shared amongst emergency room physicians.

### Methods
Describe the data used and general methodological approach. Subsequently, incorporate full R code necessary to retrieve and clean data, and perform analysis. Be sure to include a description of code so that others (including your future self) can understand what you are doing and why. 


```{r simulate-data}
# 
# set.seed(12345)
# 
# image_types <- c("Imaged", "Not imaged")
# image_freq <- c(0.2, 0.8)
# outcome_types <- c("Abnormality", "No abnormality")
# outcome_freq <- c(0.05, 0.95)
# 
# nsymptoms <- 10
# symptom_corr <- genCorMat(nsymptoms)
# nobs <- 6000
# 
# dt <- fabricate(N = nobs,
#                 age = runif(N, min = 3, max = 17),
#                 sex = correlate(given = age, rho = 0.2, draw_binary, prob = 0.55),
#                 outcome_true = correlate(given = age, rho = -0.6, draw_binary, prob = outcome_freq[[1]]),
#                 image = correlate(given = outcome_true, rho = 0.8, draw_binary, prob = image_freq[[1]]),
#                 symptoms_mu = pmin(pmax(rnorm(N, mean = 0.05 + 0.2*image + 0.7*outcome_true - 0.05*age, 
#                                               sd = 0.05 + 0.05*image + 0.05*outcome_true),0),1))
# 
# rmat <- matrix(rnorm(nsymptoms^2),nsymptoms,nsymptoms)
# cov_mat <- rmat%*%t(rmat)
# corr_mat <- cov_mat/sqrt(diag(cov_mat)%*%t(diag(cov_mat)))
# 
# dt_symptoms <- cbind(genData(nobs, id = "ID"), "symptoms_mu" = dt$symptoms_mu) %>%
#   addCorGen(., nvars = nsymptoms, idvar = "ID", param1 = "symptoms_mu", dist = "binary", 
#             corMatrix = corr_mat, cnames = paste("symptom", 1:nsymptoms, sep = "_")) %>% 
#   dplyr::select(-ID, -symptoms_mu)
# 
# dt <- bind_cols(dt, dt_symptoms) %>% 
#   dplyr::select(-symptoms_mu) %>%
#   dplyr::mutate(outcome_measured = ifelse(image == 0, NA, outcome_true),
#                 sex = factor(sex, levels = 0:1, labels = c("Male", "Female")),
#                 image = factor(image, levels = 0:1, labels = rev(image_types)),
#                 across(starts_with("outcome"), ~factor(.x, levels = 0:1, labels = rev(outcome_types))))
# 
# dt_assignments <- sample(1:2, size = nobs, replace = T, prob = c(0.8, 0.2))

```


```{r eval = FALSE, echo = FALSE}

# imaging_data %>%
#   unnest_tokens(word, img_impression) %>%
#   count(word, sort = TRUE) %>% 
#   filter(between(row_number(),200,300)) %>%
#   pull(word) %>%
#   paste0('"', ., '"', collapse = ', ')

med_stop_words <- c(
  "the", "of", "and", "with", "i", "images", "have", "reviewed", "agree", 
  "brain", "personally", "mri", "interpretation", "in", "to", "end", "is", 
  "noncontrast", "impression", "as", "contrast", "a", "or", "on", "for", 
  "be", "are", "this", "at", "appears", "further", "has", "possibly",
  "without", "detailed", "there", "clinical", "above", "false", "evidence", 
  "seen", "may", "which", "patient", "report", "noted", "examination", "by", 
  "study", "related", "act", "apos", "identified", "s", "likely", "described", 
  "from", "magnetic", "resonance", "codes", "professional", "notification", 
  "dr", "appearance", "mr", "associated", "clinically", "recommended", "an", 
  "interpretation.act", "up", "correlation", "please", "represent", "requires",
  "new", "follow", "imaging", "but", "correlate", "evaluation", "along", 
  "performed", "can", "could", "was", "change", "if", "however", "discussed", 
  "most", "time", "visualized", "compared", "were", "limits", "that", "into", 
  "these", "involving", "appear", "exam", "than", "also", "definite", "pm", 
  "source", "due", "post", "limitations", "major", "although", "tesla"
)

icd10cm <- get_icd10cm_latest()

num_grams <- 3
impression_flags <- readxl::read_excel("../../Secondary Headache (SNOOPY Review)/Danielle work/imaging_impressions.xlsx") %>%
  mutate(flag = case_when(
    `...7` == "FALSE" ~ "Other",
    `...7` == "TRUE" ~ "Unremarkable",
    is.na(`...7`) ~ "Other",
    TRUE ~ as.character(`...7`))) %>%
  unnest_tokens(ngram, img_impression, token = "ngrams", n = num_grams) %>%
  separate(ngram, paste0("word", 1:num_grams), sep = " ", remove = FALSE) %>%
  mutate(across(starts_with("word"), 
                ~ as.numeric(.x %in% med_stop_words | str_detect(.x, "\\d+")))) %>%
  rowwise() %>%
  filter(!is.na(ngram) & sum(c_across(starts_with("word"))) <= 1) %>%
  group_by(flag) %>%
  filter(n_distinct(record_id) >= 3) %>%
  mutate(
    flag_label = str_wrap(
      glue::glue("{flag} (n={n_distinct(record_id)})"), width = 30)
    ) %>%
  count(flag, flag_label, ngram) %>%
  bind_tf_idf(ngram, flag, n) %>% 
  slice_max(order_by = tf_idf, n = 10, with_ties = FALSE) %>% 
  ungroup() %>%
  mutate(ngram = fct_reorder(ngram, tf_idf)) %>%
  ggplot(aes(ngram, tf_idf, fill = flag_label)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ flag_label, scales = "free", ncol = 2) +
  scale_y_continuous(limits = c(0,NA)) +
  coord_flip() +
  theme_bw()

ggsave("Y:\\Downloads\\three-grams.png", width = 10, height = 10)

icd_flags <- readxl::read_xlsx("Additional ICD Codes.xlsx", sheet = "WIP4") %>%
  select(flag = Flag, icd10 = `ICD-10 codes`, code_meaning = `code meaning`) %>%
  filter(!is.na(icd10)) %>%
  separate_rows(icd10, sep = "(\\s)?,(\\s)?") %>%
  mutate(icd10 = str_remove_all(icd10, "\\.")) %>%
  separate(icd10, c("icd10_1", "icd10_2"), sep = "-", fill = "right", remove = FALSE) %>%
  mutate(across(c(icd10_1, icd10_2), ~match(.x, icd10cm$code))) %>%
  rowwise() %>%
  mutate(icdx = ifelse(
    !is.na(icd10_2), list(icd10cm$code[icd10_1:icd10_2]), list(icd10cm$code[icd10_1])
  )) %>%
  unnest(icdx) %>%
  filter(!is.na(icdx))




dx_visit <- visitDx_data %>%
  filter(redcap_repeat_instrument == "visit_diagnoses") %>%
  mutate(icdx = str_remove_all(icd10, "\\.")) %>%
  left_join(icd_flags %>%
              select(icdx, flag) %>% 
              mutate(icdx = as.character(icdx)), by = "icdx" ) %>%
  select(record_id, icd10, dx_name, icdx, flag)

pmh_data %>%
  filter(redcap_repeat_instrument == "all_problems") %>%
  mutate(icdx = str_remove_all(pl_icd10, "\\.")) %>%
  left_join(icd_flags %>%
              select(icdx, flag) %>% 
              mutate(icdx = as.character(icdx)), by = "icdx" ) %>%
  select(record_id, pl_icd10, pl_dx_nm, icdx, flag) %>% 
  filter(!is.na(flag))


num_grams <- 4 
dx_imaging <- imaging_data %>% 
  filter(redcap_repeat_instrument == "imaging") %>%
  group_by(record_id) %>%
  filter(img_ord_dt == first(img_ord_dt)) %>%
  left_join(dx_visit, by = "record_id") %>%
  unnest_tokens(ngram, img_impression, token = "ngrams", n = num_grams) %>%
  separate(ngram, paste0("word", 1:num_grams), sep = " ", remove = FALSE) %>%
  mutate(across(starts_with("word"), 
                ~ as.numeric(.x %in% med_stop_words | str_detect(.x, "\\d+")))) %>%
  rowwise() %>%
  filter(!is.na(ngram) & sum(c_across(starts_with("word"))) <= 2)

tf_idf_plot_raw <- dx_imaging %>% 
  mutate(flag = ifelse(is.na(flag), "Other", flag)) %>%
  count(flag, ngram) %>%
  bind_tf_idf(ngram, flag, n) %>% 
  group_by(flag) %>%
  filter(n_distinct(record_id) >= 5) %>%
  mutate(
    flag_label = str_wrap(
      glue::glue("{flag} (n={n_distinct(record_id)})"), width = 30)
    ) %>%
  slice_max(order_by = tf_idf, n = 20, with_ties = FALSE) %>% 
  ungroup() %>%
  mutate(ngram = fct_reorder(ngram, tf_idf)) %>%
  ggplot(aes(ngram, tf_idf, fill = flag_label)) +
  geom_col(show.legend = FALSE) +
  scale_y_continuous(limits = c(0,NA)) +
  coord_flip() +
  theme_bw()
  
gg <- tf_idf_plot_raw +
 facet_wrap_paginate(~ flag_label, scales = "free", ncol = 2, nrow = 1, page = 1) 

n <- n_pages(gg)

pdf('Y://Downloads\\tf-idfs_by_flag.pdf', paper= 'A4r', w= 297/25.4, 210/25.4)
for(i in 1:n){
    print(gg + facet_wrap_paginate(~ flag_label, scales = "free", ncol = 2, nrow = 1, page = i))
}
dev.off()

  
  # mutate(headache = is.numeric(str_detect(icd10, paste(c("G43", "G44", "R51", "M54.2"), collapse = '|'))),
  #        psych = is.numeric(str_detect(icd10, paste(c("F41", "F32.9", "F90"), collapse = '|'))),
  #        dizzy = is.numeric(str_detect(icd10, paste(c("R42"), collapse = '|'))),
  #        autism = is.numeric(str_detect(icd10, paste(c("F84.0"), collapse = '|'))),
  #        autonomic = is.numeric(str_detect(icd10, paste(c("G90.9", "R00.0", "I95.1"), collapse = '|'))),
  #        seizure = is.numeric(str_detect(icd10, paste(c("R56.9"), collapse = '|'))),
  #        chiari = is.numeric(str_detect(icd10, paste(c("G93.5"), collapse = '|'))),
  #        concussion = is.numeric(str_detect(icd10, paste(c("F07.81", "S06.0X0S"), collapse = '|'))),
  #        coma = is.numeric(str_detect(icd10, paste(c("R40.4"), collapse = '|')))) 



dx_imaging %>%
  filter(across(headache:seizure, ~ .x == 0)) %>%
  group_by(icd10) %>%
  summarise(dx_name = Mode(dx_name),
            n_patients = n_distinct(record_id)) %>% 
  arrange(desc(n_patients)) %>%
  View()  

dx_imaging %>% group_by(icd10) %>% 
  summarise(dx_name = Mode(dx_name),
            n_patients = n_distinct(record_id)) %>% 
  arrange(desc(n_patients)) %>%
  View()

```

```{r}
# Pull in data from outpatient redcap database

# Select names of columns that end in ".factor"
demo_factor_names <- str_subset(names(demo_data),".factor") %>% 
  str_remove(., ".factor") 

# Select names of factors with only two levels
 #Can keep binary integer columns instead
ha_factor_names_binary <- ha_data %>% 
  select(matches("^p_.*\\.factor$")) %>%
  select_if(~ nlevels(.) == 2) %>%
  names(.)

# Select names of factors with more than two factors.
# Remove integer column counterparts
ha_factor_names_nonbinary <- ha_data %>% 
  select(matches("^p_.*\\.factor$")) %>%
  select_if(~ nlevels(.) != 2) %>%
  names(.) %>%
  str_remove(., ".factor")

# Select names of columns that end in ".factor"
image_factor_names <- str_subset(names(imaging_data),".factor") %>% 
  str_remove(., ".factor")

```


```{r}

# Select subset of demographic data based on number of observations
# Select patients that completed headache questionnaire
# Clean up columns and remove duplicates (keep factor counterparts)
dt_demo <- demo_data %>%
  filter(between(age, 2,18) & pt_ha_quest_yn  == 1) %>%
  select(-all_of(demo_factor_names)) %>%
  rename_with(~str_remove(.x, ".factor")) %>%
  mutate(gender = fct_recode(gender, Other = "Unknown"))

# Select subset of headache questionnaire data based on number of observations
# Clean up columns and remove duplicates (keep factor counterparts nonbinary, keep integer counterparts if binary)
dt_ha_data <- ha_data %>%
  filter(record_id %in% unique(dt_demo$record_id) ) %>%
  filter(patient_ha_complete == 2) %>%
  select(-all_of(c("redcap_repeat_instrument", "redcap_repeat_instance"))) %>%
  select(-starts_with("c_")) %>%
  select(-all_of(ha_factor_names_binary)) %>%
  select(-all_of(ha_factor_names_nonbinary)) %>%
  select(record_id, p_age_first_ha:p_assoc_sx_pul_ear___oth, p_prob_preg_birth:p_fam_hist_med___oth, p_ha_in_lifetime.factor:p_preg_full_term.factor) %>%
  select_if(~is.factor(.) | is.numeric(.)) %>%
  rename_with(~str_remove(.x, ".factor"))


```


```{r}

# Merge demographic + HA data
# sample by number of observations
dt_demo_ha <- dt_demo %>%
  select(record_id, age, gender, ethnicity, race) %>%
  inner_join(dt_ha_data, by = "record_id") %>%
  slice_sample(n = nobs) 


# Select subset of imaging data based on number of observations
# Select any imaging done on the first day (trying to exclude prior findings)
# Rough regex searches for key words to flag if impression mentioned a finding
dt_imaging_all <- imaging_data %>%
  filter(record_id %in% unique(dt_demo_ha$record_id)) %>%
  filter(redcap_repeat_instrument == "imaging") %>%
  group_by(record_id) %>%
  filter(img_ord_dt >= visit_dt) %>%
  filter(img_ord_dt == first(img_ord_dt)) %>% 
  mutate(
    impression_lower = str_squish(str_to_lower(img_impression)),
    finding = case_when(
      str_detect(impression_lower, 'discuss') ~ 1,
      str_detect(impression_lower, 'advise') ~ 1,
      str_detect(impression_lower, 'communicate') ~ 1,
      str_detect(impression_lower,
                 regex('112(?!.*false)' )) ~ 1,
      str_detect(impression_lower, 'finding[\\w\\s]{0,3}(?:was|were)[\\s]{0,3}(?:discuss|communica|review|relay|acknowled)') ~ 1,
      str_detect(impression_lower, '\\bemergen') ~ 1,
      str_detect(impression_lower,
                 regex('immediate(?!.*(?:postsurg|post surg|adjacent|subjacent|postoper|prior))' )) ~ 1,
      str_detect(impression_lower, 'phone') ~ 1,
      str_detect(impression_lower, 'email') ~ 1,
      TRUE ~ NA_real_),
    finding = case_when(
      finding == 1 ~ 1,
      is.na(finding) & str_detect(impression_lower,
                                  regex("(?:otherwise|essential).*[\\s,]{0,3}(?:unremarkable|normal)")) ~ 0,
      is.na(finding) & str_detect(impression_lower, "^[\\s\\d\\.]{0,4}(?:unremarkable|normal|stable)") ~ 0,
      is.na(finding) & str_detect(impression_lower, "^[\\s\\d\\.]{0,4}(?:brain mr| brain ct|brain|impression)[^a-z]{0,4}(?:unremarkable|normal)") ~ 0,
      is.na(finding) & str_detect(impression_lower, '\\b(?:no|none)[\\w\\s]{0,30}(?:finding|abnormality|mass|hydrocephalus|infarct|hemo|struct)') ~ 0,
      TRUE ~ NA_real_
    )) 

dt_imaging <- dt_imaging_all %>%
  summarise(
    finding = case_when(
      any(finding == 1) ~ 1,
      all(finding == 0) ~ 0,
      all(is.na(finding)) ~ NA_real_
    ),
    img_ord_dt = first(img_ord_dt),
    img_impression = first(img_impression),
    .groups = 'drop')


```




```{r}

# Merge in imaging data
# Mark if patient was imaged based on date of imaging 
# (not all kids imaged had conclusive findings)
dt_all <- dt_demo_ha %>%
  left_join(dt_imaging, by = "record_id") %>%
  mutate(imaging = ifelse(!is.na(img_ord_dt), 1, 0))

# Select names of columns with missingness above a threshold
# Exclude columns from imaging dataset as not all kids were imaged
dt_missing_cols_all <- dt_all %>%
  select(-any_of(names(dt_imaging))) %>%
  summarise(across(everything(), ~sum(is.na(.x))/length(.x))) %>%
  pivot_longer(everything(), names_to = "column", values_to = "prop") %>%
  filter(prop >= missing_threshold)

dt_missing_cols_imaged <- dt_all %>%
  filter(imaging == 1) %>%
  select(-any_of(names(dt_imaging))) %>%
  summarise(across(everything(), ~sum(is.na(.x))/length(.x))) %>%
  pivot_longer(everything(), names_to = "column", values_to = "prop") %>%
  filter(prop >= missing_threshold)

# Exclude variables with missingness above a certain variable
dt <- dt_all %>%
  select(-any_of(dt_missing_cols_imaged$column))

dt_exclude <- demo_data %>% 
  filter(between(age, 2,18)) %>% 
  select(record_id, age) %>% 
  anti_join(dt)

```

# Methods

## Participants
We conducted a retrospective cohort study consisting of children ages 2-18 seen in the outpatient pediatric neurology clinic between July 2016 and November 2020 with the primary complaint of headache or migraine. This study took place within a tertiary pediatric hospital system which often receives referrals from nearby healthcare systems for specialized care. This can inflate the number of cases with rare and/or serious etiologies compared to another pediatric outpatient setting. Children with a condition predisposing to an intracranial abnormality but no prior documented findings were included in the study. 

## Red Flag Findings
We extracted symptom information from a health questionnaire completed by the patient for the visit of interest. Based on past work, we were particularly interested in self-report of fever and other constitutional symptoms, acute neurological deficits, age, descriptions of sudden onset or "thunderclap" headache, awakening from sleep, occipital location, and responsiveness to positional changes or the Valsalva maneuver [@Do2019]. We also included other variables often associated with headache assessment including age, family history of headache, blurry vision, nausea and vomiting, photophobia and phonophobia, headache frequency at baseline, and current headache duration. 

Given the nature of secondary data collection, we expected to encounter records with missing variables. We excluded records that lacked documentation of a neurological exam, headache characterization, or overall lacked data for >= XX% variables of interest. For analysis of a single variable, we excluded records with missing data if the variable's missingness in the dataset did not exceed 10% across age and sex strata. In cases where a variable's missingness rested between 10% and 20%, we used data imputation with the median for a continuous value by age and sex strata. Missingness that exceeded 20% was evaluated on a case-by-case basis to assess the value of and ramifications of analysis with investigation of nonrandom patterns.

<!-- Given the nature of secondary data collection, we expected to encounter records with missing variables. We excluded any records that lacked a visit diagnosis commonly associated with headache such as minor trauma to extremities. Given the broad relationship between infection and headache, we included cases related to head and neck local infections such as sinusitis and dental infections, along with cases of systemic infection such as influenza and recorded sepsis. Further, we excluded records that lacked documentation of a neurological exam, headache characterization, or overall lacked data for >= XX% variables of interest. For analysis of a single variable, we excluded records with missing data if the variable's missingness in the dataset did not exceed 10% across age and sex strata. In cases where a variable's missingness rested between 10% and 20%, we used data imputation with the median for a continuous value by age and sex strata. Missingness that exceeded 20% was evaluated on a case-by-case basis to assess the value of and ramifications of analysis with investigation of nonrandom patterns. -->

Data analysis was done using `r R.version.string` [@RCoreTeam2020]. The dataset was divided into 3 parts for descriptive analyses and logistic regression modeling, creation of a predictive model for case classification, and testing of predictive model performance. The exploratory analyses on the first third of the dataset were completed using binomial logistic regression modeling provided by base R and visualization done using the *gtsummary* package and *tidyverse* package collection [@DanielDSjoberg2020; @Wickham2019]. For descriptive purposes, data was represented using the median and interquartile ranges for continuous variables and counts and proportions for categorical data. In order to create a model capable of predicting case severity by clinical presentation, the random forests method was used to design a set of decision trees based on randomly generated subsets of cases and predictors from the middle third of the dataset using the *randomForest* R package based on Leo Breiman's machine learning method [@AndyLiaw2002; @Breiman2001]. The ensemble predictive model was then simplified into a single decision tree using the *inTrees* package and tested against the final third of the dataset [@Deng2014].


### Results
Describe your results and include relevant tables, plots, and code/comments used to obtain them. End with a brief conclusion of your findings related to the question you set out to address. You can include references if you'd like, but this is not required.

```{r table-1}

#Table 1 to describe patient characteristics
dt %>%
  mutate(
    finding = factor(case_when(
      finding == 0 ~ "Unremarkable",
      finding == 1 ~ "Urgent Findings",
      is.na(finding) & imaging == 1 ~ "Non-Urgent Findings",
      is.na(finding) & imaging == 0 ~ "Not imaged"
    ))) %>%
  mutate(across(where(is.factor), fct_drop)) %>%
  select(age, gender, race, ethnicity, finding) %>%
  rename_with(stringr::str_to_title) %>%
  tbl_summary(by = Finding)


```

We found a total of `r demo_data %>% filter(between(age, 2,18)) %>% nrow(.)` records from children ages 2 to 18 years who visited the outpatient neurology clinic with a complaint of headache or migraine and. After excluding `r nrow(dt_exclude)` children who did not completed the headache questionnaire `r glue("(median age = {quant[3]} yo, IQR: {quant[2]}-{quant[4]})", quant = quantile(dt_exclude$age))`, we had a remaining `r nrow(dt)`children `r glue("(median age = {quant[3]} yo, IQR: {quant[2]}-{quant[4]})", quant = quantile(dt$age))` of which `r glue("{imaged$n} children ({imaged$prop}%)", imaged = dt %>% count(imaging) %>% mutate(prop = round(100*n/sum(n))) %>% filter(imaging == 0))` had undergone imaging (\@ref(table-1)). For the sake of simplification, we selected `r dt %>% filter(finding == 0) %>% nrow(.)` cases in which the radiology note describes unremarkable imaging compared to `r dt %>% filter(finding == 1) %>% nrow(.)` cases in which the radiologists described reaching out to the ordering physician to relay findings in an urgent manner. A remaining `r dt %>% filter(imaging == 1 & is.na(finding)) %>% nrow(.)` cases lacked a description of the radiologist reaching out to the ordering physician and often had findings that did not warrant urgent intervention such as anatomic variants. Given the nature of imaging done on an outpatient basis, few cases warranted urgent delivery of findings and we expect to have a greater proportion of urgent cases in the impending emergency medicine dataset from which the predictive model will have more data to examine for trends.


```{r propensity,echo=FALSE}

# # Calculates propensity scores for imaging selection based on demographics and symptoms
# prop_formula <- str_c("imaging ~ s(age) + ", paste0(names(select(dt, -record_id, -age, -finding:-imaging)), collapse = " + "))
# 
# propensity_mod <- gam(as.formula(prop_formula), 
#                       family = binomial(), data = dt)
# # Create curated dataset for machine learning
# # Select kids with imaging and conclusive findings
# # Select kids with no NAs
# # Predict propensity score and inverse weight
# dt_propensity <- dt %>%
#   filter(imaging == 1 & !is.na(finding)) %>%
#   modelr::add_predictions(propensity_mod, 
#                           var = "propensity_score", type = "response") %>%
#   filter(complete.cases(.)) %>%
#   mutate(propensity_weight = (1 /(propensity_score)),
#          finding = factor(finding))


```


```{r echo = FALSE}

# set.seed(12345)
# 
# # Create random assignments for test and training datasets
# dt_assignments <- sample(1:2, size = nrow(dt_propensity), 
#                          replace = T, prob = test_to_train)
# 
# dt_train <- filter(dt_propensity, dt_assignments == 1) 
# 
# dt_test <- filter(dt_propensity, dt_assignments == 2) 
# 
# #Select variables not to include in machine learning 
# trim_vars <- dt_propensity %>%
#   select(record_id, finding:imaging, starts_with("propensity")) %>%
#   names(.) 
# 
# #Convert predictor variables into a matrix
# dt_predictors <- select(dt_train, -all_of(trim_vars)) %>% data.matrix()


```

```{r}

set.seed(12345)

#Select variables not to include in machine learning 
trim_vars <- dt %>%
  select(record_id, img_ord_dt:imaging, starts_with("propensity")) %>%
  names(.) 

#Select predictor variables and impute
dt_findings <- dt %>% 
  filter(imaging == 1 & !is.na(finding)) %>%
  mutate(finding = factor(finding)) %>%
  select(-all_of(trim_vars))

dt_findings_impute <- rfImpute(finding ~ ., data = dt_findings)

# Create random assignments for test and training datasets
dt_assignments <- sample(1:2, size = nrow(dt_findings_impute), 
                         replace = T, prob = test_to_train)

dt_train <- filter(dt_findings_impute, dt_assignments == 1)

dt_test <- filter(dt_findings_impute, dt_assignments == 2)


#Select predictor variables and impute
dt_predictors <- dt_train %>% select(-finding)


```


```{r randomForest-cutoffs}

pred_normal_cutoff_seq <- c(seq(0.5,0.95, 0.05), seq(0.96,0.99, 0.01))

cutoff_performance <- pred_normal_cutoff_seq %>%
  map_df(function(curr_cutoff){
    
    outcome_cols <- c(TP = 0, FN = 0, FP = 0, TN = 0)

    curr_rf <- randomForest(
      x = dt_predictors, y = dt_train$finding, ntree = num_randomforest_trees,
      importance = TRUE, cutoff = c(curr_cutoff, 1-curr_cutoff), nodesize = 3
    )
    
    curr_pred <-  predict(curr_rf, dt_test, type = "response")
    
    curr_perform <- tibble(cutoff = curr_cutoff,
                           model = list(curr_rf),
                           true = dt_test$finding, 
                           pred = curr_pred) %>%
      count(cutoff, model, true, pred) %>%
  mutate(outcome = case_when(
    true == 1 & pred == 1 ~ "TP",
    true == 1 & pred == 0 ~ "FN",
    true == 0 & pred == 0 ~ "TN",
    true == 0 & pred == 1 ~ "FP"
  )) %>% 
  pivot_wider(id_cols = c(cutoff, model), names_from = outcome, 
              values_from = n, values_fill = 0) %>%
  add_column(!!!outcome_cols[!names(outcome_cols) %in% names(.)]) %>%
  mutate(Sensitivity = TP/(TP+FN),
         Specificity = TN/(TN+FP)) 
    
    curr_perform
  })


cutoff_performance %>%
  select(cutoff, Sensitivity, Specificity) %>%
  pivot_longer(-cutoff, names_to = "measure", values_to = "score") %>%
  ggplot(aes(x = cutoff, y = score, group = measure, color = measure)) +
  geom_line() +
  scale_y_continuous(name = "Proportion", limits = c(0,1), breaks = seq(0,1,0.25)) +
  scale_x_continuous(name = "Cutoff for predicting 'no finding'", limits = c(0.5, 1), breaks = seq(0.5, 1, 0.1)) +
  ggtitle("Random Forest Performance\nwith varying cutoffs") +
  cowplot::theme_half_open() +
  theme(legend.title = element_blank())

```



```{r randomForest-creation}

set.seed(12345)

rf_normal_cutoff <- 0.98
  
dt_randomForest <- filter(cutoff_performance, cutoff == rf_normal_cutoff)$model[[1]]

# dt_randomForest <- randomForest(
#   x = dt_predictors, y = dt_train$finding, ntree = num_randomforest_trees,
#   importance = TRUE, cutoff = c(rf_normal_cutoff, 1-rf_normal_cutoff), nodesize = 3
#   )

ha_var_labels <- as_tibble(sjlabelled::get_label(ha_data), rownames = "var_name") %>%
  rename(var_mean = value)

as_tibble(dt_randomForest$importance, rownames = "var_name") %>%
  arrange(desc(MeanDecreaseAccuracy)) %>%
  select(var_name, starts_with("Mean")) %>%
  filter(row_number() <= 20) %>%
  left_join(ha_var_labels, by = "var_name") %>%
  select(`Variable Name` = var_mean, starts_with("Mean")) %>%
  data.table::as.data.table()
  

```


```{r randomForest-prediction}
dt_randomForest_pred <- dt_test %>%
  predict(dt_randomForest, ., type = "response")

table(Outcome = dt_test$finding, Predicted = dt_randomForest_pred)

treeList_randomForest <- RF2List(dt_randomForest)
ruleExec_randomForest <- extractRules(treeList_randomForest, X = dt_predictors, digits = 2)

ruleMetric <- getRuleMetric(ruleExec_randomForest, X = dt_predictors, target = dt_train$finding) %>%
  pruneRule(., X = dt_predictors, target = dt_train$finding, maxDecay = 0.2)

learner_randomForest <- buildLearner(ruleMetric, X = dt_predictors, target = dt_train$finding, minFreq = 0.05)

prettyLearner_randomForest <- presentRules(learner_randomForest, colnames(dt_predictors))

bind_cols(true = dt_test$finding, 
          pred = applyLearner(learner_randomForest, 
                              X = select(dt_test, -any_of(trim_vars)))) %>%
  group_by(true, pred) %>%
  summarise(n = n())

```


```{r ranger, eval = FALSE, echo = FALSE}

set.seed(12345)

dt_ranger_noweight <- ranger(x = dt_predictors, y = dt_train$finding, 
                          num.trees = num_randomforest_trees, importance = "impurity",
                          class.weights =  c(rf_normal_cutoff, 1-rf_normal_cutoff), min.node.size = 3,
                          seed = 12345, classification = TRUE)

dt_ranger_invweight <- ranger(x = dt_predictors, y = dt_train$finding, 
                          num.trees = num_randomforest_trees, importance = "impurity",
                          class.weights =  c(rf_normal_cutoff, 1-rf_normal_cutoff), min.node.size = 3,
                          case.weights = dt_train$propensity_weight,
                          seed = 12345, classification = TRUE)

dt_ranger_pred <- dt_test %>%
  select(-all_of(trim_vars)) %>%
  predict(dt_ranger_invweight, data = ., type = "response", seed = 12345)

table(Outcome = dt_test$finding, Predicted = dt_ranger_pred$predictions)

# treeList_ranger <- Ranger2List(dt_ranger_invweight)
# 
# debug_treeList_ranger <- list()
# debug_treeList_ranger$ntree <- 1
# debug_treeList_ranger$list[[1]] <- treeList_ranger$list[[1]]
# ruleExec_ranger <- extractRules(treeList_ranger,dt_predictors_noNA,digits=10) 
# rule_metric <- getRuleMetric(ruleExec_ranger[1,,drop=FALSE],dt_predictors_noNA,outcome_measured_noNA)

```




# References
