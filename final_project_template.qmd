---
title: "Comparison of Machine Learning Models to Predict Biomarker-based PARDS Subphenotypes Using Clinical Data"
subtitle: "BMIN503/EPID600 Final Project"
author: "Daniel Balcarcel"
format: html
editor: visual
embed-resources: true
---

------------------------------------------------------------------------

### Overview

I have previously developed and validated an XGBoost machine learning model to predict biomarker-based Pediatric ARDS Subphenotypes using clinical data available in the electronic health record. For my final project, I will utilize additional supervised machine learning techniques, including k-nearest neighbors, Random Forest, and neural networks package, to evaluate the performance of these models in comparison to XGBoost.

### Introduction

Pediatric Acute Respiratory Distress Syndrome (ARDS) is a condition that affects 10% of children admitted to the Pediatric Intensive Care Unit (PICU) and carries a mortality as high as 33% in severe cases. Despite a high burden of disease and extensive research, treatment of this condition remains supportive and there is a complete lack of any targeted therapies. The lack of specific treatments is thought to be due in large part to inherent heterogeneity in this patient population. Recently, two distinct ARDS subphenotypes (hypoinflammatory and hyperinflammatory) have been identified in multiple pediatric and adult cohorts using a combination of biomarkers and clinical variables, with some evidence of differential response to therapeutic interventions. The clinical use of these subphenotypes has been limited by the cost and lack of immediate availability of biomarkers. Machine learning algorithms have been shown to predict ARDS subphenotypes in adults using exclusively electronic health record (EHR) data. We aimed to develop an EHR-based prediction model to identify Pediatric ARDS subphenotypes within 24 hours of diagnosis.

A multidisciplinary approach is necessary to untangle the heterogeneity of ARDS. Due to it's broad clinical criteria, patients with ARDS are a diverse group. Fortunately, there is a wealth of clinical data available in the EHR that can be leveraged to define more precise subtypes within ARDS. Using machine learning techniques and clinical data, models can be created to predict subtypes of ARDS without the high cost and delay of obtaining biomakers. Ultimately, the use of clinical informatics could be used to rapidly identify ARDS subphenotypes with tools embdeded in the EHR.

### Methods

Describe the data used and general methodological approach. Subsequently, incorporate full R code necessary to retrieve and clean data, and perform analysis. Be sure to include a description of code so that others (including your future self) can understand what you are doing and why.

Load packages needed for the analysis

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(here)
library(dbplyr)
library(DBI)
library(readxl)
library(glue)
library(imputeTS)
library(imputeTS)
library(xgboost)
library(Matrix)
library(tidyverse)
library(mice)
library(caret)
library(randomForest)
library(missForest)
library(pROC)
library(ROCR)
library(magrittr)
library(car)
library(kernlab)
library(glmnet)
library(tidymodels)
```

Load training data, clean it

```{r}

ARDS_train_raw <- read.csv("H:/Research/ARDS Extra cohort/Final Data/PARDS_1_Training.csv", fileEncoding="UTF-8-BOM")
  
ARDS_validate_raw <- read.csv("H:/Research/ARDS Extra cohort/Final Data/PARDS_2_Validation.csv",fileEncoding="UTF-8-BOM")

ARDS_train <- ARDS_train_raw

#Remove incomplete data
ARDS_validate <- ARDS_validate_raw |>
  drop_na(Class)

#Change Sex to an integer
#Make M=0, F=1
ARDS_train$SEX <- if_else(ARDS_train$SEX == "M", "0", "1")
ARDS_train$SEX <- as.integer(ARDS_train$SEX)

ARDS_validate$SEX <- if_else(ARDS_validate$SEX == "M", "0", "1")
ARDS_validate$SEX <- as.integer(ARDS_validate$SEX)

#Ensure all clinical variables are numeric
# Function to convert specified columns of a dataframe to numeric
convert_columns_to_numeric <- function(dataframe, columns) {
  for (column in columns) {
    dataframe[[column]] <- as.numeric(dataframe[[column]])
  }
  return(dataframe)
}

# List of column names to convert
columns_to_convert <- c("ALC_Max", "ALT_Max", "ANC_Max", "AST_Max", "BUN_Max", 
                        "Fibrinogen_Max", "Glucose_Max", "Platelets_Max", "Sodium_Max", "GGT_Max",
                        "ALC_Min", "ALT_Min", "ANC_Min", "AST_Min", "BUN_Min", 
                        "Fibrinogen_Min", "Glucose_Min", "Platelets_Min", "Sodium_Min", "GGT_Min",
                        "Systolic.max", "Diastolic.max", "SpO2.max",
                        "MAP.max", "Systolic.min", "Diastolic.min", "SpO2.min", "MAP.min")

# Convert columns for ARDS_train
ARDS_train <- convert_columns_to_numeric(ARDS_train, columns_to_convert)

# Convert columns for ARDS_validate
ARDS_validate <- convert_columns_to_numeric(ARDS_validate, columns_to_convert)

#Make CLass 0 and 1
    
ARDS_train$Class <- as.numeric(ARDS_train$Class) - 1

ARDS_validate$Class <- as.numeric(ARDS_validate$Class)

```

Impute Missing Variables

```{r}

#Training
ARDS_train.imp <- missForest(ARDS_train)

ARDS_train <- ARDS_train.imp$ximp



#Validation

ARDS_validate.imp <- missForest(ARDS_validate)

ARDS_validate <- ARDS_validate.imp$ximp

```

XG Boost

```{r}

#Run the classifier model

set.seed(1234)
              
train <- ARDS_train
test <- ARDS_validate


#Preparing data set

trainm <- sparse.model.matrix(Class ~ .-1, data = train)

train_label <- train[,"Class"]

train_matrix <- xgb.DMatrix(data =as.matrix(trainm), label = train_label)

#Prepare validation data

testm <- sparse.model.matrix(Class~ .-1, data = test)

test_label <- test[,"Class"]
test_matrix <-xgb.DMatrix(data = as.matrix(testm), label = test_label)



#parameters
xgb_params <- list(objective   = "binary:logistic",
                   eval_metric = "error",
                   max_depth   = 3,
                   eta         = 0.25,
                   gammma      = 1,
                   colsample_bytree = 0.5,
                   min_child_weight = 1)

#model


bst_model <- xgb.train(params = xgb_params, data = train_matrix,
                      nrounds = 1000)
bst_model

#Confusion Matrix
p <- predict(bst_model, newdata = test_matrix)

test$predicted <- ifelse(p > 0.5,1,0)

confusionMatrix(table(test$predicted, test$Class))

#AUC
roc_24 <- roc(test$Class, p)
auc_val <- auc(roc_24)
```

Support Vector Machine

```{r}
svm_cls_spec <- 
  svm_linear(cost = 1) |> 
  set_engine("kernlab") |>
  set_mode("classification") 
svm_cls_spec

svm_cls_fit <- svm_cls_spec |>
  fit(Class ~ ., data = train)


# Making predictions on the test set
svm_preds <- predict(svm_cls_fit, new_data = test)

# You can view the predictions using:
svm_preds

# To evaluate the model's performance, you might want to use a confusion matrix or other metrics
conf_mat <- confusion_matrix(svm_preds, test$Class)

# View the confusion matrix
conf_mat

# Other performance metrics like accuracy, precision, recall, etc. can also be calculated
accuracy <- accuracy(svm_preds, test$Class)
precision <- precision(svm_preds, test$Class)
recall <- recall(svm_preds, test$Class)

# Print the performance metrics
accuracy
precision
recall

```

K nearest neighbors

```{r}

```

Random Forest Model

```{r}

```

### Results

Plot all of the ROC Curves together

```{r}

```

Find the most important features for each

```{r}

```

Describe your results and include relevant tables, plots, and code/comments used to obtain them. End with a brief conclusion of your findings related to the question you set out to address. You can include references if you'd like, but this is not required.

### Conclusion

Therefore, I conclude that...
