---
title: "Differential Gene Expression in Adult Versus Pediatric Septic Shock"
author: "Michael Bonk"
output: 
  html_document:
    toc: false 
    depth: 3 
    theme: paper 
    highlight: tango
---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 400)
```  
***
Use this template to complete your project throughout the course. Your Final Project presentation in class will be based on the contents of this document. Replace the title/name and text below with your own, but leave the headers.

### Overview

This project is a retrospective secondary analysis of prospective cohort studies examining whole blood differential gene expression of septic shock patients within 24 hours of diagnosis compared to healthy controls. The objective is to perform a meta-analysis of publically available gene expression datasets in both pediatric and adult patient cohorts in order to identify which transcripts are differentially expressed both in common and unique to each population. Functional gene annotation enrichment analysis will then be performed utilizing the Database for Annotation, Visualization, and Integrated Discovery (DAVID) in order to identify which biologic and cellular processes are differentially regulated both in common and unique to each patient group. These results will help to characterize the transcriptomic response to septic shock in each patient population. 

### Introduction 

Sepsis is an overwhelming, dysregulated, and maladaptive host response to infection. Approximately one million patients in the United States suffer form sepsis annually. Septic shock, defined as sepsis complicated by acute circulatory failure, portends a particularly dire prognosis, with adult patients experiencing a mortality rate as high as 50% and pediatric patients up to 34% (2). Despite the prevalence and morbidity associated with sepsis and septic shock, there currently exists no therapeutics that directly target the host response and no specific test to diagnose sepsis. Peripheral blood gene expression studies have identified distinct endotypes within both adult and pediatric sepsis and septic shock cohorts. The degree of overlap in transcriptomic response to septic shock in adult and pediatric populations is currently unknown. Identification of common gene dysregulation in adult and pediatric cohorts may identify biologic processes that affect all patients with septic shock. Recognition of transcriptome derangements in each unique patient population may identify potential diagnostic or therapeutic targets unique to each age group.  

Identification of transcripts related to septic shock requires expertise from multiple specialties. Clinicians are needed to determine which patients meet criteria for septic shock and collect patient samples. Bioinformaticians, data scientists, and statisticians are needed to help categorize, analyze, and interpret the large amounts of data that result from gene expression studies. Cellular and molecular biologists are important in characterizing the underlying cellular and physiologic processes which are responsible for the manifestations of septic shock. Without the expertise of multiple specialties, gene expression studies would be difficult to perform and interpret.  

### Methods

This study is a retrospective analysis of gene expression datasets from prospective cohort studies. In order to identify applicable datasets, the National Center for Biotechnology Information (NCBI)’s Gene Expression Omnibus (GEO) was queried for septic shock. The available GEO microarray studies were then narrowed to whole blood samples drawn from human subjects. The remaining datasets were then limited to only microarray studies, thus excluding RNA sequencing studies.  Only datasets with blood samples drawn within 24 hours of septic shock onset were included. This isolated the pediatric datasets GSE26440, GSE26378, GSE13904, and GSE8121, and the adult datasets GSE95233 and GSE57065. Conveniently, each of these datasets utilized the microarray Affymetrix Human Genome U133 Plus 2.0 array.

The Reproducible Analysis and Validation of Expression Data (RAVED) pipeline was utilized to perform differential gene expression analysis on each of the previously identified datasets. Quality control was performed utilizing raw probe intensities, RNA degredation, density plots, MA plots, spatial plots, normalized unscaled standard error, relative log expression, and principle component analysis. Outliers were determined based on values greater than 1.5 times the interquartile range and excluded. Differential gene expression was examined for each dataset comparing healthy controls to patients with septic shock within 24 hours of diagnosis versus healthy controls.  Robust multi-array average was performed. Linear model for series of arrays and Bayes procedure were employed. Genes were considered to be differentially expressed with a fold change > 1.5 and adjusted p value < 0.05. Meta-analysis of the pediatric datasets was then performed using effect size based integration. Similarly, meta-analysis of the adult datasets was performed.  The differential GEx of the adult and pediatric meta-analyzed datasets were compared and examined for enriched biological pathways utilizing DAVID.

Quality control and differential expression analysis of the NCBI GEO datasets utilizes the Reproducible Analysis and Validation of Expression Data (RAVED) pipeline developed by Mengyuan Kan, Maya Shumyatcher, and Blanca Himes.  Certain commands and notation have been modified to reflect the goals of this research project.  Due to the significant repetition, descriptions of each step have been removed after the first dataset’s analysis to preserve space.

## Quality Control for GSE8121

Prior to running the pipline, variables datadir and resdir need to be manually changed to reflect the directories that the data and results will be saved to, respectively. 

```{r, eval=T, echo=T}
# directory stores GEO data
datadir="/home/bonkmp"
# directory stores generated files
resdir="/home/bonkmp/results"
# GEO id
geo_id="GSE8121"
```

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
normdata=FALSE
shortname_func <- function(x){gsub("^(.*)\\.(cel|CEL).gz","\\1",x)}
```

Install the prerequisite R packages if they do not exist

* GEOquery 
* oligo
* affy (Affymetrix microarray-specific QC analysis)
* viridis (heatmap color)
* ggplot2
* gplots (heatmap2 plot)
* Hmisc (compute hoeffd (Hoeffding's D statistics) for MA metrics)
* devtools (compute pca)
* dplyr
* pander

```{r, eval=F, echo=T, message=F, warning=F}
source("http://bioconductor.org/biocLite.R")
biocLite("GEOquery")
biocLite("oligo")
biocLite("affy")
biocLite("viridis")
biocLite("preprocessCore")
install.packages("ggplot2")
install.packages("gplots")
install.packages("Hmisc")
install.packages("devtools")
install.packages("dplyr")
install.packages("pander")
```

Load the necessary libraries. Load affy and dplyr packages later since they will mask other functions.

```{r, eval=T, echo=T, message=F, warning=F}
library(GEOquery)
library(oligo)
library(viridis) # heatmap colour
library(ggplot2)
library(gplots) # heatmap.2 plot
library(Hmisc) # compute hoeffd (Hoeffding's D statistics) for MA plot
library(devtools) # compuate PCs
library(preprocessCore) # quantile normalization
library(pander)
```

**Note that** three variables, platform (platform), geo_GPL (GPL id for analysis if the samples in the study were scanned on multiple platforms) and normdata (whether the expression matrix is normalized), need to be **manually** re-defined in the following steps after look into the datasets. A shortname_func function is suggested to be updated.

## GEO Data Download and Phenotype Preparation

### GEO Dataset Download 

Download the GEO series matrix files if available. 

```{r, eval=T, echo=T, message=F, warning=F}
# check if GEO matrix file exists
geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
if (length(geo_fn)==0) { # GEO matrix file is not downloaded
  gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
  if (length(gselms)>1) {  # multiple platform
    gpls=sapply(gselms,annotation)
    cat("This study was performed in multiple platforms:\n")
    cat(unname(gpls),"\n")
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
  } else {idx=1}
  gse <- gselms[[idx]]
} else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
  gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
} else { # GEO matrix file is alreadly downloaded and has multiple platforms
  cat("This study was performed in multiple platforms:\n")
  cat(geo_fn)
  cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
  if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <- geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
}
```

Show expression dataset features
```{r, eval=T, echo=F}
gse
```

### Modify raw phenotype information

Obtain raw phenotype information from the GEO dataset and generated a summary of all the phenotypic variables for overview.

For continuous variables, show the summary table. For categorical variables, only show the first five levels of variables.

Generate a variable, suppldata (whether supplementary data are available), based on whether the column supplementary_file is none.

```{r, eval=T, echo=T, results="asis"}
pheno.raw <- pData(phenoData(gse))
for (x in names(pheno.raw)) {
  vec=pheno.raw[,x]
  if (!is.numeric(vec)) {
    # create an empty data frame to save any tables with non-native characters
    tb_nonnative=data.frame()
    vec <- factor(vec)
    if (nlevels(vec)>5) {res=table(droplevels(vec[vec%in%levels(vec)[1:5]]))} else {res=table(vec)}
    res=data.frame(res)
    names(res) <- c(x,"counts")
  }
  if (is.numeric(vec)){res=summary(vec)}
  # Try if any existing non-native characters cause pander error
  if (class(try(pandoc.table(res, justify='left',split.tables=Inf, caption=x), silent = T))=="try-error") {tb_nonnative=res}
  if (nrow(tb_nonnative)>1){print(res)}
}
```

Define the variable "suppldata" (i.e. TRUE or FALSE) showing whether supplementary data is available. Samples with supplementary file column equals "None" are excluded from analysis.

```{r, eval=T, echo=T}
# check if there is missing supplementary_file
if (all(pheno.raw$supplementary_file=="NONE")) {
  suppldata=FALSE
} else if (any(pheno.raw$supplementary_file=="NONE")) {
  sample_nosuppl=as.character(pheno.raw$geo_accession[pheno.raw$supplementary_file=="NONE"])
  pheno.raw=pheno.raw[which(pheno.raw$supplementary_file!="NONE"),]
  cat("Not all samples have defined supplementary file path:\n")
  cat(paste(sample_nosuppl,collapse=", "),"\n")
  cat("These samples are excluded from analysis\n")
  suppldata=TRUE
} else {suppldata=TRUE}
```

```{r, eval=T, echo=T}
cat("suppldata =",as.character(suppldata))
```

#### Phenotype information modification

**This step requires mannual inspection.**

Raw phenotypic variables are manually modified them using a standard format (e.g. GEO_ID, Donor, Disease, Treatment, Age, Gender).  The variable Disease is used to label the comparison groups as "Control" to reflect samples of healthy controls and "Shock" to reflect samples of septic shock patients.  The variable Treatment is used to identify those samples drawn within the first 24 hours as "24hr".

```{r, eval=T, echo=T, message=F, warning=F, results="hide"}
library(dplyr)
cols <- c("title","geo_accession","source_name_ch1")
pheno <- pheno.raw %>%
  dplyr::select(cols) %>%
  dplyr::mutate(GEO_ID=geo_accession) %>%
  dplyr::mutate(Donor=gsub("^.*biological (.*)$","\\1",title)) %>%
  dplyr::mutate(Sample=paste(geo_accession,Donor,sep="_")) %>%
  dplyr::mutate(Tissue="Blood") %>%
  dplyr::mutate(treatment_time=gsub("^.*for (\\d+.*)$","\\1",source_name_ch1)) %>%
  dplyr::mutate(treatment_time=gsub(" ","",treatment_time)) %>%
  dplyr::mutate(treatment_drug=ifelse(grepl("sepsis",source_name_ch1),"sepsis","healthy")) %>%
  dplyr::mutate(Treatment=c(rep("24hr",45), rep("No",30))) %>%
  dplyr::mutate(Disease=c(rep("Control",15), rep("Shock",60))) %>%
  dplyr::mutate_if(is.character,as.factor) %>%
  dplyr::select(-one_of(cols)) # remove original columns
detach("package:dplyr")
```

### Raw intensity data download

Determine if supplementary raw data files are available, and if so, download them.

```{r, eval=T, echo=T}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and extract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (suppldata) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno.raw$supplementary_file))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}
}
```

For data from Affymetrix platform, the raw.data object is generated from importing supplementary raw data files (usually .cel files) using R oligo package. Scan date information is derived from the raw.data for batch effect adjustment.

```{r, eval=T, echo=T, message=F, warning=F, results="hide"}
if (platform=="Affymetrix"&suppldata) {
  #1. Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)

  #2. Obtain scan date information from the raw.data for batch effect adjustment
  # As the scan date and scan time are usually joined by "T" or a white space, use both pattern to split the date with time
  pheno$ScanDate_Group <- sapply(strsplit(as.character(protocolData(raw.data)$dates), "T| "), function(x) {x[[1]]})
  pheno$ScanDate_Group <- as.factor(pheno$ScanDate_Group)
}
```

If supplementary data is not available, the raw.data object is derived from GEO expression matrix. Scan date information is unknown.

```{r, eval=T, echo=T}
if (!suppldata) {raw.data=gse}
```

Assign phenotype data to raw data object.

```{r, eval=T, echo=T}
# assign phenotype data to raw expression data
pData(raw.data) <- pheno
row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
# Check if the sample names derived from expression data match those in phenotype file
rowname <- gsub("^(.*).(cel|CEL|txt|Txt).gz","\\1",row.names(pData(raw.data)))
matching <- mapply(grepl, x=rowname, pattern=as.character(pData(raw.data)$GEO_ID))
if (FALSE %in% matching) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
```

Show the summary of phenotype variables and the sample size for different groups

```{r, eval=T, warning=F,results="asis",echo=T}
# show the first five rows
pandoc.table(head(pheno,5), split.tables=Inf,caption="Show the first 5 rows of the modified phenotype file")
# show the groups of interest
avail_group=c("Tissue","Disease","Treatment")[c("Tissue","Disease","Treatment")%in%names(pheno)]
res=as.data.frame(table(pheno[,avail_group]))
names(res) <- c(avail_group,"Count")
pandoc.table(res, split.tables=Inf, caption="Sample size in different tissue and disease/treatment groups")
# show samples in different batch
if ("ScanDate_Group"%in%names(pheno)) {
  res=as.data.frame(table(pheno[,"ScanDate_Group"]))
  names(res) <- c("ScanDate_Group","Count")
  pandoc.table(res, split.tables=Inf, caption="Sample size in different batch")
} else {cat("No scan date information.")}
```

Assign colors to scan date or disease/treatment if scan date is not available.

```{r, eval=T, echo=T}
# assign colours to Scan Date for plots
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
vars=c("ScanDate_Group","Treatment","Disease")
leveluse=sapply(vars,function(x){if(x%in%names(pheno)){nlevel=nlevels(pheno[,x])}else{nlevel=0};nlevel>1})
if (any(leveluse)){varuse=names(which(leveluse)[1])}else{stop("None of the following variables scan date/Disease/Treatment has >1 level. Check the dataset!")} # varible assigned color in plot

# assign colour to corresponding variable (scan date if available otherwise disease/treatment)
i=nlevels(pheno[,varuse])
colour_list <- colours[1:i]
names(colour_list) <- levels(pheno[,varuse]) 
```

If gene expression matrix data is used, check if they are normalized/log-transformed. After **manual inspection**, assign a logistic variable "normdata" (whether needs log2 transformation/normalization or not for QC). If normdata is FALSE, we generate boxplots for log2-transformed and Quantile-normalization of log2-transformed data. Note that if the data are normalized, it is not likely to detect the outliers based on the intensity metrices.

If negative/zero intensity values are present, convert them to NAs.

```{r, eval=T, echo=T, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data)=apply(exprs(raw.data),2,function(x){replace(x,which(x<=0),NA)})
```


```{r, eval=T, echo=T, warning=F}
if (!suppldata|platform!="Affymetrix") {
  boxplot(exprs(gse),col=colour_list,main="Probe Intensity matrix of raw data",xaxt="n") # note gse here are non-coverted expression values
  legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  if (!normdata) {
    boxplot(log2(exprs(raw.data)),col=colour_list,main="Probe Intensity matrix of log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
    boxplot(normalize.quantiles(log2(exprs(raw.data))),col=colour_list,main="Probe Intensity matrix of qnormed log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  }
}
```

**Manual inspection:** Re-define the variable "normdata" (i.e. TRUE or FALSE) showing whether the expression data is normalized or not.

```{r, eval=T, warning=F, echo=T}
if (geo_GPL=="") {pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_Phenotype_withoutQC.txt"); pheno_fn_withQC=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else
{pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withoutQC.txt");pheno_fn_withQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
write.table(pheno,pheno_fn_withoutQC,col.names=T,row.names=F,sep="\t",quote=F)
```


## Quality Control for Microarray Data

The major QC steps and scoring methods for outliers were adapted from [arrayQualityMetrics](https://bioconductor.org/packages/release/bioc/html/arrayQualityMetrics.html). The threshold to determine an outlier used in arrayQualityMetrics is the boxplot's upper whisker, i.e. values beyond 1.5 times the interquartile range, which is also applied to our pipeline. The following QC metrics are included in a routine analysis. The QC metrics used for outlier detection are marked with an asterisk.

* Boxplots and density plots for raw probe intensities*
* RNA degradation plots
* Density plots for perfect match (PM) and mismatch (MM) probe
* MA plots*
* Spatial plots*
* Boxplots for the normalized unscaled standard error (NUSE)*
* Boxplots for the relative log expression (RLE)*
* Heatmap and dendrogram for distance between arrays*
* Principal component analysis (PCA) plots

All the above steps can be processed in data from Affymetrix gene expression array. For data from other platforms, metrics for "raw"" proble intensities, MA plots, heatmap for array distance and PCAs can be processed.

Use the prepared phenotype file.
```{r , eval=T, echo=T}
pheno <- read.table(pheno_fn_withoutQC, header=T, sep="\t")
```

### Raw Probe Intensity Boxplots and Density Histograms

The log2-transformed/normalized intensity distributions of all samples (arrays) are expected to have the similar scale (i.e. the similar positions and widths of the boxes). Outlier detection is applied by computing a Kolmogorov-Smirnov statistic (Ka) between log-intensity distribution for one array and the pooled array data, where an array with a Ka beyond the upper whisker is designated as an outlier.


```{r, eval=T, echo=T, warning=F}
# The subsamp function randomly selects 20000 probes
subsamp <- function(x,num=20000, seed=123) {
  set.seed(seed)
  subsample=num # if number of probes are >20000, randomly select 20000 probes for plot or compute
  if (nrow(x)>subsample) {
    ss  = sample(nrow(x), subsample)
    Mss = x[ss,,drop=FALSE]
  } else {
    ss  = TRUE
    Mss = x
  }
  Mss
}

# The outlier_KS_func function computes KS statistics for outlier detection
outlier_KS_func = function(exprs) { # matrix (row: probe intensities/RLE values etc., col: array (e.g. sample))
  fx = ecdf(as.vector(exprs)) # get empirical cumulative distribution function of the data
  KS=suppressWarnings(apply(exprs, 2, function(v)ks.test(v, y = fx, alternative="two.sided")$statistic))
  stats = stats::fivenum(KS, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=KS, outlier = which(KS > th))
}

# The boxplot_func function generates boxplots for raw data metrics (e.g. probe intensities, RLE, NUSE) 
boxplot_func <- function(Mss,outlier,ylab) {
  # use * to mark the outliers in boxplot
  array_name <- shortname_func(colnames(Mss))
  outlier <- shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  # boxplot raw intensity by array
  ylim = quantile(Mss, probs = c(0.01, 0.99), na.rm=TRUE) # create range of y-axsis
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df, aes(sample_id,values,fill=scandate)) + geom_boxplot(outlier.colour=NA) +
    coord_flip() + theme_bw() +
    ylim(ylim) +
    scale_x_discrete(labels=array_name) +
    ylab(ylab) +
    scale_fill_manual(varuse,values=cols) +
    theme(axis.title.y=element_blank())
}

# The densplot_func function plots density curve for raw data metrics (e.g. probe intensity)
densplot_func <- function(Mss) {
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df,aes(x=values,colour=scandate)) + geom_line(aes(group=sample_id),stat="density") +
    theme_bw() +
    xlab("Raw Probe Intensities") +
    ylab("Density") +
    scale_color_manual(varuse,values=cols)
}

# The raw_intensity_func function outputs raw probe intensity metrics
raw_intensity_func <- function() {
  if (!normdata) {Mss=log2(subsamp(exprs(raw.data))) # use log2 transformed raw probe intensity
  } else {
    Mss=subsamp(exprs(raw.data))
  }
  outlier_res=outlier_KS_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss=Mss, outlier=outlier, ylab="Raw Probe Intensities")
  densplot=densplot_func(Mss=Mss)
  return(list(outlier=outlier,boxplot=boxplot,densplot=densplot))
}
```

1. Outlier detection for log2 raw probe intensity/normalized intensity

Compute the Kolmogorov-Smirnov statistic Ka between each array's (i.e. sample) values (i.e. log2 transformed raw probe intensity values) and the 
pooled, overall distribution of the values.

```{r, eval=T, echo=T, warning=F}
res_intensity=raw_intensity_func()
outlier_intensity = res_intensity$outlier
cat(length(outlier_intensity), "outlier(s) are detected in the raw intensity metrics.\n")
if (length(outlier_intensity)>0) {cat("They are: ", shortname_func(outlier_intensity))}
```

2. Boxplots for log2 raw probe intensity

```{r, eval=T, echo=T, message=F, warning=F, fig.height=8, fig.width=6}
res_intensity$boxplot
```

3. Density curves for log2 raw probe intensity

The intensity curves of all samples (arrays) are expected to have the similar shapes and ranges. Samples with deviated curves are likely to have problematic experiments. For example, high levels of background will shift an array's distribution to the right. Lack of signal diminishes its right right tail. A bulge at the upper end of the intensity range often indicates signal saturation.

```{r, eval=T, echo=T, message=F, warning=F}
res_intensity$densplot
```

### RNA Digestion

Overall RNA quality can be assessed by RNA degradation plots. In the gene expression array, each probe is represented by a probe set. Each probe set is 11-20 probes (pairs of oligos). This plot shows the average intensity of each probe across all probe sets, ordered from the 5' to the 3' end. It is expected that probe intensities are lower at the 5' end of a probe set when compared to the 3´end as RNA degradation starts from the 5' end of a molecule. RNA which is too degraded will shows a very high slope from 5' to 3'. Thus, the standardized slope of the RNA degradation plot serves as quantitative indicator of the RNA degradation. 

This step requires R package affy that outputs the probes in each probe set matrix ordered from 5' to 3', while this function is not implemented in the oligo package.

```{r, eval=T, echo=T}
# The RNAdegaffy_func function compute mean PM intensities in each probe position following 5' to 3' order. Adopted from the AffyRNAdeg function in the affy package but include a step that randomly selects 20,000 probe sets.
RNAdegaffy_func <- function(data){ # input a list of probe set matrix with rows as probe ids and columns as samples
  {
    names <- colnames(data[[1]])
    probe.set.size <- function(x) {
      size <- dim(x)[1]
      return(size)
    }
    max.num <- sapply(data, probe.set.size) # get the number of probes in each probe set
    tab <- (table(max.num)) # summarize the frequencies of probe numbers in probe sets
    ord <- order(-as.numeric(tab)) # order the frequency from large to small
    K <- as.numeric(names(tab))[ord[1]] # K is the number of probes appearing in most probe sets
    data <- data[max.num == K] # select data of probe sets only have K number of probes
  }
  
  subsample=20000
  if (length(data)>subsample) { # randomly select 10000 probe sets
    set.seed(12345)
    ss = sample(length(data),subsample)
    data = data[ss,drop=FALSE]
  }

  N <- length(data) # number of probe sets
  n <- dim(data[[1]])[2] # number of samples
  
  # create two matrices: number of samples * number of probes representing a probe set
  mns <- matrix(nrow = n, ncol = K) # create matrix for mean values
  sds <- mns # create matrix for sds values

  get.row <- function(x, i = 1) {return(x[i, ])} # function to get each row (i.e. probe id, i) from one probe set x (i.e. probe list[[x]])
  rowstack <- function(x, i = 1) {return(t(sapply(x, get.row, i)))} # function to combine the rows obtained using get.row (pms across samples by probe sets) to get a table (row: samples column: probe sets) and transpose the table (row: probe sets, column: samples)

  for (i in 1:K) { # get probe id (position) from 1 to K from each probe set
    data.stack <- rowstack(data, i) # get the probe pm values in a specific probe position across all samples from each probe set (rows are samples and columns are probe sets)
    if(dim(data[[1]])[2]==1) data.stack <- t(data.stack)
    mns[, i] <- colMeans(data.stack) # get the mean values at one probe position across all probe sets
    sds[, i] <- apply(data.stack, 2, sd) # get the sd values at one probe position across all probe sets
  }
    
  mns.orig <- mns # store the original mns data matrix
  mn <- mns[, 1] # select values in the first probe position
  mns <- sweep(mns, 1, mn) # adjust for the intensity at the first probe position
  mns <- mns/(sds/sqrt(N)) # adjust for standard error
  lm.stats <- function(x) {
    index <- 0:(length(x) - 1)
    ans <- summary(lm(x ~ index))$coefficients[2, c(1, 4)] # use linear model fit the relationship between intensity and probe position
    return(ans)
  }
  stats <- apply(mns, 1, lm.stats)
  answer <- list(N, names, mns.orig, sds/sqrt(N), stats[1,], stats[2, ])
  names(answer) <- c("N", "sample.names", "means.by.number","ses", "slope", "pvalue")
  return(answer)
}

# The RNAdeg_func function generates RNA degradation plots
# return a logical variable whether this array type can be read by affy.
RNAdeg_func <- function() {
  # 1. Read in raw data as an AffyBatch object
  library(affy) # for Affymetrix microarray-specific QC analysis
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  # 2. Obtain a list of probe sets with a matrix of oligos (probes) by samples as an input and compute statistics of the mean PM intensities from 5' to 3' probe positions. 
  PM_list <- affy::pm(raw.data.affy,LIST=T) 
  PM_list <- lapply(PM_list,log2)
  raw.data.rnadeg <- RNAdegaffy_func(PM_list) # Compute mean PM intensity for probes following 5' to 3' order.
  # 3. Plot 5' to 3' mean PM intensity
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  plotAffyRNAdeg(raw.data.rnadeg,cols=status.cols)
  legend("topleft",legend=names(colour_list),fill=colour_list,cex=0.6)
  detach("package:affy", unload=TRUE) # detach the affy package
}
```

```{r, eval=T, echo=T, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {RNAdeg_func()}
}
```

### Distribution of Perfect Match (PM) and Mismatch (MM)

There are two paired probe types: perfect match (PM) and of mismatched (MM) probes. A PM probe matches a strand of cDNA, while the corresponding MM probe differs from the PM by a change in the central nucleotide. A probe set is called present if the intensity value of PM is significantly larger than MM. However, the Affymetrix approach is under attack because between 15%-30% of the MM are greater than the PM. For some newer arrays, MM probes are not used. If the number of PMs is not equal to that of MMs, this might be a PM-only array.

If both PM and MM are present, the density curves of log2 PM and MM intensities are generated, where MM probes are expected to have smaller log2-intensity at the peak than PM probes due to their nonspecific hybridization.

```{r, eval=T, echo=T}
PMMM_func <- function() {
  if (class(raw.data)=="GeneFeatureSet") {
    message("GeneFeatureSet does not have MM probes. No plots will be generated.")
  } else {
    PM <- log2(pm(raw.data))
    MM <- log2(mm(raw.data))
    if(nrow(PM) != nrow(MM)) {
      message("This might be a PM-only array. No plots will be generated.")
      rm(PM,MM)
    } else {
      subsample=20000
      if(nrow(PM)>subsample) { # randomly select 20000 probe sets
        sel = sample(nrow(PM), subsample)
        sPM = PM[sel, ]
        sMM = MM[sel, ]
      } else {
        sPM = PM
        sMM = MM
      }
      rm(PM,MM) 
      
      df <- data.frame(
        values=c(as.numeric(sPM),as.numeric(sMM)),
        types=c(rep("PM",each=length(as.numeric(sPM))),rep("MM",each=length(as.numeric(sMM))))
      )
      cols=colours[1:2]
      ggplot(df,aes(x=values,colour=types)) + geom_line(aes(group=types),stat="density") +
        theme_bw() +
        xlab("Intensity") +
        ylab("Density") +
        scale_color_manual(values=cols) +
        theme(legend.title=element_blank())
    }
  }
}
```

```{r, eval=T, echo=T}
if (platform=="Affymetrix"&suppldata) {PMMM_func()}
```

### MA Plots
MA plots allow pairwise comparison of the log-intensity of each array to a reference array and identification of intensity-dependent biases.

The y-axis of the MA-plot shows the log-ratio intensity of one array to the reference median array, which is called M (minus). M = log2(I1)-log2(I2) (I1: the intensity of the array studied; I2: the median intensity across arrays)

The x-axis indicates the average log-intensity of both arrays, which is called A (add). A = 1/2\*(log2(I1)+log2(I2))

It is expected that the probe levels do not differ systematically within a group of replicates, so that the MA-plot is centered on the y-axis (y=0 or M=0) from low to high intensities.

```{r, eval=T, echo=T}
# The MAcal_func function computes M and A matrices, while use the intensity of 20000 randomly selected probes
MAcal_func <- function(x) { # matrix (row: probe intensities, col: array (samples)
  medArray = rowMedians(x, na.rm=TRUE)
  M =  x - medArray
  A = (x + medArray)/2
  subsample=20000
  if(nrow(M)>subsample) {
    set.seed(12345)
    sel = sample(nrow(M), subsample)
    sM = M[sel, ]
    sA = A[sel, ]
  } else {
    sM = M
    sA = A
  }
  list(M=sM,A=sA) # return a list with M and A data matrices
}

# The outlier_MA_func function computes the Hoeffding's statistic (Da) statistics for outlier detection
outlier_MA_func <- function(exprs) { # list with M and A data matrices
  M=exprs$M
  A=exprs$A
  Dstats = sapply(1:ncol(M), function(x){hoeffd(A[,x], M[,x])$D[1,2]})
  names(Dstats) <- colnames(M)
  Dthresh = 0.15
  list(threshold=Dthresh, stats=Dstats, outlier = which(Dstats > Dthresh))
}

# The MAplot_func function plots samples with the first 4 highest and lowest values of Da. The value of Da for each sample is shown in the panel headings. Outliers marked with * have Da values >0.15.
MAplot_func <- function(sMA, outlier_res) {
# select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(sMA$M)-3):ncol(sMA$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  scandate_sel <- pData(raw.data)[,varuse][column_sel]
  M_sel <- sMA$M[,column_sel]
  A_sel <- sMA$A[,column_sel]
  # use * to mark the outliers
  array_name <- shortname_func(colnames(M_sel))
  outlier_MA=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_MA] <- paste0("*",array_name[array_name%in%outlier_MA])
  array_name <- paste0(array_name," (D=",stats_sel,")") # add D statistics to corresponding samples
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    scandate=rep(scandate_sel,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    A=as.numeric(A_sel)
  )
  # MA plots
  ggplot(df,aes(x=A,y=M,color=scandate)) + geom_point(alpha=0.1) + theme_bw() +
    scale_color_manual(varuse,values=colour_list) +
    facet_wrap(~sample_id,ncol=2)
}

# The MA_func function outputs MA metrics
MA_func <- function(){
  # Compute M-A metrics
  if (!normdata) {
    sMA <- MAcal_func(log2(exprs(raw.data)))
  } else {
    sMA <- MAcal_func(exprs(raw.data))
  }
  outlier_res <- outlier_MA_func(exprs=sMA)
  outlier <- names(outlier_res$outlier)
  plot <- MAplot_func(sMA=sMA, outlier_res=outlier_res)
  return(list(outlier=outlier, plot=plot))
}
```

1. Outlier detection for MA plots

Outlier detection is applied by computing a Hoeffding's statistic (Da) on the joint distribution of A and M for each array, where an array with a Da >0.15 is designated as an outlier.

```{r, eval=T, echo=T, message=F, warning=F}
res_MA=MA_func()
outlier_MA=res_MA$outlier
cat(length(outlier_MA), "outliers are detected in the MA metrics.\n")
if (length(outlier_MA)>0) {cat("They are: ", shortname_func(outlier_MA))}
```

2. MA plots

MA plots of the samples with the 4 highest and lowest Hoeffding's statistics.

```{r, eval=T, echo=T, message=F, warning=F, fig.height=10, fig.width=7}
res_MA$plot
```

### Spatial Distribution

Spatial plots show an artificial colored image of an array's spatial distribution of intensities that indicate spatial variation in an array. Log-intensities of probes are plotted by their corresponding spatial x and y-coordinate in the array and are expected to be uniformly distributed if the array data has good quality. The rank scale is applied for plotting as it has the potential to amplify patterns that are small in amplitude but systematic within an array.

The affy package is required to obtain the AffyBatch object that contains information of spatial x- and y-coordinate, while this function is not implemented in the oligo package.

```{r, eval=T, echo=T}
# The affyspatial_func function computes spatial x- and y-coordinate using raw data object classed as AffyBatch
affyspatial_func <- function() {
  library(affy)
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  maxc = ncol(raw.data.affy) # number of probes in x-coordinate
  maxr = nrow(raw.data.affy) # number of probes in y-coordinate
  sx = rep(seq_len(maxc), each = maxr) ## spatial x-coordinate
  sy = rep(seq_len(maxr), maxc) ## spatial y-coordinate
  M = log2(affy::exprs(raw.data.affy))
  detach("package:affy", unload=TRUE)
  numArrays = dim(M)[2]
  return(list(M=M,numArrays=numArrays,sx=sx,sy=sy))
}

# The outlier_spatial_func function computes the Fourier coefficients for outlier detection
outlier_spatial_func <- function(affy_spatial_list) {
  sx=affy_spatial_list$sx # spatial x-coordinate
  sy=affy_spatial_list$sy # spatial y-coordinate
  M=affy_spatial_list$M
  numArrays=affy_spatial_list$numArrays
  maxx = max(sx, na.rm=TRUE)
  maxy = max(sy, na.rm=TRUE)
  stat_spatial = numeric(numArrays)
  for(a in seq_len(numArrays)) {
    mat = matrix(NA_real_, nrow=maxy, ncol=maxx)
    mat[cbind(sy, sx) ] = M[, a]
    pg  = fft(mat) ## periodogram, computes the discrete fourier transform
    npg = Re(pg*Conj(pg))
    npg[1,1] = 0 ## drop the constant component
    stat_spatial[a] = sqrt(sum(npg[1:4, 1:4]) / sum(npg)) # low frequency power
  }
  names(stat_spatial)=colnames(M)
  stats = stats::fivenum(stat_spatial, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=stat_spatial, outlier = which(stat_spatial > th))
}

# The spatplot_func function plots samples with the first 4 highest and lowest values of Fa. The value of Fa for each sample is shown in the panel headings.
spatplot_func <- function(raw.data.spatial,outlier_res) {
  # select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(raw.data.spatial$M)-3):ncol(raw.data.spatial$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  M_sel <- raw.data.spatial$M[,column_sel]
  # apply rank to expression data
  M_sel = apply(M_sel, 2, rank)
  # use * to mark the outliers
  array_name=shortname_func(colnames(M_sel))
  outlier_spatial=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_spatial] <- paste0("*",array_name[array_name%in%outlier_spatial])
  array_name <- paste0(array_name," (F=",stats_sel,")") # add F statistics to corresponding samples
  # create variables for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    row=rep(raw.data.spatial$sy,ncol(M_sel)),
    column=rep(raw.data.spatial$sx,ncol(M_sel))
  )
  # spatial distribution plots
  ggplot(df,aes(x=row,y=column,fill=M)) + geom_tile() + 
    theme_bw() +
    xlab("Raw Probe Intensiry in X") + ylab("Raw Probe Intensiry in Y") +
    scale_fill_gradientn(name="Ranked Intensity",colours=viridis(256,option="B")) +
    facet_wrap(~sample_id,ncol=2)
}

# The spatial_func function outputs spatial metrics
spatial_func <- function() {
  raw.data.spatial=affyspatial_func()
  outlier_res=outlier_spatial_func(affy_spatial_list=raw.data.spatial)
  outlier=names(outlier_res$outlier)
  plot=spatplot_func(raw.data.spatial=raw.data.spatial,outlier_res=outlier_res)
  return(list(outlier=outlier,plot=plot))
}
```


1. Outlier detection for spatial plots

Outlier detection is applied by computing a sum of the absolute values of low frequency Fourier coefficients (Fa) across all probe sets for each array, where an array with a Fa beyond the upper whisker is designated as an outlier.

```{r, eval=T, echo=T, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial=spatial_func()
    outlier_spatial=res_spatial$outlier
    cat(length(outlier_spatial), "outlier(s) are detected in the spatial metrics.\n")
    if (length(outlier_spatial)>0) {cat("They are: ", shortname_func(outlier_spatial))}
  }
}
```
  
2. Spatial distribution plots

Spatial distribution plots of samples with the 4 highest and lowest values of Fa. The value of Fa for each sample is shown in the panel headings. Outliers marked with * have Fa values of large scale spatial structures.

```{r, eval=T, echo=T, fig.height=10, fig.width=7}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial$plot
  }
}
```

### Relative Log Expression (RLE) Distribution

The normalized unscaled standard error (NUSE) and relative log expression (RLE) boxplots indicate probe set homogeneity in one array, where the metrics are derived from a fitted probe level model by the fitProbeLevelModel function (oligo). The RLE plots represent the distribution of the ratio between the log-intensity of a probe set and the median log-intensity of the corresponding probe set across all arrays, expected to be centered near 0, as a log scale is applied. Outlier detection is applied by computing a Kolmogorov-Smirnov statistic (Ra) between RLE distribution for one array and the pooled array data, where an array with a Ra beyond the upper whisker is designated as an outlier 

```{r, eval=T, echo=T, message=F, warning=F}
# The fitPLM_func function generates RLE and NUSE matrices
fitPLM_func <- function(raw.data) {
  exprs(raw.data) <- log2(exprs(raw.data)) # The fitProbeLevelModel function needs ExpressionFeatureSet object as an input. Assign log transformed expression values to a new object
  fitPLM <- fitProbeLevelModel(raw.data)
  # RLE
  M_RLE <- RLE(fitPLM, type="values") # generate RLE matrix
  Mss_RLE <- subsamp(M_RLE,seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  # NUSE
  M_NUSE <- NUSE(fitPLM, type="values") # generate NUSE matrix
  Mss_NUSE <- subsamp(M_NUSE, seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  return(list(Mss_RLE=Mss_RLE,Mss_NUSE=Mss_NUSE))
}
# The RLE_func function outputs RLE metrics
RLE_func <- function(Mss) {
  outlier_res=outlier_KS_func(Mss) # compute KS statistics to detect outliers
  outlier=names(outlier_res$outlier)
  plot=boxplot_func(Mss,outlier,"RLE")
  return(list(outlier=outlier,plot=plot))
}
```

1. Outlier detection for RLE

Compute the Kolmogorov-Smirnov statistic Ra between each array's (i.e. sample) values (i.e. relative log expression values) and the pooled, overall distribution of the values. Detect outliers that are deviated from the threshold.

```{r, eval=T, echo=T, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  fitPLM=fitPLM_func(raw.data)
  res_RLE=RLE_func(Mss=fitPLM$Mss_RLE)
  outlier_RLE=res_RLE$outlier
  cat(length(outlier_RLE), "outlier(s) are detected in RLE metrics.\n")
  if (length(outlier_RLE)>0) {cat("They are: ", shortname_func(outlier_RLE))}
}
```

2. Boxplot for RLE

Use boxplot_func function to plot RLE. Outliers marked with * have values centered away from 0 and/or are more spread out are potentially problematic.

```{r, eval=T, echo=T, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_RLE$plot}
```

### Normalized Unscaled Standard Error (NUSE) Outlier Detection and Plots

The NUSE plots show the distribution of normalized standard error estimates, expected to be centered near 1. Outlier detection is applied by computing an upper hinge (Na) across all probe sets for each array, where an array with a Na beyond the upper whisker is designated as an outlier.

```{r, eval=T, echo=T, message=F, warning=F}
# The function outlier_upperquartile_func function computes upper 75% quantile for outlier detection
outlier_upperquartile_func <- function(exprs) { # matrix (row: NUSE values, col: array (e.g. sample))
  upperquartile = apply(exprs, 2, quantile, na.rm=TRUE, probs=0.75)
  stats = stats::fivenum(upperquartile, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(upperquartile > th))
}

# The NUSE_func function outputs the NUSE metrics
NUSE_func <- function(Mss) {
  outlier_res = outlier_upperquartile_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss,outlier,"NUSE")
  return(list(outlier=outlier,boxplot=boxplot))
}
```

1. Outlier detection for NUSE

Compute 75% quantile Na of each array's NUSE values Detect outliers that have larger Na deviated from the threshold.

```{r, eval=T, echo=T, message=F, warning=F, results="asis"}
if (platform=="Affymetrix"&suppldata) {
  res_NUSE <- NUSE_func(Mss=fitPLM$Mss_NUSE)
  outlier_NUSE = res_NUSE$outlier # compute upper 75% quantile statistics to detect outliers
  cat(length(outlier_NUSE), "outlier(s) are detected in NUSE metrics.\n")
  if (length(outlier_NUSE)>0) {cat("They are: ", shortname_func(outlier_NUSE))}
}
```

2. Boxplot for NUSE

Use boxplot_func function to plot RLE. Outliers marked with * have values centered away from 0 and/or are more spread out are potentially problematic.

```{r, eval=T, echo=T, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_NUSE$boxplot}
```

### Distance between Samples and Outlier Detection

Distance between arrays is evaluated using mean absolute difference of log-intensity/normalized intensity between each pair of arrays, where the hierarchical tree between arrays is created based on the distance, which is visualized by a heatmap and dendrogram.

The distance d(ab) between two arrays a and b is computed as the mean absolute difference (L1-distance) between the data of the arrays (using the data from all probes without filtering). In the formula (the dist2 function from genefilter package), d(ab) = mean | M(ai) - M(bi) |, where M(ai) is the value of the i-th probe on the a-th array. 

```{r, eval=T, echo=T, warning=F}
# The dist2 estimates distance between samples
dist2 <- function (x,fun = function(a, b) mean(abs(a - b), na.rm = TRUE),diagonal = 0) {
  if (!(is.numeric(diagonal) && (length(diagonal) == 1)))
    stop("'diagonal' must be a numeric scalar.")

  if (missing(fun)) {
    res = apply(x, 2, function(w) colMeans(abs(x-w), na.rm=TRUE))
  } else {
    res = matrix(diagonal, ncol = ncol(x), nrow = ncol(x))
    if (ncol(x) >= 2) {
      for (j in 2:ncol(x))
        for (i in 1:(j - 1))
          res[i, j] = res[j, i] = fun(x[, i], x[, j])
    } # if
  } # else
  colnames(res) = rownames(res) = colnames(x)
  return(res)
}

# The outlier_dist_func function computes the sum of all distance of one sample to other samples for outlier detection
outlier_dist_func <- function(exprs) { # matrix (row: distance to each sample, col: array (e.g. sample))
  sum = colSums(exprs, na.rm=TRUE) # sum the total distance
  stats = stats::fivenum(sum, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(sum > th))
}

# The displot_func function plots distance between samples
distplot_func <- function(m,outlier) {
  dend = as.dendrogram(hclust(as.dist(m), method = "single"))
  ord = order.dendrogram(dend)
  array_name=shortname_func(colnames(m))
  outlier=shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  array_name <- shortname_func(array_name) # shorten the sample id
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256, option="B"),ColSideColors=status.cols,RowSideColors=status.cols,
    labCol=array_name,labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_list),fill=colour_list,cex=0.6)
}

# The dist_func function outputs distance metrics
dist_func <- function() {
  if (!normdata) {
    m <- dist2(log2(exprs(raw.data)))
  } else {
    m <- dist2(exprs(raw.data))
  }
  
  outlier_res=outlier_dist_func(m)
  outlier=names(outlier_res$outlier)
  return(list(outlier=outlier,m=m))
}
```

1. Outlier detection for sample distance

Outlier detection is applied by computing the sum of the distances of one array to all other arrays (Sa) (Sa=Sum(b)d(ab)), where an array with a Sa beyond the upper whisker is designated as an outlier.

```{r, eval=T, echo=T}
res_dist=dist_func()
outlier_dist=res_dist$outlier
cat(length(outlier_dist), "outlier(s) are detected in sample distance metrics.\n")
if (length(outlier_dist)>0) {cat("They are: ", shortname_func(outlier_dist))}
```

2. Plot distance between samples
```{r, eval=T, echo=T, fig.height=10, fig.width=12}
distplot_func(m=res_dist$m,outlier=res_dist$outlier)
```

### Principal Component Analysis (PCA)

PCA demonstrates information of the expression dataset in a reduced number of dimensions. Clustering and PCA plots enable to assess to what extent arrays resemble each other, and whether this corresponds to the known resemblances of the samples.

```{r, eval=T, echo=T}
# The pcastat_func function computes principal components
pcastat_func <- function() {
  # obtain original expression data
  if (!normdata) {
    raw.data.pca <- na.omit(log2(exprs(raw.data)))
  } else {
    raw.data.pca <- na.omit(exprs(raw.data))
  } # remove NAs
 
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(pc, group_var,legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(raw.data)[,group_var]
  )
  i=length(levels(pData(raw.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(raw.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(pc) {
  group_vars=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  legends=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(raw.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    nlevel=nlevels(pData(raw.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=20)) {
      plot_list[[group_var]]=pcaplot_func(pc, group_var=group_var,legend=legend)
    }
  }
  return(plot_list)
}
```

1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=T, message=F, warning=F, results="asis"}
res_pca <- pcastat_func()
pandoc.table(res_pca$tb,split.tables=Inf, caption="Variance explained")
```

2. PCA plots

PCA plots are generated using the first two principle components colored by known factors (e.g. treatment/disease conditions, tissue, donors and scan dates), visualizing similarities between arrays and these similarities' correlation to batch effects.

```{r, eval=T, echo=T}
plot_list=pca_func(pc=res_pca$pc)
for (i in plot_list) {print(i)}
```

### QC Summary

```{r, eval=T, echo=T}
# The outlier_summ_func function outputs a summary table of outlier and the detected frequency
outlier_summ_func <- function() {
  outlier_all <- c("outlier_intensity","outlier_MA","outlier_spatial","outlier_RLE","outlier_NUSE","outlier_dist") # all outliers
  outlier_env=ls(envir=.GlobalEnv, pattern="outlier_") # "outlier_" enviromental variables
  outlier=outlier_env[outlier_env%in%outlier_all]
  method=gsub("outlier_","",outlier)
  outliers=unlist(lapply(1:length(outlier),function(x){get(outlier[x],envir=.GlobalEnv)}))
  if (length(outliers)==0) {
    cat("No outlier was detected\n")
    res <- data.frame() # create an empty data frame
  } else {
    methods=unlist(lapply(1:length(outlier),function(x){n=length(get(outlier[x]));rep(method[x],n)}))
    outlier_list=list()
    for (x in 1:length(outliers)){outlier=outliers[x];method=methods[x];outlier_list[[outlier]]=append(outlier_list[[outlier]],method)}
    # summary table
    Frequency <- sapply(outlier_list,length) # times to detect
    Method <- unlist(lapply(names(outlier_list),function(x){paste0(outlier_list[[x]],collapse=", ")}))
    res <- data.frame(Frequency,Method)
    res <- res[order(res$Frequency),]
  }
  return(res)
}

# The tbQC_func function
tbQC_func <- function(outliers) { # define outliers
  tb=pData(raw.data)
  tb$QC_Pass=1
  if (missing(outliers)) { # if outliers are not defined, use those detected more than twice
    tb$QC_Pass[rownames(tb)%in%rownames(outlier_tb)[outlier_tb$Frequency>2]]<-0 # assign 0 to outliers detected more than twice
  } else {
    tb$QC_Pass[rownames(tb)%in%outliers]<-0
  }
  tb$Filename <- rownames(tb) # add filename in a new column
  # save in a new phenotype file
  write.table(tb,pheno_fn_withQC,col.names=T,row.names=F,sep="\t",quote=F)
  # defined outliers
  outlier=as.character(tb$GEO_ID)[which(tb$QC_Pass==0)]
  # summary of phenotype information before QC
  vars=c("Tissue","Treatment","Disease","QC") # variables of interest
  # before QC
  tb_withoutQC=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb_withoutQC)[ncol(tb_withoutQC)]="Counts"
  # after QC
  tb_withQC=as.data.frame(table(tb[which(tb$QC==1),names(tb)%in%vars]))
  names(tb_withQC)[ncol(tb_withQC)]="Counts"
  return(list(outlier=outlier, tb_withoutQC=tb_withoutQC, tb_withQC=tb_withQC))
}
```

The summary of outliers and detection methods

```{r, eval=T, echo=T, results="asis"}
outlier_tb=outlier_summ_func()
if (nrow(outlier_tb)>0) {
  pandoc.table(outlier_tb,caption="Outlier Summary",split.tables=Inf)
}
```

Create a new column "QC_Pass" in the phenotype file. By default, samples detected as an outlier more than twice are assigned to 0 otherwise to 1.

```{r, eval=T, echo=T}
res_tbQC=tbQC_func()
outlier=res_tbQC$outlier
cat(length(outlier), "outlier(s) are defined.\n")
if (length(outlier)>0) {cat("They are: ", outlier)}
```

```{r, eval=T, echo=T, results="asis"}
pandoc.table(res_tbQC$tb_withoutQC, split.tables=Inf, caption="Summary of samples without QC")
pandoc.table(res_tbQC$tb_withQC, split.tables=Inf, caption="Summary of samples with QC")
```

> Differential Gene Expression Analysis for GSE8121

Mannually change the variables for GEO ID (geo_id), data directory (datadir), result directory (resdir), tissue, disease/treatment status, and comparison conditions

```{r, eval=T, echo=T}
# GEO id
geo_id="GSE8121"
# tissue
tissue="Blood"
# reference condition
con0="Control"
# altered condition
con1="Shock"
# treatment. Assign "comparison" if this column is used for DE.
treatment="24hr"
# disease. Assign "comparison" if this column is used for DE.
disease=c(con0,con1)
```

Manually change these variables according to dataset:
**Note that** four variables, platform (platform), geo_GPL (GPL id for analysis if the samples in the study were scanned on multiple platforms), usesuppl (whether to use supplementary data for DE analysis), and normdata (whether the expression matrix is normalized), need to be **manually** defined based on the QC reports. A shortname_func function is suggested to be updated.

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
usesuppl=TRUE
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*).(cel|CEL).gz","\\1",x)} # remove .cel.gz or .CEL.gz from sample
```

Automatically generate phenotype file variable pheno_fn if it is generated from QC step, otherwise manually assign this variable.

```{r, eval=T, echo=T}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
```

```{r, eval=T, echo=T}
cat(paste0("pheno_fn = '", pheno_fn,"'"))
```

Install the prerequisite R packages if they do not exist

* GEOquery 
* oligo
* limma
* sva
* annotate
* Bioconductor AnnotationData Packages: hgu133plus2.db, hgug4112a.db, hugene10sttranscriptcluster.db
* viridis (heatmap color)
* ggplot2
* gplots (heatmap2 plot)
* devtools (compute pca)
* pander


```{r, eval=F, echo=T}
source("http://bioconductor.org/biocLite.R")
biocLite("GEOquery")
biocLite("preprocessCore")
biocLite("oligo")
biocLite("limma")
biocLite("sva")
biocLite("annotate")
biocLite("viridis")
install.packages("ggplot2")
install.packages("gplots")
install.packages("devtools")
install.packages("pander")
```

Load the necessary libraries

```{r, eval=T, echo=T, message=F, warning=F}
library(GEOquery)
library(oligo)
library(limma)
library(sva)
library(annotate)
library(viridis)
library(ggplot2)
library(gplots)
library(devtools)
library(preprocessCore)
library(pander)
```

## Obtain Phenotype and GEO Data

### Phenotype data preparation

```{r, eval=T, echo=T}
# The phenosub_func function subsets phenotypes based on the user defined variables
phenosub_func <- function(){
  pheno.sub=subset(pheno,(Tissue%in%tissue)&(Treatment%in%treatment)&(Disease%in%disease))
  pheno.sub=droplevels(pheno.sub)
  # assign comparison to "Status" column
  if (length(treatment)==2) {
    if (identical(sort(levels(pheno.sub$Treatment)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Treatment} else {stop("Assigned treatment variables are not included in the Treatment column")}
  } else if (length(disease)==2) {
    if (identical(sort(levels(pheno.sub$Disease)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Disease} else {stop("Assigned treatment variables are not included in the Disease column")}
  }
  pheno.sub$Status <-factor(pheno.sub$Status,levels=c(con0,con1))
  return(pheno.sub)
}

# The phenoqc_func function excludes outliers from phenotype file 
phenoqc_func <- function(outlier,pheno) {
  if (missing(outlier)) {pheno=subset(pheno, QC_Pass==1)} else {pheno=subset(pheno, Filename%in%outlier)}
  droplevels(pheno)
}

# The phenopair_func function excludes unpaired donor from analysis
phenopair_func <- function(dat) {
  unpaired_samp=names(which(table(dat$Donor)==1))
  dat=dat[which(!dat$Donor%in%unpaired_samp),]
  droplevels(pheno)
  if (length(unpaired_samp)>0) {
    cat(paste0(length(unpaired_samp)," sample(s) with unpaired donor are excluded from analysis\n"))
    cat(paste(unpaired_samp,collapse=", "),"\n")
  }
  return(dat)
}

# The tbsum_func function generates summary of variables of interest
tbsum_func <- function(tb) {
  vars=c("Status", "ScanDate_Group") # variables of interest
  tb=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb)[ncol(tb)]="Counts"
  return(tb)
}

# The infosumm_function generates summary of the comparison
infosumm_func <- function(pheno) {
  N_Condition0 <- sum(pheno$Status==con0) # count number of samples under condition 0
  N_Condition1 <- sum(pheno$Status==con1) # count number of samples under condition 1
  if (identical(sort(levels(pheno$Treatment)),sort(c(con0,con1)))) {
    App="GC"
    if (geo_GPL=="") {name=paste(geo_id,tissue,disease,con1,"vs",con0, sep="_")} else {{name=paste(geo_id,geo_GPL,tissue,disease,con1,"vs",con0, sep="_")}}
    Disease=disease
    Treatment=con1
  } else {
    App="Asthma"
    if (geo_GPL=="") {name=paste(geo_id,tissue,treatment,con1,"vs",con0, sep="_")} else {name=paste(geo_id,geo_GPL,tissue,treatment,con1,"vs",con0, sep="_")}
    Disease=con1
    Treatment=treatment
  }
  
  df <- data.frame(
    GEO_ID=geo_id,
    Tissue=tissue,
    App=App,
    Disease=Disease,
    Treatment=Treatment,
    N_Condition0=N_Condition0,
    N_Condition1=N_Condition1,
    Total=N_Condition0+N_Condition1,
    Unique_ID=name
  )
  return(list(df=df,name=name))
}
```

Read in pre-prepared phenotype data

```{r, eval=T, echo=T}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
# read in the pre-prepared phenotype data
if (!file.exists(pheno_fn)) {stop("The phenotype file does not exist. Please check!")} else {pheno <- read.table(pheno_fn, header=TRUE, sep="\t")}
```

Subset phenotypes based on the comparison variables. Check variables (before and after QC if outliers are detected).

```{r, eval=T, echo=T}
pheno.sub=phenosub_func()
outlier=as.character(pheno.sub$Filename)[pheno.sub$QC_Pass==0]
if (length(outlier)>0) {
  cat("Remove outlier(s)", outlier, "from phenotype file\n")
  pheno.of.interest=phenoqc_func(pheno=pheno.sub)
} else {pheno.of.interest=pheno.sub}
```

Define paired variable.

If the same donors underwent treated and untreated condition, gene expression pattens are likely influenced by the same donor. Therefore, in this case, we adjust for Donor in limma regression as well as in sva batch-effect adjustment where both scan date and donor will be used as a known covariate (if donor is not correlated with scan date). For treatments/medication received by different patient groups, donor will not be adjusted.

```{r, eval=T, echo=T, results="asis"}
if (length(disease)==2) {
  paired=FALSE
} else if (length(disease)==1) {
  if (all((pheno.sub$Donor)==1)) {paired=FALSE} # if treatment is in different donors
  else {paired=TRUE} # if treatment is in samd donors
}
```

```{r, eval=T, echo=T}
cat("paired =",as.character(paired))
```

Exclude samples missing the other paired donors in treatment comparisons
```{r, eval=T, echo=T, results="asis"}
if (paired) {
  pheno.of.interest <- phenopair_func(pheno.of.interest)
}
```

```{r, eval=T, echo=T, results="asis"}
if (nrow(pheno.sub)!=nrow(pheno.of.interest)) {
  pandoc.table(tbsum_func(tb=pheno.sub), split.tables=Inf, caption="Summary of subsetted samples without QC")
  pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples with QC")
} else {pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples")}

# create a summary table for this comparison
pandoc.table(t(infosumm_func(pheno=pheno.of.interest)$df),split.tables=Inf, caption="Summary of the comparison")
```

Assign colours to status and scan date (if available)

```{r, eval=T, echo=T}
# assign colours to comparison status
colour_status <- c("navy","red")
names(colour_status) <- c(con0,con1) # assign red to condition 1 and navy to condition 2
colour_status_list <- unlist(lapply(pheno.of.interest$Status,function(x){colour_status[x]}))
# assign colours to scan date
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
if ("ScanDate_Group"%in%names(pheno)) {
  i=nlevels(pheno.of.interest$ScanDate_Group)
  colour_scandate <- colours[1:i]
  names(colour_scandate) <- levels(pheno.of.interest$ScanDate_Group) # colour to corresponding scan date
  colour_scandate_list <- unlist(lapply(pheno.of.interest$ScanDate_Group,function(x){colour_scandate[x]}))
}
```

### Gene expression data preparation

For data from Affymetrix platform, raw probe intensity data from supplementary files (usually .cel files) in GEO are downloaded and used for DE analysis. For data from Agilent platform, the intensity data is derived from GEO expression matrix.

Generate raw.data object using supplementary files (for Affymetrix data).

```{r, eval=T, echo=T, message=F, warning=F, results="hide"}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and unextract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (usesuppl) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno$Filename))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}

  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)
}
```


Generate raw.data object using expression matrix from GEO (for platforms other than Affymetrix).

```{r, eval=T, echo=T, message=F, warning=F}
if (!usesuppl) {
  # check if GEO matrix file exists
  geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
  if (length(geo_fn)==0) { # # GEO matrix file is not downloaded
    gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
    if (length(gselms)>1) {  # multiple platform
      gpls=sapply(gselms,annotation)
      cat("This study was performed in multiple platforms:\n")
      cat(unname(gpls),"\n")
      cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
      if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
    } else {idx=1}
    gse <- gselms[[idx]]
  } else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
    gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
  } else { # GEO matrix file is alreadly downloaded and has multiple platforms
    cat("This study was performed in multiple platforms:\n")
    cat(geo_fn)
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <-geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
  }
  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.data=gse
}
```

Obtain raw.data.of.interest by subsetting raw.data based on the phenotype of interest

```{r, eval=T, echo=T}
# The subdat_func function subsets data based on the phenotype of interest
subdat_func <- function(raw.data, pheno) {
  # subset raw.data based on the phenotype of interest
  raw.data=raw.data[,colnames(raw.data)%in%pheno$Filename]
  # assign phenotype data to raw expression data
  pData(raw.data) <- pheno
  row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
  # check if the sample names derived from expression data match those in phenotype file
  if (usesuppl) {matching=mapply(identical,row.names(pData(raw.data)),as.character(pheno$Filename))}
  else {matching=mapply(grepl,row.names(pData(raw.data)),as.character(pheno$Filename))}
  if (!all(matching)) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
  return(raw.data)
}
raw.data.of.interest=subdat_func(raw.data=raw.data, pheno=pheno.of.interest)
```

Show expression dataset features
```{r, eval=T, echo=T}
raw.data.of.interest
```

## Differential Gene Expression Analysis

### Normalize raw gene expression data

Normalize gene expression raw data using robust multi-array average (RMA) method (if supplementary data is available) or quantile normalize (if use expression matrix), unless the raw.data object is already normalized (based on the variable normdata).


If negative/zero intensity values are present, convert them to NAs.

```{r, eval=T, echo=T, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data.of.interest),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data.of.interest)=apply(exprs(raw.data.of.interest),2,function(x){replace(x,which(x<=0),NA)})
```

```{r, eval=T, echo=T, message=F, results="hide"}
if (usesuppl) {
  rma.data.of.interest = rma(raw.data.of.interest)
  cat("RMA normalization is used.\n")
} else {
  rma.data.of.interest=raw.data.of.interest
  if (!normdata) {exprs(rma.data.of.interest)=normalize.quantiles(log2(exprs(rma.data.of.interest)))
  cat("Quantile normalization and log2 transformation is used.\n")
  }
}
```

```{r, eval=T, echo=T}
cols=colour_status_list
boxplot(raw.data.of.interest,target="core",col=cols,main="Raw Probe Intensities",xaxt="n") # view raw data
legend("topright",legend=names(colour_status),fill=colour_status)

if (!normdata) {
  boxplot(rma.data.of.interest,col=cols,main="Normalized Probe Intensities",xaxt="n") # view RMA-adjusted data
  legend("topright",legend=names(colour_status),fill=colour_status)
} else {cat("The raw data is already normalized")}
```


### Pairwise Comparison between Status

```{r, eval=T, echo=T, results="asis"}
limma_func <- function(paired=FALSE) { # here only con0, con1 are used in comparisons. use a function to reduce the factor levels
  if (paired) {
    cat("Donor is adjusted in this regression\n")
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$Donor)) # create design model matrix
    colnames(design) = c(levels(factor(rma.data.of.interest$Status)),levels(factor(rma.data.of.interest$Donor))[-1])
  } else {
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)) # create design model matrix
    colnames(design) = levels(factor(rma.data.of.interest$Status))
  }
  fit = lmFit(rma.data.of.interest, design) # fit a linear model to estimate the fold changes and standard error
  # Create a contrast group and fit it in a linear model
  data.contrast = makeContrasts(contrasts=paste(c(con1,con0),collapse="-"),levels = design) # create a contrast group by comparing con1 vs con0
  fit2 = contrasts.fit(fit, data.contrast) # get the contrasts for samples of interest
  fit2 = eBayes(fit2) # adjust fit coefficients using an empirical Bayes moderation of standard errors
  return(list(design=design,data.contrast=data.contrast,fit2=fit2))
}
```

Fit a linear model to RMA log-intensity values, fit this model to a contrast matrix for the comparison of interest, and apply empirical Bayes smoothing to obtain more precise standard errors.

```{r, eval=T, echo=T, message=F, warning=F, results="asis"}
res_DE=limma_func(paired=paired)
fit2=res_DE$fit2
pandoc.table(data.frame(Sample=rma.data.of.interest$Sample,res_DE$design), split.tables=Inf, caption="A design model matrix for linear model")
pandoc.table(as.data.frame(res_DE$data.contrast), caption="A contract matrix for comparison")
contrast_table <- topTable(fit2, adjust="BH",num=Inf) # get full set of results for each hypothesis test
col.sel=c("logFC","AveExpr","t","P.Value","adj.P.Val","B") # select the columns of DE results
contrast_table <- data.frame(ID=row.names(contrast_table), contrast_table[,col.sel])
```

### Adjusting for Batch Effect

```{r, eval=T, echo=T}
# The nbatch_func function obtains number of batches (scan date) in the data
nbatch_func <- function() {
  if (!"ScanDate_Group"%in%names(pData(rma.data.of.interest))) {nbatch=0} else {nbatch=nlevels(rma.data.of.interest$ScanDate_Group)}
}

# The svamod_func function creates full and null models, and Checks if the batch and comparison status are confounded
svamod_func <- function(paired=FALSE) {
  # Create a full model
  modBatch = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)) # full model (adjusted variables and variables of interest)
  # Create a null model only including batch variables
  nullBatch =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)) # null model (adjusted variables only)
  # Check if the scan date and comparison status are confounded
  if (class(try(solve(t(modBatch)%*%modBatch),silent=T))=="matrix") {batchadj=TRUE} else {batchadj=FALSE; message("The scan date and comparison status are highly confounded")}
  # summary of the full model
  tb.fullmod <- as.data.frame(modBatch)
  names(tb.fullmod) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])
  # summary of the null model
  tb.nullmod <- as.data.frame(nullBatch)
  names(tb.nullmod) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])

  donoradj=NULL # assign variable is donor is adjusted
  tb.nullmod1=NULL # assign null matrix for donor adjustment
  if ((paired)&(batchadj)) { # same donor treatment adjust for donor
    # Test if donor and scandate are correlated
    modBatch1 = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # full model including donor
    nullBatch1 =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # null model including donor
    # summary of the full model
    tb.fullmod1 <- as.data.frame(modBatch1)
    names(tb.fullmod1) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
    # summary of the null model
    tb.nullmod1 <- as.data.frame(nullBatch1)
    names(tb.nullmod1) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
      
    # check if scandate correlated with donor
    if (class(try(solve(t(modBatch1)%*%modBatch1),silent=T))=="matrix") {
      donoradj="yes"
      modBatch=modBatch1
      nullBatch=nullBatch1
      tb.fullmod=tb.fullmod1
      tb.nullmod=tb.nullmod1
    }
  }

  return(list(modBatch=modBatch, nullBatch=nullBatch, tb.fullmod=tb.fullmod, tb.nullmod=tb.nullmod, batchadj=batchadj, donoradj=donoradj, tb.nullmod_donor=tb.nullmod1))
}

# The batcherror_func function assigns a variable batcherror to decide whether to adjust for batch effect under various scenarios
batcherror_func <- function() {
  if (nbatch==0) {
    batcherror="zero"
  } else if (nbatch==1) {
    batcherror="one"
  } else {
    if (batchadj) {batcherror="no"} else {batcherror="correlate"}
  }
  return(batcherror)
}

# The batchadj_func function outputs table with batch effects adjusted p-values
batchadj_func <- function(batcherror=batcherror, contrast_table=contrast_table, paired=paired) {
  if (batcherror=="no") {
    modBatch=svamod_func(paired=paired)$modBatch
    nullBatch=svamod_func(paired=paired)$nullBatch
    pValuesBatch=f.pvalue(exprs(rma.data.of.interest), modBatch, nullBatch) # get batch effect-adjusted p-values
    qValuesBatch=p.adjust(pValuesBatch, method="BH") # get q-values
    tb.sva <- data.frame(ID=names(pValuesBatch),pValuesBatch,qValuesBatch)
    contrast_table <- merge(contrast_table, tb.sva, by="ID", all=TRUE)
  } else if (batcherror=="correlate") {
    contrast_table$pValuesBatch=contrast_table$qValuesBatch=rep(NA,nrow(contrast_table))
  } else {
    contrast_table$pValuesBatch=contrast_table$P.Value
    contrast_table$qValuesBatch=contrast_table$adj.P.Val
  }
  return(contrast_table)
}
```

Check whether to adjust for scan date and donor.

```{r, eval=T, echo=T}
nbatch=nbatch_func()
if (nbatch>1) {res_svamod=svamod_func(paired=paired);batchadj=res_svamod$batchadj}
batcherror=batcherror_func()
if (batcherror=="zero") {cat("No scan date is present in the data.")} else if (batcherror=="one") {cat("Only one batch is present in the data.")} else if (batcherror=="correlate") {cat("The scan date and the comparison status are highly confounded (See the model matrix). Cannot ajust for batch effect.")}
```

Create a full model that includes all variables and a null model that only includes the batch variable. Note that as SVA computes the matrix x in t(batch model)%*%x=batch model, batch effect can be adjusted only when the solve function works.

```{r, eval=T, echo=T, results="asis"}
if (nbatch>1) {
  if (paired) {
    if (is.null(res_svamod$donoradj)) {
      cat("Scan date and donor are highly confounded. See the matrix below.\n")
      pandoc.table(res_svamod$tb.nullmod_donor, split.tables=Inf, caption="Null model matrix with scan date and donor")
      cat("Only adjust for scan date.\n")
    } else {cat("Both scan date and donor are adjusted.\n")}
  }
  pandoc.table(res_svamod$tb.fullmod, split.tables=Inf, caption="Full model matrix")
  pandoc.table(res_svamod$tb.nullmod, split.tables=Inf, caption="Null model matrix")
}
```


Compute F statistic p-values adjusted for batch effect. Q-values are obtained by the Benjamini-Hochberg method. If the batch and the status are correlated, assign NA to the batch adjusted p- and q-values. If there is no batch variable or only one batch, assign p- and q-values computed by limma to the batch adjusted p-values

```{r, eval=T, echo=T, results="asis"}
contrast_table=batchadj_func(batcherror=batcherror, contrast_table=contrast_table, paired=paired)
pandoc.table(summary(contrast_table), split.tables=Inf, caption=paste0(con1, " vs. ", con0, " summary"))
```


### Assign Official Gene Symbol

Annotate official gene symbol to probes. Install the [R annotation database package](https://bioconductor.org/packages/3.7/data/annotation/) corresponding to your gene expression data. For any newly installed annotation databases, it can be added to the list anno_list reserved for future use.

```{r, eval=T, echo=T}
anno_list=list()
# Affymetrix
anno_list[["pd.hg.u133.plus.2"]]="hgu133plus2.db"
```

```{r, echo=T}
# glpanno_func creates anntoation vector based on GPL annotation from GEO
glpanno_func <- function(GPL_ID){
  gpl <- Table(getGEO(GPL_ID, destdir = "data"))
  if (GPL_ID%in%names(symbol_list)) {anno_vect <- gpl[,symbol_col]} else {anno_vect <- gpl[,"gene name"]}
  names(anno_vect) <- gpl[,"ID"]
  return(anno_vect)
}

# ranno_func creates anntoation vector based on R annotation database
ranno_func <- function(anno_lib){
  # check if the annotation database is installed
  if (!anno_lib%in%installed.packages()[,1]){source("http://bioconductor.org/biocLite.R"); biocLite(anno_lib)}
  library(anno_lib, character.only=T)
  anno_symbol=gsub(".db","SYMBOL",anno_lib) # The name of the R object mapping between probe id and gene symbol
  x=get(anno_symbol)
  # Get the probe identifiers that are mapped to a gene symbol
  mapped_probes <- mappedkeys(x)
  # Convert to a list
  xx <- as.list(x[mapped_probes])
  # Convert list to annotation vector
  anno_vect <- sapply(xx,function(x){x})
  return(anno_vect)
}

# geneannot_func annotates gene symbol to DE result table
geneannot_func <- function(tb, anno_vect) {
  remove.pm <- function(x) {gsub("_PM", "", x)} # Assign official gene symbol using hgu133plus2.db package if anntoation is based on pd.hg.u133.plus.2. Note that the probe names have additional "PM"s in the results will be removed to match the names in the gene symbol package.
  if (exists("anno_lib")) {
    if (anno_lib=="hgu133plus2.db") {tb$ID=sapply(as.character(tb$ID), remove.pm)}
  }
  tb$ID=as.character(tb$ID)
  tb$SYMBOL=sapply(as.character(tb$ID), function(x){if (x%in%names(anno_vect)){anno_vect[x]} else {"NA"}})
  tb$SYMBOL[which(tb$SYMBOL=="")]="NA"
  # remove probes with NA in logFC column
  tb <- tb[!is.na(tb$logFC),]
  tb[order(tb$P.Value),]
}
```

```{r, eval=T, echo=T, warning=F, message=F}
# install corresponding annotation database if it is not installed
anno_array=annotation(rma.data.of.interest)
cat("The platform used is", anno_array, "\n")
if (!anno_array%in%names(anno_list)) {
  cat("Annotate using GPL annotation in GEO\n")
  anno_vect=glpanno_func(GPL_ID=anno_array)
} else {
  anno_lib=anno_list[[anno_array]] # use the annotation database
  cat("The corresponding R annotation database package is", anno_lib,"\n")
  anno_vect <- ranno_func(anno_lib=anno_lib)
}
```

```{r, eval=T, echo=T}
contrast_name=infosumm_func(pheno=pheno.of.interest)$name # adopt Unique_ID created in the information summary table
contrast_fn=paste0(resdir,"/", contrast_name, ".csv")
```

```{r, eval=T, echo=T, warning=F, message=F}
contrast_table <- geneannot_func(tb=contrast_table, anno_vect=anno_vect)
write.csv(contrast_table, file=contrast_fn, row.names = FALSE)
```

```{r, eval=T, echo=T}
if (file.exists(contrast_fn)) {contrast_fn=paste0(resdir,"/", contrast_name, ".csv")}
res=read.csv(contrast_fn)
```

## Gene Expression Results Visualization

### Volcano Plots

```{r, eval=T, echo=T}
# The volplot_func function generates volcano plots
volplot_func <- function(df,qval_column,title) {
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else {          
    df <- df[!is.na(qval),] # remove NA values
    qval <- df[,qval_column]
    if (min(df[,qval_column])>=0.05) {
      df$sig <- "black" # assign colors to DE and non-DE genes
    } else {
      # assign colors to DE and non-DE genes
      df$sig <- rep(NA,nrow(df))
      df$sig[qval<0.05] <- "red"
      df$sig[qval>=0.05] <- "black"
    }
    df$sig <- as.factor(df$sig)
    color <- levels(df$sig)
    # log10 transformed q values
    df$logqval <- -log10(qval)
    diffgenes <- df$ID[qval<0.05] #Create list of all DEG's
    signum = paste0(length(diffgenes), " significant genes based on ", qval_column)
    if (missing(title)) {title=signum}
    print(
    ggplot(df, aes(x = logFC, y = logqval, color=sig)) + geom_point() +
      theme_bw() +
      labs(title=title,x="logFC",y=paste0("-log10(",qval_column,")")) +
      scale_color_manual(values=color) +
      theme(legend.position="none")
    )
  }
}
```

Volcano plot (probes with a q-value <0.05 are present in red)

```{r, eval=T, echo=T, fig.height=4, fig.width=4.5}
for (qval in c("adj.P.Val","qValuesBatch")) {volplot_func(res, qval)}
```


### Histograms

```{r, eval=T, echo=T}
# The histplot_func function generates histogram for p-value distributions
histplot_func <- function(df,qval_column,title) {
  if (missing(title)) {title=""}
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else{hist(qval,main=title,xlab=qval_column)}
}
```

Histograms of p-value distributions

```{r, eval=T, echo=T, fig.width=4.5, fig.height=4}
for (pval in c("P.Value","pValuesBatch")) {histplot_func(res, pval)}
for (qval in c("adj.P.Val","qValuesBatch")) {histplot_func(res, qval)}
```

### Top 20 Differentially Expression Results

```{r, eval=T, echo=T}
# The datreform_func function reformats the DE table
datreform_func <- function(dt,topnum=200) {
  dt=dt[order(dt$P.Value),]
  dt=dt[1:topnum,]
  round2 <- function(x){round(x,2)}
  dt[,c("logFC","AveExpr","t","B")] <- sapply(dt[,c("logFC","AveExpr","t","B")],round2)
  sciform <- function(x){format(x,scientific=TRUE,digits =2)}
  dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")] <- sapply(dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")],sciform)
  dt
}
```

Show top 20 probes sorted by un-adjusted p-values

```{r, eval=T, echo=T, results="asis"}
res <- datreform_func(dt=res)
rownames(res) <- NULL
pandoc.table(res[1:20,],split.tables=Inf)
```

### Boxplots for Top 6 Differentially Expressed Genes

This step helps to visualize and check the effect direction in the comparison.

```{r, eval=T, echo=T}
# function for top gene boxplot
topgene_boxplot_func <- function(tb,colour,comp) { # comp: comparison status
  for (i in 1:nrow(tb)) {# top i probe in res
    if (missing(comp)) {comp=""}
    if (missing(colour)) {colour=colours[1]}
    probe_top <- tb$ID[i]
    gene_top <- tb$SYMBOL[i]
    row.names(rma.data.of.interest) <- gsub("_PM","",row.names(rma.data.of.interest))
    values=exprs(rma.data.of.interest)[row.names(rma.data.of.interest)%in%probe_top, ]
    status=rma.data.of.interest$Status
    df <- data.frame(values=values,status=status)
    title=paste0(comp," top ",i," probe ", probe_top, " gene ", gene_top)
    print(
      ggplot(df,aes(x=status,y=values)) +
        geom_boxplot(outlier.colour=NA,color="grey18",fill=colour) +
        stat_boxplot(geom ='errorbar', color="grey18") +
        geom_jitter(size=1,position = position_jitter(width=0.3)) +
        labs(title=title) +
        theme_bw() +
        theme(legend.position="none",axis.title=element_blank())
    )
  }
}
```

```{r, eval=T, echo=T, message=F, warning=F, fig.height=4, fig.width=4.5}
topgene_boxplot_func(tb=res[1:6,])
```


### Heatmap for Top 200 Differentially Expressed Genes

```{r, eval=T, echo=T}
# The heatmap_topgene_func function for top gene heatmap plots
heatmap_topgene_func <- function(tb, topnum=200, colour_status_list, colour_status, main="") { # colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  top.rma <- rma.data.of.interest[row.names(rma.data.of.interest)%in%tb[1:topnum,"ID"],] # plot heatmap for top 200 genes
  array_name <- shortname_func(colnames(exprs(top.rma))) # shorten the sample id
  heatmap.2(na.omit(exprs(top.rma)), col=viridis(256, option="B"),
    ColSideColors=colour_status_list, # use predefined colour_status_list, assign colors to status
    labCol=array_name,labRow = "", # take out gene probe id
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow=1,cexCol=1,
    keysize=1.5,key.title=NA,key.xlab="Gene Expression Values",key.ylab="Counts",
    main=main)
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.8) # use predifined colour_status
}
```


```{r, eval=T, echo=T, fig.height=10, fig.width=12}
heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_status_list, colour_status=colour_status, main="Gene expression heatmap by comparison status")
```

```{r, eval=T, echo=T, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Gene expression heatmap by scan date")
}
```

### Heatmap for Sample Correlation

```{r, eval=T, echo=T, fig.height=10, fig.width=12}
# The corplot_func function plots correlation between samples
corplot_func <- function(m, colour_status_list, colour_status, main="") {  # m: correlation matrix, colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  m <- cor(na.omit(m)) # compute correlation matrix
  # compute distance based on 1-correlation efficient
  dend = as.dendrogram(hclust(as.dist(1-m), method = "single"))
  ord = order.dendrogram(dend)
  array_name <- shortname_func(colnames(m)) # shorten the sample id
  # heatmap plot
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256,option="B"), ColSideColors=colour_status_list, RowSideColors=colour_status_list,
    labCol=array_name, labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.6)
}
```


```{r, eval=T, echo=T, fig.height=10, fig.width=12}
corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_status_list, colour_status=colour_status, main="Correlation heatmap by comparison status")
```

```{r, eval=T, echo=T, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Correlation heatmap by scan date")
}
```

### Principal Component Analysis (PCA)

```{r, eval=T, echo=T, warning=F, message=F, results="asis"}
# The pcastat_func function computes principal components
pcastat_func <- function(m) {
  # obtain original expression data
  raw.data.pca <- na.omit(apply(m,2,function(x)replace(x,is.infinite(x),NA))) # replace infinite values to NAs and omit NAs
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(oligo.data, pc, group_var, legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(oligo.data)[,group_var]
  )
  i=length(levels(pData(oligo.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(oligo.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(oligo.data, pc) {
  group_vars=c("ScanDate_Group", "Status", "Donor")
  legends=c("ScanDate_Group", "Status", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(oligo.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    pData(oligo.data)[,group_var]=as.factor(as.character(pData(oligo.data)[,group_var])) # convert to factor
    nlevel=nlevels(pData(oligo.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=10)) {
      if (group_var=="Status") {
        plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)+scale_color_manual(legend,values=colour_status,na.value="grey") # assign colour to comparison stauts
      } else {plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)}
    }
  }
  return(plot_list)
}
```

1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=T, warning=F, message=F, results="asis"}
res_pca <- pcastat_func(m=exprs(rma.data.of.interest))
pandoc.table(res_pca$tb, split.tables=Inf, caption="Variance explained")
```

2. PCA plots

PCA plots are generated using the first two principle components colored by known factors (e.g. comparison status, donors and scan dates), visualizing similarities between arrays and these similarities' correlation to batch effects.

```{r, eval=T, echo=T, message=F, warning=F}
plot_list=pca_func(oligo.data=rma.data.of.interest, pc=res_pca$pc)
for (i in plot_list) {print(i)}
```

## Quality Control for GSE13904

```{r, eval=T, echo=T}
# GEO id
geo_id="GSE13904"
```

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*)\\.(cel|CEL).gz","\\1",x)}
```

```{r, eval=T, echo=F, message=F, warning=F}
library(GEOquery)
library(oligo)
library(viridis) # heatmap colour
library(ggplot2)
library(gplots) # heatmap.2 plot
library(Hmisc) # compute hoeffd (Hoeffding's D statistics) for MA plot
library(devtools) # compuate PCs
library(preprocessCore) # quantile normalization
library(pander)
```

## GEO Data Download and Phenotype Preparation

### GEO Dataset Download

```{r, eval=T, echo=F, message=F, warning=F}
# check if GEO matrix file exists
geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
if (length(geo_fn)==0) { # GEO matrix file is not downloaded
  gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
  if (length(gselms)>1) {  # multiple platform
    gpls=sapply(gselms,annotation)
    cat("This study was performed in multiple platforms:\n")
    cat(unname(gpls),"\n")
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
  } else {idx=1}
  gse <- gselms[[idx]]
} else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
  gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
} else { # GEO matrix file is alreadly downloaded and has multiple platforms
  cat("This study was performed in multiple platforms:\n")
  cat(geo_fn)
  cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
  if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <- geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
}
```


Show expression dataset features
```{r, eval=T, echo=F}
gse
```

### Modify raw phenotype information

```{r, eval=T, echo=F, results="asis"}
pheno.raw <- pData(phenoData(gse))
for (x in names(pheno.raw)) {
  vec=pheno.raw[,x]
  if (!is.numeric(vec)) {
    # create an empty data frame to save any tables with non-native characters
    tb_nonnative=data.frame()
    vec <- factor(vec)
    if (nlevels(vec)>5) {res=table(droplevels(vec[vec%in%levels(vec)[1:5]]))} else {res=table(vec)}
    res=data.frame(res)
    names(res) <- c(x,"counts")
  }
  if (is.numeric(vec)){res=summary(vec)}
  # Try if any existing non-native characters cause pander error
  if (class(try(pandoc.table(res, justify='left',split.tables=Inf, caption=x), silent = T))=="try-error") {tb_nonnative=res}
  if (nrow(tb_nonnative)>1){print(res)}
}
```

```{r, eval=T, echo=F}
# check if there is missing supplementary_file
if (all(pheno.raw$supplementary_file=="NONE")) {
  suppldata=FALSE
} else if (any(pheno.raw$supplementary_file=="NONE")) {
  sample_nosuppl=as.character(pheno.raw$geo_accession[pheno.raw$supplementary_file=="NONE"])
  pheno.raw=pheno.raw[which(pheno.raw$supplementary_file!="NONE"),]
  cat("Not all samples have defined supplementary file path:\n")
  cat(paste(sample_nosuppl,collapse=", "),"\n")
  cat("These samples are excluded from analysis\n")
  suppldata=TRUE
} else {suppldata=TRUE}
```

```{r, eval=T, echo=F}
cat("suppldata =",as.character(suppldata))
```

#### Phenotype information modification

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
library(dplyr)
cols <- c("title","geo_accession","source_name_ch1")
pheno <- pheno.raw %>%
  dplyr::select(cols) %>%
  dplyr::mutate(GEO_ID=geo_accession) %>%
  dplyr::mutate(Donor=gsub("^.*biological (.*)$","\\1",title)) %>%
  dplyr::mutate(Sample=paste(geo_accession,Donor,sep="_")) %>%
  dplyr::mutate(Tissue="Blood") %>%
  dplyr::mutate(treatment_time=gsub("^.*for (\\d+.*)$","\\1",source_name_ch1)) %>%
  dplyr::mutate(treatment_time=gsub(" ","",treatment_time)) %>%
  dplyr::mutate(treatment_drug=ifelse(grepl("sepsis",source_name_ch1),"sepsis","healthy")) %>%
  dplyr::mutate(Treatment=c(rep("24hr",18), rep("No",51), rep("No",52), rep("24hr",67), rep("No",39))) %>%
  dplyr::mutate(Disease=c(rep("Control",18), rep("SIRS",51), rep("Sepsis",52), rep("Shock",106))) %>%
  dplyr::mutate_if(is.character,as.factor) %>%
  dplyr::select(-one_of(cols)) # remove original columns
detach("package:dplyr")
```

### Raw intensity data download

```{r, eval=T, echo=F}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and extract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (suppldata) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno.raw$supplementary_file))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}
}
```

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
if (platform=="Affymetrix"&suppldata) {
  #1. Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)

  #2. Obtain scan date information from the raw.data for batch effect adjustment
  # As the scan date and scan time are usually joined by "T" or a white space, use both pattern to split the date with time
  pheno$ScanDate_Group <- sapply(strsplit(as.character(protocolData(raw.data)$dates), "T| "), function(x) {x[[1]]})
  pheno$ScanDate_Group <- as.factor(pheno$ScanDate_Group)
}
```

```{r, eval=T, echo=F}
if (!suppldata) {raw.data=gse}
```

```{r, eval=T, echo=F}
# assign phenotype data to raw expression data
pData(raw.data) <- pheno
row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
# Check if the sample names derived from expression data match those in phenotype file
rowname <- gsub("^(.*).(cel|CEL|txt|Txt).gz","\\1",row.names(pData(raw.data)))
matching <- mapply(grepl, x=rowname, pattern=as.character(pData(raw.data)$GEO_ID))
if (FALSE %in% matching) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
```

```{r, eval=T, warning=F,results="asis",echo=F}
# show the first five rows
pandoc.table(head(pheno,5), split.tables=Inf,caption="Show the first 5 rows of the modified phenotype file")
# show the groups of interest
avail_group=c("Tissue","Disease","Treatment")[c("Tissue","Disease","Treatment")%in%names(pheno)]
res=as.data.frame(table(pheno[,avail_group]))
names(res) <- c(avail_group,"Count")
pandoc.table(res, split.tables=Inf, caption="Sample size in different tissue and disease/treatment groups")
# show samples in different batch
if ("ScanDate_Group"%in%names(pheno)) {
  res=as.data.frame(table(pheno[,"ScanDate_Group"]))
  names(res) <- c("ScanDate_Group","Count")
  pandoc.table(res, split.tables=Inf, caption="Sample size in different batch")
} else {cat("No scan date information.")}
```

```{r, eval=T, echo=F}
# assign colours to Scan Date for plots
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
vars=c("ScanDate_Group","Treatment","Disease")
leveluse=sapply(vars,function(x){if(x%in%names(pheno)){nlevel=nlevels(pheno[,x])}else{nlevel=0};nlevel>1})
if (any(leveluse)){varuse=names(which(leveluse)[1])}else{stop("None of the following variables scan date/Disease/Treatment has >1 level. Check the dataset!")} # varible assigned color in plot

# assign colour to corresponding variable (scan date if available otherwise disease/treatment)
i=nlevels(pheno[,varuse])
colour_list <- colours[1:i]
names(colour_list) <- levels(pheno[,varuse]) 
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data)=apply(exprs(raw.data),2,function(x){replace(x,which(x<=0),NA)})
```

```{r, eval=T, echo=F, warning=F}
if (!suppldata|platform!="Affymetrix") {
  boxplot(exprs(gse),col=colour_list,main="Probe Intensity matrix of raw data",xaxt="n") # note gse here are non-coverted expression values
  legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  if (!normdata) {
    boxplot(log2(exprs(raw.data)),col=colour_list,main="Probe Intensity matrix of log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
    boxplot(normalize.quantiles(log2(exprs(raw.data))),col=colour_list,main="Probe Intensity matrix of qnormed log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  }
}
```

```{r, eval=T, warning=F, echo=F}
if (geo_GPL=="") {pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_Phenotype_withoutQC.txt"); pheno_fn_withQC=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else
{pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withoutQC.txt");pheno_fn_withQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
write.table(pheno,pheno_fn_withoutQC,col.names=T,row.names=F,sep="\t",quote=F)
```

## Quality Control for Microarray Data

```{r, eval=T, echo=F}
pheno <- read.table(pheno_fn_withoutQC, header=T, sep="\t")
```

### Raw Probe Intensity Boxplots and Density Histograms

```{r, eval=T, echo=F, warning=F}
# The subsamp function randomly selects 20000 probes
subsamp <- function(x,num=20000, seed=123) {
  set.seed(seed)
  subsample=num # if number of probes are >20000, randomly select 20000 probes for plot or compute
  if (nrow(x)>subsample) {
    ss  = sample(nrow(x), subsample)
    Mss = x[ss,,drop=FALSE]
  } else {
    ss  = TRUE
    Mss = x
  }
  Mss
}

# The outlier_KS_func function computes KS statistics for outlier detection
outlier_KS_func = function(exprs) { # matrix (row: probe intensities/RLE values etc., col: array (e.g. sample))
  fx = ecdf(as.vector(exprs)) # get empirical cumulative distribution function of the data
  KS=suppressWarnings(apply(exprs, 2, function(v)ks.test(v, y = fx, alternative="two.sided")$statistic))
  stats = stats::fivenum(KS, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=KS, outlier = which(KS > th))
}

# The boxplot_func function generates boxplots for raw data metrics (e.g. probe intensities, RLE, NUSE) 
boxplot_func <- function(Mss,outlier,ylab) {
  # use * to mark the outliers in boxplot
  array_name <- shortname_func(colnames(Mss))
  outlier <- shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  # boxplot raw intensity by array
  ylim = quantile(Mss, probs = c(0.01, 0.99), na.rm=TRUE) # create range of y-axsis
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df, aes(sample_id,values,fill=scandate)) + geom_boxplot(outlier.colour=NA) +
    coord_flip() + theme_bw() +
    ylim(ylim) +
    scale_x_discrete(labels=array_name) +
    ylab(ylab) +
    scale_fill_manual(varuse,values=cols) +
    theme(axis.title.y=element_blank())
}

# The densplot_func function plots density curve for raw data metrics (e.g. probe intensity)
densplot_func <- function(Mss) {
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df,aes(x=values,colour=scandate)) + geom_line(aes(group=sample_id),stat="density") +
    theme_bw() +
    xlab("Raw Probe Intensities") +
    ylab("Density") +
    scale_color_manual(varuse,values=cols)
}

# The raw_intensity_func function outputs raw probe intensity metrics
raw_intensity_func <- function() {
  if (!normdata) {Mss=log2(subsamp(exprs(raw.data))) # use log2 transformed raw probe intensity
  } else {
    Mss=subsamp(exprs(raw.data))
  }
  outlier_res=outlier_KS_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss=Mss, outlier=outlier, ylab="Raw Probe Intensities")
  densplot=densplot_func(Mss=Mss)
  return(list(outlier=outlier,boxplot=boxplot,densplot=densplot))
}
```

1. Outlier detection for log2 raw probe intensity/normalized intensity

```{r, eval=T, echo=F, warning=F}
res_intensity=raw_intensity_func()
outlier_intensity = res_intensity$outlier
cat(length(outlier_intensity), "outlier(s) are detected in the raw intensity metrics.\n")
if (length(outlier_intensity)>0) {cat("They are: ", shortname_func(outlier_intensity))}
```

2. Boxplots for log2 raw probe intensity

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
res_intensity$boxplot
```

3. Density curves for log2 raw probe intensity

```{r, eval=T, echo=F, message=F, warning=F}
res_intensity$densplot
```

### RNA Digestion

```{r, eval=T, echo=F}
# The RNAdegaffy_func function compute mean PM intensities in each probe position following 5' to 3' order. Adopted from the AffyRNAdeg function in the affy package but include a step that randomly selects 20,000 probe sets.
RNAdegaffy_func <- function(data){ # input a list of probe set matrix with rows as probe ids and columns as samples
  {
    names <- colnames(data[[1]])
    probe.set.size <- function(x) {
      size <- dim(x)[1]
      return(size)
    }
    max.num <- sapply(data, probe.set.size) # get the number of probes in each probe set
    tab <- (table(max.num)) # summarize the frequencies of probe numbers in probe sets
    ord <- order(-as.numeric(tab)) # order the frequency from large to small
    K <- as.numeric(names(tab))[ord[1]] # K is the number of probes appearing in most probe sets
    data <- data[max.num == K] # select data of probe sets only have K number of probes
  }
  
  subsample=20000
  if (length(data)>subsample) { # randomly select 10000 probe sets
    set.seed(12345)
    ss = sample(length(data),subsample)
    data = data[ss,drop=FALSE]
  }

  N <- length(data) # number of probe sets
  n <- dim(data[[1]])[2] # number of samples
  
  # create two matrices: number of samples * number of probes representing a probe set
  mns <- matrix(nrow = n, ncol = K) # create matrix for mean values
  sds <- mns # create matrix for sds values

  get.row <- function(x, i = 1) {return(x[i, ])} # function to get each row (i.e. probe id, i) from one probe set x (i.e. probe list[[x]])
  rowstack <- function(x, i = 1) {return(t(sapply(x, get.row, i)))} # function to combine the rows obtained using get.row (pms across samples by probe sets) to get a table (row: samples column: probe sets) and transpose the table (row: probe sets, column: samples)

  for (i in 1:K) { # get probe id (position) from 1 to K from each probe set
    data.stack <- rowstack(data, i) # get the probe pm values in a specific probe position across all samples from each probe set (rows are samples and columns are probe sets)
    if(dim(data[[1]])[2]==1) data.stack <- t(data.stack)
    mns[, i] <- colMeans(data.stack) # get the mean values at one probe position across all probe sets
    sds[, i] <- apply(data.stack, 2, sd) # get the sd values at one probe position across all probe sets
  }
    
  mns.orig <- mns # store the original mns data matrix
  mn <- mns[, 1] # select values in the first probe position
  mns <- sweep(mns, 1, mn) # adjust for the intensity at the first probe position
  mns <- mns/(sds/sqrt(N)) # adjust for standard error
  lm.stats <- function(x) {
    index <- 0:(length(x) - 1)
    ans <- summary(lm(x ~ index))$coefficients[2, c(1, 4)] # use linear model fit the relationship between intensity and probe position
    return(ans)
  }
  stats <- apply(mns, 1, lm.stats)
  answer <- list(N, names, mns.orig, sds/sqrt(N), stats[1,], stats[2, ])
  names(answer) <- c("N", "sample.names", "means.by.number","ses", "slope", "pvalue")
  return(answer)
}

# The RNAdeg_func function generates RNA degradation plots
# return a logical variable whether this array type can be read by affy.
RNAdeg_func <- function() {
  # 1. Read in raw data as an AffyBatch object
  library(affy) # for Affymetrix microarray-specific QC analysis
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  # 2. Obtain a list of probe sets with a matrix of oligos (probes) by samples as an input and compute statistics of the mean PM intensities from 5' to 3' probe positions. 
  PM_list <- affy::pm(raw.data.affy,LIST=T) 
  PM_list <- lapply(PM_list,log2)
  raw.data.rnadeg <- RNAdegaffy_func(PM_list) # Compute mean PM intensity for probes following 5' to 3' order.
  # 3. Plot 5' to 3' mean PM intensity
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  plotAffyRNAdeg(raw.data.rnadeg,cols=status.cols)
  legend("topleft",legend=names(colour_list),fill=colour_list,cex=0.6)
  detach("package:affy", unload=TRUE) # detach the affy package
}
```

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {RNAdeg_func()}
}
```

### Distribution of Perfect Match (PM) and Mismatch (MM)

```{r, eval=T, echo=F}
PMMM_func <- function() {
  if (class(raw.data)=="GeneFeatureSet") {
    message("GeneFeatureSet does not have MM probes. No plots will be generated.")
  } else {
    PM <- log2(pm(raw.data))
    MM <- log2(mm(raw.data))
    if(nrow(PM) != nrow(MM)) {
      message("This might be a PM-only array. No plots will be generated.")
      rm(PM,MM)
    } else {
      subsample=20000
      if(nrow(PM)>subsample) { # randomly select 20000 probe sets
        sel = sample(nrow(PM), subsample)
        sPM = PM[sel, ]
        sMM = MM[sel, ]
      } else {
        sPM = PM
        sMM = MM
      }
      rm(PM,MM) 
      
      df <- data.frame(
        values=c(as.numeric(sPM),as.numeric(sMM)),
        types=c(rep("PM",each=length(as.numeric(sPM))),rep("MM",each=length(as.numeric(sMM))))
      )
      cols=colours[1:2]
      ggplot(df,aes(x=values,colour=types)) + geom_line(aes(group=types),stat="density") +
        theme_bw() +
        xlab("Intensity") +
        ylab("Density") +
        scale_color_manual(values=cols) +
        theme(legend.title=element_blank())
    }
  }
}
```

```{r, eval=T, echo=F}
if (platform=="Affymetrix"&suppldata) {PMMM_func()}
```

### MA Plots

```{r, eval=T, echo=F}
# The MAcal_func function computes M and A matrices, while use the intensity of 20000 randomly selected probes
MAcal_func <- function(x) { # matrix (row: probe intensities, col: array (samples)
  medArray = rowMedians(x, na.rm=TRUE)
  M =  x - medArray
  A = (x + medArray)/2
  subsample=20000
  if(nrow(M)>subsample) {
    set.seed(12345)
    sel = sample(nrow(M), subsample)
    sM = M[sel, ]
    sA = A[sel, ]
  } else {
    sM = M
    sA = A
  }
  list(M=sM,A=sA) # return a list with M and A data matrices
}

# The outlier_MA_func function computes the Hoeffding's statistic (Da) statistics for outlier detection
outlier_MA_func <- function(exprs) { # list with M and A data matrices
  M=exprs$M
  A=exprs$A
  Dstats = sapply(1:ncol(M), function(x){hoeffd(A[,x], M[,x])$D[1,2]})
  names(Dstats) <- colnames(M)
  Dthresh = 0.15
  list(threshold=Dthresh, stats=Dstats, outlier = which(Dstats > Dthresh))
}

# The MAplot_func function plots samples with the first 4 highest and lowest values of Da. The value of Da for each sample is shown in the panel headings. Outliers marked with * have Da values >0.15.
MAplot_func <- function(sMA, outlier_res) {
# select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(sMA$M)-3):ncol(sMA$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  scandate_sel <- pData(raw.data)[,varuse][column_sel]
  M_sel <- sMA$M[,column_sel]
  A_sel <- sMA$A[,column_sel]
  # use * to mark the outliers
  array_name <- shortname_func(colnames(M_sel))
  outlier_MA=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_MA] <- paste0("*",array_name[array_name%in%outlier_MA])
  array_name <- paste0(array_name," (D=",stats_sel,")") # add D statistics to corresponding samples
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    scandate=rep(scandate_sel,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    A=as.numeric(A_sel)
  )
  # MA plots
  ggplot(df,aes(x=A,y=M,color=scandate)) + geom_point(alpha=0.1) + theme_bw() +
    scale_color_manual(varuse,values=colour_list) +
    facet_wrap(~sample_id,ncol=2)
}

# The MA_func function outputs MA metrics
MA_func <- function(){
  # Compute M-A metrics
  if (!normdata) {
    sMA <- MAcal_func(log2(exprs(raw.data)))
  } else {
    sMA <- MAcal_func(exprs(raw.data))
  }
  outlier_res <- outlier_MA_func(exprs=sMA)
  outlier <- names(outlier_res$outlier)
  plot <- MAplot_func(sMA=sMA, outlier_res=outlier_res)
  return(list(outlier=outlier, plot=plot))
}
```

1. Outlier detection for MA plots

```{r, eval=T, echo=F, message=F, warning=F}
res_MA=MA_func()
outlier_MA=res_MA$outlier
cat(length(outlier_MA), "outliers are detected in the MA metrics.\n")
if (length(outlier_MA)>0) {cat("They are: ", shortname_func(outlier_MA))}
```

2. MA plots

```{r MA_plot, eval=T, echo=F, message=F, warning=F, fig.height=10, fig.width=7}
res_MA$plot
```

### Spatial Distribution

```{r, eval=T, echo=F}
# The affyspatial_func function computes spatial x- and y-coordinate using raw data object classed as AffyBatch
affyspatial_func <- function() {
  library(affy)
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  maxc = ncol(raw.data.affy) # number of probes in x-coordinate
  maxr = nrow(raw.data.affy) # number of probes in y-coordinate
  sx = rep(seq_len(maxc), each = maxr) ## spatial x-coordinate
  sy = rep(seq_len(maxr), maxc) ## spatial y-coordinate
  M = log2(affy::exprs(raw.data.affy))
  detach("package:affy", unload=TRUE)
  numArrays = dim(M)[2]
  return(list(M=M,numArrays=numArrays,sx=sx,sy=sy))
}

# The outlier_spatial_func function computes the Fourier coefficients for outlier detection
outlier_spatial_func <- function(affy_spatial_list) {
  sx=affy_spatial_list$sx # spatial x-coordinate
  sy=affy_spatial_list$sy # spatial y-coordinate
  M=affy_spatial_list$M
  numArrays=affy_spatial_list$numArrays
  maxx = max(sx, na.rm=TRUE)
  maxy = max(sy, na.rm=TRUE)
  stat_spatial = numeric(numArrays)
  for(a in seq_len(numArrays)) {
    mat = matrix(NA_real_, nrow=maxy, ncol=maxx)
    mat[cbind(sy, sx) ] = M[, a]
    pg  = fft(mat) ## periodogram, computes the discrete fourier transform
    npg = Re(pg*Conj(pg))
    npg[1,1] = 0 ## drop the constant component
    stat_spatial[a] = sqrt(sum(npg[1:4, 1:4]) / sum(npg)) # low frequency power
  }
  names(stat_spatial)=colnames(M)
  stats = stats::fivenum(stat_spatial, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=stat_spatial, outlier = which(stat_spatial > th))
}

# The spatplot_func function plots samples with the first 4 highest and lowest values of Fa. The value of Fa for each sample is shown in the panel headings.
spatplot_func <- function(raw.data.spatial,outlier_res) {
  # select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(raw.data.spatial$M)-3):ncol(raw.data.spatial$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  M_sel <- raw.data.spatial$M[,column_sel]
  # apply rank to expression data
  M_sel = apply(M_sel, 2, rank)
  # use * to mark the outliers
  array_name=shortname_func(colnames(M_sel))
  outlier_spatial=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_spatial] <- paste0("*",array_name[array_name%in%outlier_spatial])
  array_name <- paste0(array_name," (F=",stats_sel,")") # add F statistics to corresponding samples
  # create variables for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    row=rep(raw.data.spatial$sy,ncol(M_sel)),
    column=rep(raw.data.spatial$sx,ncol(M_sel))
  )
  # spatial distribution plots
  ggplot(df,aes(x=row,y=column,fill=M)) + geom_tile() + 
    theme_bw() +
    xlab("Raw Probe Intensiry in X") + ylab("Raw Probe Intensiry in Y") +
    scale_fill_gradientn(name="Ranked Intensity",colours=viridis(256,option="B")) +
    facet_wrap(~sample_id,ncol=2)
}

# The spatial_func function outputs spatial metrics
spatial_func <- function() {
  raw.data.spatial=affyspatial_func()
  outlier_res=outlier_spatial_func(affy_spatial_list=raw.data.spatial)
  outlier=names(outlier_res$outlier)
  plot=spatplot_func(raw.data.spatial=raw.data.spatial,outlier_res=outlier_res)
  return(list(outlier=outlier,plot=plot))
}
```

1. Outlier detection for spatial plots

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial=spatial_func()
    outlier_spatial=res_spatial$outlier
    cat(length(outlier_spatial), "outlier(s) are detected in the spatial metrics.\n")
    if (length(outlier_spatial)>0) {cat("They are: ", shortname_func(outlier_spatial))}
  }
}
```
  
2. Spatial distribution plots

```{r, eval=T, echo=F, fig.height=10, fig.width=7}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial$plot
  }
}
```

### Relative Log Expression (RLE) Distribution

```{r, eval=T, echo=F, message=F, warning=F}
# The fitPLM_func function generates RLE and NUSE matrices
fitPLM_func <- function(raw.data) {
  exprs(raw.data) <- log2(exprs(raw.data)) # The fitProbeLevelModel function needs ExpressionFeatureSet object as an input. Assign log transformed expression values to a new object
  fitPLM <- fitProbeLevelModel(raw.data)
  # RLE
  M_RLE <- RLE(fitPLM, type="values") # generate RLE matrix
  Mss_RLE <- subsamp(M_RLE,seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  # NUSE
  M_NUSE <- NUSE(fitPLM, type="values") # generate NUSE matrix
  Mss_NUSE <- subsamp(M_NUSE, seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  return(list(Mss_RLE=Mss_RLE,Mss_NUSE=Mss_NUSE))
}
# The RLE_func function outputs RLE metrics
RLE_func <- function(Mss) {
  outlier_res=outlier_KS_func(Mss) # compute KS statistics to detect outliers
  outlier=names(outlier_res$outlier)
  plot=boxplot_func(Mss,outlier,"RLE")
  return(list(outlier=outlier,plot=plot))
}
```

1. Outlier detection for RLE

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  fitPLM=fitPLM_func(raw.data)
  res_RLE=RLE_func(Mss=fitPLM$Mss_RLE)
  outlier_RLE=res_RLE$outlier
  cat(length(outlier_RLE), "outlier(s) are detected in RLE metrics.\n")
  if (length(outlier_RLE)>0) {cat("They are: ", shortname_func(outlier_RLE))}
}
```

2. Boxplot for RLE

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_RLE$plot}
```

### Normalized Unscaled Standard Error (NUSE) Outlier Detection and Plots

```{r, eval=T, echo=F, message=F, warning=F}
# The function outlier_upperquartile_func function computes upper 75% quantile for outlier detection
outlier_upperquartile_func <- function(exprs) { # matrix (row: NUSE values, col: array (e.g. sample))
  upperquartile = apply(exprs, 2, quantile, na.rm=TRUE, probs=0.75)
  stats = stats::fivenum(upperquartile, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(upperquartile > th))
}

# The NUSE_func function outputs the NUSE metrics
NUSE_func <- function(Mss) {
  outlier_res = outlier_upperquartile_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss,outlier,"NUSE")
  return(list(outlier=outlier,boxplot=boxplot))
}
```

1. Outlier detection for NUSE

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
if (platform=="Affymetrix"&suppldata) {
  res_NUSE <- NUSE_func(Mss=fitPLM$Mss_NUSE)
  outlier_NUSE = res_NUSE$outlier # compute upper 75% quantile statistics to detect outliers
  cat(length(outlier_NUSE), "outlier(s) are detected in NUSE metrics.\n")
  if (length(outlier_NUSE)>0) {cat("They are: ", shortname_func(outlier_NUSE))}
}
```

2. Boxplot for NUSE

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_NUSE$boxplot}
```

### Distance between Samples and Outlier Detection

```{r, eval=T, echo=F, warning=F}
# The dist2 estimates distance between samples
dist2 <- function (x,fun = function(a, b) mean(abs(a - b), na.rm = TRUE),diagonal = 0) {
  if (!(is.numeric(diagonal) && (length(diagonal) == 1)))
    stop("'diagonal' must be a numeric scalar.")

  if (missing(fun)) {
    res = apply(x, 2, function(w) colMeans(abs(x-w), na.rm=TRUE))
  } else {
    res = matrix(diagonal, ncol = ncol(x), nrow = ncol(x))
    if (ncol(x) >= 2) {
      for (j in 2:ncol(x))
        for (i in 1:(j - 1))
          res[i, j] = res[j, i] = fun(x[, i], x[, j])
    } # if
  } # else
  colnames(res) = rownames(res) = colnames(x)
  return(res)
}

# The outlier_dist_func function computes the sum of all distance of one sample to other samples for outlier detection
outlier_dist_func <- function(exprs) { # matrix (row: distance to each sample, col: array (e.g. sample))
  sum = colSums(exprs, na.rm=TRUE) # sum the total distance
  stats = stats::fivenum(sum, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(sum > th))
}

# The displot_func function plots distance between samples
distplot_func <- function(m,outlier) {
  dend = as.dendrogram(hclust(as.dist(m), method = "single"))
  ord = order.dendrogram(dend)
  array_name=shortname_func(colnames(m))
  outlier=shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  array_name <- shortname_func(array_name) # shorten the sample id
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256, option="B"),ColSideColors=status.cols,RowSideColors=status.cols,
    labCol=array_name,labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_list),fill=colour_list,cex=0.6)
}

# The dist_func function outputs distance metrics
dist_func <- function() {
  if (!normdata) {
    m <- dist2(log2(exprs(raw.data)))
  } else {
    m <- dist2(exprs(raw.data))
  }
  
  outlier_res=outlier_dist_func(m)
  outlier=names(outlier_res$outlier)
  return(list(outlier=outlier,m=m))
}
```

1. Outlier detection for sample distance

```{r, eval=T, echo=F}
res_dist=dist_func()
outlier_dist=res_dist$outlier
cat(length(outlier_dist), "outlier(s) are detected in sample distance metrics.\n")
if (length(outlier_dist)>0) {cat("They are: ", shortname_func(outlier_dist))}
```

2. Plot distance between samples
```{r, eval=T, echo=F, fig.height=10, fig.width=12}
distplot_func(m=res_dist$m,outlier=res_dist$outlier)
```

### Principal Component Analysis (PCA)

```{r, eval=T, echo=F}
# The pcastat_func function computes principal components
pcastat_func <- function() {
  # obtain original expression data
  if (!normdata) {
    raw.data.pca <- na.omit(log2(exprs(raw.data)))
  } else {
    raw.data.pca <- na.omit(exprs(raw.data))
  } # remove NAs
 
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(pc, group_var,legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(raw.data)[,group_var]
  )
  i=length(levels(pData(raw.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(raw.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(pc) {
  group_vars=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  legends=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(raw.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    nlevel=nlevels(pData(raw.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=20)) {
      plot_list[[group_var]]=pcaplot_func(pc, group_var=group_var,legend=legend)
    }
  }
  return(plot_list)
}
```

1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
res_pca <- pcastat_func()
pandoc.table(res_pca$tb,split.tables=Inf, caption="Variance explained")
```

2. PCA plots

```{r, eval=T, echo=F}
plot_list=pca_func(pc=res_pca$pc)
for (i in plot_list) {print(i)}
```


### QC Summary

```{r, eval=T, echo=F}
# The outlier_summ_func function outputs a summary table of outlier and the detected frequency
outlier_summ_func <- function() {
  outlier_all <- c("outlier_intensity","outlier_MA","outlier_spatial","outlier_RLE","outlier_NUSE","outlier_dist") # all outliers
  outlier_env=ls(envir=.GlobalEnv, pattern="outlier_") # "outlier_" enviromental variables
  outlier=outlier_env[outlier_env%in%outlier_all]
  method=gsub("outlier_","",outlier)
  outliers=unlist(lapply(1:length(outlier),function(x){get(outlier[x],envir=.GlobalEnv)}))
  if (length(outliers)==0) {
    cat("No outlier was detected\n")
    res <- data.frame() # create an empty data frame
  } else {
    methods=unlist(lapply(1:length(outlier),function(x){n=length(get(outlier[x]));rep(method[x],n)}))
    outlier_list=list()
    for (x in 1:length(outliers)){outlier=outliers[x];method=methods[x];outlier_list[[outlier]]=append(outlier_list[[outlier]],method)}
    # summary table
    Frequency <- sapply(outlier_list,length) # times to detect
    Method <- unlist(lapply(names(outlier_list),function(x){paste0(outlier_list[[x]],collapse=", ")}))
    res <- data.frame(Frequency,Method)
    res <- res[order(res$Frequency),]
  }
  return(res)
}

# The tbQC_func function
tbQC_func <- function(outliers) { # define outliers
  tb=pData(raw.data)
  tb$QC_Pass=1
  if (missing(outliers)) { # if outliers are not defined, use those detected more than twice
    tb$QC_Pass[rownames(tb)%in%rownames(outlier_tb)[outlier_tb$Frequency>2]]<-0 # assign 0 to outliers detected more than twice
  } else {
    tb$QC_Pass[rownames(tb)%in%outliers]<-0
  }
  tb$Filename <- rownames(tb) # add filename in a new column
  # save in a new phenotype file
  write.table(tb,pheno_fn_withQC,col.names=T,row.names=F,sep="\t",quote=F)
  # defined outliers
  outlier=as.character(tb$GEO_ID)[which(tb$QC_Pass==0)]
  # summary of phenotype information before QC
  vars=c("Tissue","Treatment","Disease","QC") # variables of interest
  # before QC
  tb_withoutQC=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb_withoutQC)[ncol(tb_withoutQC)]="Counts"
  # after QC
  tb_withQC=as.data.frame(table(tb[which(tb$QC==1),names(tb)%in%vars]))
  names(tb_withQC)[ncol(tb_withQC)]="Counts"
  return(list(outlier=outlier, tb_withoutQC=tb_withoutQC, tb_withQC=tb_withQC))
}
```

```{r, eval=T, echo=F, results="asis"}
outlier_tb=outlier_summ_func()
if (nrow(outlier_tb)>0) {
  pandoc.table(outlier_tb,caption="Outlier Summary",split.tables=Inf)
}
```

```{r, eval=T, echo=F}
res_tbQC=tbQC_func()
outlier=res_tbQC$outlier
cat(length(outlier), "outlier(s) are defined.\n")
if (length(outlier)>0) {cat("They are: ", outlier)}
```

```{r, eval=T, echo=F, results="asis"}
pandoc.table(res_tbQC$tb_withoutQC, split.tables=Inf, caption="Summary of samples without QC")
pandoc.table(res_tbQC$tb_withQC, split.tables=Inf, caption="Summary of samples with QC")
```

> Differential Gene Expression Analysis for GSE13904

```{r, eval=T, echo=T}
# GEO id
geo_id="GSE13904"
# tissue
tissue="Blood"
# reference condition
con0="Control"
# altered condition
con1="Shock"
# treatment. Assign "comparison" if this column is used for DE.
treatment="24hr"
# disease. Assign "comparison" if this column is used for DE.
disease=c(con0,con1)
```

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
usesuppl=TRUE
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*).(cel|CEL).gz","\\1",x)} # remove .cel.gz or .CEL.gz from sample
```

```{r, eval=T, echo=F}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
```

```{r, eval=T, echo=F}
cat(paste0("pheno_fn = '", pheno_fn,"'"))
```

```{r, eval=T, echo=F, message=F, warning=F}
library(GEOquery)
library(oligo)
library(limma)
library(sva)
library(annotate)
library(viridis)
library(ggplot2)
library(gplots)
library(devtools)
library(preprocessCore)
library(pander)
```

## Obtain Phenotype and GEO Data

### Phenotype data preparation

```{r, eval=T, echo=F}
# The phenosub_func function subsets phenotypes based on the user defined variables
phenosub_func <- function(){
  pheno.sub=subset(pheno,(Tissue%in%tissue)&(Treatment%in%treatment)&(Disease%in%disease))
  pheno.sub=droplevels(pheno.sub)
  # assign comparison to "Status" column
  if (length(treatment)==2) {
    if (identical(sort(levels(pheno.sub$Treatment)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Treatment} else {stop("Assigned treatment variables are not included in the Treatment column")}
  } else if (length(disease)==2) {
    if (identical(sort(levels(pheno.sub$Disease)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Disease} else {stop("Assigned treatment variables are not included in the Disease column")}
  }
  pheno.sub$Status <-factor(pheno.sub$Status,levels=c(con0,con1))
  return(pheno.sub)
}

# The phenoqc_func function excludes outliers from phenotype file 
phenoqc_func <- function(outlier,pheno) {
  if (missing(outlier)) {pheno=subset(pheno, QC_Pass==1)} else {pheno=subset(pheno, Filename%in%outlier)}
  droplevels(pheno)
}

# The phenopair_func function excludes unpaired donor from analysis
phenopair_func <- function(dat) {
  unpaired_samp=names(which(table(dat$Donor)==1))
  dat=dat[which(!dat$Donor%in%unpaired_samp),]
  droplevels(pheno)
  if (length(unpaired_samp)>0) {
    cat(paste0(length(unpaired_samp)," sample(s) with unpaired donor are excluded from analysis\n"))
    cat(paste(unpaired_samp,collapse=", "),"\n")
  }
  return(dat)
}

# The tbsum_func function generates summary of variables of interest
tbsum_func <- function(tb) {
  vars=c("Status", "ScanDate_Group") # variables of interest
  tb=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb)[ncol(tb)]="Counts"
  return(tb)
}

# The infosumm_function generates summary of the comparison
infosumm_func <- function(pheno) {
  N_Condition0 <- sum(pheno$Status==con0) # count number of samples under condition 0
  N_Condition1 <- sum(pheno$Status==con1) # count number of samples under condition 1
  if (identical(sort(levels(pheno$Treatment)),sort(c(con0,con1)))) {
    App="GC"
    if (geo_GPL=="") {name=paste(geo_id,tissue,disease,con1,"vs",con0, sep="_")} else {{name=paste(geo_id,geo_GPL,tissue,disease,con1,"vs",con0, sep="_")}}
    Disease=disease
    Treatment=con1
  } else {
    App="Asthma"
    if (geo_GPL=="") {name=paste(geo_id,tissue,treatment,con1,"vs",con0, sep="_")} else {name=paste(geo_id,geo_GPL,tissue,treatment,con1,"vs",con0, sep="_")}
    Disease=con1
    Treatment=treatment
  }
  
  df <- data.frame(
    GEO_ID=geo_id,
    Tissue=tissue,
    App=App,
    Disease=Disease,
    Treatment=Treatment,
    N_Condition0=N_Condition0,
    N_Condition1=N_Condition1,
    Total=N_Condition0+N_Condition1,
    Unique_ID=name
  )
  return(list(df=df,name=name))
}
```

```{r, eval=T, echo=F}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
# read in the pre-prepared phenotype data
if (!file.exists(pheno_fn)) {stop("The phenotype file does not exist. Please check!")} else {pheno <- read.table(pheno_fn, header=TRUE, sep="\t")}
```

```{r, eval=T, echo=F}
pheno.sub=phenosub_func()
outlier=as.character(pheno.sub$Filename)[pheno.sub$QC_Pass==0]
if (length(outlier)>0) {
  cat("Remove outlier(s)", outlier, "from phenotype file\n")
  pheno.of.interest=phenoqc_func(pheno=pheno.sub)
} else {pheno.of.interest=pheno.sub}
```

Define paired variable.

```{r, eval=T, echo=F, results="asis"}
if (length(disease)==2) {
  paired=FALSE
} else if (length(disease)==1) {
  if (all((pheno.sub$Donor)==1)) {paired=FALSE} # if treatment is in different donors
  else {paired=TRUE} # if treatment is in samd donors
}
```

```{r, eval=T, echo=F}
cat("paired =",as.character(paired))
```

Exclude samples missing the other paired donors in treatment comparisons
```{r, eval=T, echo=F, results="asis"}
if (paired) {
  pheno.of.interest <- phenopair_func(pheno.of.interest)
}
```

```{r, eval=T, echo=F, results="asis"}
if (nrow(pheno.sub)!=nrow(pheno.of.interest)) {
  pandoc.table(tbsum_func(tb=pheno.sub), split.tables=Inf, caption="Summary of subsetted samples without QC")
  pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples with QC")
} else {pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples")}

# create a summary table for this comparison
pandoc.table(t(infosumm_func(pheno=pheno.of.interest)$df),split.tables=Inf, caption="Summary of the comparison")
```

```{r, eval=T, echo=F}
# assign colours to comparison status
colour_status <- c("navy","red")
names(colour_status) <- c(con0,con1) # assign red to condition 1 and navy to condition 2
colour_status_list <- unlist(lapply(pheno.of.interest$Status,function(x){colour_status[x]}))
# assign colours to scan date
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
if ("ScanDate_Group"%in%names(pheno)) {
  i=nlevels(pheno.of.interest$ScanDate_Group)
  colour_scandate <- colours[1:i]
  names(colour_scandate) <- levels(pheno.of.interest$ScanDate_Group) # colour to corresponding scan date
  colour_scandate_list <- unlist(lapply(pheno.of.interest$ScanDate_Group,function(x){colour_scandate[x]}))
}
```

### Gene expression data preparation

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and unextract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (usesuppl) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno$Filename))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}

  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)
}
```

```{r, eval=T, echo=F, message=F, warning=F}
if (!usesuppl) {
  # check if GEO matrix file exists
  geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
  if (length(geo_fn)==0) { # # GEO matrix file is not downloaded
    gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
    if (length(gselms)>1) {  # multiple platform
      gpls=sapply(gselms,annotation)
      cat("This study was performed in multiple platforms:\n")
      cat(unname(gpls),"\n")
      cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
      if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
    } else {idx=1}
    gse <- gselms[[idx]]
  } else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
    gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
  } else { # GEO matrix file is alreadly downloaded and has multiple platforms
    cat("This study was performed in multiple platforms:\n")
    cat(geo_fn)
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <-geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
  }
  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.data=gse
}
```

```{r, eval=T, echo=F}
# The subdat_func function subsets data based on the phenotype of interest
subdat_func <- function(raw.data, pheno) {
  # subset raw.data based on the phenotype of interest
  raw.data=raw.data[,colnames(raw.data)%in%pheno$Filename]
  # assign phenotype data to raw expression data
  pData(raw.data) <- pheno
  row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
  # check if the sample names derived from expression data match those in phenotype file
  if (usesuppl) {matching=mapply(identical,row.names(pData(raw.data)),as.character(pheno$Filename))}
  else {matching=mapply(grepl,row.names(pData(raw.data)),as.character(pheno$Filename))}
  if (!all(matching)) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
  return(raw.data)
}
raw.data.of.interest=subdat_func(raw.data=raw.data, pheno=pheno.of.interest)
```

Show expression dataset features
```{r, eval=T, echo=F}
raw.data.of.interest
```

## Differential Gene Expression Analysis

### Normalize raw gene expression data

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data.of.interest),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data.of.interest)=apply(exprs(raw.data.of.interest),2,function(x){replace(x,which(x<=0),NA)})
```

```{r, eval=T, echo=F, message=F, results="hide"}
if (usesuppl) {
  rma.data.of.interest = rma(raw.data.of.interest)
  cat("RMA normalization is used.\n")
} else {
  rma.data.of.interest=raw.data.of.interest
  if (!normdata) {exprs(rma.data.of.interest)=normalize.quantiles(log2(exprs(rma.data.of.interest)))
  cat("Quantile normalization and log2 transformation is used.\n")
  }
}
```

```{r, eval=T, echo=F}
cols=colour_status_list
boxplot(raw.data.of.interest,target="core",col=cols,main="Raw Probe Intensities",xaxt="n") # view raw data
legend("topright",legend=names(colour_status),fill=colour_status)

if (!normdata) {
  boxplot(rma.data.of.interest,col=cols,main="Normalized Probe Intensities",xaxt="n") # view RMA-adjusted data
  legend("topright",legend=names(colour_status),fill=colour_status)
} else {cat("The raw data is already normalized")}
```


### Pairwise Comparison between Status

```{r, eval=T, echo=F, results="asis"}
limma_func <- function(paired=FALSE) { # here only con0, con1 are used in comparisons. use a function to reduce the factor levels
  if (paired) {
    cat("Donor is adjusted in this regression\n")
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$Donor)) # create design model matrix
    colnames(design) = c(levels(factor(rma.data.of.interest$Status)),levels(factor(rma.data.of.interest$Donor))[-1])
  } else {
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)) # create design model matrix
    colnames(design) = levels(factor(rma.data.of.interest$Status))
  }
  fit = lmFit(rma.data.of.interest, design) # fit a linear model to estimate the fold changes and standard error
  # Create a contrast group and fit it in a linear model
  data.contrast = makeContrasts(contrasts=paste(c(con1,con0),collapse="-"),levels = design) # create a contrast group by comparing con1 vs con0
  fit2 = contrasts.fit(fit, data.contrast) # get the contrasts for samples of interest
  fit2 = eBayes(fit2) # adjust fit coefficients using an empirical Bayes moderation of standard errors
  return(list(design=design,data.contrast=data.contrast,fit2=fit2))
}
```

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
res_DE=limma_func(paired=paired)
fit2=res_DE$fit2
pandoc.table(data.frame(Sample=rma.data.of.interest$Sample,res_DE$design), split.tables=Inf, caption="A design model matrix for linear model")
pandoc.table(as.data.frame(res_DE$data.contrast), caption="A contract matrix for comparison")
contrast_table <- topTable(fit2, adjust="BH",num=Inf) # get full set of results for each hypothesis test
col.sel=c("logFC","AveExpr","t","P.Value","adj.P.Val","B") # select the columns of DE results
contrast_table <- data.frame(ID=row.names(contrast_table), contrast_table[,col.sel])
```

### Adjusting for Batch Effect

```{r, eval=T, echo=F}
# The nbatch_func function obtains number of batches (scan date) in the data
nbatch_func <- function() {
  if (!"ScanDate_Group"%in%names(pData(rma.data.of.interest))) {nbatch=0} else {nbatch=nlevels(rma.data.of.interest$ScanDate_Group)}
}

# The svamod_func function creates full and null models, and Checks if the batch and comparison status are confounded
svamod_func <- function(paired=FALSE) {
  # Create a full model
  modBatch = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)) # full model (adjusted variables and variables of interest)
  # Create a null model only including batch variables
  nullBatch =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)) # null model (adjusted variables only)
  # Check if the scan date and comparison status are confounded
  if (class(try(solve(t(modBatch)%*%modBatch),silent=T))=="matrix") {batchadj=TRUE} else {batchadj=FALSE; message("The scan date and comparison status are highly confounded")}
  # summary of the full model
  tb.fullmod <- as.data.frame(modBatch)
  names(tb.fullmod) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])
  # summary of the null model
  tb.nullmod <- as.data.frame(nullBatch)
  names(tb.nullmod) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])

  donoradj=NULL # assign variable is donor is adjusted
  tb.nullmod1=NULL # assign null matrix for donor adjustment
  if ((paired)&(batchadj)) { # same donor treatment adjust for donor
    # Test if donor and scandate are correlated
    modBatch1 = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # full model including donor
    nullBatch1 =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # null model including donor
    # summary of the full model
    tb.fullmod1 <- as.data.frame(modBatch1)
    names(tb.fullmod1) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
    # summary of the null model
    tb.nullmod1 <- as.data.frame(nullBatch1)
    names(tb.nullmod1) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
      
    # check if scandate correlated with donor
    if (class(try(solve(t(modBatch1)%*%modBatch1),silent=T))=="matrix") {
      donoradj="yes"
      modBatch=modBatch1
      nullBatch=nullBatch1
      tb.fullmod=tb.fullmod1
      tb.nullmod=tb.nullmod1
    }
  }

  return(list(modBatch=modBatch, nullBatch=nullBatch, tb.fullmod=tb.fullmod, tb.nullmod=tb.nullmod, batchadj=batchadj, donoradj=donoradj, tb.nullmod_donor=tb.nullmod1))
}

# The batcherror_func function assigns a variable batcherror to decide whether to adjust for batch effect under various scenarios
batcherror_func <- function() {
  if (nbatch==0) {
    batcherror="zero"
  } else if (nbatch==1) {
    batcherror="one"
  } else {
    if (batchadj) {batcherror="no"} else {batcherror="correlate"}
  }
  return(batcherror)
}

# The batchadj_func function outputs table with batch effects adjusted p-values
batchadj_func <- function(batcherror=batcherror, contrast_table=contrast_table, paired=paired) {
  if (batcherror=="no") {
    modBatch=svamod_func(paired=paired)$modBatch
    nullBatch=svamod_func(paired=paired)$nullBatch
    pValuesBatch=f.pvalue(exprs(rma.data.of.interest), modBatch, nullBatch) # get batch effect-adjusted p-values
    qValuesBatch=p.adjust(pValuesBatch, method="BH") # get q-values
    tb.sva <- data.frame(ID=names(pValuesBatch),pValuesBatch,qValuesBatch)
    contrast_table <- merge(contrast_table, tb.sva, by="ID", all=TRUE)
  } else if (batcherror=="correlate") {
    contrast_table$pValuesBatch=contrast_table$qValuesBatch=rep(NA,nrow(contrast_table))
  } else {
    contrast_table$pValuesBatch=contrast_table$P.Value
    contrast_table$qValuesBatch=contrast_table$adj.P.Val
  }
  return(contrast_table)
}
```

```{r, eval=T, echo=F}
nbatch=nbatch_func()
if (nbatch>1) {res_svamod=svamod_func(paired=paired);batchadj=res_svamod$batchadj}
batcherror=batcherror_func()
if (batcherror=="zero") {cat("No scan date is present in the data.")} else if (batcherror=="one") {cat("Only one batch is present in the data.")} else if (batcherror=="correlate") {cat("The scan date and the comparison status are highly confounded (See the model matrix). Cannot ajust for batch effect.")}
```

```{r, eval=T, echo=F, results="asis"}
if (nbatch>1) {
  if (paired) {
    if (is.null(res_svamod$donoradj)) {
      cat("Scan date and donor are highly confounded. See the matrix below.\n")
      pandoc.table(res_svamod$tb.nullmod_donor, split.tables=Inf, caption="Null model matrix with scan date and donor")
      cat("Only adjust for scan date.\n")
    } else {cat("Both scan date and donor are adjusted.\n")}
  }
  pandoc.table(res_svamod$tb.fullmod, split.tables=Inf, caption="Full model matrix")
  pandoc.table(res_svamod$tb.nullmod, split.tables=Inf, caption="Null model matrix")
}
```

```{r, eval=T, echo=F, results="asis"}
contrast_table=batchadj_func(batcherror=batcherror, contrast_table=contrast_table, paired=paired)
pandoc.table(summary(contrast_table), split.tables=Inf, caption=paste0(con1, " vs. ", con0, " summary"))
```


### Assign Official Gene Symbol

```{r, eval=T, echo=F}
anno_list=list()
# Affymetrix
anno_list[["pd.hg.u133.plus.2"]]="hgu133plus2.db"
```

```{r, echo=F}
# glpanno_func creates anntoation vector based on GPL annotation from GEO
glpanno_func <- function(GPL_ID){
  gpl <- Table(getGEO(GPL_ID, destdir = "data"))
  if (GPL_ID%in%names(symbol_list)) {anno_vect <- gpl[,symbol_col]} else {anno_vect <- gpl[,"gene name"]}
  names(anno_vect) <- gpl[,"ID"]
  return(anno_vect)
}

# ranno_func creates anntoation vector based on R annotation database
ranno_func <- function(anno_lib){
  # check if the annotation database is installed
  if (!anno_lib%in%installed.packages()[,1]){source("http://bioconductor.org/biocLite.R"); biocLite(anno_lib)}
  library(anno_lib, character.only=T)
  anno_symbol=gsub(".db","SYMBOL",anno_lib) # The name of the R object mapping between probe id and gene symbol
  x=get(anno_symbol)
  # Get the probe identifiers that are mapped to a gene symbol
  mapped_probes <- mappedkeys(x)
  # Convert to a list
  xx <- as.list(x[mapped_probes])
  # Convert list to annotation vector
  anno_vect <- sapply(xx,function(x){x})
  return(anno_vect)
}

# geneannot_func annotates gene symbol to DE result table
geneannot_func <- function(tb, anno_vect) {
  remove.pm <- function(x) {gsub("_PM", "", x)} # Assign official gene symbol using hgu133plus2.db package if anntoation is based on pd.hg.u133.plus.2. Note that the probe names have additional "PM"s in the results will be removed to match the names in the gene symbol package.
  if (exists("anno_lib")) {
    if (anno_lib=="hgu133plus2.db") {tb$ID=sapply(as.character(tb$ID), remove.pm)}
  }
  tb$ID=as.character(tb$ID)
  tb$SYMBOL=sapply(as.character(tb$ID), function(x){if (x%in%names(anno_vect)){anno_vect[x]} else {"NA"}})
  tb$SYMBOL[which(tb$SYMBOL=="")]="NA"
  # remove probes with NA in logFC column
  tb <- tb[!is.na(tb$logFC),]
  tb[order(tb$P.Value),]
}
```

```{r, eval=T, echo=F, warning=F, message=F}
# install corresponding annotation database if it is not installed
anno_array=annotation(rma.data.of.interest)
cat("The platform used is", anno_array, "\n")
if (!anno_array%in%names(anno_list)) {
  cat("Annotate using GPL annotation in GEO\n")
  anno_vect=glpanno_func(GPL_ID=anno_array)
} else {
  anno_lib=anno_list[[anno_array]] # use the annotation database
  cat("The corresponding R annotation database package is", anno_lib,"\n")
  anno_vect <- ranno_func(anno_lib=anno_lib)
}
```

```{r, eval=T, echo=F}
contrast_name=infosumm_func(pheno=pheno.of.interest)$name # adopt Unique_ID created in the information summary table
contrast_fn=paste0(resdir,"/", contrast_name, ".csv")
```

```{r, eval=T, echo=F, warning=F, message=F}
contrast_table <- geneannot_func(tb=contrast_table, anno_vect=anno_vect)
write.csv(contrast_table, file=contrast_fn, row.names = FALSE)
```

```{r, eval=T, echo=F}
if (file.exists(contrast_fn)) {contrast_fn=paste0(resdir,"/", contrast_name, ".csv")}
res=read.csv(contrast_fn)
```

## Gene Expression Results Visualization

### Volcano Plots

```{r, eval=T, echo=F}
# The volplot_func function generates volcano plots
volplot_func <- function(df,qval_column,title) {
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else {          
    df <- df[!is.na(qval),] # remove NA values
    qval <- df[,qval_column]
    if (min(df[,qval_column])>=0.05) {
      df$sig <- "black" # assign colors to DE and non-DE genes
    } else {
      # assign colors to DE and non-DE genes
      df$sig <- rep(NA,nrow(df))
      df$sig[qval<0.05] <- "red"
      df$sig[qval>=0.05] <- "black"
    }
    df$sig <- as.factor(df$sig)
    color <- levels(df$sig)
    # log10 transformed q values
    df$logqval <- -log10(qval)
    diffgenes <- df$ID[qval<0.05] #Create list of all DEG's
    signum = paste0(length(diffgenes), " significant genes based on ", qval_column)
    if (missing(title)) {title=signum}
    print(
    ggplot(df, aes(x = logFC, y = logqval, color=sig)) + geom_point() +
      theme_bw() +
      labs(title=title,x="logFC",y=paste0("-log10(",qval_column,")")) +
      scale_color_manual(values=color) +
      theme(legend.position="none")
    )
  }
}
```

Volcano plot (probes with a q-value <0.05 are present in red)

```{r, eval=T, echo=F, fig.height=4, fig.width=4.5}
for (qval in c("adj.P.Val","qValuesBatch")) {volplot_func(res, qval)}
```


### Histograms

```{r, eval=T, echo=F}
# The histplot_func function generates histogram for p-value distributions
histplot_func <- function(df,qval_column,title) {
  if (missing(title)) {title=""}
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else{hist(qval,main=title,xlab=qval_column)}
}
```

Histograms of p-value distributions

```{r, eval=T, echo=F, fig.width=4.5, fig.height=4}
for (pval in c("P.Value","pValuesBatch")) {histplot_func(res, pval)}
for (qval in c("adj.P.Val","qValuesBatch")) {histplot_func(res, qval)}
```

### Top 20 Differentially Expression Results

```{r, eval=T, echo=F}
# The datreform_func function reformats the DE table
datreform_func <- function(dt,topnum=200) {
  dt=dt[order(dt$P.Value),]
  dt=dt[1:topnum,]
  round2 <- function(x){round(x,2)}
  dt[,c("logFC","AveExpr","t","B")] <- sapply(dt[,c("logFC","AveExpr","t","B")],round2)
  sciform <- function(x){format(x,scientific=TRUE,digits =2)}
  dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")] <- sapply(dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")],sciform)
  dt
}
```

Show top 20 probes sorted by un-adjusted p-values

```{r, eval=T, echo=F, results="asis"}
res <- datreform_func(dt=res)
rownames(res) <- NULL
pandoc.table(res[1:20,],split.tables=Inf)
```

### Boxplots for Top 6 Differentially Expressed Genes

This step helps to visualize and check the effect direction in the comparison.

```{r, eval=T, echo=F}
# function for top gene boxplot
topgene_boxplot_func <- function(tb,colour,comp) { # comp: comparison status
  for (i in 1:nrow(tb)) {# top i probe in res
    if (missing(comp)) {comp=""}
    if (missing(colour)) {colour=colours[1]}
    probe_top <- tb$ID[i]
    gene_top <- tb$SYMBOL[i]
    row.names(rma.data.of.interest) <- gsub("_PM","",row.names(rma.data.of.interest))
    values=exprs(rma.data.of.interest)[row.names(rma.data.of.interest)%in%probe_top, ]
    status=rma.data.of.interest$Status
    df <- data.frame(values=values,status=status)
    title=paste0(comp," top ",i," probe ", probe_top, " gene ", gene_top)
    print(
      ggplot(df,aes(x=status,y=values)) +
        geom_boxplot(outlier.colour=NA,color="grey18",fill=colour) +
        stat_boxplot(geom ='errorbar', color="grey18") +
        geom_jitter(size=1,position = position_jitter(width=0.3)) +
        labs(title=title) +
        theme_bw() +
        theme(legend.position="none",axis.title=element_blank())
    )
  }
}
```

```{r, eval=T, echo=F, message=F, warning=F, fig.height=4, fig.width=4.5}
topgene_boxplot_func(tb=res[1:6,])
```


### Heatmap for Top 200 Differentially Expressed Genes

```{r, eval=T, echo=F}
# The heatmap_topgene_func function for top gene heatmap plots
heatmap_topgene_func <- function(tb, topnum=200, colour_status_list, colour_status, main="") { # colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  top.rma <- rma.data.of.interest[row.names(rma.data.of.interest)%in%tb[1:topnum,"ID"],] # plot heatmap for top 200 genes
  array_name <- shortname_func(colnames(exprs(top.rma))) # shorten the sample id
  heatmap.2(na.omit(exprs(top.rma)), col=viridis(256, option="B"),
    ColSideColors=colour_status_list, # use predefined colour_status_list, assign colors to status
    labCol=array_name,labRow = "", # take out gene probe id
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow=1,cexCol=1,
    keysize=1.5,key.title=NA,key.xlab="Gene Expression Values",key.ylab="Counts",
    main=main)
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.8) # use predifined colour_status
}
```


```{r, eval=T, echo=F, fig.height=10, fig.width=12}
heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_status_list, colour_status=colour_status, main="Gene expression heatmap by comparison status")
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Gene expression heatmap by scan date")
}
```

### Heatmap for Sample Correlation

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# The corplot_func function plots correlation between samples
corplot_func <- function(m, colour_status_list, colour_status, main="") {  # m: correlation matrix, colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  m <- cor(na.omit(m)) # compute correlation matrix
  # compute distance based on 1-correlation efficient
  dend = as.dendrogram(hclust(as.dist(1-m), method = "single"))
  ord = order.dendrogram(dend)
  array_name <- shortname_func(colnames(m)) # shorten the sample id
  # heatmap plot
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256,option="B"), ColSideColors=colour_status_list, RowSideColors=colour_status_list,
    labCol=array_name, labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.6)
}
```


```{r, eval=T, echo=F, fig.height=10, fig.width=12}
corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_status_list, colour_status=colour_status, main="Correlation heatmap by comparison status")
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Correlation heatmap by scan date")
}
```

### Principal Component Analysis (PCA)

```{r, eval=T, echo=F, warning=F, message=F, results="asis"}
# The pcastat_func function computes principal components
pcastat_func <- function(m) {
  # obtain original expression data
  raw.data.pca <- na.omit(apply(m,2,function(x)replace(x,is.infinite(x),NA))) # replace infinite values to NAs and omit NAs
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(oligo.data, pc, group_var, legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(oligo.data)[,group_var]
  )
  i=length(levels(pData(oligo.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(oligo.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(oligo.data, pc) {
  group_vars=c("ScanDate_Group", "Status", "Donor")
  legends=c("ScanDate_Group", "Status", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(oligo.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    pData(oligo.data)[,group_var]=as.factor(as.character(pData(oligo.data)[,group_var])) # convert to factor
    nlevel=nlevels(pData(oligo.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=10)) {
      if (group_var=="Status") {
        plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)+scale_color_manual(legend,values=colour_status,na.value="grey") # assign colour to comparison stauts
      } else {plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)}
    }
  }
  return(plot_list)
}
```

1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=F, warning=F, message=F, results="asis"}
res_pca <- pcastat_func(m=exprs(rma.data.of.interest))
pandoc.table(res_pca$tb, split.tables=Inf, caption="Variance explained")
```

2. PCA plots

```{r, eval=T, echo=F, message=F, warning=F}
plot_list=pca_func(oligo.data=rma.data.of.interest, pc=res_pca$pc)
for (i in plot_list) {print(i)}
```

## Quality Control for GSE26378

```{r, eval=T, echo=T}
# GEO id
geo_id="GSE26378"
```

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*)\\.(cel|CEL).gz","\\1",x)}
```

```{r, eval=T, echo=F, message=F, warning=F}
library(GEOquery)
library(oligo)
library(viridis) # heatmap colour
library(ggplot2)
library(gplots) # heatmap.2 plot
library(Hmisc) # compute hoeffd (Hoeffding's D statistics) for MA plot
library(devtools) # compuate PCs
library(preprocessCore) # quantile normalization
library(pander)
```

## GEO Data Download and Phenotype Preparation

### GEO Dataset Download

```{r, eval=T, echo=F, message=F, warning=F}
# check if GEO matrix file exists
geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
if (length(geo_fn)==0) { # GEO matrix file is not downloaded
  gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
  if (length(gselms)>1) {  # multiple platform
    gpls=sapply(gselms,annotation)
    cat("This study was performed in multiple platforms:\n")
    cat(unname(gpls),"\n")
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
  } else {idx=1}
  gse <- gselms[[idx]]
} else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
  gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
} else { # GEO matrix file is alreadly downloaded and has multiple platforms
  cat("This study was performed in multiple platforms:\n")
  cat(geo_fn)
  cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
  if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <- geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
}
```


Show expression dataset features
```{r, eval=T, echo=F}
gse
```

### Modify raw phenotype information

```{r, eval=T, echo=F, results="asis"}
pheno.raw <- pData(phenoData(gse))
for (x in names(pheno.raw)) {
  vec=pheno.raw[,x]
  if (!is.numeric(vec)) {
    # create an empty data frame to save any tables with non-native characters
    tb_nonnative=data.frame()
    vec <- factor(vec)
    if (nlevels(vec)>5) {res=table(droplevels(vec[vec%in%levels(vec)[1:5]]))} else {res=table(vec)}
    res=data.frame(res)
    names(res) <- c(x,"counts")
  }
  if (is.numeric(vec)){res=summary(vec)}
  # Try if any existing non-native characters cause pander error
  if (class(try(pandoc.table(res, justify='left',split.tables=Inf, caption=x), silent = T))=="try-error") {tb_nonnative=res}
  if (nrow(tb_nonnative)>1){print(res)}
}
```

```{r, eval=T, echo=F}
# check if there is missing supplementary_file
if (all(pheno.raw$supplementary_file=="NONE")) {
  suppldata=FALSE
} else if (any(pheno.raw$supplementary_file=="NONE")) {
  sample_nosuppl=as.character(pheno.raw$geo_accession[pheno.raw$supplementary_file=="NONE"])
  pheno.raw=pheno.raw[which(pheno.raw$supplementary_file!="NONE"),]
  cat("Not all samples have defined supplementary file path:\n")
  cat(paste(sample_nosuppl,collapse=", "),"\n")
  cat("These samples are excluded from analysis\n")
  suppldata=TRUE
} else {suppldata=TRUE}
```

```{r, eval=T, echo=F}
cat("suppldata =",as.character(suppldata))
```

#### Phenotype information modification

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
library(dplyr)
cols <- c("title","geo_accession","source_name_ch1")
pheno <- pheno.raw %>%
  dplyr::select(cols) %>%
  dplyr::mutate(GEO_ID=geo_accession) %>%
  dplyr::mutate(Donor=gsub("^.*biological (.*)$","\\1",title)) %>%
  dplyr::mutate(Sample=paste(geo_accession,Donor,sep="_")) %>%
  dplyr::mutate(Tissue="Blood") %>%
  dplyr::mutate(treatment_time=gsub("^.*for (\\d+.*)$","\\1",source_name_ch1)) %>%
  dplyr::mutate(treatment_time=gsub(" ","",treatment_time)) %>%
  dplyr::mutate(treatment_drug=ifelse(grepl("sepsis",source_name_ch1),"sepsis","healthy")) %>%
  dplyr::mutate(Treatment="24hr") %>%
  dplyr::mutate(Disease=c(rep("Shock",6), rep("Control",2), rep("Shock",1), rep("Control",4), rep("Shock",26), rep("Control",1), rep("Shock",8), rep("Control",1), rep("Shock",13), rep("Control",2), rep("Shock",13), rep("Control",5), rep("Shock",12), rep("Control",6), rep("Shock",3))) %>%
  dplyr::mutate_if(is.character,as.factor) %>%
  dplyr::select(-one_of(cols)) # remove original columns
detach("package:dplyr")
```

### Raw intensity data download

```{r, eval=T, echo=F}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and extract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (suppldata) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno.raw$supplementary_file))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}
}
```

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
if (platform=="Affymetrix"&suppldata) {
  #1. Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)

  #2. Obtain scan date information from the raw.data for batch effect adjustment
  # As the scan date and scan time are usually joined by "T" or a white space, use both pattern to split the date with time
  pheno$ScanDate_Group <- sapply(strsplit(as.character(protocolData(raw.data)$dates), "T| "), function(x) {x[[1]]})
  pheno$ScanDate_Group <- as.factor(pheno$ScanDate_Group)
}
```

```{r, eval=T, echo=F}
if (!suppldata) {raw.data=gse}
```

```{r, eval=T, echo=F}
# assign phenotype data to raw expression data
pData(raw.data) <- pheno
row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
# Check if the sample names derived from expression data match those in phenotype file
rowname <- gsub("^(.*).(cel|CEL|txt|Txt).gz","\\1",row.names(pData(raw.data)))
matching <- mapply(grepl, x=rowname, pattern=as.character(pData(raw.data)$GEO_ID))
if (FALSE %in% matching) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
```

```{r, eval=T, warning=F,results="asis",echo=F}
# show the first five rows
pandoc.table(head(pheno,5), split.tables=Inf,caption="Show the first 5 rows of the modified phenotype file")
# show the groups of interest
avail_group=c("Tissue","Disease","Treatment")[c("Tissue","Disease","Treatment")%in%names(pheno)]
res=as.data.frame(table(pheno[,avail_group]))
names(res) <- c(avail_group,"Count")
pandoc.table(res, split.tables=Inf, caption="Sample size in different tissue and disease/treatment groups")
# show samples in different batch
if ("ScanDate_Group"%in%names(pheno)) {
  res=as.data.frame(table(pheno[,"ScanDate_Group"]))
  names(res) <- c("ScanDate_Group","Count")
  pandoc.table(res, split.tables=Inf, caption="Sample size in different batch")
} else {cat("No scan date information.")}
```

```{r, eval=T, echo=F}
# assign colours to Scan Date for plots
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
vars=c("ScanDate_Group","Treatment","Disease")
leveluse=sapply(vars,function(x){if(x%in%names(pheno)){nlevel=nlevels(pheno[,x])}else{nlevel=0};nlevel>1})
if (any(leveluse)){varuse=names(which(leveluse)[1])}else{stop("None of the following variables scan date/Disease/Treatment has >1 level. Check the dataset!")} # varible assigned color in plot

# assign colour to corresponding variable (scan date if available otherwise disease/treatment)
i=nlevels(pheno[,varuse])
colour_list <- colours[1:i]
names(colour_list) <- levels(pheno[,varuse]) 
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data)=apply(exprs(raw.data),2,function(x){replace(x,which(x<=0),NA)})
```


```{r, eval=T, echo=F, warning=F}
if (!suppldata|platform!="Affymetrix") {
  boxplot(exprs(gse),col=colour_list,main="Probe Intensity matrix of raw data",xaxt="n") # note gse here are non-coverted expression values
  legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  if (!normdata) {
    boxplot(log2(exprs(raw.data)),col=colour_list,main="Probe Intensity matrix of log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
    boxplot(normalize.quantiles(log2(exprs(raw.data))),col=colour_list,main="Probe Intensity matrix of qnormed log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  }
}
```

```{r, eval=T, warning=F, echo=F}
if (geo_GPL=="") {pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_Phenotype_withoutQC.txt"); pheno_fn_withQC=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else
{pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withoutQC.txt");pheno_fn_withQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
write.table(pheno,pheno_fn_withoutQC,col.names=T,row.names=F,sep="\t",quote=F)
```


## Quality Control for Microarray Data

```{r, eval=T, echo=F}
pheno <- read.table(pheno_fn_withoutQC, header=T, sep="\t")
```

### Raw Probe Intensity Boxplots and Density Histograms

```{r, eval=T, echo=F, warning=F}
# The subsamp function randomly selects 20000 probes
subsamp <- function(x,num=20000, seed=123) {
  set.seed(seed)
  subsample=num # if number of probes are >20000, randomly select 20000 probes for plot or compute
  if (nrow(x)>subsample) {
    ss  = sample(nrow(x), subsample)
    Mss = x[ss,,drop=FALSE]
  } else {
    ss  = TRUE
    Mss = x
  }
  Mss
}

# The outlier_KS_func function computes KS statistics for outlier detection
outlier_KS_func = function(exprs) { # matrix (row: probe intensities/RLE values etc., col: array (e.g. sample))
  fx = ecdf(as.vector(exprs)) # get empirical cumulative distribution function of the data
  KS=suppressWarnings(apply(exprs, 2, function(v)ks.test(v, y = fx, alternative="two.sided")$statistic))
  stats = stats::fivenum(KS, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=KS, outlier = which(KS > th))
}

# The boxplot_func function generates boxplots for raw data metrics (e.g. probe intensities, RLE, NUSE) 
boxplot_func <- function(Mss,outlier,ylab) {
  # use * to mark the outliers in boxplot
  array_name <- shortname_func(colnames(Mss))
  outlier <- shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  # boxplot raw intensity by array
  ylim = quantile(Mss, probs = c(0.01, 0.99), na.rm=TRUE) # create range of y-axsis
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df, aes(sample_id,values,fill=scandate)) + geom_boxplot(outlier.colour=NA) +
    coord_flip() + theme_bw() +
    ylim(ylim) +
    scale_x_discrete(labels=array_name) +
    ylab(ylab) +
    scale_fill_manual(varuse,values=cols) +
    theme(axis.title.y=element_blank())
}

# The densplot_func function plots density curve for raw data metrics (e.g. probe intensity)
densplot_func <- function(Mss) {
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df,aes(x=values,colour=scandate)) + geom_line(aes(group=sample_id),stat="density") +
    theme_bw() +
    xlab("Raw Probe Intensities") +
    ylab("Density") +
    scale_color_manual(varuse,values=cols)
}

# The raw_intensity_func function outputs raw probe intensity metrics
raw_intensity_func <- function() {
  if (!normdata) {Mss=log2(subsamp(exprs(raw.data))) # use log2 transformed raw probe intensity
  } else {
    Mss=subsamp(exprs(raw.data))
  }
  outlier_res=outlier_KS_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss=Mss, outlier=outlier, ylab="Raw Probe Intensities")
  densplot=densplot_func(Mss=Mss)
  return(list(outlier=outlier,boxplot=boxplot,densplot=densplot))
}
```

1. Outlier detection for log2 raw probe intensity/normalized intensity

```{r, eval=T, echo=F, warning=F}
res_intensity=raw_intensity_func()
outlier_intensity = res_intensity$outlier
cat(length(outlier_intensity), "outlier(s) are detected in the raw intensity metrics.\n")
if (length(outlier_intensity)>0) {cat("They are: ", shortname_func(outlier_intensity))}
```

2. Boxplots for log2 raw probe intensity

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
res_intensity$boxplot
```

3. Density curves for log2 raw probe intensity

```{r, eval=T, echo=F, message=F, warning=F}
res_intensity$densplot
```

### RNA Digestion

```{r, eval=T, echo=F}
# The RNAdegaffy_func function compute mean PM intensities in each probe position following 5' to 3' order. Adopted from the AffyRNAdeg function in the affy package but include a step that randomly selects 20,000 probe sets.
RNAdegaffy_func <- function(data){ # input a list of probe set matrix with rows as probe ids and columns as samples
  {
    names <- colnames(data[[1]])
    probe.set.size <- function(x) {
      size <- dim(x)[1]
      return(size)
    }
    max.num <- sapply(data, probe.set.size) # get the number of probes in each probe set
    tab <- (table(max.num)) # summarize the frequencies of probe numbers in probe sets
    ord <- order(-as.numeric(tab)) # order the frequency from large to small
    K <- as.numeric(names(tab))[ord[1]] # K is the number of probes appearing in most probe sets
    data <- data[max.num == K] # select data of probe sets only have K number of probes
  }
  
  subsample=20000
  if (length(data)>subsample) { # randomly select 10000 probe sets
    set.seed(12345)
    ss = sample(length(data),subsample)
    data = data[ss,drop=FALSE]
  }

  N <- length(data) # number of probe sets
  n <- dim(data[[1]])[2] # number of samples
  
  # create two matrices: number of samples * number of probes representing a probe set
  mns <- matrix(nrow = n, ncol = K) # create matrix for mean values
  sds <- mns # create matrix for sds values

  get.row <- function(x, i = 1) {return(x[i, ])} # function to get each row (i.e. probe id, i) from one probe set x (i.e. probe list[[x]])
  rowstack <- function(x, i = 1) {return(t(sapply(x, get.row, i)))} # function to combine the rows obtained using get.row (pms across samples by probe sets) to get a table (row: samples column: probe sets) and transpose the table (row: probe sets, column: samples)

  for (i in 1:K) { # get probe id (position) from 1 to K from each probe set
    data.stack <- rowstack(data, i) # get the probe pm values in a specific probe position across all samples from each probe set (rows are samples and columns are probe sets)
    if(dim(data[[1]])[2]==1) data.stack <- t(data.stack)
    mns[, i] <- colMeans(data.stack) # get the mean values at one probe position across all probe sets
    sds[, i] <- apply(data.stack, 2, sd) # get the sd values at one probe position across all probe sets
  }
    
  mns.orig <- mns # store the original mns data matrix
  mn <- mns[, 1] # select values in the first probe position
  mns <- sweep(mns, 1, mn) # adjust for the intensity at the first probe position
  mns <- mns/(sds/sqrt(N)) # adjust for standard error
  lm.stats <- function(x) {
    index <- 0:(length(x) - 1)
    ans <- summary(lm(x ~ index))$coefficients[2, c(1, 4)] # use linear model fit the relationship between intensity and probe position
    return(ans)
  }
  stats <- apply(mns, 1, lm.stats)
  answer <- list(N, names, mns.orig, sds/sqrt(N), stats[1,], stats[2, ])
  names(answer) <- c("N", "sample.names", "means.by.number","ses", "slope", "pvalue")
  return(answer)
}

# The RNAdeg_func function generates RNA degradation plots
# return a logical variable whether this array type can be read by affy.
RNAdeg_func <- function() {
  # 1. Read in raw data as an AffyBatch object
  library(affy) # for Affymetrix microarray-specific QC analysis
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  # 2. Obtain a list of probe sets with a matrix of oligos (probes) by samples as an input and compute statistics of the mean PM intensities from 5' to 3' probe positions. 
  PM_list <- affy::pm(raw.data.affy,LIST=T) 
  PM_list <- lapply(PM_list,log2)
  raw.data.rnadeg <- RNAdegaffy_func(PM_list) # Compute mean PM intensity for probes following 5' to 3' order.
  # 3. Plot 5' to 3' mean PM intensity
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  plotAffyRNAdeg(raw.data.rnadeg,cols=status.cols)
  legend("topleft",legend=names(colour_list),fill=colour_list,cex=0.6)
  detach("package:affy", unload=TRUE) # detach the affy package
}
```

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {RNAdeg_func()}
}
```

### Distribution of Perfect Match (PM) and Mismatch (MM)

```{r, eval=T, echo=F}
PMMM_func <- function() {
  if (class(raw.data)=="GeneFeatureSet") {
    message("GeneFeatureSet does not have MM probes. No plots will be generated.")
  } else {
    PM <- log2(pm(raw.data))
    MM <- log2(mm(raw.data))
    if(nrow(PM) != nrow(MM)) {
      message("This might be a PM-only array. No plots will be generated.")
      rm(PM,MM)
    } else {
      subsample=20000
      if(nrow(PM)>subsample) { # randomly select 20000 probe sets
        sel = sample(nrow(PM), subsample)
        sPM = PM[sel, ]
        sMM = MM[sel, ]
      } else {
        sPM = PM
        sMM = MM
      }
      rm(PM,MM) 
      
      df <- data.frame(
        values=c(as.numeric(sPM),as.numeric(sMM)),
        types=c(rep("PM",each=length(as.numeric(sPM))),rep("MM",each=length(as.numeric(sMM))))
      )
      cols=colours[1:2]
      ggplot(df,aes(x=values,colour=types)) + geom_line(aes(group=types),stat="density") +
        theme_bw() +
        xlab("Intensity") +
        ylab("Density") +
        scale_color_manual(values=cols) +
        theme(legend.title=element_blank())
    }
  }
}
```

```{r, eval=T, echo=F}
if (platform=="Affymetrix"&suppldata) {PMMM_func()}
```

### MA Plots

```{r, eval=T, echo=F}
# The MAcal_func function computes M and A matrices, while use the intensity of 20000 randomly selected probes
MAcal_func <- function(x) { # matrix (row: probe intensities, col: array (samples)
  medArray = rowMedians(x, na.rm=TRUE)
  M =  x - medArray
  A = (x + medArray)/2
  subsample=20000
  if(nrow(M)>subsample) {
    set.seed(12345)
    sel = sample(nrow(M), subsample)
    sM = M[sel, ]
    sA = A[sel, ]
  } else {
    sM = M
    sA = A
  }
  list(M=sM,A=sA) # return a list with M and A data matrices
}

# The outlier_MA_func function computes the Hoeffding's statistic (Da) statistics for outlier detection
outlier_MA_func <- function(exprs) { # list with M and A data matrices
  M=exprs$M
  A=exprs$A
  Dstats = sapply(1:ncol(M), function(x){hoeffd(A[,x], M[,x])$D[1,2]})
  names(Dstats) <- colnames(M)
  Dthresh = 0.15
  list(threshold=Dthresh, stats=Dstats, outlier = which(Dstats > Dthresh))
}

# The MAplot_func function plots samples with the first 4 highest and lowest values of Da. The value of Da for each sample is shown in the panel headings. Outliers marked with * have Da values >0.15.
MAplot_func <- function(sMA, outlier_res) {
# select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(sMA$M)-3):ncol(sMA$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  scandate_sel <- pData(raw.data)[,varuse][column_sel]
  M_sel <- sMA$M[,column_sel]
  A_sel <- sMA$A[,column_sel]
  # use * to mark the outliers
  array_name <- shortname_func(colnames(M_sel))
  outlier_MA=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_MA] <- paste0("*",array_name[array_name%in%outlier_MA])
  array_name <- paste0(array_name," (D=",stats_sel,")") # add D statistics to corresponding samples
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    scandate=rep(scandate_sel,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    A=as.numeric(A_sel)
  )
  # MA plots
  ggplot(df,aes(x=A,y=M,color=scandate)) + geom_point(alpha=0.1) + theme_bw() +
    scale_color_manual(varuse,values=colour_list) +
    facet_wrap(~sample_id,ncol=2)
}

# The MA_func function outputs MA metrics
MA_func <- function(){
  # Compute M-A metrics
  if (!normdata) {
    sMA <- MAcal_func(log2(exprs(raw.data)))
  } else {
    sMA <- MAcal_func(exprs(raw.data))
  }
  outlier_res <- outlier_MA_func(exprs=sMA)
  outlier <- names(outlier_res$outlier)
  plot <- MAplot_func(sMA=sMA, outlier_res=outlier_res)
  return(list(outlier=outlier, plot=plot))
}
```

1. Outlier detection for MA plots

```{r, eval=T, echo=F, message=F, warning=F}
res_MA=MA_func()
outlier_MA=res_MA$outlier
cat(length(outlier_MA), "outliers are detected in the MA metrics.\n")
if (length(outlier_MA)>0) {cat("They are: ", shortname_func(outlier_MA))}
```

2. MA plots

```{r, eval=T, echo=F, message=F, warning=F, fig.height=10, fig.width=7}
res_MA$plot
```

### Spatial Distribution

```{r, eval=T, echo=F}
# The affyspatial_func function computes spatial x- and y-coordinate using raw data object classed as AffyBatch
affyspatial_func <- function() {
  library(affy)
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  maxc = ncol(raw.data.affy) # number of probes in x-coordinate
  maxr = nrow(raw.data.affy) # number of probes in y-coordinate
  sx = rep(seq_len(maxc), each = maxr) ## spatial x-coordinate
  sy = rep(seq_len(maxr), maxc) ## spatial y-coordinate
  M = log2(affy::exprs(raw.data.affy))
  detach("package:affy", unload=TRUE)
  numArrays = dim(M)[2]
  return(list(M=M,numArrays=numArrays,sx=sx,sy=sy))
}

# The outlier_spatial_func function computes the Fourier coefficients for outlier detection
outlier_spatial_func <- function(affy_spatial_list) {
  sx=affy_spatial_list$sx # spatial x-coordinate
  sy=affy_spatial_list$sy # spatial y-coordinate
  M=affy_spatial_list$M
  numArrays=affy_spatial_list$numArrays
  maxx = max(sx, na.rm=TRUE)
  maxy = max(sy, na.rm=TRUE)
  stat_spatial = numeric(numArrays)
  for(a in seq_len(numArrays)) {
    mat = matrix(NA_real_, nrow=maxy, ncol=maxx)
    mat[cbind(sy, sx) ] = M[, a]
    pg  = fft(mat) ## periodogram, computes the discrete fourier transform
    npg = Re(pg*Conj(pg))
    npg[1,1] = 0 ## drop the constant component
    stat_spatial[a] = sqrt(sum(npg[1:4, 1:4]) / sum(npg)) # low frequency power
  }
  names(stat_spatial)=colnames(M)
  stats = stats::fivenum(stat_spatial, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=stat_spatial, outlier = which(stat_spatial > th))
}

# The spatplot_func function plots samples with the first 4 highest and lowest values of Fa. The value of Fa for each sample is shown in the panel headings.
spatplot_func <- function(raw.data.spatial,outlier_res) {
  # select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(raw.data.spatial$M)-3):ncol(raw.data.spatial$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  M_sel <- raw.data.spatial$M[,column_sel]
  # apply rank to expression data
  M_sel = apply(M_sel, 2, rank)
  # use * to mark the outliers
  array_name=shortname_func(colnames(M_sel))
  outlier_spatial=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_spatial] <- paste0("*",array_name[array_name%in%outlier_spatial])
  array_name <- paste0(array_name," (F=",stats_sel,")") # add F statistics to corresponding samples
  # create variables for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    row=rep(raw.data.spatial$sy,ncol(M_sel)),
    column=rep(raw.data.spatial$sx,ncol(M_sel))
  )
  # spatial distribution plots
  ggplot(df,aes(x=row,y=column,fill=M)) + geom_tile() + 
    theme_bw() +
    xlab("Raw Probe Intensiry in X") + ylab("Raw Probe Intensiry in Y") +
    scale_fill_gradientn(name="Ranked Intensity",colours=viridis(256,option="B")) +
    facet_wrap(~sample_id,ncol=2)
}

# The spatial_func function outputs spatial metrics
spatial_func <- function() {
  raw.data.spatial=affyspatial_func()
  outlier_res=outlier_spatial_func(affy_spatial_list=raw.data.spatial)
  outlier=names(outlier_res$outlier)
  plot=spatplot_func(raw.data.spatial=raw.data.spatial,outlier_res=outlier_res)
  return(list(outlier=outlier,plot=plot))
}
```


1. Outlier detection for spatial plots

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial=spatial_func()
    outlier_spatial=res_spatial$outlier
    cat(length(outlier_spatial), "outlier(s) are detected in the spatial metrics.\n")
    if (length(outlier_spatial)>0) {cat("They are: ", shortname_func(outlier_spatial))}
  }
}
```
  
2. Spatial distribution plots

```{r, eval=T, echo=F, fig.height=10, fig.width=7}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial$plot
  }
}
```

### Relative Log Expression (RLE) Distribution

```{r, eval=T, echo=F, message=F, warning=F}
# The fitPLM_func function generates RLE and NUSE matrices
fitPLM_func <- function(raw.data) {
  exprs(raw.data) <- log2(exprs(raw.data)) # The fitProbeLevelModel function needs ExpressionFeatureSet object as an input. Assign log transformed expression values to a new object
  fitPLM <- fitProbeLevelModel(raw.data)
  # RLE
  M_RLE <- RLE(fitPLM, type="values") # generate RLE matrix
  Mss_RLE <- subsamp(M_RLE,seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  # NUSE
  M_NUSE <- NUSE(fitPLM, type="values") # generate NUSE matrix
  Mss_NUSE <- subsamp(M_NUSE, seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  return(list(Mss_RLE=Mss_RLE,Mss_NUSE=Mss_NUSE))
}
# The RLE_func function outputs RLE metrics
RLE_func <- function(Mss) {
  outlier_res=outlier_KS_func(Mss) # compute KS statistics to detect outliers
  outlier=names(outlier_res$outlier)
  plot=boxplot_func(Mss,outlier,"RLE")
  return(list(outlier=outlier,plot=plot))
}
```

1. Outlier detection for RLE

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  fitPLM=fitPLM_func(raw.data)
  res_RLE=RLE_func(Mss=fitPLM$Mss_RLE)
  outlier_RLE=res_RLE$outlier
  cat(length(outlier_RLE), "outlier(s) are detected in RLE metrics.\n")
  if (length(outlier_RLE)>0) {cat("They are: ", shortname_func(outlier_RLE))}
}
```

2. Boxplot for RLE

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_RLE$plot}
```

### Normalized Unscaled Standard Error (NUSE) Outlier Detection and Plots

```{r, eval=T, echo=F, message=F, warning=F}
# The function outlier_upperquartile_func function computes upper 75% quantile for outlier detection
outlier_upperquartile_func <- function(exprs) { # matrix (row: NUSE values, col: array (e.g. sample))
  upperquartile = apply(exprs, 2, quantile, na.rm=TRUE, probs=0.75)
  stats = stats::fivenum(upperquartile, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(upperquartile > th))
}

# The NUSE_func function outputs the NUSE metrics
NUSE_func <- function(Mss) {
  outlier_res = outlier_upperquartile_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss,outlier,"NUSE")
  return(list(outlier=outlier,boxplot=boxplot))
}
```

1. Outlier detection for NUSE

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
if (platform=="Affymetrix"&suppldata) {
  res_NUSE <- NUSE_func(Mss=fitPLM$Mss_NUSE)
  outlier_NUSE = res_NUSE$outlier # compute upper 75% quantile statistics to detect outliers
  cat(length(outlier_NUSE), "outlier(s) are detected in NUSE metrics.\n")
  if (length(outlier_NUSE)>0) {cat("They are: ", shortname_func(outlier_NUSE))}
}
```

2. Boxplot for NUSE

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_NUSE$boxplot}
```

### Distance between Samples and Outlier Detection

```{r, eval=T, echo=F, warning=F}
# The dist2 estimates distance between samples
dist2 <- function (x,fun = function(a, b) mean(abs(a - b), na.rm = TRUE),diagonal = 0) {
  if (!(is.numeric(diagonal) && (length(diagonal) == 1)))
    stop("'diagonal' must be a numeric scalar.")

  if (missing(fun)) {
    res = apply(x, 2, function(w) colMeans(abs(x-w), na.rm=TRUE))
  } else {
    res = matrix(diagonal, ncol = ncol(x), nrow = ncol(x))
    if (ncol(x) >= 2) {
      for (j in 2:ncol(x))
        for (i in 1:(j - 1))
          res[i, j] = res[j, i] = fun(x[, i], x[, j])
    } # if
  } # else
  colnames(res) = rownames(res) = colnames(x)
  return(res)
}

# The outlier_dist_func function computes the sum of all distance of one sample to other samples for outlier detection
outlier_dist_func <- function(exprs) { # matrix (row: distance to each sample, col: array (e.g. sample))
  sum = colSums(exprs, na.rm=TRUE) # sum the total distance
  stats = stats::fivenum(sum, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(sum > th))
}

# The displot_func function plots distance between samples
distplot_func <- function(m,outlier) {
  dend = as.dendrogram(hclust(as.dist(m), method = "single"))
  ord = order.dendrogram(dend)
  array_name=shortname_func(colnames(m))
  outlier=shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  array_name <- shortname_func(array_name) # shorten the sample id
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256, option="B"),ColSideColors=status.cols,RowSideColors=status.cols,
    labCol=array_name,labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_list),fill=colour_list,cex=0.6)
}

# The dist_func function outputs distance metrics
dist_func <- function() {
  if (!normdata) {
    m <- dist2(log2(exprs(raw.data)))
  } else {
    m <- dist2(exprs(raw.data))
  }
  
  outlier_res=outlier_dist_func(m)
  outlier=names(outlier_res$outlier)
  return(list(outlier=outlier,m=m))
}
```

1. Outlier detection for sample distance

```{r, eval=T, echo=F}
res_dist=dist_func()
outlier_dist=res_dist$outlier
cat(length(outlier_dist), "outlier(s) are detected in sample distance metrics.\n")
if (length(outlier_dist)>0) {cat("They are: ", shortname_func(outlier_dist))}
```

2. Plot distance between samples
```{r, eval=T, echo=F, fig.height=10, fig.width=12}
distplot_func(m=res_dist$m,outlier=res_dist$outlier)
```

### Principal Component Analysis (PCA)

```{r, eval=T, echo=F}
# The pcastat_func function computes principal components
pcastat_func <- function() {
  # obtain original expression data
  if (!normdata) {
    raw.data.pca <- na.omit(log2(exprs(raw.data)))
  } else {
    raw.data.pca <- na.omit(exprs(raw.data))
  } # remove NAs
 
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(pc, group_var,legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(raw.data)[,group_var]
  )
  i=length(levels(pData(raw.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(raw.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(pc) {
  group_vars=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  legends=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(raw.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    nlevel=nlevels(pData(raw.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=20)) {
      plot_list[[group_var]]=pcaplot_func(pc, group_var=group_var,legend=legend)
    }
  }
  return(plot_list)
}
```


1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
res_pca <- pcastat_func()
pandoc.table(res_pca$tb,split.tables=Inf, caption="Variance explained")
```

2. PCA plots

```{r, eval=T, echo=F}
plot_list=pca_func(pc=res_pca$pc)
for (i in plot_list) {print(i)}
```


### QC Summary

```{r, eval=T, echo=F}
# The outlier_summ_func function outputs a summary table of outlier and the detected frequency
outlier_summ_func <- function() {
  outlier_all <- c("outlier_intensity","outlier_MA","outlier_spatial","outlier_RLE","outlier_NUSE","outlier_dist") # all outliers
  outlier_env=ls(envir=.GlobalEnv, pattern="outlier_") # "outlier_" enviromental variables
  outlier=outlier_env[outlier_env%in%outlier_all]
  method=gsub("outlier_","",outlier)
  outliers=unlist(lapply(1:length(outlier),function(x){get(outlier[x],envir=.GlobalEnv)}))
  if (length(outliers)==0) {
    cat("No outlier was detected\n")
    res <- data.frame() # create an empty data frame
  } else {
    methods=unlist(lapply(1:length(outlier),function(x){n=length(get(outlier[x]));rep(method[x],n)}))
    outlier_list=list()
    for (x in 1:length(outliers)){outlier=outliers[x];method=methods[x];outlier_list[[outlier]]=append(outlier_list[[outlier]],method)}
    # summary table
    Frequency <- sapply(outlier_list,length) # times to detect
    Method <- unlist(lapply(names(outlier_list),function(x){paste0(outlier_list[[x]],collapse=", ")}))
    res <- data.frame(Frequency,Method)
    res <- res[order(res$Frequency),]
  }
  return(res)
}

# The tbQC_func function
tbQC_func <- function(outliers) { # define outliers
  tb=pData(raw.data)
  tb$QC_Pass=1
  if (missing(outliers)) { # if outliers are not defined, use those detected more than twice
    tb$QC_Pass[rownames(tb)%in%rownames(outlier_tb)[outlier_tb$Frequency>2]]<-0 # assign 0 to outliers detected more than twice
  } else {
    tb$QC_Pass[rownames(tb)%in%outliers]<-0
  }
  tb$Filename <- rownames(tb) # add filename in a new column
  # save in a new phenotype file
  write.table(tb,pheno_fn_withQC,col.names=T,row.names=F,sep="\t",quote=F)
  # defined outliers
  outlier=as.character(tb$GEO_ID)[which(tb$QC_Pass==0)]
  # summary of phenotype information before QC
  vars=c("Tissue","Treatment","Disease","QC") # variables of interest
  # before QC
  tb_withoutQC=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb_withoutQC)[ncol(tb_withoutQC)]="Counts"
  # after QC
  tb_withQC=as.data.frame(table(tb[which(tb$QC==1),names(tb)%in%vars]))
  names(tb_withQC)[ncol(tb_withQC)]="Counts"
  return(list(outlier=outlier, tb_withoutQC=tb_withoutQC, tb_withQC=tb_withQC))
}
```

```{r, eval=T, echo=F, results="asis"}
outlier_tb=outlier_summ_func()
if (nrow(outlier_tb)>0) {
  pandoc.table(outlier_tb,caption="Outlier Summary",split.tables=Inf)
}
```

```{r, eval=T, echo=F}
res_tbQC=tbQC_func()
outlier=res_tbQC$outlier
cat(length(outlier), "outlier(s) are defined.\n")
if (length(outlier)>0) {cat("They are: ", outlier)}
```

```{r, eval=T, echo=F, results="asis"}
pandoc.table(res_tbQC$tb_withoutQC, split.tables=Inf, caption="Summary of samples without QC")
pandoc.table(res_tbQC$tb_withQC, split.tables=Inf, caption="Summary of samples with QC")
```

> Differential Gene Expression Analysis of GSE26378

```{r, eval=T, echo=T}
# GEO id
geo_id="GSE26378"
# direcotry stores GEO data
datadir="/home/bonkmp"
# directory stores generated files
resdir="/home/bonkmp/results"
# tissue
tissue="Blood"
# reference condition
con0="Control"
# altered condition
con1="Shock"
# treatment. Assign "comparison" if this column is used for DE.
treatment="24hr"
# disease. Assign "comparison" if this column is used for DE.
disease=c(con0,con1)
```

Manually change these variables according to dataset:
**Note that** four variables, platform (platform), geo_GPL (GPL id for analysis if the samples in the study were scanned on multiple platforms), usesuppl (whether to use supplementary data for DE analysis), and normdata (whether the expression matrix is normalized), need to be **manually** defined based on the QC reports. A shortname_func function is suggested to be updated.

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
usesuppl=TRUE
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*).(cel|CEL).gz","\\1",x)} # remove .cel.gz or .CEL.gz from sample
```

Automatically generate phenotype file variable pheno_fn if it is generated from QC step, otherwise manually assign this variable.

```{r, eval=T, echo=F}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
```

```{r, eval=T, echo=F}
cat(paste0("pheno_fn = '", pheno_fn,"'"))
```

Install the prerequisite R packages if they do not exist

* GEOquery 
* oligo
* limma
* sva
* annotate
* Bioconductor AnnotationData Packages: hgu133plus2.db, hgug4112a.db, hugene10sttranscriptcluster.db
* viridis (heatmap color)
* ggplot2
* gplots (heatmap2 plot)
* devtools (compute pca)
* pander


```{r, eval=F, echo=F}
source("http://bioconductor.org/biocLite.R")
biocLite("GEOquery")
biocLite("preprocessCore")
biocLite("oligo")
biocLite("limma")
biocLite("sva")
biocLite("annotate")
biocLite("viridis")
install.packages("ggplot2")
install.packages("gplots")
install.packages("devtools")
install.packages("pander")
```

Load the necessary libraries

```{r, eval=T, echo=F, message=F, warning=F}
library(GEOquery)
library(oligo)
library(limma)
library(sva)
library(annotate)
library(viridis)
library(ggplot2)
library(gplots)
library(devtools)
library(preprocessCore)
library(pander)
```

## Obtain Phenotype and GEO Data

### Phenotype data preparation

```{r, eval=T, echo=F}
# The phenosub_func function subsets phenotypes based on the user defined variables
phenosub_func <- function(){
  pheno.sub=subset(pheno,(Tissue%in%tissue)&(Treatment%in%treatment)&(Disease%in%disease))
  pheno.sub=droplevels(pheno.sub)
  # assign comparison to "Status" column
  if (length(treatment)==2) {
    if (identical(sort(levels(pheno.sub$Treatment)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Treatment} else {stop("Assigned treatment variables are not included in the Treatment column")}
  } else if (length(disease)==2) {
    if (identical(sort(levels(pheno.sub$Disease)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Disease} else {stop("Assigned treatment variables are not included in the Disease column")}
  }
  pheno.sub$Status <-factor(pheno.sub$Status,levels=c(con0,con1))
  return(pheno.sub)
}

# The phenoqc_func function excludes outliers from phenotype file 
phenoqc_func <- function(outlier,pheno) {
  if (missing(outlier)) {pheno=subset(pheno, QC_Pass==1)} else {pheno=subset(pheno, Filename%in%outlier)}
  droplevels(pheno)
}

# The phenopair_func function excludes unpaired donor from analysis
phenopair_func <- function(dat) {
  unpaired_samp=names(which(table(dat$Donor)==1))
  dat=dat[which(!dat$Donor%in%unpaired_samp),]
  droplevels(pheno)
  if (length(unpaired_samp)>0) {
    cat(paste0(length(unpaired_samp)," sample(s) with unpaired donor are excluded from analysis\n"))
    cat(paste(unpaired_samp,collapse=", "),"\n")
  }
  return(dat)
}

# The tbsum_func function generates summary of variables of interest
tbsum_func <- function(tb) {
  vars=c("Status", "ScanDate_Group") # variables of interest
  tb=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb)[ncol(tb)]="Counts"
  return(tb)
}

# The infosumm_function generates summary of the comparison
infosumm_func <- function(pheno) {
  N_Condition0 <- sum(pheno$Status==con0) # count number of samples under condition 0
  N_Condition1 <- sum(pheno$Status==con1) # count number of samples under condition 1
  if (identical(sort(levels(pheno$Treatment)),sort(c(con0,con1)))) {
    App="GC"
    if (geo_GPL=="") {name=paste(geo_id,tissue,disease,con1,"vs",con0, sep="_")} else {{name=paste(geo_id,geo_GPL,tissue,disease,con1,"vs",con0, sep="_")}}
    Disease=disease
    Treatment=con1
  } else {
    App="Asthma"
    if (geo_GPL=="") {name=paste(geo_id,tissue,treatment,con1,"vs",con0, sep="_")} else {name=paste(geo_id,geo_GPL,tissue,treatment,con1,"vs",con0, sep="_")}
    Disease=con1
    Treatment=treatment
  }
  
  df <- data.frame(
    GEO_ID=geo_id,
    Tissue=tissue,
    App=App,
    Disease=Disease,
    Treatment=Treatment,
    N_Condition0=N_Condition0,
    N_Condition1=N_Condition1,
    Total=N_Condition0+N_Condition1,
    Unique_ID=name
  )
  return(list(df=df,name=name))
}
```

Read in pre-prepared phenotype data

```{r, eval=T, echo=F}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
# read in the pre-prepared phenotype data
if (!file.exists(pheno_fn)) {stop("The phenotype file does not exist. Please check!")} else {pheno <- read.table(pheno_fn, header=TRUE, sep="\t")}
```

Subset phenotypes based on the comparison variables. Check variables (before and after QC if outliers are detected).

```{r, eval=T, echo=F}
pheno.sub=phenosub_func()
outlier=as.character(pheno.sub$Filename)[pheno.sub$QC_Pass==0]
if (length(outlier)>0) {
  cat("Remove outlier(s)", outlier, "from phenotype file\n")
  pheno.of.interest=phenoqc_func(pheno=pheno.sub)
} else {pheno.of.interest=pheno.sub}
```

Define paired variable.

```{r, eval=T, echo=F, results="asis"}
if (length(disease)==2) {
  paired=FALSE
} else if (length(disease)==1) {
  if (all((pheno.sub$Donor)==1)) {paired=FALSE} # if treatment is in different donors
  else {paired=TRUE} # if treatment is in samd donors
}
```

```{r, eval=T, echo=F}
cat("paired =",as.character(paired))
```

Exclude samples missing the other paired donors in treatment comparisons
```{r, eval=T, echo=F, results="asis"}
if (paired) {
  pheno.of.interest <- phenopair_func(pheno.of.interest)
}
```

```{r, eval=T, echo=F, results="asis"}
if (nrow(pheno.sub)!=nrow(pheno.of.interest)) {
  pandoc.table(tbsum_func(tb=pheno.sub), split.tables=Inf, caption="Summary of subsetted samples without QC")
  pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples with QC")
} else {pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples")}

# create a summary table for this comparison
pandoc.table(t(infosumm_func(pheno=pheno.of.interest)$df),split.tables=Inf, caption="Summary of the comparison")
```

```{r, eval=T, echo=F}
# assign colours to comparison status
colour_status <- c("navy","red")
names(colour_status) <- c(con0,con1) # assign red to condition 1 and navy to condition 2
colour_status_list <- unlist(lapply(pheno.of.interest$Status,function(x){colour_status[x]}))
# assign colours to scan date
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
if ("ScanDate_Group"%in%names(pheno)) {
  i=nlevels(pheno.of.interest$ScanDate_Group)
  colour_scandate <- colours[1:i]
  names(colour_scandate) <- levels(pheno.of.interest$ScanDate_Group) # colour to corresponding scan date
  colour_scandate_list <- unlist(lapply(pheno.of.interest$ScanDate_Group,function(x){colour_scandate[x]}))
}
```

### Gene expression data preparation

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and unextract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (usesuppl) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno$Filename))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}

  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)
}
```

```{r, eval=T, echo=F, message=F, warning=F}
if (!usesuppl) {
  # check if GEO matrix file exists
  geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
  if (length(geo_fn)==0) { # # GEO matrix file is not downloaded
    gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
    if (length(gselms)>1) {  # multiple platform
      gpls=sapply(gselms,annotation)
      cat("This study was performed in multiple platforms:\n")
      cat(unname(gpls),"\n")
      cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
      if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
    } else {idx=1}
    gse <- gselms[[idx]]
  } else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
    gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
  } else { # GEO matrix file is alreadly downloaded and has multiple platforms
    cat("This study was performed in multiple platforms:\n")
    cat(geo_fn)
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <-geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
  }
  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.data=gse
}
```

```{r, eval=T, echo=F}
# The subdat_func function subsets data based on the phenotype of interest
subdat_func <- function(raw.data, pheno) {
  # subset raw.data based on the phenotype of interest
  raw.data=raw.data[,colnames(raw.data)%in%pheno$Filename]
  # assign phenotype data to raw expression data
  pData(raw.data) <- pheno
  row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
  # check if the sample names derived from expression data match those in phenotype file
  if (usesuppl) {matching=mapply(identical,row.names(pData(raw.data)),as.character(pheno$Filename))}
  else {matching=mapply(grepl,row.names(pData(raw.data)),as.character(pheno$Filename))}
  if (!all(matching)) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
  return(raw.data)
}
raw.data.of.interest=subdat_func(raw.data=raw.data, pheno=pheno.of.interest)
```

Show expression dataset features
```{r, eval=T, echo=F}
raw.data.of.interest
```

## Differential Gene Expression Analysis

### Normalize raw gene expression data

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data.of.interest),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data.of.interest)=apply(exprs(raw.data.of.interest),2,function(x){replace(x,which(x<=0),NA)})
```

```{r, eval=T, echo=F, message=F, results="hide"}
if (usesuppl) {
  rma.data.of.interest = rma(raw.data.of.interest)
  cat("RMA normalization is used.\n")
} else {
  rma.data.of.interest=raw.data.of.interest
  if (!normdata) {exprs(rma.data.of.interest)=normalize.quantiles(log2(exprs(rma.data.of.interest)))
  cat("Quantile normalization and log2 transformation is used.\n")
  }
}
```

```{r, eval=T, echo=F}
cols=colour_status_list
boxplot(raw.data.of.interest,target="core",col=cols,main="Raw Probe Intensities",xaxt="n") # view raw data
legend("topright",legend=names(colour_status),fill=colour_status)

if (!normdata) {
  boxplot(rma.data.of.interest,col=cols,main="Normalized Probe Intensities",xaxt="n") # view RMA-adjusted data
  legend("topright",legend=names(colour_status),fill=colour_status)
} else {cat("The raw data is already normalized")}
```


### Pairwise Comparison between Status

```{r, eval=T, echo=F, results="asis"}
limma_func <- function(paired=FALSE) { # here only con0, con1 are used in comparisons. use a function to reduce the factor levels
  if (paired) {
    cat("Donor is adjusted in this regression\n")
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$Donor)) # create design model matrix
    colnames(design) = c(levels(factor(rma.data.of.interest$Status)),levels(factor(rma.data.of.interest$Donor))[-1])
  } else {
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)) # create design model matrix
    colnames(design) = levels(factor(rma.data.of.interest$Status))
  }
  fit = lmFit(rma.data.of.interest, design) # fit a linear model to estimate the fold changes and standard error
  # Create a contrast group and fit it in a linear model
  data.contrast = makeContrasts(contrasts=paste(c(con1,con0),collapse="-"),levels = design) # create a contrast group by comparing con1 vs con0
  fit2 = contrasts.fit(fit, data.contrast) # get the contrasts for samples of interest
  fit2 = eBayes(fit2) # adjust fit coefficients using an empirical Bayes moderation of standard errors
  return(list(design=design,data.contrast=data.contrast,fit2=fit2))
}
```

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
res_DE=limma_func(paired=paired)
fit2=res_DE$fit2
pandoc.table(data.frame(Sample=rma.data.of.interest$Sample,res_DE$design), split.tables=Inf, caption="A design model matrix for linear model")
pandoc.table(as.data.frame(res_DE$data.contrast), caption="A contract matrix for comparison")
contrast_table <- topTable(fit2, adjust="BH",num=Inf) # get full set of results for each hypothesis test
col.sel=c("logFC","AveExpr","t","P.Value","adj.P.Val","B") # select the columns of DE results
contrast_table <- data.frame(ID=row.names(contrast_table), contrast_table[,col.sel])
```

### Adjusting for Batch Effect

```{r, eval=T, echo=F}
# The nbatch_func function obtains number of batches (scan date) in the data
nbatch_func <- function() {
  if (!"ScanDate_Group"%in%names(pData(rma.data.of.interest))) {nbatch=0} else {nbatch=nlevels(rma.data.of.interest$ScanDate_Group)}
}

# The svamod_func function creates full and null models, and Checks if the batch and comparison status are confounded
svamod_func <- function(paired=FALSE) {
  # Create a full model
  modBatch = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)) # full model (adjusted variables and variables of interest)
  # Create a null model only including batch variables
  nullBatch =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)) # null model (adjusted variables only)
  # Check if the scan date and comparison status are confounded
  if (class(try(solve(t(modBatch)%*%modBatch),silent=T))=="matrix") {batchadj=TRUE} else {batchadj=FALSE; message("The scan date and comparison status are highly confounded")}
  # summary of the full model
  tb.fullmod <- as.data.frame(modBatch)
  names(tb.fullmod) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])
  # summary of the null model
  tb.nullmod <- as.data.frame(nullBatch)
  names(tb.nullmod) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])

  donoradj=NULL # assign variable is donor is adjusted
  tb.nullmod1=NULL # assign null matrix for donor adjustment
  if ((paired)&(batchadj)) { # same donor treatment adjust for donor
    # Test if donor and scandate are correlated
    modBatch1 = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # full model including donor
    nullBatch1 =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # null model including donor
    # summary of the full model
    tb.fullmod1 <- as.data.frame(modBatch1)
    names(tb.fullmod1) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
    # summary of the null model
    tb.nullmod1 <- as.data.frame(nullBatch1)
    names(tb.nullmod1) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
      
    # check if scandate correlated with donor
    if (class(try(solve(t(modBatch1)%*%modBatch1),silent=T))=="matrix") {
      donoradj="yes"
      modBatch=modBatch1
      nullBatch=nullBatch1
      tb.fullmod=tb.fullmod1
      tb.nullmod=tb.nullmod1
    }
  }

  return(list(modBatch=modBatch, nullBatch=nullBatch, tb.fullmod=tb.fullmod, tb.nullmod=tb.nullmod, batchadj=batchadj, donoradj=donoradj, tb.nullmod_donor=tb.nullmod1))
}

# The batcherror_func function assigns a variable batcherror to decide whether to adjust for batch effect under various scenarios
batcherror_func <- function() {
  if (nbatch==0) {
    batcherror="zero"
  } else if (nbatch==1) {
    batcherror="one"
  } else {
    if (batchadj) {batcherror="no"} else {batcherror="correlate"}
  }
  return(batcherror)
}

# The batchadj_func function outputs table with batch effects adjusted p-values
batchadj_func <- function(batcherror=batcherror, contrast_table=contrast_table, paired=paired) {
  if (batcherror=="no") {
    modBatch=svamod_func(paired=paired)$modBatch
    nullBatch=svamod_func(paired=paired)$nullBatch
    pValuesBatch=f.pvalue(exprs(rma.data.of.interest), modBatch, nullBatch) # get batch effect-adjusted p-values
    qValuesBatch=p.adjust(pValuesBatch, method="BH") # get q-values
    tb.sva <- data.frame(ID=names(pValuesBatch),pValuesBatch,qValuesBatch)
    contrast_table <- merge(contrast_table, tb.sva, by="ID", all=TRUE)
  } else if (batcherror=="correlate") {
    contrast_table$pValuesBatch=contrast_table$qValuesBatch=rep(NA,nrow(contrast_table))
  } else {
    contrast_table$pValuesBatch=contrast_table$P.Value
    contrast_table$qValuesBatch=contrast_table$adj.P.Val
  }
  return(contrast_table)
}
```

```{r, eval=T, echo=F}
nbatch=nbatch_func()
if (nbatch>1) {res_svamod=svamod_func(paired=paired);batchadj=res_svamod$batchadj}
batcherror=batcherror_func()
if (batcherror=="zero") {cat("No scan date is present in the data.")} else if (batcherror=="one") {cat("Only one batch is present in the data.")} else if (batcherror=="correlate") {cat("The scan date and the comparison status are highly confounded (See the model matrix). Cannot ajust for batch effect.")}
```

```{r, eval=T, echo=F, results="asis"}
if (nbatch>1) {
  if (paired) {
    if (is.null(res_svamod$donoradj)) {
      cat("Scan date and donor are highly confounded. See the matrix below.\n")
      pandoc.table(res_svamod$tb.nullmod_donor, split.tables=Inf, caption="Null model matrix with scan date and donor")
      cat("Only adjust for scan date.\n")
    } else {cat("Both scan date and donor are adjusted.\n")}
  }
  pandoc.table(res_svamod$tb.fullmod, split.tables=Inf, caption="Full model matrix")
  pandoc.table(res_svamod$tb.nullmod, split.tables=Inf, caption="Null model matrix")
}
```

```{r, eval=T, echo=F, results="asis"}
contrast_table=batchadj_func(batcherror=batcherror, contrast_table=contrast_table, paired=paired)
pandoc.table(summary(contrast_table), split.tables=Inf, caption=paste0(con1, " vs. ", con0, " summary"))
```


### Assign Official Gene Symbol

```{r, eval=T, echo=F}
anno_list=list()
# Affymetrix
anno_list[["pd.hg.u133.plus.2"]]="hgu133plus2.db"
```

```{r, echo=F}
# glpanno_func creates anntoation vector based on GPL annotation from GEO
glpanno_func <- function(GPL_ID){
  gpl <- Table(getGEO(GPL_ID, destdir = "data"))
  if (GPL_ID%in%names(symbol_list)) {anno_vect <- gpl[,symbol_col]} else {anno_vect <- gpl[,"gene name"]}
  names(anno_vect) <- gpl[,"ID"]
  return(anno_vect)
}

# ranno_func creates anntoation vector based on R annotation database
ranno_func <- function(anno_lib){
  # check if the annotation database is installed
  if (!anno_lib%in%installed.packages()[,1]){source("http://bioconductor.org/biocLite.R"); biocLite(anno_lib)}
  library(anno_lib, character.only=T)
  anno_symbol=gsub(".db","SYMBOL",anno_lib) # The name of the R object mapping between probe id and gene symbol
  x=get(anno_symbol)
  # Get the probe identifiers that are mapped to a gene symbol
  mapped_probes <- mappedkeys(x)
  # Convert to a list
  xx <- as.list(x[mapped_probes])
  # Convert list to annotation vector
  anno_vect <- sapply(xx,function(x){x})
  return(anno_vect)
}

# geneannot_func annotates gene symbol to DE result table
geneannot_func <- function(tb, anno_vect) {
  remove.pm <- function(x) {gsub("_PM", "", x)} # Assign official gene symbol using hgu133plus2.db package if anntoation is based on pd.hg.u133.plus.2. Note that the probe names have additional "PM"s in the results will be removed to match the names in the gene symbol package.
  if (exists("anno_lib")) {
    if (anno_lib=="hgu133plus2.db") {tb$ID=sapply(as.character(tb$ID), remove.pm)}
  }
  tb$ID=as.character(tb$ID)
  tb$SYMBOL=sapply(as.character(tb$ID), function(x){if (x%in%names(anno_vect)){anno_vect[x]} else {"NA"}})
  tb$SYMBOL[which(tb$SYMBOL=="")]="NA"
  # remove probes with NA in logFC column
  tb <- tb[!is.na(tb$logFC),]
  tb[order(tb$P.Value),]
}
```

```{r, eval=T, echo=F, warning=F, message=F}
# install corresponding annotation database if it is not installed
anno_array=annotation(rma.data.of.interest)
cat("The platform used is", anno_array, "\n")
if (!anno_array%in%names(anno_list)) {
  cat("Annotate using GPL annotation in GEO\n")
  anno_vect=glpanno_func(GPL_ID=anno_array)
} else {
  anno_lib=anno_list[[anno_array]] # use the annotation database
  cat("The corresponding R annotation database package is", anno_lib,"\n")
  anno_vect <- ranno_func(anno_lib=anno_lib)
}
```

```{r, eval=T, echo=F}
contrast_name=infosumm_func(pheno=pheno.of.interest)$name # adopt Unique_ID created in the information summary table
contrast_fn=paste0(resdir,"/", contrast_name, ".csv")
```

```{r, eval=T, echo=F, warning=F, message=F}
contrast_table <- geneannot_func(tb=contrast_table, anno_vect=anno_vect)
write.csv(contrast_table, file=contrast_fn, row.names = FALSE)
```

```{r, eval=T, echo=F}
if (file.exists(contrast_fn)) {contrast_fn=paste0(resdir,"/", contrast_name, ".csv")}
res=read.csv(contrast_fn)
```

## Gene Expression Results Visualization

### Volcano Plots

```{r, eval=T, echo=F}
# The volplot_func function generates volcano plots
volplot_func <- function(df,qval_column,title) {
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else {          
    df <- df[!is.na(qval),] # remove NA values
    qval <- df[,qval_column]
    if (min(df[,qval_column])>=0.05) {
      df$sig <- "black" # assign colors to DE and non-DE genes
    } else {
      # assign colors to DE and non-DE genes
      df$sig <- rep(NA,nrow(df))
      df$sig[qval<0.05] <- "red"
      df$sig[qval>=0.05] <- "black"
    }
    df$sig <- as.factor(df$sig)
    color <- levels(df$sig)
    # log10 transformed q values
    df$logqval <- -log10(qval)
    diffgenes <- df$ID[qval<0.05] #Create list of all DEG's
    signum = paste0(length(diffgenes), " significant genes based on ", qval_column)
    if (missing(title)) {title=signum}
    print(
    ggplot(df, aes(x = logFC, y = logqval, color=sig)) + geom_point() +
      theme_bw() +
      labs(title=title,x="logFC",y=paste0("-log10(",qval_column,")")) +
      scale_color_manual(values=color) +
      theme(legend.position="none")
    )
  }
}
```

Volcano plot (probes with a q-value <0.05 are present in red)

```{r, eval=T, echo=F, fig.height=4, fig.width=4.5}
for (qval in c("adj.P.Val","qValuesBatch")) {volplot_func(res, qval)}
```


### Histograms

```{r, eval=T, echo=F}
# The histplot_func function generates histogram for p-value distributions
histplot_func <- function(df,qval_column,title) {
  if (missing(title)) {title=""}
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else{hist(qval,main=title,xlab=qval_column)}
}
```

Histograms of p-value distributions

```{r, eval=T, echo=F, fig.width=4.5, fig.height=4}
for (pval in c("P.Value","pValuesBatch")) {histplot_func(res, pval)}
for (qval in c("adj.P.Val","qValuesBatch")) {histplot_func(res, qval)}
```

### Top 20 Differentially Expression Results

```{r, eval=T, echo=F}
# The datreform_func function reformats the DE table
datreform_func <- function(dt,topnum=200) {
  dt=dt[order(dt$P.Value),]
  dt=dt[1:topnum,]
  round2 <- function(x){round(x,2)}
  dt[,c("logFC","AveExpr","t","B")] <- sapply(dt[,c("logFC","AveExpr","t","B")],round2)
  sciform <- function(x){format(x,scientific=TRUE,digits =2)}
  dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")] <- sapply(dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")],sciform)
  dt
}
```

Show top 20 probes sorted by un-adjusted p-values

```{r, eval=T, echo=F, results="asis"}
res <- datreform_func(dt=res)
rownames(res) <- NULL
pandoc.table(res[1:20,],split.tables=Inf)
```

### Boxplots for Top 6 Differentially Expressed Genes

This step helps to visualize and check the effect direction in the comparison.

```{r, eval=T, echo=F}
# function for top gene boxplot
topgene_boxplot_func <- function(tb,colour,comp) { # comp: comparison status
  for (i in 1:nrow(tb)) {# top i probe in res
    if (missing(comp)) {comp=""}
    if (missing(colour)) {colour=colours[1]}
    probe_top <- tb$ID[i]
    gene_top <- tb$SYMBOL[i]
    row.names(rma.data.of.interest) <- gsub("_PM","",row.names(rma.data.of.interest))
    values=exprs(rma.data.of.interest)[row.names(rma.data.of.interest)%in%probe_top, ]
    status=rma.data.of.interest$Status
    df <- data.frame(values=values,status=status)
    title=paste0(comp," top ",i," probe ", probe_top, " gene ", gene_top)
    print(
      ggplot(df,aes(x=status,y=values)) +
        geom_boxplot(outlier.colour=NA,color="grey18",fill=colour) +
        stat_boxplot(geom ='errorbar', color="grey18") +
        geom_jitter(size=1,position = position_jitter(width=0.3)) +
        labs(title=title) +
        theme_bw() +
        theme(legend.position="none",axis.title=element_blank())
    )
  }
}
```

```{r, eval=T, echo=F, message=F, warning=F, fig.height=4, fig.width=4.5}
topgene_boxplot_func(tb=res[1:6,])
```


### Heatmap for Top 200 Differentially Expressed Genes

```{r, eval=T, echo=F}
# The heatmap_topgene_func function for top gene heatmap plots
heatmap_topgene_func <- function(tb, topnum=200, colour_status_list, colour_status, main="") { # colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  top.rma <- rma.data.of.interest[row.names(rma.data.of.interest)%in%tb[1:topnum,"ID"],] # plot heatmap for top 200 genes
  array_name <- shortname_func(colnames(exprs(top.rma))) # shorten the sample id
  heatmap.2(na.omit(exprs(top.rma)), col=viridis(256, option="B"),
    ColSideColors=colour_status_list, # use predefined colour_status_list, assign colors to status
    labCol=array_name,labRow = "", # take out gene probe id
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow=1,cexCol=1,
    keysize=1.5,key.title=NA,key.xlab="Gene Expression Values",key.ylab="Counts",
    main=main)
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.8) # use predifined colour_status
}
```


```{r, eval=T, echo=F, fig.height=10, fig.width=12}
heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_status_list, colour_status=colour_status, main="Gene expression heatmap by comparison status")
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Gene expression heatmap by scan date")
}
```

### Heatmap for Sample Correlation

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# The corplot_func function plots correlation between samples
corplot_func <- function(m, colour_status_list, colour_status, main="") {  # m: correlation matrix, colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  m <- cor(na.omit(m)) # compute correlation matrix
  # compute distance based on 1-correlation efficient
  dend = as.dendrogram(hclust(as.dist(1-m), method = "single"))
  ord = order.dendrogram(dend)
  array_name <- shortname_func(colnames(m)) # shorten the sample id
  # heatmap plot
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256,option="B"), ColSideColors=colour_status_list, RowSideColors=colour_status_list,
    labCol=array_name, labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.6)
}
```


```{r, eval=T, echo=F, fig.height=10, fig.width=12}
corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_status_list, colour_status=colour_status, main="Correlation heatmap by comparison status")
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Correlation heatmap by scan date")
}
```

### Principal Component Analysis (PCA)

```{r, eval=T, echo=F, warning=F, message=F, results="asis"}
# The pcastat_func function computes principal components
pcastat_func <- function(m) {
  # obtain original expression data
  raw.data.pca <- na.omit(apply(m,2,function(x)replace(x,is.infinite(x),NA))) # replace infinite values to NAs and omit NAs
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(oligo.data, pc, group_var, legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(oligo.data)[,group_var]
  )
  i=length(levels(pData(oligo.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(oligo.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(oligo.data, pc) {
  group_vars=c("ScanDate_Group", "Status", "Donor")
  legends=c("ScanDate_Group", "Status", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(oligo.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    pData(oligo.data)[,group_var]=as.factor(as.character(pData(oligo.data)[,group_var])) # convert to factor
    nlevel=nlevels(pData(oligo.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=10)) {
      if (group_var=="Status") {
        plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)+scale_color_manual(legend,values=colour_status,na.value="grey") # assign colour to comparison stauts
      } else {plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)}
    }
  }
  return(plot_list)
}
```

1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=F, warning=F, message=F, results="asis"}
res_pca <- pcastat_func(m=exprs(rma.data.of.interest))
pandoc.table(res_pca$tb, split.tables=Inf, caption="Variance explained")
```

2. PCA plots

```{r, eval=T, echo=F, message=F, warning=F}
plot_list=pca_func(oligo.data=rma.data.of.interest, pc=res_pca$pc)
for (i in plot_list) {print(i)}
```

## Quality Control for GSE26440

```{r, eval=T, echo=T}
# GEO id
geo_id="GSE26440"
```

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*)\\.(cel|CEL).gz","\\1",x)}
```

```{r, eval=T, echo=F, message=F, warning=F}
library(GEOquery)
library(oligo)
library(viridis) # heatmap colour
library(ggplot2)
library(gplots) # heatmap.2 plot
library(Hmisc) # compute hoeffd (Hoeffding's D statistics) for MA plot
library(devtools) # compuate PCs
library(preprocessCore) # quantile normalization
library(pander)
```

## GEO Data Download and Phenotype Preparation

### GEO Dataset Download

```{r, eval=T, echo=F, message=F, warning=F}
# check if GEO matrix file exists
geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
if (length(geo_fn)==0) { # GEO matrix file is not downloaded
  gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
  if (length(gselms)>1) {  # multiple platform
    gpls=sapply(gselms,annotation)
    cat("This study was performed in multiple platforms:\n")
    cat(unname(gpls),"\n")
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
  } else {idx=1}
  gse <- gselms[[idx]]
} else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
  gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
} else { # GEO matrix file is alreadly downloaded and has multiple platforms
  cat("This study was performed in multiple platforms:\n")
  cat(geo_fn)
  cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
  if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <- geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
}
```


Show expression dataset features
```{r, eval=T, echo=F}
gse
```

### Modify raw phenotype information

```{r, eval=T, echo=F, results="asis"}
pheno.raw <- pData(phenoData(gse))
for (x in names(pheno.raw)) {
  vec=pheno.raw[,x]
  if (!is.numeric(vec)) {
    # create an empty data frame to save any tables with non-native characters
    tb_nonnative=data.frame()
    vec <- factor(vec)
    if (nlevels(vec)>5) {res=table(droplevels(vec[vec%in%levels(vec)[1:5]]))} else {res=table(vec)}
    res=data.frame(res)
    names(res) <- c(x,"counts")
  }
  if (is.numeric(vec)){res=summary(vec)}
  # Try if any existing non-native characters cause pander error
  if (class(try(pandoc.table(res, justify='left',split.tables=Inf, caption=x), silent = T))=="try-error") {tb_nonnative=res}
  if (nrow(tb_nonnative)>1){print(res)}
}
```

```{r, eval=T, echo=F}
# check if there is missing supplementary_file
if (all(pheno.raw$supplementary_file=="NONE")) {
  suppldata=FALSE
} else if (any(pheno.raw$supplementary_file=="NONE")) {
  sample_nosuppl=as.character(pheno.raw$geo_accession[pheno.raw$supplementary_file=="NONE"])
  pheno.raw=pheno.raw[which(pheno.raw$supplementary_file!="NONE"),]
  cat("Not all samples have defined supplementary file path:\n")
  cat(paste(sample_nosuppl,collapse=", "),"\n")
  cat("These samples are excluded from analysis\n")
  suppldata=TRUE
} else {suppldata=TRUE}
```

```{r, eval=T, echo=F}
cat("suppldata =",as.character(suppldata))
```

#### Phenotype information modification

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
library(dplyr)
cols <- c("title","geo_accession","source_name_ch1")
pheno <- pheno.raw %>%
  dplyr::select(cols) %>%
  dplyr::mutate(GEO_ID=geo_accession) %>%
  dplyr::mutate(Donor=gsub("^.*biological (.*)$","\\1",title)) %>%
  dplyr::mutate(Sample=paste(geo_accession,Donor,sep="_")) %>%
  dplyr::mutate(Tissue="Blood") %>%
  dplyr::mutate(treatment_time=gsub("^.*for (\\d+.*)$","\\1",source_name_ch1)) %>%
  dplyr::mutate(treatment_time=gsub(" ","",treatment_time)) %>%
  dplyr::mutate(treatment_drug=ifelse(grepl("sepsis",source_name_ch1),"sepsis","healthy")) %>%
  dplyr::mutate(Treatment="24hr") %>%
  dplyr::mutate(Disease=c(rep("Shock",98), rep("Control",32))) %>%
  dplyr::mutate_if(is.character,as.factor) %>%
  dplyr::select(-one_of(cols)) # remove original columns
detach("package:dplyr")
```

### Raw intensity data download

```{r, eval=T, echo=F}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and extract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (suppldata) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno.raw$supplementary_file))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}
}
```

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
if (platform=="Affymetrix"&suppldata) {
  #1. Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)

  #2. Obtain scan date information from the raw.data for batch effect adjustment
  # As the scan date and scan time are usually joined by "T" or a white space, use both pattern to split the date with time
  pheno$ScanDate_Group <- sapply(strsplit(as.character(protocolData(raw.data)$dates), "T| "), function(x) {x[[1]]})
  pheno$ScanDate_Group <- as.factor(pheno$ScanDate_Group)
}
```

```{r, eval=T, echo=F}
if (!suppldata) {raw.data=gse}
```

```{r, eval=T, echo=F}
# assign phenotype data to raw expression data
pData(raw.data) <- pheno
row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
# Check if the sample names derived from expression data match those in phenotype file
rowname <- gsub("^(.*).(cel|CEL|txt|Txt).gz","\\1",row.names(pData(raw.data)))
matching <- mapply(grepl, x=rowname, pattern=as.character(pData(raw.data)$GEO_ID))
if (FALSE %in% matching) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
```

```{r, eval=T, warning=F,results="asis",echo=F}
# show the first five rows
pandoc.table(head(pheno,5), split.tables=Inf,caption="Show the first 5 rows of the modified phenotype file")
# show the groups of interest
avail_group=c("Tissue","Disease","Treatment")[c("Tissue","Disease","Treatment")%in%names(pheno)]
res=as.data.frame(table(pheno[,avail_group]))
names(res) <- c(avail_group,"Count")
pandoc.table(res, split.tables=Inf, caption="Sample size in different tissue and disease/treatment groups")
# show samples in different batch
if ("ScanDate_Group"%in%names(pheno)) {
  res=as.data.frame(table(pheno[,"ScanDate_Group"]))
  names(res) <- c("ScanDate_Group","Count")
  pandoc.table(res, split.tables=Inf, caption="Sample size in different batch")
} else {cat("No scan date information.")}
```

```{r, eval=T, echo=F}
# assign colours to Scan Date for plots
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
vars=c("ScanDate_Group","Treatment","Disease")
leveluse=sapply(vars,function(x){if(x%in%names(pheno)){nlevel=nlevels(pheno[,x])}else{nlevel=0};nlevel>1})
if (any(leveluse)){varuse=names(which(leveluse)[1])}else{stop("None of the following variables scan date/Disease/Treatment has >1 level. Check the dataset!")} # varible assigned color in plot

# assign colour to corresponding variable (scan date if available otherwise disease/treatment)
i=nlevels(pheno[,varuse])
colour_list <- colours[1:i]
names(colour_list) <- levels(pheno[,varuse]) 
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data)=apply(exprs(raw.data),2,function(x){replace(x,which(x<=0),NA)})
```

```{r, eval=T, echo=F, warning=F}
if (!suppldata|platform!="Affymetrix") {
  boxplot(exprs(gse),col=colour_list,main="Probe Intensity matrix of raw data",xaxt="n") # note gse here are non-coverted expression values
  legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  if (!normdata) {
    boxplot(log2(exprs(raw.data)),col=colour_list,main="Probe Intensity matrix of log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
    boxplot(normalize.quantiles(log2(exprs(raw.data))),col=colour_list,main="Probe Intensity matrix of qnormed log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  }
}
```

```{r, eval=T, warning=F, echo=F}
if (geo_GPL=="") {pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_Phenotype_withoutQC.txt"); pheno_fn_withQC=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else
{pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withoutQC.txt");pheno_fn_withQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
write.table(pheno,pheno_fn_withoutQC,col.names=T,row.names=F,sep="\t",quote=F)
```


## Quality Control for Microarray Data

```{r, eval=T, echo=F}
pheno <- read.table(pheno_fn_withoutQC, header=T, sep="\t")
```

### Raw Probe Intensity Boxplots and Density Histograms

```{r, eval=T, echo=F, warning=F}
# The subsamp function randomly selects 20000 probes
subsamp <- function(x,num=20000, seed=123) {
  set.seed(seed)
  subsample=num # if number of probes are >20000, randomly select 20000 probes for plot or compute
  if (nrow(x)>subsample) {
    ss  = sample(nrow(x), subsample)
    Mss = x[ss,,drop=FALSE]
  } else {
    ss  = TRUE
    Mss = x
  }
  Mss
}

# The outlier_KS_func function computes KS statistics for outlier detection
outlier_KS_func = function(exprs) { # matrix (row: probe intensities/RLE values etc., col: array (e.g. sample))
  fx = ecdf(as.vector(exprs)) # get empirical cumulative distribution function of the data
  KS=suppressWarnings(apply(exprs, 2, function(v)ks.test(v, y = fx, alternative="two.sided")$statistic))
  stats = stats::fivenum(KS, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=KS, outlier = which(KS > th))
}

# The boxplot_func function generates boxplots for raw data metrics (e.g. probe intensities, RLE, NUSE) 
boxplot_func <- function(Mss,outlier,ylab) {
  # use * to mark the outliers in boxplot
  array_name <- shortname_func(colnames(Mss))
  outlier <- shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  # boxplot raw intensity by array
  ylim = quantile(Mss, probs = c(0.01, 0.99), na.rm=TRUE) # create range of y-axsis
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df, aes(sample_id,values,fill=scandate)) + geom_boxplot(outlier.colour=NA) +
    coord_flip() + theme_bw() +
    ylim(ylim) +
    scale_x_discrete(labels=array_name) +
    ylab(ylab) +
    scale_fill_manual(varuse,values=cols) +
    theme(axis.title.y=element_blank())
}

# The densplot_func function plots density curve for raw data metrics (e.g. probe intensity)
densplot_func <- function(Mss) {
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df,aes(x=values,colour=scandate)) + geom_line(aes(group=sample_id),stat="density") +
    theme_bw() +
    xlab("Raw Probe Intensities") +
    ylab("Density") +
    scale_color_manual(varuse,values=cols)
}

# The raw_intensity_func function outputs raw probe intensity metrics
raw_intensity_func <- function() {
  if (!normdata) {Mss=log2(subsamp(exprs(raw.data))) # use log2 transformed raw probe intensity
  } else {
    Mss=subsamp(exprs(raw.data))
  }
  outlier_res=outlier_KS_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss=Mss, outlier=outlier, ylab="Raw Probe Intensities")
  densplot=densplot_func(Mss=Mss)
  return(list(outlier=outlier,boxplot=boxplot,densplot=densplot))
}
```

1. Outlier detection for log2 raw probe intensity/normalized intensity

```{r, eval=T, echo=F, warning=F}
res_intensity=raw_intensity_func()
outlier_intensity = res_intensity$outlier
cat(length(outlier_intensity), "outlier(s) are detected in the raw intensity metrics.\n")
if (length(outlier_intensity)>0) {cat("They are: ", shortname_func(outlier_intensity))}
```

2. Boxplots for log2 raw probe intensity

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
res_intensity$boxplot
```

3. Density curves for log2 raw probe intensity

```{r, eval=T, echo=F, message=F, warning=F}
res_intensity$densplot
```

### RNA Digestion

```{r, eval=T, echo=F}
# The RNAdegaffy_func function compute mean PM intensities in each probe position following 5' to 3' order. Adopted from the AffyRNAdeg function in the affy package but include a step that randomly selects 20,000 probe sets.
RNAdegaffy_func <- function(data){ # input a list of probe set matrix with rows as probe ids and columns as samples
  {
    names <- colnames(data[[1]])
    probe.set.size <- function(x) {
      size <- dim(x)[1]
      return(size)
    }
    max.num <- sapply(data, probe.set.size) # get the number of probes in each probe set
    tab <- (table(max.num)) # summarize the frequencies of probe numbers in probe sets
    ord <- order(-as.numeric(tab)) # order the frequency from large to small
    K <- as.numeric(names(tab))[ord[1]] # K is the number of probes appearing in most probe sets
    data <- data[max.num == K] # select data of probe sets only have K number of probes
  }
  
  subsample=20000
  if (length(data)>subsample) { # randomly select 10000 probe sets
    set.seed(12345)
    ss = sample(length(data),subsample)
    data = data[ss,drop=FALSE]
  }

  N <- length(data) # number of probe sets
  n <- dim(data[[1]])[2] # number of samples
  
  # create two matrices: number of samples * number of probes representing a probe set
  mns <- matrix(nrow = n, ncol = K) # create matrix for mean values
  sds <- mns # create matrix for sds values

  get.row <- function(x, i = 1) {return(x[i, ])} # function to get each row (i.e. probe id, i) from one probe set x (i.e. probe list[[x]])
  rowstack <- function(x, i = 1) {return(t(sapply(x, get.row, i)))} # function to combine the rows obtained using get.row (pms across samples by probe sets) to get a table (row: samples column: probe sets) and transpose the table (row: probe sets, column: samples)

  for (i in 1:K) { # get probe id (position) from 1 to K from each probe set
    data.stack <- rowstack(data, i) # get the probe pm values in a specific probe position across all samples from each probe set (rows are samples and columns are probe sets)
    if(dim(data[[1]])[2]==1) data.stack <- t(data.stack)
    mns[, i] <- colMeans(data.stack) # get the mean values at one probe position across all probe sets
    sds[, i] <- apply(data.stack, 2, sd) # get the sd values at one probe position across all probe sets
  }
    
  mns.orig <- mns # store the original mns data matrix
  mn <- mns[, 1] # select values in the first probe position
  mns <- sweep(mns, 1, mn) # adjust for the intensity at the first probe position
  mns <- mns/(sds/sqrt(N)) # adjust for standard error
  lm.stats <- function(x) {
    index <- 0:(length(x) - 1)
    ans <- summary(lm(x ~ index))$coefficients[2, c(1, 4)] # use linear model fit the relationship between intensity and probe position
    return(ans)
  }
  stats <- apply(mns, 1, lm.stats)
  answer <- list(N, names, mns.orig, sds/sqrt(N), stats[1,], stats[2, ])
  names(answer) <- c("N", "sample.names", "means.by.number","ses", "slope", "pvalue")
  return(answer)
}

# The RNAdeg_func function generates RNA degradation plots
# return a logical variable whether this array type can be read by affy.
RNAdeg_func <- function() {
  # 1. Read in raw data as an AffyBatch object
  library(affy) # for Affymetrix microarray-specific QC analysis
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  # 2. Obtain a list of probe sets with a matrix of oligos (probes) by samples as an input and compute statistics of the mean PM intensities from 5' to 3' probe positions. 
  PM_list <- affy::pm(raw.data.affy,LIST=T) 
  PM_list <- lapply(PM_list,log2)
  raw.data.rnadeg <- RNAdegaffy_func(PM_list) # Compute mean PM intensity for probes following 5' to 3' order.
  # 3. Plot 5' to 3' mean PM intensity
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  plotAffyRNAdeg(raw.data.rnadeg,cols=status.cols)
  legend("topleft",legend=names(colour_list),fill=colour_list,cex=0.6)
  detach("package:affy", unload=TRUE) # detach the affy package
}
```

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {RNAdeg_func()}
}
```

### Distribution of Perfect Match (PM) and Mismatch (MM)

```{r, eval=T, echo=F}
PMMM_func <- function() {
  if (class(raw.data)=="GeneFeatureSet") {
    message("GeneFeatureSet does not have MM probes. No plots will be generated.")
  } else {
    PM <- log2(pm(raw.data))
    MM <- log2(mm(raw.data))
    if(nrow(PM) != nrow(MM)) {
      message("This might be a PM-only array. No plots will be generated.")
      rm(PM,MM)
    } else {
      subsample=20000
      if(nrow(PM)>subsample) { # randomly select 20000 probe sets
        sel = sample(nrow(PM), subsample)
        sPM = PM[sel, ]
        sMM = MM[sel, ]
      } else {
        sPM = PM
        sMM = MM
      }
      rm(PM,MM) 
      
      df <- data.frame(
        values=c(as.numeric(sPM),as.numeric(sMM)),
        types=c(rep("PM",each=length(as.numeric(sPM))),rep("MM",each=length(as.numeric(sMM))))
      )
      cols=colours[1:2]
      ggplot(df,aes(x=values,colour=types)) + geom_line(aes(group=types),stat="density") +
        theme_bw() +
        xlab("Intensity") +
        ylab("Density") +
        scale_color_manual(values=cols) +
        theme(legend.title=element_blank())
    }
  }
}
```

```{r, eval=T, echo=F}
if (platform=="Affymetrix"&suppldata) {PMMM_func()}
```

### MA Plots

```{r, eval=T, echo=F}
# The MAcal_func function computes M and A matrices, while use the intensity of 20000 randomly selected probes
MAcal_func <- function(x) { # matrix (row: probe intensities, col: array (samples)
  medArray = rowMedians(x, na.rm=TRUE)
  M =  x - medArray
  A = (x + medArray)/2
  subsample=20000
  if(nrow(M)>subsample) {
    set.seed(12345)
    sel = sample(nrow(M), subsample)
    sM = M[sel, ]
    sA = A[sel, ]
  } else {
    sM = M
    sA = A
  }
  list(M=sM,A=sA) # return a list with M and A data matrices
}

# The outlier_MA_func function computes the Hoeffding's statistic (Da) statistics for outlier detection
outlier_MA_func <- function(exprs) { # list with M and A data matrices
  M=exprs$M
  A=exprs$A
  Dstats = sapply(1:ncol(M), function(x){hoeffd(A[,x], M[,x])$D[1,2]})
  names(Dstats) <- colnames(M)
  Dthresh = 0.15
  list(threshold=Dthresh, stats=Dstats, outlier = which(Dstats > Dthresh))
}

# The MAplot_func function plots samples with the first 4 highest and lowest values of Da. The value of Da for each sample is shown in the panel headings. Outliers marked with * have Da values >0.15.
MAplot_func <- function(sMA, outlier_res) {
# select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(sMA$M)-3):ncol(sMA$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  scandate_sel <- pData(raw.data)[,varuse][column_sel]
  M_sel <- sMA$M[,column_sel]
  A_sel <- sMA$A[,column_sel]
  # use * to mark the outliers
  array_name <- shortname_func(colnames(M_sel))
  outlier_MA=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_MA] <- paste0("*",array_name[array_name%in%outlier_MA])
  array_name <- paste0(array_name," (D=",stats_sel,")") # add D statistics to corresponding samples
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    scandate=rep(scandate_sel,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    A=as.numeric(A_sel)
  )
  # MA plots
  ggplot(df,aes(x=A,y=M,color=scandate)) + geom_point(alpha=0.1) + theme_bw() +
    scale_color_manual(varuse,values=colour_list) +
    facet_wrap(~sample_id,ncol=2)
}

# The MA_func function outputs MA metrics
MA_func <- function(){
  # Compute M-A metrics
  if (!normdata) {
    sMA <- MAcal_func(log2(exprs(raw.data)))
  } else {
    sMA <- MAcal_func(exprs(raw.data))
  }
  outlier_res <- outlier_MA_func(exprs=sMA)
  outlier <- names(outlier_res$outlier)
  plot <- MAplot_func(sMA=sMA, outlier_res=outlier_res)
  return(list(outlier=outlier, plot=plot))
}
```

1. Outlier detection for MA plots

```{r, eval=T, echo=F, message=F, warning=F}
res_MA=MA_func()
outlier_MA=res_MA$outlier
cat(length(outlier_MA), "outliers are detected in the MA metrics.\n")
if (length(outlier_MA)>0) {cat("They are: ", shortname_func(outlier_MA))}
```

2. MA plots

```{r, eval=T, echo=F, message=F, warning=F, fig.height=10, fig.width=7}
res_MA$plot
```

### Spatial Distribution

```{r, eval=T, echo=F}
# The affyspatial_func function computes spatial x- and y-coordinate using raw data object classed as AffyBatch
affyspatial_func <- function() {
  library(affy)
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  maxc = ncol(raw.data.affy) # number of probes in x-coordinate
  maxr = nrow(raw.data.affy) # number of probes in y-coordinate
  sx = rep(seq_len(maxc), each = maxr) ## spatial x-coordinate
  sy = rep(seq_len(maxr), maxc) ## spatial y-coordinate
  M = log2(affy::exprs(raw.data.affy))
  detach("package:affy", unload=TRUE)
  numArrays = dim(M)[2]
  return(list(M=M,numArrays=numArrays,sx=sx,sy=sy))
}

# The outlier_spatial_func function computes the Fourier coefficients for outlier detection
outlier_spatial_func <- function(affy_spatial_list) {
  sx=affy_spatial_list$sx # spatial x-coordinate
  sy=affy_spatial_list$sy # spatial y-coordinate
  M=affy_spatial_list$M
  numArrays=affy_spatial_list$numArrays
  maxx = max(sx, na.rm=TRUE)
  maxy = max(sy, na.rm=TRUE)
  stat_spatial = numeric(numArrays)
  for(a in seq_len(numArrays)) {
    mat = matrix(NA_real_, nrow=maxy, ncol=maxx)
    mat[cbind(sy, sx) ] = M[, a]
    pg  = fft(mat) ## periodogram, computes the discrete fourier transform
    npg = Re(pg*Conj(pg))
    npg[1,1] = 0 ## drop the constant component
    stat_spatial[a] = sqrt(sum(npg[1:4, 1:4]) / sum(npg)) # low frequency power
  }
  names(stat_spatial)=colnames(M)
  stats = stats::fivenum(stat_spatial, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=stat_spatial, outlier = which(stat_spatial > th))
}

# The spatplot_func function plots samples with the first 4 highest and lowest values of Fa. The value of Fa for each sample is shown in the panel headings.
spatplot_func <- function(raw.data.spatial,outlier_res) {
  # select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(raw.data.spatial$M)-3):ncol(raw.data.spatial$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  M_sel <- raw.data.spatial$M[,column_sel]
  # apply rank to expression data
  M_sel = apply(M_sel, 2, rank)
  # use * to mark the outliers
  array_name=shortname_func(colnames(M_sel))
  outlier_spatial=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_spatial] <- paste0("*",array_name[array_name%in%outlier_spatial])
  array_name <- paste0(array_name," (F=",stats_sel,")") # add F statistics to corresponding samples
  # create variables for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    row=rep(raw.data.spatial$sy,ncol(M_sel)),
    column=rep(raw.data.spatial$sx,ncol(M_sel))
  )
  # spatial distribution plots
  ggplot(df,aes(x=row,y=column,fill=M)) + geom_tile() + 
    theme_bw() +
    xlab("Raw Probe Intensiry in X") + ylab("Raw Probe Intensiry in Y") +
    scale_fill_gradientn(name="Ranked Intensity",colours=viridis(256,option="B")) +
    facet_wrap(~sample_id,ncol=2)
}

# The spatial_func function outputs spatial metrics
spatial_func <- function() {
  raw.data.spatial=affyspatial_func()
  outlier_res=outlier_spatial_func(affy_spatial_list=raw.data.spatial)
  outlier=names(outlier_res$outlier)
  plot=spatplot_func(raw.data.spatial=raw.data.spatial,outlier_res=outlier_res)
  return(list(outlier=outlier,plot=plot))
}
```


1. Outlier detection for spatial plots

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial=spatial_func()
    outlier_spatial=res_spatial$outlier
    cat(length(outlier_spatial), "outlier(s) are detected in the spatial metrics.\n")
    if (length(outlier_spatial)>0) {cat("They are: ", shortname_func(outlier_spatial))}
  }
}
```
  
2. Spatial distribution plots

```{r, eval=T, echo=F, fig.height=10, fig.width=7}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial$plot
  }
}
```

### Relative Log Expression (RLE) Distribution

```{r, eval=T, echo=F, message=F, warning=F}
# The fitPLM_func function generates RLE and NUSE matrices
fitPLM_func <- function(raw.data) {
  exprs(raw.data) <- log2(exprs(raw.data)) # The fitProbeLevelModel function needs ExpressionFeatureSet object as an input. Assign log transformed expression values to a new object
  fitPLM <- fitProbeLevelModel(raw.data)
  # RLE
  M_RLE <- RLE(fitPLM, type="values") # generate RLE matrix
  Mss_RLE <- subsamp(M_RLE,seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  # NUSE
  M_NUSE <- NUSE(fitPLM, type="values") # generate NUSE matrix
  Mss_NUSE <- subsamp(M_NUSE, seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  return(list(Mss_RLE=Mss_RLE,Mss_NUSE=Mss_NUSE))
}
# The RLE_func function outputs RLE metrics
RLE_func <- function(Mss) {
  outlier_res=outlier_KS_func(Mss) # compute KS statistics to detect outliers
  outlier=names(outlier_res$outlier)
  plot=boxplot_func(Mss,outlier,"RLE")
  return(list(outlier=outlier,plot=plot))
}
```

1. Outlier detection for RLE

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  fitPLM=fitPLM_func(raw.data)
  res_RLE=RLE_func(Mss=fitPLM$Mss_RLE)
  outlier_RLE=res_RLE$outlier
  cat(length(outlier_RLE), "outlier(s) are detected in RLE metrics.\n")
  if (length(outlier_RLE)>0) {cat("They are: ", shortname_func(outlier_RLE))}
}
```

2. Boxplot for RLE

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_RLE$plot}
```

### Normalized Unscaled Standard Error (NUSE) Outlier Detection and Plots

```{r, eval=T, echo=F, message=F, warning=F}
# The function outlier_upperquartile_func function computes upper 75% quantile for outlier detection
outlier_upperquartile_func <- function(exprs) { # matrix (row: NUSE values, col: array (e.g. sample))
  upperquartile = apply(exprs, 2, quantile, na.rm=TRUE, probs=0.75)
  stats = stats::fivenum(upperquartile, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(upperquartile > th))
}

# The NUSE_func function outputs the NUSE metrics
NUSE_func <- function(Mss) {
  outlier_res = outlier_upperquartile_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss,outlier,"NUSE")
  return(list(outlier=outlier,boxplot=boxplot))
}
```

1. Outlier detection for NUSE

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
if (platform=="Affymetrix"&suppldata) {
  res_NUSE <- NUSE_func(Mss=fitPLM$Mss_NUSE)
  outlier_NUSE = res_NUSE$outlier # compute upper 75% quantile statistics to detect outliers
  cat(length(outlier_NUSE), "outlier(s) are detected in NUSE metrics.\n")
  if (length(outlier_NUSE)>0) {cat("They are: ", shortname_func(outlier_NUSE))}
}
```

2. Boxplot for NUSE

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_NUSE$boxplot}
```

### Distance between Samples and Outlier Detection

```{r, eval=T, echo=F, warning=F}
# The dist2 estimates distance between samples
dist2 <- function (x,fun = function(a, b) mean(abs(a - b), na.rm = TRUE),diagonal = 0) {
  if (!(is.numeric(diagonal) && (length(diagonal) == 1)))
    stop("'diagonal' must be a numeric scalar.")

  if (missing(fun)) {
    res = apply(x, 2, function(w) colMeans(abs(x-w), na.rm=TRUE))
  } else {
    res = matrix(diagonal, ncol = ncol(x), nrow = ncol(x))
    if (ncol(x) >= 2) {
      for (j in 2:ncol(x))
        for (i in 1:(j - 1))
          res[i, j] = res[j, i] = fun(x[, i], x[, j])
    } # if
  } # else
  colnames(res) = rownames(res) = colnames(x)
  return(res)
}

# The outlier_dist_func function computes the sum of all distance of one sample to other samples for outlier detection
outlier_dist_func <- function(exprs) { # matrix (row: distance to each sample, col: array (e.g. sample))
  sum = colSums(exprs, na.rm=TRUE) # sum the total distance
  stats = stats::fivenum(sum, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(sum > th))
}

# The displot_func function plots distance between samples
distplot_func <- function(m,outlier) {
  dend = as.dendrogram(hclust(as.dist(m), method = "single"))
  ord = order.dendrogram(dend)
  array_name=shortname_func(colnames(m))
  outlier=shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  array_name <- shortname_func(array_name) # shorten the sample id
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256, option="B"),ColSideColors=status.cols,RowSideColors=status.cols,
    labCol=array_name,labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_list),fill=colour_list,cex=0.6)
}

# The dist_func function outputs distance metrics
dist_func <- function() {
  if (!normdata) {
    m <- dist2(log2(exprs(raw.data)))
  } else {
    m <- dist2(exprs(raw.data))
  }
  
  outlier_res=outlier_dist_func(m)
  outlier=names(outlier_res$outlier)
  return(list(outlier=outlier,m=m))
}
```

1. Outlier detection for sample distance

```{r, eval=T, echo=F}
res_dist=dist_func()
outlier_dist=res_dist$outlier
cat(length(outlier_dist), "outlier(s) are detected in sample distance metrics.\n")
if (length(outlier_dist)>0) {cat("They are: ", shortname_func(outlier_dist))}
```

2. Plot distance between samples
```{r, eval=T, echo=F, fig.height=10, fig.width=12}
distplot_func(m=res_dist$m,outlier=res_dist$outlier)
```

### Principal Component Analysis (PCA)

```{r, eval=T, echo=F}
# The pcastat_func function computes principal components
pcastat_func <- function() {
  # obtain original expression data
  if (!normdata) {
    raw.data.pca <- na.omit(log2(exprs(raw.data)))
  } else {
    raw.data.pca <- na.omit(exprs(raw.data))
  } # remove NAs
 
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(pc, group_var,legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(raw.data)[,group_var]
  )
  i=length(levels(pData(raw.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(raw.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(pc) {
  group_vars=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  legends=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(raw.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    nlevel=nlevels(pData(raw.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=20)) {
      plot_list[[group_var]]=pcaplot_func(pc, group_var=group_var,legend=legend)
    }
  }
  return(plot_list)
}
```


1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
res_pca <- pcastat_func()
pandoc.table(res_pca$tb,split.tables=Inf, caption="Variance explained")
```

2. PCA plots

```{r, eval=T, echo=F}
plot_list=pca_func(pc=res_pca$pc)
for (i in plot_list) {print(i)}
```


### QC Summary

```{r, eval=T, echo=F}
# The outlier_summ_func function outputs a summary table of outlier and the detected frequency
outlier_summ_func <- function() {
  outlier_all <- c("outlier_intensity","outlier_MA","outlier_spatial","outlier_RLE","outlier_NUSE","outlier_dist") # all outliers
  outlier_env=ls(envir=.GlobalEnv, pattern="outlier_") # "outlier_" enviromental variables
  outlier=outlier_env[outlier_env%in%outlier_all]
  method=gsub("outlier_","",outlier)
  outliers=unlist(lapply(1:length(outlier),function(x){get(outlier[x],envir=.GlobalEnv)}))
  if (length(outliers)==0) {
    cat("No outlier was detected\n")
    res <- data.frame() # create an empty data frame
  } else {
    methods=unlist(lapply(1:length(outlier),function(x){n=length(get(outlier[x]));rep(method[x],n)}))
    outlier_list=list()
    for (x in 1:length(outliers)){outlier=outliers[x];method=methods[x];outlier_list[[outlier]]=append(outlier_list[[outlier]],method)}
    # summary table
    Frequency <- sapply(outlier_list,length) # times to detect
    Method <- unlist(lapply(names(outlier_list),function(x){paste0(outlier_list[[x]],collapse=", ")}))
    res <- data.frame(Frequency,Method)
    res <- res[order(res$Frequency),]
  }
  return(res)
}

# The tbQC_func function
tbQC_func <- function(outliers) { # define outliers
  tb=pData(raw.data)
  tb$QC_Pass=1
  if (missing(outliers)) { # if outliers are not defined, use those detected more than twice
    tb$QC_Pass[rownames(tb)%in%rownames(outlier_tb)[outlier_tb$Frequency>2]]<-0 # assign 0 to outliers detected more than twice
  } else {
    tb$QC_Pass[rownames(tb)%in%outliers]<-0
  }
  tb$Filename <- rownames(tb) # add filename in a new column
  # save in a new phenotype file
  write.table(tb,pheno_fn_withQC,col.names=T,row.names=F,sep="\t",quote=F)
  # defined outliers
  outlier=as.character(tb$GEO_ID)[which(tb$QC_Pass==0)]
  # summary of phenotype information before QC
  vars=c("Tissue","Treatment","Disease","QC") # variables of interest
  # before QC
  tb_withoutQC=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb_withoutQC)[ncol(tb_withoutQC)]="Counts"
  # after QC
  tb_withQC=as.data.frame(table(tb[which(tb$QC==1),names(tb)%in%vars]))
  names(tb_withQC)[ncol(tb_withQC)]="Counts"
  return(list(outlier=outlier, tb_withoutQC=tb_withoutQC, tb_withQC=tb_withQC))
}
```

```{r, eval=T, echo=F, results="asis"}
outlier_tb=outlier_summ_func()
if (nrow(outlier_tb)>0) {
  pandoc.table(outlier_tb,caption="Outlier Summary",split.tables=Inf)
}
```

```{r, eval=T, echo=F}
res_tbQC=tbQC_func()
outlier=res_tbQC$outlier
cat(length(outlier), "outlier(s) are defined.\n")
if (length(outlier)>0) {cat("They are: ", outlier)}
```

```{r, eval=T, echo=F, results="asis"}
pandoc.table(res_tbQC$tb_withoutQC, split.tables=Inf, caption="Summary of samples without QC")
pandoc.table(res_tbQC$tb_withQC, split.tables=Inf, caption="Summary of samples with QC")
```

> Differential Gene Expression Analysis for GSE26440

```{r, eval=T, echo=T}
# GEO id
geo_id="GSE26440"
# tissue
tissue="Blood"
# reference condition
con0="Control"
# altered condition
con1="Shock"
# treatment. Assign "comparison" if this column is used for DE.
treatment="24hr"
# disease. Assign "comparison" if this column is used for DE.
disease=c(con0,con1)
```

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
usesuppl=TRUE
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*).(cel|CEL).gz","\\1",x)} # remove .cel.gz or .CEL.gz from sample
```

```{r, eval=T, echo=F}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
```

```{r, eval=T, echo=F}
cat(paste0("pheno_fn = '", pheno_fn,"'"))
```

```{r, eval=T, echo=F, message=F, warning=F}
library(GEOquery)
library(oligo)
library(limma)
library(sva)
library(annotate)
library(viridis)
library(ggplot2)
library(gplots)
library(devtools)
library(preprocessCore)
library(pander)
```

## Obtain Phenotype and GEO Data

### Phenotype data preparation

```{r, eval=T, echo=F}
# The phenosub_func function subsets phenotypes based on the user defined variables
phenosub_func <- function(){
  pheno.sub=subset(pheno,(Tissue%in%tissue)&(Treatment%in%treatment)&(Disease%in%disease))
  pheno.sub=droplevels(pheno.sub)
  # assign comparison to "Status" column
  if (length(treatment)==2) {
    if (identical(sort(levels(pheno.sub$Treatment)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Treatment} else {stop("Assigned treatment variables are not included in the Treatment column")}
  } else if (length(disease)==2) {
    if (identical(sort(levels(pheno.sub$Disease)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Disease} else {stop("Assigned treatment variables are not included in the Disease column")}
  }
  pheno.sub$Status <-factor(pheno.sub$Status,levels=c(con0,con1))
  return(pheno.sub)
}

# The phenoqc_func function excludes outliers from phenotype file 
phenoqc_func <- function(outlier,pheno) {
  if (missing(outlier)) {pheno=subset(pheno, QC_Pass==1)} else {pheno=subset(pheno, Filename%in%outlier)}
  droplevels(pheno)
}

# The phenopair_func function excludes unpaired donor from analysis
phenopair_func <- function(dat) {
  unpaired_samp=names(which(table(dat$Donor)==1))
  dat=dat[which(!dat$Donor%in%unpaired_samp),]
  droplevels(pheno)
  if (length(unpaired_samp)>0) {
    cat(paste0(length(unpaired_samp)," sample(s) with unpaired donor are excluded from analysis\n"))
    cat(paste(unpaired_samp,collapse=", "),"\n")
  }
  return(dat)
}

# The tbsum_func function generates summary of variables of interest
tbsum_func <- function(tb) {
  vars=c("Status", "ScanDate_Group") # variables of interest
  tb=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb)[ncol(tb)]="Counts"
  return(tb)
}

# The infosumm_function generates summary of the comparison
infosumm_func <- function(pheno) {
  N_Condition0 <- sum(pheno$Status==con0) # count number of samples under condition 0
  N_Condition1 <- sum(pheno$Status==con1) # count number of samples under condition 1
  if (identical(sort(levels(pheno$Treatment)),sort(c(con0,con1)))) {
    App="GC"
    if (geo_GPL=="") {name=paste(geo_id,tissue,disease,con1,"vs",con0, sep="_")} else {{name=paste(geo_id,geo_GPL,tissue,disease,con1,"vs",con0, sep="_")}}
    Disease=disease
    Treatment=con1
  } else {
    App="Asthma"
    if (geo_GPL=="") {name=paste(geo_id,tissue,treatment,con1,"vs",con0, sep="_")} else {name=paste(geo_id,geo_GPL,tissue,treatment,con1,"vs",con0, sep="_")}
    Disease=con1
    Treatment=treatment
  }
  
  df <- data.frame(
    GEO_ID=geo_id,
    Tissue=tissue,
    App=App,
    Disease=Disease,
    Treatment=Treatment,
    N_Condition0=N_Condition0,
    N_Condition1=N_Condition1,
    Total=N_Condition0+N_Condition1,
    Unique_ID=name
  )
  return(list(df=df,name=name))
}
```

```{r, eval=T, echo=F}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
# read in the pre-prepared phenotype data
if (!file.exists(pheno_fn)) {stop("The phenotype file does not exist. Please check!")} else {pheno <- read.table(pheno_fn, header=TRUE, sep="\t")}
```

```{r, eval=T, echo=F}
pheno.sub=phenosub_func()
outlier=as.character(pheno.sub$Filename)[pheno.sub$QC_Pass==0]
if (length(outlier)>0) {
  cat("Remove outlier(s)", outlier, "from phenotype file\n")
  pheno.of.interest=phenoqc_func(pheno=pheno.sub)
} else {pheno.of.interest=pheno.sub}
```

Define paired variable.

```{r, eval=T, echo=F, results="asis"}
if (length(disease)==2) {
  paired=FALSE
} else if (length(disease)==1) {
  if (all((pheno.sub$Donor)==1)) {paired=FALSE} # if treatment is in different donors
  else {paired=TRUE} # if treatment is in samd donors
}
```

```{r, eval=T, echo=F}
cat("paired =",as.character(paired))
```

Exclude samples missing the other paired donors in treatment comparisons
```{r, eval=T, echo=F, results="asis"}
if (paired) {
  pheno.of.interest <- phenopair_func(pheno.of.interest)
}
```

```{r, eval=T, echo=F, results="asis"}
if (nrow(pheno.sub)!=nrow(pheno.of.interest)) {
  pandoc.table(tbsum_func(tb=pheno.sub), split.tables=Inf, caption="Summary of subsetted samples without QC")
  pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples with QC")
} else {pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples")}

# create a summary table for this comparison
pandoc.table(t(infosumm_func(pheno=pheno.of.interest)$df),split.tables=Inf, caption="Summary of the comparison")
```

Assign colours to status and scan date (if available)

```{r, eval=T, echo=F}
# assign colours to comparison status
colour_status <- c("navy","red")
names(colour_status) <- c(con0,con1) # assign red to condition 1 and navy to condition 2
colour_status_list <- unlist(lapply(pheno.of.interest$Status,function(x){colour_status[x]}))
# assign colours to scan date
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
if ("ScanDate_Group"%in%names(pheno)) {
  i=nlevels(pheno.of.interest$ScanDate_Group)
  colour_scandate <- colours[1:i]
  names(colour_scandate) <- levels(pheno.of.interest$ScanDate_Group) # colour to corresponding scan date
  colour_scandate_list <- unlist(lapply(pheno.of.interest$ScanDate_Group,function(x){colour_scandate[x]}))
}
```

### Gene expression data preparation

For data from Affymetrix platform, raw probe intensity data from supplementary files (usually .cel files) in GEO are downloaded and used for DE analysis. For data from Agilent platform, the intensity data is derived from GEO expression matrix.

Generate raw.data object using supplementary files (for Affymetrix data).

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and unextract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (usesuppl) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno$Filename))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}

  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)
}
```


Generate raw.data object using expression matrix from GEO (for platforms other than Affymetrix).

```{r, eval=T, echo=F, message=F, warning=F}
if (!usesuppl) {
  # check if GEO matrix file exists
  geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
  if (length(geo_fn)==0) { # # GEO matrix file is not downloaded
    gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
    if (length(gselms)>1) {  # multiple platform
      gpls=sapply(gselms,annotation)
      cat("This study was performed in multiple platforms:\n")
      cat(unname(gpls),"\n")
      cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
      if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
    } else {idx=1}
    gse <- gselms[[idx]]
  } else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
    gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
  } else { # GEO matrix file is alreadly downloaded and has multiple platforms
    cat("This study was performed in multiple platforms:\n")
    cat(geo_fn)
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <-geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
  }
  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.data=gse
}
```

Obtain raw.data.of.interest by subsetting raw.data based on the phenotype of interest

```{r, eval=T, echo=F}
# The subdat_func function subsets data based on the phenotype of interest
subdat_func <- function(raw.data, pheno) {
  # subset raw.data based on the phenotype of interest
  raw.data=raw.data[,colnames(raw.data)%in%pheno$Filename]
  # assign phenotype data to raw expression data
  pData(raw.data) <- pheno
  row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
  # check if the sample names derived from expression data match those in phenotype file
  if (usesuppl) {matching=mapply(identical,row.names(pData(raw.data)),as.character(pheno$Filename))}
  else {matching=mapply(grepl,row.names(pData(raw.data)),as.character(pheno$Filename))}
  if (!all(matching)) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
  return(raw.data)
}
raw.data.of.interest=subdat_func(raw.data=raw.data, pheno=pheno.of.interest)
```

Show expression dataset features
```{r, eval=T, echo=F}
raw.data.of.interest
```

## Differential Gene Expression Analysis

### Normalize raw gene expression data

Normalize gene expression raw data using robust multi-array average (RMA) method (if supplementary data is available) or quantile normalize (if use expression matrix), unless the raw.data object is already normalized (based on the variable normdata).


If negative/zero intensity values are present, convert them to NAs.

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data.of.interest),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data.of.interest)=apply(exprs(raw.data.of.interest),2,function(x){replace(x,which(x<=0),NA)})
```

```{r, eval=T, echo=F, message=F, results="hide"}
if (usesuppl) {
  rma.data.of.interest = rma(raw.data.of.interest)
  cat("RMA normalization is used.\n")
} else {
  rma.data.of.interest=raw.data.of.interest
  if (!normdata) {exprs(rma.data.of.interest)=normalize.quantiles(log2(exprs(rma.data.of.interest)))
  cat("Quantile normalization and log2 transformation is used.\n")
  }
}
```

```{r, eval=T, echo=F}
cols=colour_status_list
boxplot(raw.data.of.interest,target="core",col=cols,main="Raw Probe Intensities",xaxt="n") # view raw data
legend("topright",legend=names(colour_status),fill=colour_status)

if (!normdata) {
  boxplot(rma.data.of.interest,col=cols,main="Normalized Probe Intensities",xaxt="n") # view RMA-adjusted data
  legend("topright",legend=names(colour_status),fill=colour_status)
} else {cat("The raw data is already normalized")}
```


### Pairwise Comparison between Status

```{r, eval=T, echo=F, results="asis"}
limma_func <- function(paired=FALSE) { # here only con0, con1 are used in comparisons. use a function to reduce the factor levels
  if (paired) {
    cat("Donor is adjusted in this regression\n")
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$Donor)) # create design model matrix
    colnames(design) = c(levels(factor(rma.data.of.interest$Status)),levels(factor(rma.data.of.interest$Donor))[-1])
  } else {
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)) # create design model matrix
    colnames(design) = levels(factor(rma.data.of.interest$Status))
  }
  fit = lmFit(rma.data.of.interest, design) # fit a linear model to estimate the fold changes and standard error
  # Create a contrast group and fit it in a linear model
  data.contrast = makeContrasts(contrasts=paste(c(con1,con0),collapse="-"),levels = design) # create a contrast group by comparing con1 vs con0
  fit2 = contrasts.fit(fit, data.contrast) # get the contrasts for samples of interest
  fit2 = eBayes(fit2) # adjust fit coefficients using an empirical Bayes moderation of standard errors
  return(list(design=design,data.contrast=data.contrast,fit2=fit2))
}
```

Fit a linear model to RMA log-intensity values, fit this model to a contrast matrix for the comparison of interest, and apply empirical Bayes smoothing to obtain more precise standard errors.

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
res_DE=limma_func(paired=paired)
fit2=res_DE$fit2
pandoc.table(data.frame(Sample=rma.data.of.interest$Sample,res_DE$design), split.tables=Inf, caption="A design model matrix for linear model")
pandoc.table(as.data.frame(res_DE$data.contrast), caption="A contract matrix for comparison")
contrast_table <- topTable(fit2, adjust="BH",num=Inf) # get full set of results for each hypothesis test
col.sel=c("logFC","AveExpr","t","P.Value","adj.P.Val","B") # select the columns of DE results
contrast_table <- data.frame(ID=row.names(contrast_table), contrast_table[,col.sel])
```

### Adjusting for Batch Effect

```{r, eval=T, echo=F}
# The nbatch_func function obtains number of batches (scan date) in the data
nbatch_func <- function() {
  if (!"ScanDate_Group"%in%names(pData(rma.data.of.interest))) {nbatch=0} else {nbatch=nlevels(rma.data.of.interest$ScanDate_Group)}
}

# The svamod_func function creates full and null models, and Checks if the batch and comparison status are confounded
svamod_func <- function(paired=FALSE) {
  # Create a full model
  modBatch = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)) # full model (adjusted variables and variables of interest)
  # Create a null model only including batch variables
  nullBatch =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)) # null model (adjusted variables only)
  # Check if the scan date and comparison status are confounded
  if (class(try(solve(t(modBatch)%*%modBatch),silent=T))=="matrix") {batchadj=TRUE} else {batchadj=FALSE; message("The scan date and comparison status are highly confounded")}
  # summary of the full model
  tb.fullmod <- as.data.frame(modBatch)
  names(tb.fullmod) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])
  # summary of the null model
  tb.nullmod <- as.data.frame(nullBatch)
  names(tb.nullmod) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])

  donoradj=NULL # assign variable is donor is adjusted
  tb.nullmod1=NULL # assign null matrix for donor adjustment
  if ((paired)&(batchadj)) { # same donor treatment adjust for donor
    # Test if donor and scandate are correlated
    modBatch1 = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # full model including donor
    nullBatch1 =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # null model including donor
    # summary of the full model
    tb.fullmod1 <- as.data.frame(modBatch1)
    names(tb.fullmod1) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
    # summary of the null model
    tb.nullmod1 <- as.data.frame(nullBatch1)
    names(tb.nullmod1) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
      
    # check if scandate correlated with donor
    if (class(try(solve(t(modBatch1)%*%modBatch1),silent=T))=="matrix") {
      donoradj="yes"
      modBatch=modBatch1
      nullBatch=nullBatch1
      tb.fullmod=tb.fullmod1
      tb.nullmod=tb.nullmod1
    }
  }

  return(list(modBatch=modBatch, nullBatch=nullBatch, tb.fullmod=tb.fullmod, tb.nullmod=tb.nullmod, batchadj=batchadj, donoradj=donoradj, tb.nullmod_donor=tb.nullmod1))
}

# The batcherror_func function assigns a variable batcherror to decide whether to adjust for batch effect under various scenarios
batcherror_func <- function() {
  if (nbatch==0) {
    batcherror="zero"
  } else if (nbatch==1) {
    batcherror="one"
  } else {
    if (batchadj) {batcherror="no"} else {batcherror="correlate"}
  }
  return(batcherror)
}

# The batchadj_func function outputs table with batch effects adjusted p-values
batchadj_func <- function(batcherror=batcherror, contrast_table=contrast_table, paired=paired) {
  if (batcherror=="no") {
    modBatch=svamod_func(paired=paired)$modBatch
    nullBatch=svamod_func(paired=paired)$nullBatch
    pValuesBatch=f.pvalue(exprs(rma.data.of.interest), modBatch, nullBatch) # get batch effect-adjusted p-values
    qValuesBatch=p.adjust(pValuesBatch, method="BH") # get q-values
    tb.sva <- data.frame(ID=names(pValuesBatch),pValuesBatch,qValuesBatch)
    contrast_table <- merge(contrast_table, tb.sva, by="ID", all=TRUE)
  } else if (batcherror=="correlate") {
    contrast_table$pValuesBatch=contrast_table$qValuesBatch=rep(NA,nrow(contrast_table))
  } else {
    contrast_table$pValuesBatch=contrast_table$P.Value
    contrast_table$qValuesBatch=contrast_table$adj.P.Val
  }
  return(contrast_table)
}
```

Check whether to adjust for scan date and donor.

```{r, eval=T, echo=F}
nbatch=nbatch_func()
if (nbatch>1) {res_svamod=svamod_func(paired=paired);batchadj=res_svamod$batchadj}
batcherror=batcherror_func()
if (batcherror=="zero") {cat("No scan date is present in the data.")} else if (batcherror=="one") {cat("Only one batch is present in the data.")} else if (batcherror=="correlate") {cat("The scan date and the comparison status are highly confounded (See the model matrix). Cannot ajust for batch effect.")}
```

Create a full model that includes all variables and a null model that only includes the batch variable. Note that as SVA computes the matrix x in t(batch model)%*%x=batch model, batch effect can be adjusted only when the solve function works.

```{r, eval=T, echo=F, results="asis"}
if (nbatch>1) {
  if (paired) {
    if (is.null(res_svamod$donoradj)) {
      cat("Scan date and donor are highly confounded. See the matrix below.\n")
      pandoc.table(res_svamod$tb.nullmod_donor, split.tables=Inf, caption="Null model matrix with scan date and donor")
      cat("Only adjust for scan date.\n")
    } else {cat("Both scan date and donor are adjusted.\n")}
  }
  pandoc.table(res_svamod$tb.fullmod, split.tables=Inf, caption="Full model matrix")
  pandoc.table(res_svamod$tb.nullmod, split.tables=Inf, caption="Null model matrix")
}
```


Compute F statistic p-values adjusted for batch effect. Q-values are obtained by the Benjamini-Hochberg method. If the batch and the status are correlated, assign NA to the batch adjusted p- and q-values. If there is no batch variable or only one batch, assign p- and q-values computed by limma to the batch adjusted p-values

```{r, eval=T, echo=F, results="asis"}
contrast_table=batchadj_func(batcherror=batcherror, contrast_table=contrast_table, paired=paired)
pandoc.table(summary(contrast_table), split.tables=Inf, caption=paste0(con1, " vs. ", con0, " summary"))
```


### Assign Official Gene Symbol

Annotate official gene symbol to probes. Install the [R annotation database package](https://bioconductor.org/packages/3.7/data/annotation/) corresponding to your gene expression data. For any newly installed annotation databases, it can be added to the list anno_list reserved for future use.

```{r, eval=T, echo=F}
anno_list=list()
# Affymetrix
anno_list[["pd.hg.u133.plus.2"]]="hgu133plus2.db"
```

```{r, echo=F}
# glpanno_func creates anntoation vector based on GPL annotation from GEO
glpanno_func <- function(GPL_ID){
  gpl <- Table(getGEO(GPL_ID, destdir = "data"))
  if (GPL_ID%in%names(symbol_list)) {anno_vect <- gpl[,symbol_col]} else {anno_vect <- gpl[,"gene name"]}
  names(anno_vect) <- gpl[,"ID"]
  return(anno_vect)
}

# ranno_func creates anntoation vector based on R annotation database
ranno_func <- function(anno_lib){
  # check if the annotation database is installed
  if (!anno_lib%in%installed.packages()[,1]){source("http://bioconductor.org/biocLite.R"); biocLite(anno_lib)}
  library(anno_lib, character.only=T)
  anno_symbol=gsub(".db","SYMBOL",anno_lib) # The name of the R object mapping between probe id and gene symbol
  x=get(anno_symbol)
  # Get the probe identifiers that are mapped to a gene symbol
  mapped_probes <- mappedkeys(x)
  # Convert to a list
  xx <- as.list(x[mapped_probes])
  # Convert list to annotation vector
  anno_vect <- sapply(xx,function(x){x})
  return(anno_vect)
}

# geneannot_func annotates gene symbol to DE result table
geneannot_func <- function(tb, anno_vect) {
  remove.pm <- function(x) {gsub("_PM", "", x)} # Assign official gene symbol using hgu133plus2.db package if anntoation is based on pd.hg.u133.plus.2. Note that the probe names have additional "PM"s in the results will be removed to match the names in the gene symbol package.
  if (exists("anno_lib")) {
    if (anno_lib=="hgu133plus2.db") {tb$ID=sapply(as.character(tb$ID), remove.pm)}
  }
  tb$ID=as.character(tb$ID)
  tb$SYMBOL=sapply(as.character(tb$ID), function(x){if (x%in%names(anno_vect)){anno_vect[x]} else {"NA"}})
  tb$SYMBOL[which(tb$SYMBOL=="")]="NA"
  # remove probes with NA in logFC column
  tb <- tb[!is.na(tb$logFC),]
  tb[order(tb$P.Value),]
}
```

```{r, eval=T, echo=F, warning=F, message=F}
# install corresponding annotation database if it is not installed
anno_array=annotation(rma.data.of.interest)
cat("The platform used is", anno_array, "\n")
if (!anno_array%in%names(anno_list)) {
  cat("Annotate using GPL annotation in GEO\n")
  anno_vect=glpanno_func(GPL_ID=anno_array)
} else {
  anno_lib=anno_list[[anno_array]] # use the annotation database
  cat("The corresponding R annotation database package is", anno_lib,"\n")
  anno_vect <- ranno_func(anno_lib=anno_lib)
}
```

```{r, eval=T, echo=F}
contrast_name=infosumm_func(pheno=pheno.of.interest)$name # adopt Unique_ID created in the information summary table
contrast_fn=paste0(resdir,"/", contrast_name, ".csv")
```

```{r, eval=T, echo=F, warning=F, message=F}
contrast_table <- geneannot_func(tb=contrast_table, anno_vect=anno_vect)
write.csv(contrast_table, file=contrast_fn, row.names = FALSE)
```

```{r, eval=T, echo=F}
if (file.exists(contrast_fn)) {contrast_fn=paste0(resdir,"/", contrast_name, ".csv")}
res=read.csv(contrast_fn)
```

## Gene Expression Results Visualization

### Volcano Plots

```{r, eval=T, echo=F}
# The volplot_func function generates volcano plots
volplot_func <- function(df,qval_column,title) {
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else {          
    df <- df[!is.na(qval),] # remove NA values
    qval <- df[,qval_column]
    if (min(df[,qval_column])>=0.05) {
      df$sig <- "black" # assign colors to DE and non-DE genes
    } else {
      # assign colors to DE and non-DE genes
      df$sig <- rep(NA,nrow(df))
      df$sig[qval<0.05] <- "red"
      df$sig[qval>=0.05] <- "black"
    }
    df$sig <- as.factor(df$sig)
    color <- levels(df$sig)
    # log10 transformed q values
    df$logqval <- -log10(qval)
    diffgenes <- df$ID[qval<0.05] #Create list of all DEG's
    signum = paste0(length(diffgenes), " significant genes based on ", qval_column)
    if (missing(title)) {title=signum}
    print(
    ggplot(df, aes(x = logFC, y = logqval, color=sig)) + geom_point() +
      theme_bw() +
      labs(title=title,x="logFC",y=paste0("-log10(",qval_column,")")) +
      scale_color_manual(values=color) +
      theme(legend.position="none")
    )
  }
}
```

Volcano plot (probes with a q-value <0.05 are present in red)

```{r, eval=T, echo=F, fig.height=4, fig.width=4.5}
for (qval in c("adj.P.Val","qValuesBatch")) {volplot_func(res, qval)}
```


### Histograms

```{r, eval=T, echo=F}
# The histplot_func function generates histogram for p-value distributions
histplot_func <- function(df,qval_column,title) {
  if (missing(title)) {title=""}
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else{hist(qval,main=title,xlab=qval_column)}
}
```

Histograms of p-value distributions

```{r, eval=T, echo=F, fig.width=4.5, fig.height=4}
for (pval in c("P.Value","pValuesBatch")) {histplot_func(res, pval)}
for (qval in c("adj.P.Val","qValuesBatch")) {histplot_func(res, qval)}
```

### Top 20 Differentially Expression Results

```{r, eval=T, echo=F}
# The datreform_func function reformats the DE table
datreform_func <- function(dt,topnum=200) {
  dt=dt[order(dt$P.Value),]
  dt=dt[1:topnum,]
  round2 <- function(x){round(x,2)}
  dt[,c("logFC","AveExpr","t","B")] <- sapply(dt[,c("logFC","AveExpr","t","B")],round2)
  sciform <- function(x){format(x,scientific=TRUE,digits =2)}
  dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")] <- sapply(dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")],sciform)
  dt
}
```

Show top 20 probes sorted by un-adjusted p-values

```{r, eval=T, echo=F, results="asis"}
res <- datreform_func(dt=res)
rownames(res) <- NULL
pandoc.table(res[1:20,],split.tables=Inf)
```

### Boxplots for Top 6 Differentially Expressed Genes

This step helps to visualize and check the effect direction in the comparison.

```{r, eval=T, echo=F}
# function for top gene boxplot
topgene_boxplot_func <- function(tb,colour,comp) { # comp: comparison status
  for (i in 1:nrow(tb)) {# top i probe in res
    if (missing(comp)) {comp=""}
    if (missing(colour)) {colour=colours[1]}
    probe_top <- tb$ID[i]
    gene_top <- tb$SYMBOL[i]
    row.names(rma.data.of.interest) <- gsub("_PM","",row.names(rma.data.of.interest))
    values=exprs(rma.data.of.interest)[row.names(rma.data.of.interest)%in%probe_top, ]
    status=rma.data.of.interest$Status
    df <- data.frame(values=values,status=status)
    title=paste0(comp," top ",i," probe ", probe_top, " gene ", gene_top)
    print(
      ggplot(df,aes(x=status,y=values)) +
        geom_boxplot(outlier.colour=NA,color="grey18",fill=colour) +
        stat_boxplot(geom ='errorbar', color="grey18") +
        geom_jitter(size=1,position = position_jitter(width=0.3)) +
        labs(title=title) +
        theme_bw() +
        theme(legend.position="none",axis.title=element_blank())
    )
  }
}
```

```{r, eval=T, echo=F, message=F, warning=F, fig.height=4, fig.width=4.5}
topgene_boxplot_func(tb=res[1:6,])
```


### Heatmap for Top 200 Differentially Expressed Genes

```{r, eval=T, echo=F}
# The heatmap_topgene_func function for top gene heatmap plots
heatmap_topgene_func <- function(tb, topnum=200, colour_status_list, colour_status, main="") { # colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  top.rma <- rma.data.of.interest[row.names(rma.data.of.interest)%in%tb[1:topnum,"ID"],] # plot heatmap for top 200 genes
  array_name <- shortname_func(colnames(exprs(top.rma))) # shorten the sample id
  heatmap.2(na.omit(exprs(top.rma)), col=viridis(256, option="B"),
    ColSideColors=colour_status_list, # use predefined colour_status_list, assign colors to status
    labCol=array_name,labRow = "", # take out gene probe id
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow=1,cexCol=1,
    keysize=1.5,key.title=NA,key.xlab="Gene Expression Values",key.ylab="Counts",
    main=main)
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.8) # use predifined colour_status
}
```


```{r, eval=T, echo=F, fig.height=10, fig.width=12}
heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_status_list, colour_status=colour_status, main="Gene expression heatmap by comparison status")
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Gene expression heatmap by scan date")
}
```

### Heatmap for Sample Correlation

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# The corplot_func function plots correlation between samples
corplot_func <- function(m, colour_status_list, colour_status, main="") {  # m: correlation matrix, colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  m <- cor(na.omit(m)) # compute correlation matrix
  # compute distance based on 1-correlation efficient
  dend = as.dendrogram(hclust(as.dist(1-m), method = "single"))
  ord = order.dendrogram(dend)
  array_name <- shortname_func(colnames(m)) # shorten the sample id
  # heatmap plot
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256,option="B"), ColSideColors=colour_status_list, RowSideColors=colour_status_list,
    labCol=array_name, labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.6)
}
```


```{r, eval=T, echo=F, fig.height=10, fig.width=12}
corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_status_list, colour_status=colour_status, main="Correlation heatmap by comparison status")
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Correlation heatmap by scan date")
}
```

### Principal Component Analysis (PCA)

```{r, eval=T, echo=F, warning=F, message=F, results="asis"}
# The pcastat_func function computes principal components
pcastat_func <- function(m) {
  # obtain original expression data
  raw.data.pca <- na.omit(apply(m,2,function(x)replace(x,is.infinite(x),NA))) # replace infinite values to NAs and omit NAs
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(oligo.data, pc, group_var, legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(oligo.data)[,group_var]
  )
  i=length(levels(pData(oligo.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(oligo.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(oligo.data, pc) {
  group_vars=c("ScanDate_Group", "Status", "Donor")
  legends=c("ScanDate_Group", "Status", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(oligo.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    pData(oligo.data)[,group_var]=as.factor(as.character(pData(oligo.data)[,group_var])) # convert to factor
    nlevel=nlevels(pData(oligo.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=10)) {
      if (group_var=="Status") {
        plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)+scale_color_manual(legend,values=colour_status,na.value="grey") # assign colour to comparison stauts
      } else {plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)}
    }
  }
  return(plot_list)
}
```

1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=F, warning=F, message=F, results="asis"}
res_pca <- pcastat_func(m=exprs(rma.data.of.interest))
pandoc.table(res_pca$tb, split.tables=Inf, caption="Variance explained")
```

2. PCA plots

PCA plots are generated using the first two principle components colored by known factors (e.g. comparison status, donors and scan dates), visualizing similarities between arrays and these similarities' correlation to batch effects.

```{r, eval=T, echo=F, message=F, warning=F}
plot_list=pca_func(oligo.data=rma.data.of.interest, pc=res_pca$pc)
for (i in plot_list) {print(i)}
```

## Quality Control for GSE57065

```{r, eval=T, echo=T}
# GEO id
geo_id="GSE57065"
```

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*)\\.(cel|CEL).gz","\\1",x)}
```

```{r, eval=T, echo=F, message=F, warning=F}
library(GEOquery)
library(oligo)
library(viridis) # heatmap colour
library(ggplot2)
library(gplots) # heatmap.2 plot
library(Hmisc) # compute hoeffd (Hoeffding's D statistics) for MA plot
library(devtools) # compuate PCs
library(preprocessCore) # quantile normalization
library(pander)
```

## GEO Data Download and Phenotype Preparation

### GEO Dataset Download

```{r, eval=T, echo=F, message=F, warning=F}
# check if GEO matrix file exists
geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
if (length(geo_fn)==0) { # GEO matrix file is not downloaded
  gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
  if (length(gselms)>1) {  # multiple platform
    gpls=sapply(gselms,annotation)
    cat("This study was performed in multiple platforms:\n")
    cat(unname(gpls),"\n")
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
  } else {idx=1}
  gse <- gselms[[idx]]
} else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
  gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
} else { # GEO matrix file is alreadly downloaded and has multiple platforms
  cat("This study was performed in multiple platforms:\n")
  cat(geo_fn)
  cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
  if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <- geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
}
```


Show expression dataset features
```{r, eval=T, echo=F}
gse
```

### Modify raw phenotype information

```{r, eval=T, echo=F, results="asis"}
pheno.raw <- pData(phenoData(gse))
for (x in names(pheno.raw)) {
  vec=pheno.raw[,x]
  if (!is.numeric(vec)) {
    # create an empty data frame to save any tables with non-native characters
    tb_nonnative=data.frame()
    vec <- factor(vec)
    if (nlevels(vec)>5) {res=table(droplevels(vec[vec%in%levels(vec)[1:5]]))} else {res=table(vec)}
    res=data.frame(res)
    names(res) <- c(x,"counts")
  }
  if (is.numeric(vec)){res=summary(vec)}
  # Try if any existing non-native characters cause pander error
  if (class(try(pandoc.table(res, justify='left',split.tables=Inf, caption=x), silent = T))=="try-error") {tb_nonnative=res}
  if (nrow(tb_nonnative)>1){print(res)}
}
```

```{r, eval=T, echo=F}
# check if there is missing supplementary_file
if (all(pheno.raw$supplementary_file=="NONE")) {
  suppldata=FALSE
} else if (any(pheno.raw$supplementary_file=="NONE")) {
  sample_nosuppl=as.character(pheno.raw$geo_accession[pheno.raw$supplementary_file=="NONE"])
  pheno.raw=pheno.raw[which(pheno.raw$supplementary_file!="NONE"),]
  cat("Not all samples have defined supplementary file path:\n")
  cat(paste(sample_nosuppl,collapse=", "),"\n")
  cat("These samples are excluded from analysis\n")
  suppldata=TRUE
} else {suppldata=TRUE}
```

```{r, eval=T, echo=F}
cat("suppldata =",as.character(suppldata))
```

#### Phenotype information modification

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
library(dplyr)
cols <- c("title","geo_accession","source_name_ch1")
pheno <- pheno.raw %>%
  dplyr::select(cols) %>%
  dplyr::mutate(GEO_ID=geo_accession) %>%
  dplyr::mutate(Donor=gsub("^.*biological (.*)$","\\1",title)) %>%
  dplyr::mutate(Sample=paste(geo_accession,Donor,sep="_")) %>%
  dplyr::mutate(Tissue="Blood") %>%
  dplyr::mutate(treatment_time=gsub("^.*for (\\d+.*)$","\\1",source_name_ch1)) %>%
  dplyr::mutate(treatment_time=gsub(" ","",treatment_time)) %>%
  dplyr::mutate(treatment_drug=ifelse(grepl("sepsis",source_name_ch1),"sepsis","healthy")) %>%
  dplyr::mutate(Treatment=c(rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",1), rep("No",2), rep("24hr",25))) %>%
  dplyr::mutate(Disease=c(rep("Shock",82), rep("Control",25))) %>%
  dplyr::mutate_if(is.character,as.factor) %>%
  dplyr::select(-one_of(cols)) # remove original columns
detach("package:dplyr")
```

### Raw intensity data download

```{r, eval=T, echo=F}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and extract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (suppldata) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno.raw$supplementary_file))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}
}
```

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
if (platform=="Affymetrix"&suppldata) {
  #1. Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)

  #2. Obtain scan date information from the raw.data for batch effect adjustment
  # As the scan date and scan time are usually joined by "T" or a white space, use both pattern to split the date with time
  pheno$ScanDate_Group <- sapply(strsplit(as.character(protocolData(raw.data)$dates), "T| "), function(x) {x[[1]]})
  pheno$ScanDate_Group <- as.factor(pheno$ScanDate_Group)
}
```

```{r, eval=T, echo=F}
if (!suppldata) {raw.data=gse}
```

```{r, eval=T, echo=F}
# assign phenotype data to raw expression data
pData(raw.data) <- pheno
row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
# Check if the sample names derived from expression data match those in phenotype file
rowname <- gsub("^(.*).(cel|CEL|txt|Txt).gz","\\1",row.names(pData(raw.data)))
matching <- mapply(grepl, x=rowname, pattern=as.character(pData(raw.data)$GEO_ID))
if (FALSE %in% matching) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
```

```{r, eval=T, warning=F,results="asis",echo=F}
# show the first five rows
pandoc.table(head(pheno,5), split.tables=Inf,caption="Show the first 5 rows of the modified phenotype file")
# show the groups of interest
avail_group=c("Tissue","Disease","Treatment")[c("Tissue","Disease","Treatment")%in%names(pheno)]
res=as.data.frame(table(pheno[,avail_group]))
names(res) <- c(avail_group,"Count")
pandoc.table(res, split.tables=Inf, caption="Sample size in different tissue and disease/treatment groups")
# show samples in different batch
if ("ScanDate_Group"%in%names(pheno)) {
  res=as.data.frame(table(pheno[,"ScanDate_Group"]))
  names(res) <- c("ScanDate_Group","Count")
  pandoc.table(res, split.tables=Inf, caption="Sample size in different batch")
} else {cat("No scan date information.")}
```

```{r, eval=T, echo=F}
# assign colours to Scan Date for plots
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
vars=c("ScanDate_Group","Treatment","Disease")
leveluse=sapply(vars,function(x){if(x%in%names(pheno)){nlevel=nlevels(pheno[,x])}else{nlevel=0};nlevel>1})
if (any(leveluse)){varuse=names(which(leveluse)[1])}else{stop("None of the following variables scan date/Disease/Treatment has >1 level. Check the dataset!")} # varible assigned color in plot

# assign colour to corresponding variable (scan date if available otherwise disease/treatment)
i=nlevels(pheno[,varuse])
colour_list <- colours[1:i]
names(colour_list) <- levels(pheno[,varuse]) 
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data)=apply(exprs(raw.data),2,function(x){replace(x,which(x<=0),NA)})
```

```{r, eval=T, echo=F, warning=F}
if (!suppldata|platform!="Affymetrix") {
  boxplot(exprs(gse),col=colour_list,main="Probe Intensity matrix of raw data",xaxt="n") # note gse here are non-coverted expression values
  legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  if (!normdata) {
    boxplot(log2(exprs(raw.data)),col=colour_list,main="Probe Intensity matrix of log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
    boxplot(normalize.quantiles(log2(exprs(raw.data))),col=colour_list,main="Probe Intensity matrix of qnormed log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  }
}
```

```{r, eval=T, warning=F, echo=F}
if (geo_GPL=="") {pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_Phenotype_withoutQC.txt"); pheno_fn_withQC=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else
{pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withoutQC.txt");pheno_fn_withQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
write.table(pheno,pheno_fn_withoutQC,col.names=T,row.names=F,sep="\t",quote=F)
```


## Quality Control for Microarray Data

```{r, eval=T, echo=F}
pheno <- read.table(pheno_fn_withoutQC, header=T, sep="\t")
```

### Raw Probe Intensity Boxplots and Density Histograms

```{r, eval=T, echo=F, warning=F}
# The subsamp function randomly selects 20000 probes
subsamp <- function(x,num=20000, seed=123) {
  set.seed(seed)
  subsample=num # if number of probes are >20000, randomly select 20000 probes for plot or compute
  if (nrow(x)>subsample) {
    ss  = sample(nrow(x), subsample)
    Mss = x[ss,,drop=FALSE]
  } else {
    ss  = TRUE
    Mss = x
  }
  Mss
}

# The outlier_KS_func function computes KS statistics for outlier detection
outlier_KS_func = function(exprs) { # matrix (row: probe intensities/RLE values etc., col: array (e.g. sample))
  fx = ecdf(as.vector(exprs)) # get empirical cumulative distribution function of the data
  KS=suppressWarnings(apply(exprs, 2, function(v)ks.test(v, y = fx, alternative="two.sided")$statistic))
  stats = stats::fivenum(KS, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=KS, outlier = which(KS > th))
}

# The boxplot_func function generates boxplots for raw data metrics (e.g. probe intensities, RLE, NUSE) 
boxplot_func <- function(Mss,outlier,ylab) {
  # use * to mark the outliers in boxplot
  array_name <- shortname_func(colnames(Mss))
  outlier <- shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  # boxplot raw intensity by array
  ylim = quantile(Mss, probs = c(0.01, 0.99), na.rm=TRUE) # create range of y-axsis
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df, aes(sample_id,values,fill=scandate)) + geom_boxplot(outlier.colour=NA) +
    coord_flip() + theme_bw() +
    ylim(ylim) +
    scale_x_discrete(labels=array_name) +
    ylab(ylab) +
    scale_fill_manual(varuse,values=cols) +
    theme(axis.title.y=element_blank())
}

# The densplot_func function plots density curve for raw data metrics (e.g. probe intensity)
densplot_func <- function(Mss) {
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df,aes(x=values,colour=scandate)) + geom_line(aes(group=sample_id),stat="density") +
    theme_bw() +
    xlab("Raw Probe Intensities") +
    ylab("Density") +
    scale_color_manual(varuse,values=cols)
}

# The raw_intensity_func function outputs raw probe intensity metrics
raw_intensity_func <- function() {
  if (!normdata) {Mss=log2(subsamp(exprs(raw.data))) # use log2 transformed raw probe intensity
  } else {
    Mss=subsamp(exprs(raw.data))
  }
  outlier_res=outlier_KS_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss=Mss, outlier=outlier, ylab="Raw Probe Intensities")
  densplot=densplot_func(Mss=Mss)
  return(list(outlier=outlier,boxplot=boxplot,densplot=densplot))
}
```

1. Outlier detection for log2 raw probe intensity/normalized intensity

```{r, eval=T, echo=F, warning=F}
res_intensity=raw_intensity_func()
outlier_intensity = res_intensity$outlier
cat(length(outlier_intensity), "outlier(s) are detected in the raw intensity metrics.\n")
if (length(outlier_intensity)>0) {cat("They are: ", shortname_func(outlier_intensity))}
```

2. Boxplots for log2 raw probe intensity

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
res_intensity$boxplot
```

3. Density curves for log2 raw probe intensity

```{r, eval=T, echo=F, message=F, warning=F}
res_intensity$densplot
```

### RNA Digestion

```{r, eval=T, echo=F}
# The RNAdegaffy_func function compute mean PM intensities in each probe position following 5' to 3' order. Adopted from the AffyRNAdeg function in the affy package but include a step that randomly selects 20,000 probe sets.
RNAdegaffy_func <- function(data){ # input a list of probe set matrix with rows as probe ids and columns as samples
  {
    names <- colnames(data[[1]])
    probe.set.size <- function(x) {
      size <- dim(x)[1]
      return(size)
    }
    max.num <- sapply(data, probe.set.size) # get the number of probes in each probe set
    tab <- (table(max.num)) # summarize the frequencies of probe numbers in probe sets
    ord <- order(-as.numeric(tab)) # order the frequency from large to small
    K <- as.numeric(names(tab))[ord[1]] # K is the number of probes appearing in most probe sets
    data <- data[max.num == K] # select data of probe sets only have K number of probes
  }
  
  subsample=20000
  if (length(data)>subsample) { # randomly select 10000 probe sets
    set.seed(12345)
    ss = sample(length(data),subsample)
    data = data[ss,drop=FALSE]
  }

  N <- length(data) # number of probe sets
  n <- dim(data[[1]])[2] # number of samples
  
  # create two matrices: number of samples * number of probes representing a probe set
  mns <- matrix(nrow = n, ncol = K) # create matrix for mean values
  sds <- mns # create matrix for sds values

  get.row <- function(x, i = 1) {return(x[i, ])} # function to get each row (i.e. probe id, i) from one probe set x (i.e. probe list[[x]])
  rowstack <- function(x, i = 1) {return(t(sapply(x, get.row, i)))} # function to combine the rows obtained using get.row (pms across samples by probe sets) to get a table (row: samples column: probe sets) and transpose the table (row: probe sets, column: samples)

  for (i in 1:K) { # get probe id (position) from 1 to K from each probe set
    data.stack <- rowstack(data, i) # get the probe pm values in a specific probe position across all samples from each probe set (rows are samples and columns are probe sets)
    if(dim(data[[1]])[2]==1) data.stack <- t(data.stack)
    mns[, i] <- colMeans(data.stack) # get the mean values at one probe position across all probe sets
    sds[, i] <- apply(data.stack, 2, sd) # get the sd values at one probe position across all probe sets
  }
    
  mns.orig <- mns # store the original mns data matrix
  mn <- mns[, 1] # select values in the first probe position
  mns <- sweep(mns, 1, mn) # adjust for the intensity at the first probe position
  mns <- mns/(sds/sqrt(N)) # adjust for standard error
  lm.stats <- function(x) {
    index <- 0:(length(x) - 1)
    ans <- summary(lm(x ~ index))$coefficients[2, c(1, 4)] # use linear model fit the relationship between intensity and probe position
    return(ans)
  }
  stats <- apply(mns, 1, lm.stats)
  answer <- list(N, names, mns.orig, sds/sqrt(N), stats[1,], stats[2, ])
  names(answer) <- c("N", "sample.names", "means.by.number","ses", "slope", "pvalue")
  return(answer)
}

# The RNAdeg_func function generates RNA degradation plots
# return a logical variable whether this array type can be read by affy.
RNAdeg_func <- function() {
  # 1. Read in raw data as an AffyBatch object
  library(affy) # for Affymetrix microarray-specific QC analysis
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  # 2. Obtain a list of probe sets with a matrix of oligos (probes) by samples as an input and compute statistics of the mean PM intensities from 5' to 3' probe positions. 
  PM_list <- affy::pm(raw.data.affy,LIST=T) 
  PM_list <- lapply(PM_list,log2)
  raw.data.rnadeg <- RNAdegaffy_func(PM_list) # Compute mean PM intensity for probes following 5' to 3' order.
  # 3. Plot 5' to 3' mean PM intensity
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  plotAffyRNAdeg(raw.data.rnadeg,cols=status.cols)
  legend("topleft",legend=names(colour_list),fill=colour_list,cex=0.6)
  detach("package:affy", unload=TRUE) # detach the affy package
}
```

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {RNAdeg_func()}
}
```

### Distribution of Perfect Match (PM) and Mismatch (MM)

```{r, eval=T, echo=F}
PMMM_func <- function() {
  if (class(raw.data)=="GeneFeatureSet") {
    message("GeneFeatureSet does not have MM probes. No plots will be generated.")
  } else {
    PM <- log2(pm(raw.data))
    MM <- log2(mm(raw.data))
    if(nrow(PM) != nrow(MM)) {
      message("This might be a PM-only array. No plots will be generated.")
      rm(PM,MM)
    } else {
      subsample=20000
      if(nrow(PM)>subsample) { # randomly select 20000 probe sets
        sel = sample(nrow(PM), subsample)
        sPM = PM[sel, ]
        sMM = MM[sel, ]
      } else {
        sPM = PM
        sMM = MM
      }
      rm(PM,MM) 
      
      df <- data.frame(
        values=c(as.numeric(sPM),as.numeric(sMM)),
        types=c(rep("PM",each=length(as.numeric(sPM))),rep("MM",each=length(as.numeric(sMM))))
      )
      cols=colours[1:2]
      ggplot(df,aes(x=values,colour=types)) + geom_line(aes(group=types),stat="density") +
        theme_bw() +
        xlab("Intensity") +
        ylab("Density") +
        scale_color_manual(values=cols) +
        theme(legend.title=element_blank())
    }
  }
}
```

```{r, eval=T, echo=F}
if (platform=="Affymetrix"&suppldata) {PMMM_func()}
```

### MA Plots

```{r, eval=T, echo=F}
# The MAcal_func function computes M and A matrices, while use the intensity of 20000 randomly selected probes
MAcal_func <- function(x) { # matrix (row: probe intensities, col: array (samples)
  medArray = rowMedians(x, na.rm=TRUE)
  M =  x - medArray
  A = (x + medArray)/2
  subsample=20000
  if(nrow(M)>subsample) {
    set.seed(12345)
    sel = sample(nrow(M), subsample)
    sM = M[sel, ]
    sA = A[sel, ]
  } else {
    sM = M
    sA = A
  }
  list(M=sM,A=sA) # return a list with M and A data matrices
}

# The outlier_MA_func function computes the Hoeffding's statistic (Da) statistics for outlier detection
outlier_MA_func <- function(exprs) { # list with M and A data matrices
  M=exprs$M
  A=exprs$A
  Dstats = sapply(1:ncol(M), function(x){hoeffd(A[,x], M[,x])$D[1,2]})
  names(Dstats) <- colnames(M)
  Dthresh = 0.15
  list(threshold=Dthresh, stats=Dstats, outlier = which(Dstats > Dthresh))
}

# The MAplot_func function plots samples with the first 4 highest and lowest values of Da. The value of Da for each sample is shown in the panel headings. Outliers marked with * have Da values >0.15.
MAplot_func <- function(sMA, outlier_res) {
# select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(sMA$M)-3):ncol(sMA$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  scandate_sel <- pData(raw.data)[,varuse][column_sel]
  M_sel <- sMA$M[,column_sel]
  A_sel <- sMA$A[,column_sel]
  # use * to mark the outliers
  array_name <- shortname_func(colnames(M_sel))
  outlier_MA=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_MA] <- paste0("*",array_name[array_name%in%outlier_MA])
  array_name <- paste0(array_name," (D=",stats_sel,")") # add D statistics to corresponding samples
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    scandate=rep(scandate_sel,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    A=as.numeric(A_sel)
  )
  # MA plots
  ggplot(df,aes(x=A,y=M,color=scandate)) + geom_point(alpha=0.1) + theme_bw() +
    scale_color_manual(varuse,values=colour_list) +
    facet_wrap(~sample_id,ncol=2)
}

# The MA_func function outputs MA metrics
MA_func <- function(){
  # Compute M-A metrics
  if (!normdata) {
    sMA <- MAcal_func(log2(exprs(raw.data)))
  } else {
    sMA <- MAcal_func(exprs(raw.data))
  }
  outlier_res <- outlier_MA_func(exprs=sMA)
  outlier <- names(outlier_res$outlier)
  plot <- MAplot_func(sMA=sMA, outlier_res=outlier_res)
  return(list(outlier=outlier, plot=plot))
}
```

1. Outlier detection for MA plots

```{r, eval=T, echo=F, message=F, warning=F}
res_MA=MA_func()
outlier_MA=res_MA$outlier
cat(length(outlier_MA), "outliers are detected in the MA metrics.\n")
if (length(outlier_MA)>0) {cat("They are: ", shortname_func(outlier_MA))}
```

2. MA plots

```{r, eval=T, echo=F, message=F, warning=F, fig.height=10, fig.width=7}
res_MA$plot
```

### Spatial Distribution

```{r, eval=T, echo=F}
# The affyspatial_func function computes spatial x- and y-coordinate using raw data object classed as AffyBatch
affyspatial_func <- function() {
  library(affy)
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  maxc = ncol(raw.data.affy) # number of probes in x-coordinate
  maxr = nrow(raw.data.affy) # number of probes in y-coordinate
  sx = rep(seq_len(maxc), each = maxr) ## spatial x-coordinate
  sy = rep(seq_len(maxr), maxc) ## spatial y-coordinate
  M = log2(affy::exprs(raw.data.affy))
  detach("package:affy", unload=TRUE)
  numArrays = dim(M)[2]
  return(list(M=M,numArrays=numArrays,sx=sx,sy=sy))
}

# The outlier_spatial_func function computes the Fourier coefficients for outlier detection
outlier_spatial_func <- function(affy_spatial_list) {
  sx=affy_spatial_list$sx # spatial x-coordinate
  sy=affy_spatial_list$sy # spatial y-coordinate
  M=affy_spatial_list$M
  numArrays=affy_spatial_list$numArrays
  maxx = max(sx, na.rm=TRUE)
  maxy = max(sy, na.rm=TRUE)
  stat_spatial = numeric(numArrays)
  for(a in seq_len(numArrays)) {
    mat = matrix(NA_real_, nrow=maxy, ncol=maxx)
    mat[cbind(sy, sx) ] = M[, a]
    pg  = fft(mat) ## periodogram, computes the discrete fourier transform
    npg = Re(pg*Conj(pg))
    npg[1,1] = 0 ## drop the constant component
    stat_spatial[a] = sqrt(sum(npg[1:4, 1:4]) / sum(npg)) # low frequency power
  }
  names(stat_spatial)=colnames(M)
  stats = stats::fivenum(stat_spatial, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=stat_spatial, outlier = which(stat_spatial > th))
}

# The spatplot_func function plots samples with the first 4 highest and lowest values of Fa. The value of Fa for each sample is shown in the panel headings.
spatplot_func <- function(raw.data.spatial,outlier_res) {
  # select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(raw.data.spatial$M)-3):ncol(raw.data.spatial$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  M_sel <- raw.data.spatial$M[,column_sel]
  # apply rank to expression data
  M_sel = apply(M_sel, 2, rank)
  # use * to mark the outliers
  array_name=shortname_func(colnames(M_sel))
  outlier_spatial=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_spatial] <- paste0("*",array_name[array_name%in%outlier_spatial])
  array_name <- paste0(array_name," (F=",stats_sel,")") # add F statistics to corresponding samples
  # create variables for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    row=rep(raw.data.spatial$sy,ncol(M_sel)),
    column=rep(raw.data.spatial$sx,ncol(M_sel))
  )
  # spatial distribution plots
  ggplot(df,aes(x=row,y=column,fill=M)) + geom_tile() + 
    theme_bw() +
    xlab("Raw Probe Intensiry in X") + ylab("Raw Probe Intensiry in Y") +
    scale_fill_gradientn(name="Ranked Intensity",colours=viridis(256,option="B")) +
    facet_wrap(~sample_id,ncol=2)
}

# The spatial_func function outputs spatial metrics
spatial_func <- function() {
  raw.data.spatial=affyspatial_func()
  outlier_res=outlier_spatial_func(affy_spatial_list=raw.data.spatial)
  outlier=names(outlier_res$outlier)
  plot=spatplot_func(raw.data.spatial=raw.data.spatial,outlier_res=outlier_res)
  return(list(outlier=outlier,plot=plot))
}
```


1. Outlier detection for spatial plots

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial=spatial_func()
    outlier_spatial=res_spatial$outlier
    cat(length(outlier_spatial), "outlier(s) are detected in the spatial metrics.\n")
    if (length(outlier_spatial)>0) {cat("They are: ", shortname_func(outlier_spatial))}
  }
}
```
  
2. Spatial distribution plots

```{r, eval=T, echo=F, fig.height=10, fig.width=7}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial$plot
  }
}
```

### Relative Log Expression (RLE) Distribution

```{r, eval=T, echo=F, message=F, warning=F}
# The fitPLM_func function generates RLE and NUSE matrices
fitPLM_func <- function(raw.data) {
  exprs(raw.data) <- log2(exprs(raw.data)) # The fitProbeLevelModel function needs ExpressionFeatureSet object as an input. Assign log transformed expression values to a new object
  fitPLM <- fitProbeLevelModel(raw.data)
  # RLE
  M_RLE <- RLE(fitPLM, type="values") # generate RLE matrix
  Mss_RLE <- subsamp(M_RLE,seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  # NUSE
  M_NUSE <- NUSE(fitPLM, type="values") # generate NUSE matrix
  Mss_NUSE <- subsamp(M_NUSE, seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  return(list(Mss_RLE=Mss_RLE,Mss_NUSE=Mss_NUSE))
}
# The RLE_func function outputs RLE metrics
RLE_func <- function(Mss) {
  outlier_res=outlier_KS_func(Mss) # compute KS statistics to detect outliers
  outlier=names(outlier_res$outlier)
  plot=boxplot_func(Mss,outlier,"RLE")
  return(list(outlier=outlier,plot=plot))
}
```

1. Outlier detection for RLE

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  fitPLM=fitPLM_func(raw.data)
  res_RLE=RLE_func(Mss=fitPLM$Mss_RLE)
  outlier_RLE=res_RLE$outlier
  cat(length(outlier_RLE), "outlier(s) are detected in RLE metrics.\n")
  if (length(outlier_RLE)>0) {cat("They are: ", shortname_func(outlier_RLE))}
}
```

2. Boxplot for RLE

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_RLE$plot}
```

### Normalized Unscaled Standard Error (NUSE) Outlier Detection and Plots

```{r, eval=T, echo=F, message=F, warning=F}
# The function outlier_upperquartile_func function computes upper 75% quantile for outlier detection
outlier_upperquartile_func <- function(exprs) { # matrix (row: NUSE values, col: array (e.g. sample))
  upperquartile = apply(exprs, 2, quantile, na.rm=TRUE, probs=0.75)
  stats = stats::fivenum(upperquartile, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(upperquartile > th))
}

# The NUSE_func function outputs the NUSE metrics
NUSE_func <- function(Mss) {
  outlier_res = outlier_upperquartile_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss,outlier,"NUSE")
  return(list(outlier=outlier,boxplot=boxplot))
}
```

1. Outlier detection for NUSE

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
if (platform=="Affymetrix"&suppldata) {
  res_NUSE <- NUSE_func(Mss=fitPLM$Mss_NUSE)
  outlier_NUSE = res_NUSE$outlier # compute upper 75% quantile statistics to detect outliers
  cat(length(outlier_NUSE), "outlier(s) are detected in NUSE metrics.\n")
  if (length(outlier_NUSE)>0) {cat("They are: ", shortname_func(outlier_NUSE))}
}
```

2. Boxplot for NUSE

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_NUSE$boxplot}
```

### Distance between Samples and Outlier Detection

```{r, eval=T, echo=F, warning=F}
# The dist2 estimates distance between samples
dist2 <- function (x,fun = function(a, b) mean(abs(a - b), na.rm = TRUE),diagonal = 0) {
  if (!(is.numeric(diagonal) && (length(diagonal) == 1)))
    stop("'diagonal' must be a numeric scalar.")

  if (missing(fun)) {
    res = apply(x, 2, function(w) colMeans(abs(x-w), na.rm=TRUE))
  } else {
    res = matrix(diagonal, ncol = ncol(x), nrow = ncol(x))
    if (ncol(x) >= 2) {
      for (j in 2:ncol(x))
        for (i in 1:(j - 1))
          res[i, j] = res[j, i] = fun(x[, i], x[, j])
    } # if
  } # else
  colnames(res) = rownames(res) = colnames(x)
  return(res)
}

# The outlier_dist_func function computes the sum of all distance of one sample to other samples for outlier detection
outlier_dist_func <- function(exprs) { # matrix (row: distance to each sample, col: array (e.g. sample))
  sum = colSums(exprs, na.rm=TRUE) # sum the total distance
  stats = stats::fivenum(sum, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(sum > th))
}

# The displot_func function plots distance between samples
distplot_func <- function(m,outlier) {
  dend = as.dendrogram(hclust(as.dist(m), method = "single"))
  ord = order.dendrogram(dend)
  array_name=shortname_func(colnames(m))
  outlier=shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  array_name <- shortname_func(array_name) # shorten the sample id
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256, option="B"),ColSideColors=status.cols,RowSideColors=status.cols,
    labCol=array_name,labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_list),fill=colour_list,cex=0.6)
}

# The dist_func function outputs distance metrics
dist_func <- function() {
  if (!normdata) {
    m <- dist2(log2(exprs(raw.data)))
  } else {
    m <- dist2(exprs(raw.data))
  }
  
  outlier_res=outlier_dist_func(m)
  outlier=names(outlier_res$outlier)
  return(list(outlier=outlier,m=m))
}
```

1. Outlier detection for sample distance

```{r, eval=T, echo=F}
res_dist=dist_func()
outlier_dist=res_dist$outlier
cat(length(outlier_dist), "outlier(s) are detected in sample distance metrics.\n")
if (length(outlier_dist)>0) {cat("They are: ", shortname_func(outlier_dist))}
```

2. Plot distance between samples
```{r, eval=T, echo=F, fig.height=10, fig.width=12}
distplot_func(m=res_dist$m,outlier=res_dist$outlier)
```

### Principal Component Analysis (PCA)

```{r, eval=T, echo=F}
# The pcastat_func function computes principal components
pcastat_func <- function() {
  # obtain original expression data
  if (!normdata) {
    raw.data.pca <- na.omit(log2(exprs(raw.data)))
  } else {
    raw.data.pca <- na.omit(exprs(raw.data))
  } # remove NAs
 
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(pc, group_var,legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(raw.data)[,group_var]
  )
  i=length(levels(pData(raw.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(raw.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(pc) {
  group_vars=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  legends=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(raw.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    nlevel=nlevels(pData(raw.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=20)) {
      plot_list[[group_var]]=pcaplot_func(pc, group_var=group_var,legend=legend)
    }
  }
  return(plot_list)
}
```


1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
res_pca <- pcastat_func()
pandoc.table(res_pca$tb,split.tables=Inf, caption="Variance explained")
```

2. PCA plots

```{r, eval=T, echo=F}
plot_list=pca_func(pc=res_pca$pc)
for (i in plot_list) {print(i)}
```


### QC Summary

```{r, eval=T, echo=F}
# The outlier_summ_func function outputs a summary table of outlier and the detected frequency
outlier_summ_func <- function() {
  outlier_all <- c("outlier_intensity","outlier_MA","outlier_spatial","outlier_RLE","outlier_NUSE","outlier_dist") # all outliers
  outlier_env=ls(envir=.GlobalEnv, pattern="outlier_") # "outlier_" enviromental variables
  outlier=outlier_env[outlier_env%in%outlier_all]
  method=gsub("outlier_","",outlier)
  outliers=unlist(lapply(1:length(outlier),function(x){get(outlier[x],envir=.GlobalEnv)}))
  if (length(outliers)==0) {
    cat("No outlier was detected\n")
    res <- data.frame() # create an empty data frame
  } else {
    methods=unlist(lapply(1:length(outlier),function(x){n=length(get(outlier[x]));rep(method[x],n)}))
    outlier_list=list()
    for (x in 1:length(outliers)){outlier=outliers[x];method=methods[x];outlier_list[[outlier]]=append(outlier_list[[outlier]],method)}
    # summary table
    Frequency <- sapply(outlier_list,length) # times to detect
    Method <- unlist(lapply(names(outlier_list),function(x){paste0(outlier_list[[x]],collapse=", ")}))
    res <- data.frame(Frequency,Method)
    res <- res[order(res$Frequency),]
  }
  return(res)
}

# The tbQC_func function
tbQC_func <- function(outliers) { # define outliers
  tb=pData(raw.data)
  tb$QC_Pass=1
  if (missing(outliers)) { # if outliers are not defined, use those detected more than twice
    tb$QC_Pass[rownames(tb)%in%rownames(outlier_tb)[outlier_tb$Frequency>2]]<-0 # assign 0 to outliers detected more than twice
  } else {
    tb$QC_Pass[rownames(tb)%in%outliers]<-0
  }
  tb$Filename <- rownames(tb) # add filename in a new column
  # save in a new phenotype file
  write.table(tb,pheno_fn_withQC,col.names=T,row.names=F,sep="\t",quote=F)
  # defined outliers
  outlier=as.character(tb$GEO_ID)[which(tb$QC_Pass==0)]
  # summary of phenotype information before QC
  vars=c("Tissue","Treatment","Disease","QC") # variables of interest
  # before QC
  tb_withoutQC=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb_withoutQC)[ncol(tb_withoutQC)]="Counts"
  # after QC
  tb_withQC=as.data.frame(table(tb[which(tb$QC==1),names(tb)%in%vars]))
  names(tb_withQC)[ncol(tb_withQC)]="Counts"
  return(list(outlier=outlier, tb_withoutQC=tb_withoutQC, tb_withQC=tb_withQC))
}
```

```{r, eval=T, echo=F, results="asis"}
outlier_tb=outlier_summ_func()
if (nrow(outlier_tb)>0) {
  pandoc.table(outlier_tb,caption="Outlier Summary",split.tables=Inf)
}
```

```{r, eval=T, echo=F}
res_tbQC=tbQC_func()
outlier=res_tbQC$outlier
cat(length(outlier), "outlier(s) are defined.\n")
if (length(outlier)>0) {cat("They are: ", outlier)}
```

```{r, eval=T, echo=F, results="asis"}
pandoc.table(res_tbQC$tb_withoutQC, split.tables=Inf, caption="Summary of samples without QC")
pandoc.table(res_tbQC$tb_withQC, split.tables=Inf, caption="Summary of samples with QC")
```

> Differential Gene Expression Analysis for GSE57065

```{r, eval=T, echo=T}
# GEO id
geo_id="GSE57065"
# tissue
tissue="Blood"
# reference condition
con0="Control"
# altered condition
con1="Shock"
# treatment. Assign "comparison" if this column is used for DE.
treatment="24hr"
# disease. Assign "comparison" if this column is used for DE.
disease=c(con0,con1)
```

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
usesuppl=TRUE
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*).(cel|CEL).gz","\\1",x)} # remove .cel.gz or .CEL.gz from sample
```

```{r, eval=T, echo=F}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
```

```{r, eval=T, echo=F}
cat(paste0("pheno_fn = '", pheno_fn,"'"))
```

```{r, eval=T, echo=F, message=F, warning=F}
library(GEOquery)
library(oligo)
library(limma)
library(sva)
library(annotate)
library(viridis)
library(ggplot2)
library(gplots)
library(devtools)
library(preprocessCore)
library(pander)
```

## Obtain Phenotype and GEO Data

### Phenotype data preparation

```{r, eval=T, echo=F}
# The phenosub_func function subsets phenotypes based on the user defined variables
phenosub_func <- function(){
  pheno.sub=subset(pheno,(Tissue%in%tissue)&(Treatment%in%treatment)&(Disease%in%disease))
  pheno.sub=droplevels(pheno.sub)
  # assign comparison to "Status" column
  if (length(treatment)==2) {
    if (identical(sort(levels(pheno.sub$Treatment)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Treatment} else {stop("Assigned treatment variables are not included in the Treatment column")}
  } else if (length(disease)==2) {
    if (identical(sort(levels(pheno.sub$Disease)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Disease} else {stop("Assigned treatment variables are not included in the Disease column")}
  }
  pheno.sub$Status <-factor(pheno.sub$Status,levels=c(con0,con1))
  return(pheno.sub)
}

# The phenoqc_func function excludes outliers from phenotype file 
phenoqc_func <- function(outlier,pheno) {
  if (missing(outlier)) {pheno=subset(pheno, QC_Pass==1)} else {pheno=subset(pheno, Filename%in%outlier)}
  droplevels(pheno)
}

# The phenopair_func function excludes unpaired donor from analysis
phenopair_func <- function(dat) {
  unpaired_samp=names(which(table(dat$Donor)==1))
  dat=dat[which(!dat$Donor%in%unpaired_samp),]
  droplevels(pheno)
  if (length(unpaired_samp)>0) {
    cat(paste0(length(unpaired_samp)," sample(s) with unpaired donor are excluded from analysis\n"))
    cat(paste(unpaired_samp,collapse=", "),"\n")
  }
  return(dat)
}

# The tbsum_func function generates summary of variables of interest
tbsum_func <- function(tb) {
  vars=c("Status", "ScanDate_Group") # variables of interest
  tb=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb)[ncol(tb)]="Counts"
  return(tb)
}

# The infosumm_function generates summary of the comparison
infosumm_func <- function(pheno) {
  N_Condition0 <- sum(pheno$Status==con0) # count number of samples under condition 0
  N_Condition1 <- sum(pheno$Status==con1) # count number of samples under condition 1
  if (identical(sort(levels(pheno$Treatment)),sort(c(con0,con1)))) {
    App="GC"
    if (geo_GPL=="") {name=paste(geo_id,tissue,disease,con1,"vs",con0, sep="_")} else {{name=paste(geo_id,geo_GPL,tissue,disease,con1,"vs",con0, sep="_")}}
    Disease=disease
    Treatment=con1
  } else {
    App="Asthma"
    if (geo_GPL=="") {name=paste(geo_id,tissue,treatment,con1,"vs",con0, sep="_")} else {name=paste(geo_id,geo_GPL,tissue,treatment,con1,"vs",con0, sep="_")}
    Disease=con1
    Treatment=treatment
  }
  
  df <- data.frame(
    GEO_ID=geo_id,
    Tissue=tissue,
    App=App,
    Disease=Disease,
    Treatment=Treatment,
    N_Condition0=N_Condition0,
    N_Condition1=N_Condition1,
    Total=N_Condition0+N_Condition1,
    Unique_ID=name
  )
  return(list(df=df,name=name))
}
```

```{r, eval=T, echo=F}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
# read in the pre-prepared phenotype data
if (!file.exists(pheno_fn)) {stop("The phenotype file does not exist. Please check!")} else {pheno <- read.table(pheno_fn, header=TRUE, sep="\t")}
```

```{r, eval=T, echo=F}
pheno.sub=phenosub_func()
outlier=as.character(pheno.sub$Filename)[pheno.sub$QC_Pass==0]
if (length(outlier)>0) {
  cat("Remove outlier(s)", outlier, "from phenotype file\n")
  pheno.of.interest=phenoqc_func(pheno=pheno.sub)
} else {pheno.of.interest=pheno.sub}
```

Define paired variable.

```{r, eval=T, echo=F, results="asis"}
if (length(disease)==2) {
  paired=FALSE
} else if (length(disease)==1) {
  if (all((pheno.sub$Donor)==1)) {paired=FALSE} # if treatment is in different donors
  else {paired=TRUE} # if treatment is in samd donors
}
```

```{r, eval=T, echo=F}
cat("paired =",as.character(paired))
```

Exclude samples missing the other paired donors in treatment comparisons
```{r, eval=T, echo=F, results="asis"}
if (paired) {
  pheno.of.interest <- phenopair_func(pheno.of.interest)
}
```

```{r, eval=T, echo=F, results="asis"}
if (nrow(pheno.sub)!=nrow(pheno.of.interest)) {
  pandoc.table(tbsum_func(tb=pheno.sub), split.tables=Inf, caption="Summary of subsetted samples without QC")
  pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples with QC")
} else {pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples")}

# create a summary table for this comparison
pandoc.table(t(infosumm_func(pheno=pheno.of.interest)$df),split.tables=Inf, caption="Summary of the comparison")
```

```{r, eval=T, echo=F}
# assign colours to comparison status
colour_status <- c("navy","red")
names(colour_status) <- c(con0,con1) # assign red to condition 1 and navy to condition 2
colour_status_list <- unlist(lapply(pheno.of.interest$Status,function(x){colour_status[x]}))
# assign colours to scan date
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
if ("ScanDate_Group"%in%names(pheno)) {
  i=nlevels(pheno.of.interest$ScanDate_Group)
  colour_scandate <- colours[1:i]
  names(colour_scandate) <- levels(pheno.of.interest$ScanDate_Group) # colour to corresponding scan date
  colour_scandate_list <- unlist(lapply(pheno.of.interest$ScanDate_Group,function(x){colour_scandate[x]}))
}
```

### Gene expression data preparation

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and unextract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (usesuppl) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno$Filename))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}

  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)
}
```

```{r, eval=T, echo=F, message=F, warning=F}
if (!usesuppl) {
  # check if GEO matrix file exists
  geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
  if (length(geo_fn)==0) { # # GEO matrix file is not downloaded
    gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
    if (length(gselms)>1) {  # multiple platform
      gpls=sapply(gselms,annotation)
      cat("This study was performed in multiple platforms:\n")
      cat(unname(gpls),"\n")
      cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
      if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
    } else {idx=1}
    gse <- gselms[[idx]]
  } else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
    gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
  } else { # GEO matrix file is alreadly downloaded and has multiple platforms
    cat("This study was performed in multiple platforms:\n")
    cat(geo_fn)
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <-geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
  }
  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.data=gse
}
```

```{r, eval=T, echo=F}
# The subdat_func function subsets data based on the phenotype of interest
subdat_func <- function(raw.data, pheno) {
  # subset raw.data based on the phenotype of interest
  raw.data=raw.data[,colnames(raw.data)%in%pheno$Filename]
  # assign phenotype data to raw expression data
  pData(raw.data) <- pheno
  row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
  # check if the sample names derived from expression data match those in phenotype file
  if (usesuppl) {matching=mapply(identical,row.names(pData(raw.data)),as.character(pheno$Filename))}
  else {matching=mapply(grepl,row.names(pData(raw.data)),as.character(pheno$Filename))}
  if (!all(matching)) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
  return(raw.data)
}
raw.data.of.interest=subdat_func(raw.data=raw.data, pheno=pheno.of.interest)
```

Show expression dataset features
```{r, eval=T, echo=F}
raw.data.of.interest
```

## Differential Gene Expression Analysis

### Normalize raw gene expression data

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data.of.interest),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data.of.interest)=apply(exprs(raw.data.of.interest),2,function(x){replace(x,which(x<=0),NA)})
```

```{r, eval=T, echo=F, message=F, results="hide"}
if (usesuppl) {
  rma.data.of.interest = rma(raw.data.of.interest)
  cat("RMA normalization is used.\n")
} else {
  rma.data.of.interest=raw.data.of.interest
  if (!normdata) {exprs(rma.data.of.interest)=normalize.quantiles(log2(exprs(rma.data.of.interest)))
  cat("Quantile normalization and log2 transformation is used.\n")
  }
}
```

```{r, eval=T, echo=F}
cols=colour_status_list
boxplot(raw.data.of.interest,target="core",col=cols,main="Raw Probe Intensities",xaxt="n") # view raw data
legend("topright",legend=names(colour_status),fill=colour_status)

if (!normdata) {
  boxplot(rma.data.of.interest,col=cols,main="Normalized Probe Intensities",xaxt="n") # view RMA-adjusted data
  legend("topright",legend=names(colour_status),fill=colour_status)
} else {cat("The raw data is already normalized")}
```


### Pairwise Comparison between Status

```{r, eval=T, echo=F, results="asis"}
limma_func <- function(paired=FALSE) { # here only con0, con1 are used in comparisons. use a function to reduce the factor levels
  if (paired) {
    cat("Donor is adjusted in this regression\n")
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$Donor)) # create design model matrix
    colnames(design) = c(levels(factor(rma.data.of.interest$Status)),levels(factor(rma.data.of.interest$Donor))[-1])
  } else {
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)) # create design model matrix
    colnames(design) = levels(factor(rma.data.of.interest$Status))
  }
  fit = lmFit(rma.data.of.interest, design) # fit a linear model to estimate the fold changes and standard error
  # Create a contrast group and fit it in a linear model
  data.contrast = makeContrasts(contrasts=paste(c(con1,con0),collapse="-"),levels = design) # create a contrast group by comparing con1 vs con0
  fit2 = contrasts.fit(fit, data.contrast) # get the contrasts for samples of interest
  fit2 = eBayes(fit2) # adjust fit coefficients using an empirical Bayes moderation of standard errors
  return(list(design=design,data.contrast=data.contrast,fit2=fit2))
}
```

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
res_DE=limma_func(paired=paired)
fit2=res_DE$fit2
pandoc.table(data.frame(Sample=rma.data.of.interest$Sample,res_DE$design), split.tables=Inf, caption="A design model matrix for linear model")
pandoc.table(as.data.frame(res_DE$data.contrast), caption="A contract matrix for comparison")
contrast_table <- topTable(fit2, adjust="BH",num=Inf) # get full set of results for each hypothesis test
col.sel=c("logFC","AveExpr","t","P.Value","adj.P.Val","B") # select the columns of DE results
contrast_table <- data.frame(ID=row.names(contrast_table), contrast_table[,col.sel])
```

### Adjusting for Batch Effect

```{r, eval=T, echo=F}
# The nbatch_func function obtains number of batches (scan date) in the data
nbatch_func <- function() {
  if (!"ScanDate_Group"%in%names(pData(rma.data.of.interest))) {nbatch=0} else {nbatch=nlevels(rma.data.of.interest$ScanDate_Group)}
}

# The svamod_func function creates full and null models, and Checks if the batch and comparison status are confounded
svamod_func <- function(paired=FALSE) {
  # Create a full model
  modBatch = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)) # full model (adjusted variables and variables of interest)
  # Create a null model only including batch variables
  nullBatch =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)) # null model (adjusted variables only)
  # Check if the scan date and comparison status are confounded
  if (class(try(solve(t(modBatch)%*%modBatch),silent=T))=="matrix") {batchadj=TRUE} else {batchadj=FALSE; message("The scan date and comparison status are highly confounded")}
  # summary of the full model
  tb.fullmod <- as.data.frame(modBatch)
  names(tb.fullmod) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])
  # summary of the null model
  tb.nullmod <- as.data.frame(nullBatch)
  names(tb.nullmod) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])

  donoradj=NULL # assign variable is donor is adjusted
  tb.nullmod1=NULL # assign null matrix for donor adjustment
  if ((paired)&(batchadj)) { # same donor treatment adjust for donor
    # Test if donor and scandate are correlated
    modBatch1 = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # full model including donor
    nullBatch1 =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # null model including donor
    # summary of the full model
    tb.fullmod1 <- as.data.frame(modBatch1)
    names(tb.fullmod1) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
    # summary of the null model
    tb.nullmod1 <- as.data.frame(nullBatch1)
    names(tb.nullmod1) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
      
    # check if scandate correlated with donor
    if (class(try(solve(t(modBatch1)%*%modBatch1),silent=T))=="matrix") {
      donoradj="yes"
      modBatch=modBatch1
      nullBatch=nullBatch1
      tb.fullmod=tb.fullmod1
      tb.nullmod=tb.nullmod1
    }
  }

  return(list(modBatch=modBatch, nullBatch=nullBatch, tb.fullmod=tb.fullmod, tb.nullmod=tb.nullmod, batchadj=batchadj, donoradj=donoradj, tb.nullmod_donor=tb.nullmod1))
}

# The batcherror_func function assigns a variable batcherror to decide whether to adjust for batch effect under various scenarios
batcherror_func <- function() {
  if (nbatch==0) {
    batcherror="zero"
  } else if (nbatch==1) {
    batcherror="one"
  } else {
    if (batchadj) {batcherror="no"} else {batcherror="correlate"}
  }
  return(batcherror)
}

# The batchadj_func function outputs table with batch effects adjusted p-values
batchadj_func <- function(batcherror=batcherror, contrast_table=contrast_table, paired=paired) {
  if (batcherror=="no") {
    modBatch=svamod_func(paired=paired)$modBatch
    nullBatch=svamod_func(paired=paired)$nullBatch
    pValuesBatch=f.pvalue(exprs(rma.data.of.interest), modBatch, nullBatch) # get batch effect-adjusted p-values
    qValuesBatch=p.adjust(pValuesBatch, method="BH") # get q-values
    tb.sva <- data.frame(ID=names(pValuesBatch),pValuesBatch,qValuesBatch)
    contrast_table <- merge(contrast_table, tb.sva, by="ID", all=TRUE)
  } else if (batcherror=="correlate") {
    contrast_table$pValuesBatch=contrast_table$qValuesBatch=rep(NA,nrow(contrast_table))
  } else {
    contrast_table$pValuesBatch=contrast_table$P.Value
    contrast_table$qValuesBatch=contrast_table$adj.P.Val
  }
  return(contrast_table)
}
```

```{r, eval=T, echo=F}
nbatch=nbatch_func()
if (nbatch>1) {res_svamod=svamod_func(paired=paired);batchadj=res_svamod$batchadj}
batcherror=batcherror_func()
if (batcherror=="zero") {cat("No scan date is present in the data.")} else if (batcherror=="one") {cat("Only one batch is present in the data.")} else if (batcherror=="correlate") {cat("The scan date and the comparison status are highly confounded (See the model matrix). Cannot ajust for batch effect.")}
```

```{r, eval=T, echo=F, results="asis"}
if (nbatch>1) {
  if (paired) {
    if (is.null(res_svamod$donoradj)) {
      cat("Scan date and donor are highly confounded. See the matrix below.\n")
      pandoc.table(res_svamod$tb.nullmod_donor, split.tables=Inf, caption="Null model matrix with scan date and donor")
      cat("Only adjust for scan date.\n")
    } else {cat("Both scan date and donor are adjusted.\n")}
  }
  pandoc.table(res_svamod$tb.fullmod, split.tables=Inf, caption="Full model matrix")
  pandoc.table(res_svamod$tb.nullmod, split.tables=Inf, caption="Null model matrix")
}
```

```{r, eval=T, echo=F, results="asis"}
contrast_table=batchadj_func(batcherror=batcherror, contrast_table=contrast_table, paired=paired)
pandoc.table(summary(contrast_table), split.tables=Inf, caption=paste0(con1, " vs. ", con0, " summary"))
```


### Assign Official Gene Symbol

```{r, eval=T, echo=F}
anno_list=list()
# Affymetrix
anno_list[["pd.hg.u133.plus.2"]]="hgu133plus2.db"
```

```{r, echo=F}
# glpanno_func creates anntoation vector based on GPL annotation from GEO
glpanno_func <- function(GPL_ID){
  gpl <- Table(getGEO(GPL_ID, destdir = "data"))
  if (GPL_ID%in%names(symbol_list)) {anno_vect <- gpl[,symbol_col]} else {anno_vect <- gpl[,"gene name"]}
  names(anno_vect) <- gpl[,"ID"]
  return(anno_vect)
}

# ranno_func creates anntoation vector based on R annotation database
ranno_func <- function(anno_lib){
  # check if the annotation database is installed
  if (!anno_lib%in%installed.packages()[,1]){source("http://bioconductor.org/biocLite.R"); biocLite(anno_lib)}
  library(anno_lib, character.only=T)
  anno_symbol=gsub(".db","SYMBOL",anno_lib) # The name of the R object mapping between probe id and gene symbol
  x=get(anno_symbol)
  # Get the probe identifiers that are mapped to a gene symbol
  mapped_probes <- mappedkeys(x)
  # Convert to a list
  xx <- as.list(x[mapped_probes])
  # Convert list to annotation vector
  anno_vect <- sapply(xx,function(x){x})
  return(anno_vect)
}

# geneannot_func annotates gene symbol to DE result table
geneannot_func <- function(tb, anno_vect) {
  remove.pm <- function(x) {gsub("_PM", "", x)} # Assign official gene symbol using hgu133plus2.db package if anntoation is based on pd.hg.u133.plus.2. Note that the probe names have additional "PM"s in the results will be removed to match the names in the gene symbol package.
  if (exists("anno_lib")) {
    if (anno_lib=="hgu133plus2.db") {tb$ID=sapply(as.character(tb$ID), remove.pm)}
  }
  tb$ID=as.character(tb$ID)
  tb$SYMBOL=sapply(as.character(tb$ID), function(x){if (x%in%names(anno_vect)){anno_vect[x]} else {"NA"}})
  tb$SYMBOL[which(tb$SYMBOL=="")]="NA"
  # remove probes with NA in logFC column
  tb <- tb[!is.na(tb$logFC),]
  tb[order(tb$P.Value),]
}
```

```{r, eval=T, echo=F, warning=F, message=F}
# install corresponding annotation database if it is not installed
anno_array=annotation(rma.data.of.interest)
cat("The platform used is", anno_array, "\n")
if (!anno_array%in%names(anno_list)) {
  cat("Annotate using GPL annotation in GEO\n")
  anno_vect=glpanno_func(GPL_ID=anno_array)
} else {
  anno_lib=anno_list[[anno_array]] # use the annotation database
  cat("The corresponding R annotation database package is", anno_lib,"\n")
  anno_vect <- ranno_func(anno_lib=anno_lib)
}
```

```{r, eval=T, echo=F}
contrast_name=infosumm_func(pheno=pheno.of.interest)$name # adopt Unique_ID created in the information summary table
contrast_fn=paste0(resdir,"/", contrast_name, ".csv")
```

```{r, eval=T, echo=F, warning=F, message=F}
contrast_table <- geneannot_func(tb=contrast_table, anno_vect=anno_vect)
write.csv(contrast_table, file=contrast_fn, row.names = FALSE)
```

```{r, eval=T, echo=F}
if (file.exists(contrast_fn)) {contrast_fn=paste0(resdir,"/", contrast_name, ".csv")}
res=read.csv(contrast_fn)
```

## Gene Expression Results Visualization

### Volcano Plots

```{r, eval=T, echo=F}
# The volplot_func function generates volcano plots
volplot_func <- function(df,qval_column,title) {
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else {          
    df <- df[!is.na(qval),] # remove NA values
    qval <- df[,qval_column]
    if (min(df[,qval_column])>=0.05) {
      df$sig <- "black" # assign colors to DE and non-DE genes
    } else {
      # assign colors to DE and non-DE genes
      df$sig <- rep(NA,nrow(df))
      df$sig[qval<0.05] <- "red"
      df$sig[qval>=0.05] <- "black"
    }
    df$sig <- as.factor(df$sig)
    color <- levels(df$sig)
    # log10 transformed q values
    df$logqval <- -log10(qval)
    diffgenes <- df$ID[qval<0.05] #Create list of all DEG's
    signum = paste0(length(diffgenes), " significant genes based on ", qval_column)
    if (missing(title)) {title=signum}
    print(
    ggplot(df, aes(x = logFC, y = logqval, color=sig)) + geom_point() +
      theme_bw() +
      labs(title=title,x="logFC",y=paste0("-log10(",qval_column,")")) +
      scale_color_manual(values=color) +
      theme(legend.position="none")
    )
  }
}
```

Volcano plot (probes with a q-value <0.05 are present in red)

```{r, eval=T, echo=F, fig.height=4, fig.width=4.5}
for (qval in c("adj.P.Val","qValuesBatch")) {volplot_func(res, qval)}
```


### Histograms

```{r, eval=T, echo=F}
# The histplot_func function generates histogram for p-value distributions
histplot_func <- function(df,qval_column,title) {
  if (missing(title)) {title=""}
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else{hist(qval,main=title,xlab=qval_column)}
}
```

Histograms of p-value distributions

```{r, eval=T, echo=F, fig.width=4.5, fig.height=4}
for (pval in c("P.Value","pValuesBatch")) {histplot_func(res, pval)}
for (qval in c("adj.P.Val","qValuesBatch")) {histplot_func(res, qval)}
```

### Top 20 Differentially Expression Results

```{r, eval=T, echo=F}
# The datreform_func function reformats the DE table
datreform_func <- function(dt,topnum=200) {
  dt=dt[order(dt$P.Value),]
  dt=dt[1:topnum,]
  round2 <- function(x){round(x,2)}
  dt[,c("logFC","AveExpr","t","B")] <- sapply(dt[,c("logFC","AveExpr","t","B")],round2)
  sciform <- function(x){format(x,scientific=TRUE,digits =2)}
  dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")] <- sapply(dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")],sciform)
  dt
}
```

Show top 20 probes sorted by un-adjusted p-values

```{r, eval=T, echo=F, results="asis"}
res <- datreform_func(dt=res)
rownames(res) <- NULL
pandoc.table(res[1:20,],split.tables=Inf)
```

### Boxplots for Top 6 Differentially Expressed Genes

This step helps to visualize and check the effect direction in the comparison.

```{r, eval=T, echo=F}
# function for top gene boxplot
topgene_boxplot_func <- function(tb,colour,comp) { # comp: comparison status
  for (i in 1:nrow(tb)) {# top i probe in res
    if (missing(comp)) {comp=""}
    if (missing(colour)) {colour=colours[1]}
    probe_top <- tb$ID[i]
    gene_top <- tb$SYMBOL[i]
    row.names(rma.data.of.interest) <- gsub("_PM","",row.names(rma.data.of.interest))
    values=exprs(rma.data.of.interest)[row.names(rma.data.of.interest)%in%probe_top, ]
    status=rma.data.of.interest$Status
    df <- data.frame(values=values,status=status)
    title=paste0(comp," top ",i," probe ", probe_top, " gene ", gene_top)
    print(
      ggplot(df,aes(x=status,y=values)) +
        geom_boxplot(outlier.colour=NA,color="grey18",fill=colour) +
        stat_boxplot(geom ='errorbar', color="grey18") +
        geom_jitter(size=1,position = position_jitter(width=0.3)) +
        labs(title=title) +
        theme_bw() +
        theme(legend.position="none",axis.title=element_blank())
    )
  }
}
```

```{r, eval=T, echo=F, message=F, warning=F, fig.height=4, fig.width=4.5}
topgene_boxplot_func(tb=res[1:6,])
```


### Heatmap for Top 200 Differentially Expressed Genes

```{r, eval=T, echo=F}
# The heatmap_topgene_func function for top gene heatmap plots
heatmap_topgene_func <- function(tb, topnum=200, colour_status_list, colour_status, main="") { # colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  top.rma <- rma.data.of.interest[row.names(rma.data.of.interest)%in%tb[1:topnum,"ID"],] # plot heatmap for top 200 genes
  array_name <- shortname_func(colnames(exprs(top.rma))) # shorten the sample id
  heatmap.2(na.omit(exprs(top.rma)), col=viridis(256, option="B"),
    ColSideColors=colour_status_list, # use predefined colour_status_list, assign colors to status
    labCol=array_name,labRow = "", # take out gene probe id
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow=1,cexCol=1,
    keysize=1.5,key.title=NA,key.xlab="Gene Expression Values",key.ylab="Counts",
    main=main)
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.8) # use predifined colour_status
}
```


```{r, eval=T, echo=F, fig.height=10, fig.width=12}
heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_status_list, colour_status=colour_status, main="Gene expression heatmap by comparison status")
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Gene expression heatmap by scan date")
}
```

### Heatmap for Sample Correlation

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# The corplot_func function plots correlation between samples
corplot_func <- function(m, colour_status_list, colour_status, main="") {  # m: correlation matrix, colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  m <- cor(na.omit(m)) # compute correlation matrix
  # compute distance based on 1-correlation efficient
  dend = as.dendrogram(hclust(as.dist(1-m), method = "single"))
  ord = order.dendrogram(dend)
  array_name <- shortname_func(colnames(m)) # shorten the sample id
  # heatmap plot
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256,option="B"), ColSideColors=colour_status_list, RowSideColors=colour_status_list,
    labCol=array_name, labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.6)
}
```


```{r, eval=T, echo=F, fig.height=10, fig.width=12}
corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_status_list, colour_status=colour_status, main="Correlation heatmap by comparison status")
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Correlation heatmap by scan date")
}
```

### Principal Component Analysis (PCA)

```{r, eval=T, echo=F, warning=F, message=F, results="asis"}
# The pcastat_func function computes principal components
pcastat_func <- function(m) {
  # obtain original expression data
  raw.data.pca <- na.omit(apply(m,2,function(x)replace(x,is.infinite(x),NA))) # replace infinite values to NAs and omit NAs
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(oligo.data, pc, group_var, legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(oligo.data)[,group_var]
  )
  i=length(levels(pData(oligo.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(oligo.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(oligo.data, pc) {
  group_vars=c("ScanDate_Group", "Status", "Donor")
  legends=c("ScanDate_Group", "Status", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(oligo.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    pData(oligo.data)[,group_var]=as.factor(as.character(pData(oligo.data)[,group_var])) # convert to factor
    nlevel=nlevels(pData(oligo.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=10)) {
      if (group_var=="Status") {
        plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)+scale_color_manual(legend,values=colour_status,na.value="grey") # assign colour to comparison stauts
      } else {plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)}
    }
  }
  return(plot_list)
}
```

1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=F, warning=F, message=F, results="asis"}
res_pca <- pcastat_func(m=exprs(rma.data.of.interest))
pandoc.table(res_pca$tb, split.tables=Inf, caption="Variance explained")
```

2. PCA plots

```{r, eval=T, echo=F, message=F, warning=F}
plot_list=pca_func(oligo.data=rma.data.of.interest, pc=res_pca$pc)
for (i in plot_list) {print(i)}
```

## Quality Control for GSE95233

```{r, eval=T, echo=T}
# GEO id
geo_id="GSE95233"
```

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*)\\.(cel|CEL).gz","\\1",x)}
```

```{r, eval=T, echo=F, message=F, warning=F}
library(GEOquery)
library(oligo)
library(viridis) # heatmap colour
library(ggplot2)
library(gplots) # heatmap.2 plot
library(Hmisc) # compute hoeffd (Hoeffding's D statistics) for MA plot
library(devtools) # compuate PCs
library(preprocessCore) # quantile normalization
library(pander)
```

## GEO Data Download and Phenotype Preparation

### GEO Dataset Download

```{r, eval=T, echo=F, message=F, warning=F}
# check if GEO matrix file exists
geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
if (length(geo_fn)==0) { # GEO matrix file is not downloaded
  gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
  if (length(gselms)>1) {  # multiple platform
    gpls=sapply(gselms,annotation)
    cat("This study was performed in multiple platforms:\n")
    cat(unname(gpls),"\n")
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
  } else {idx=1}
  gse <- gselms[[idx]]
} else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
  gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
} else { # GEO matrix file is alreadly downloaded and has multiple platforms
  cat("This study was performed in multiple platforms:\n")
  cat(geo_fn)
  cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
  if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <- geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
}
```


Show expression dataset features
```{r, eval=T, echo=F}
gse
```

### Modify raw phenotype information

```{r, eval=T, echo=F, results="asis"}
pheno.raw <- pData(phenoData(gse))
for (x in names(pheno.raw)) {
  vec=pheno.raw[,x]
  if (!is.numeric(vec)) {
    # create an empty data frame to save any tables with non-native characters
    tb_nonnative=data.frame()
    vec <- factor(vec)
    if (nlevels(vec)>5) {res=table(droplevels(vec[vec%in%levels(vec)[1:5]]))} else {res=table(vec)}
    res=data.frame(res)
    names(res) <- c(x,"counts")
  }
  if (is.numeric(vec)){res=summary(vec)}
  # Try if any existing non-native characters cause pander error
  if (class(try(pandoc.table(res, justify='left',split.tables=Inf, caption=x), silent = T))=="try-error") {tb_nonnative=res}
  if (nrow(tb_nonnative)>1){print(res)}
}
```

```{r, eval=T, echo=F}
# check if there is missing supplementary_file
if (all(pheno.raw$supplementary_file=="NONE")) {
  suppldata=FALSE
} else if (any(pheno.raw$supplementary_file=="NONE")) {
  sample_nosuppl=as.character(pheno.raw$geo_accession[pheno.raw$supplementary_file=="NONE"])
  pheno.raw=pheno.raw[which(pheno.raw$supplementary_file!="NONE"),]
  cat("Not all samples have defined supplementary file path:\n")
  cat(paste(sample_nosuppl,collapse=", "),"\n")
  cat("These samples are excluded from analysis\n")
  suppldata=TRUE
} else {suppldata=TRUE}
```

```{r, eval=T, echo=F}
cat("suppldata =",as.character(suppldata))
```

#### Phenotype information modification

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
library(dplyr)
cols <- c("title","geo_accession","source_name_ch1")
pheno <- pheno.raw %>%
  dplyr::select(cols) %>%
  dplyr::mutate(GEO_ID=geo_accession) %>%
  dplyr::mutate(Donor=gsub("^.*biological (.*)$","\\1",title)) %>%
  dplyr::mutate(Sample=paste(geo_accession,Donor,sep="_")) %>%
  dplyr::mutate(Tissue="Blood") %>%
  dplyr::mutate(treatment_time=gsub("^.*for (\\d+.*)$","\\1",source_name_ch1)) %>%
  dplyr::mutate(treatment_time=gsub(" ","",treatment_time)) %>%
  dplyr::mutate(treatment_drug=ifelse(grepl("sepsis",source_name_ch1),"sepsis","healthy")) %>%
  dplyr::mutate(Treatment=c(rep("24hr",22), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1), rep("24hr",1), rep("No",1))) %>%
  dplyr::mutate(Disease=c(rep("Control",22), rep("Shock",102))) %>%
  dplyr::mutate_if(is.character,as.factor) %>%
  dplyr::select(-one_of(cols)) # remove original columns
detach("package:dplyr")
```

### Raw intensity data download

```{r, eval=T, echo=F}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and extract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (suppldata) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno.raw$supplementary_file))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}
}
```

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
if (platform=="Affymetrix"&suppldata) {
  #1. Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)

  #2. Obtain scan date information from the raw.data for batch effect adjustment
  # As the scan date and scan time are usually joined by "T" or a white space, use both pattern to split the date with time
  pheno$ScanDate_Group <- sapply(strsplit(as.character(protocolData(raw.data)$dates), "T| "), function(x) {x[[1]]})
  pheno$ScanDate_Group <- as.factor(pheno$ScanDate_Group)
}
```

```{r, eval=T, echo=F}
if (!suppldata) {raw.data=gse}
```

```{r, eval=T, echo=F}
# assign phenotype data to raw expression data
pData(raw.data) <- pheno
row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
# Check if the sample names derived from expression data match those in phenotype file
rowname <- gsub("^(.*).(cel|CEL|txt|Txt).gz","\\1",row.names(pData(raw.data)))
matching <- mapply(grepl, x=rowname, pattern=as.character(pData(raw.data)$GEO_ID))
if (FALSE %in% matching) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
```

```{r, eval=T, warning=F,results="asis",echo=F}
# show the first five rows
pandoc.table(head(pheno,5), split.tables=Inf,caption="Show the first 5 rows of the modified phenotype file")
# show the groups of interest
avail_group=c("Tissue","Disease","Treatment")[c("Tissue","Disease","Treatment")%in%names(pheno)]
res=as.data.frame(table(pheno[,avail_group]))
names(res) <- c(avail_group,"Count")
pandoc.table(res, split.tables=Inf, caption="Sample size in different tissue and disease/treatment groups")
# show samples in different batch
if ("ScanDate_Group"%in%names(pheno)) {
  res=as.data.frame(table(pheno[,"ScanDate_Group"]))
  names(res) <- c("ScanDate_Group","Count")
  pandoc.table(res, split.tables=Inf, caption="Sample size in different batch")
} else {cat("No scan date information.")}
```

```{r, eval=T, echo=F}
# assign colours to Scan Date for plots
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
vars=c("ScanDate_Group","Treatment","Disease")
leveluse=sapply(vars,function(x){if(x%in%names(pheno)){nlevel=nlevels(pheno[,x])}else{nlevel=0};nlevel>1})
if (any(leveluse)){varuse=names(which(leveluse)[1])}else{stop("None of the following variables scan date/Disease/Treatment has >1 level. Check the dataset!")} # varible assigned color in plot

# assign colour to corresponding variable (scan date if available otherwise disease/treatment)
i=nlevels(pheno[,varuse])
colour_list <- colours[1:i]
names(colour_list) <- levels(pheno[,varuse]) 
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data)=apply(exprs(raw.data),2,function(x){replace(x,which(x<=0),NA)})
```

```{r, eval=T, echo=F, warning=F}
if (!suppldata|platform!="Affymetrix") {
  boxplot(exprs(gse),col=colour_list,main="Probe Intensity matrix of raw data",xaxt="n") # note gse here are non-coverted expression values
  legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  if (!normdata) {
    boxplot(log2(exprs(raw.data)),col=colour_list,main="Probe Intensity matrix of log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
    boxplot(normalize.quantiles(log2(exprs(raw.data))),col=colour_list,main="Probe Intensity matrix of qnormed log2 data",xaxt="n")
    legend("topright",legend=names(colour_list),fill=colour_list,cex=0.8)
  }
}
```

```{r, eval=T, warning=F, echo=F}
if (geo_GPL=="") {pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_Phenotype_withoutQC.txt"); pheno_fn_withQC=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else
{pheno_fn_withoutQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withoutQC.txt");pheno_fn_withQC=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
write.table(pheno,pheno_fn_withoutQC,col.names=T,row.names=F,sep="\t",quote=F)
```


## Quality Control for Microarray Data

```{r, eval=T, echo=F}
pheno <- read.table(pheno_fn_withoutQC, header=T, sep="\t")
```

### Raw Probe Intensity Boxplots and Density Histograms

```{r raw_intensity_utility, eval=T, echo=F, warning=F}
# The subsamp function randomly selects 20000 probes
subsamp <- function(x,num=20000, seed=123) {
  set.seed(seed)
  subsample=num # if number of probes are >20000, randomly select 20000 probes for plot or compute
  if (nrow(x)>subsample) {
    ss  = sample(nrow(x), subsample)
    Mss = x[ss,,drop=FALSE]
  } else {
    ss  = TRUE
    Mss = x
  }
  Mss
}

# The outlier_KS_func function computes KS statistics for outlier detection
outlier_KS_func = function(exprs) { # matrix (row: probe intensities/RLE values etc., col: array (e.g. sample))
  fx = ecdf(as.vector(exprs)) # get empirical cumulative distribution function of the data
  KS=suppressWarnings(apply(exprs, 2, function(v)ks.test(v, y = fx, alternative="two.sided")$statistic))
  stats = stats::fivenum(KS, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=KS, outlier = which(KS > th))
}

# The boxplot_func function generates boxplots for raw data metrics (e.g. probe intensities, RLE, NUSE) 
boxplot_func <- function(Mss,outlier,ylab) {
  # use * to mark the outliers in boxplot
  array_name <- shortname_func(colnames(Mss))
  outlier <- shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  # boxplot raw intensity by array
  ylim = quantile(Mss, probs = c(0.01, 0.99), na.rm=TRUE) # create range of y-axsis
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df, aes(sample_id,values,fill=scandate)) + geom_boxplot(outlier.colour=NA) +
    coord_flip() + theme_bw() +
    ylim(ylim) +
    scale_x_discrete(labels=array_name) +
    ylab(ylab) +
    scale_fill_manual(varuse,values=cols) +
    theme(axis.title.y=element_blank())
}

# The densplot_func function plots density curve for raw data metrics (e.g. probe intensity)
densplot_func <- function(Mss) {
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(colnames(Mss),each=nrow(Mss)),
    values=as.numeric(Mss),
    scandate=rep(pData(raw.data)[,varuse],each=nrow(Mss)) # for color
  )
  cols <- colour_list
  ggplot(df,aes(x=values,colour=scandate)) + geom_line(aes(group=sample_id),stat="density") +
    theme_bw() +
    xlab("Raw Probe Intensities") +
    ylab("Density") +
    scale_color_manual(varuse,values=cols)
}

# The raw_intensity_func function outputs raw probe intensity metrics
raw_intensity_func <- function() {
  if (!normdata) {Mss=log2(subsamp(exprs(raw.data))) # use log2 transformed raw probe intensity
  } else {
    Mss=subsamp(exprs(raw.data))
  }
  outlier_res=outlier_KS_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss=Mss, outlier=outlier, ylab="Raw Probe Intensities")
  densplot=densplot_func(Mss=Mss)
  return(list(outlier=outlier,boxplot=boxplot,densplot=densplot))
}
```

1. Outlier detection for log2 raw probe intensity/normalized intensity

```{r, eval=T, echo=F, warning=F}
res_intensity=raw_intensity_func()
outlier_intensity = res_intensity$outlier
cat(length(outlier_intensity), "outlier(s) are detected in the raw intensity metrics.\n")
if (length(outlier_intensity)>0) {cat("They are: ", shortname_func(outlier_intensity))}
```

2. Boxplots for log2 raw probe intensity

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
res_intensity$boxplot
```

3. Density curves for log2 raw probe intensity

```{r, eval=T, echo=F, message=F, warning=F}
res_intensity$densplot
```

### RNA Digestion

```{r, eval=T, echo=F}
# The RNAdegaffy_func function compute mean PM intensities in each probe position following 5' to 3' order. Adopted from the AffyRNAdeg function in the affy package but include a step that randomly selects 20,000 probe sets.
RNAdegaffy_func <- function(data){ # input a list of probe set matrix with rows as probe ids and columns as samples
  {
    names <- colnames(data[[1]])
    probe.set.size <- function(x) {
      size <- dim(x)[1]
      return(size)
    }
    max.num <- sapply(data, probe.set.size) # get the number of probes in each probe set
    tab <- (table(max.num)) # summarize the frequencies of probe numbers in probe sets
    ord <- order(-as.numeric(tab)) # order the frequency from large to small
    K <- as.numeric(names(tab))[ord[1]] # K is the number of probes appearing in most probe sets
    data <- data[max.num == K] # select data of probe sets only have K number of probes
  }
  
  subsample=20000
  if (length(data)>subsample) { # randomly select 10000 probe sets
    set.seed(12345)
    ss = sample(length(data),subsample)
    data = data[ss,drop=FALSE]
  }

  N <- length(data) # number of probe sets
  n <- dim(data[[1]])[2] # number of samples
  
  # create two matrices: number of samples * number of probes representing a probe set
  mns <- matrix(nrow = n, ncol = K) # create matrix for mean values
  sds <- mns # create matrix for sds values

  get.row <- function(x, i = 1) {return(x[i, ])} # function to get each row (i.e. probe id, i) from one probe set x (i.e. probe list[[x]])
  rowstack <- function(x, i = 1) {return(t(sapply(x, get.row, i)))} # function to combine the rows obtained using get.row (pms across samples by probe sets) to get a table (row: samples column: probe sets) and transpose the table (row: probe sets, column: samples)

  for (i in 1:K) { # get probe id (position) from 1 to K from each probe set
    data.stack <- rowstack(data, i) # get the probe pm values in a specific probe position across all samples from each probe set (rows are samples and columns are probe sets)
    if(dim(data[[1]])[2]==1) data.stack <- t(data.stack)
    mns[, i] <- colMeans(data.stack) # get the mean values at one probe position across all probe sets
    sds[, i] <- apply(data.stack, 2, sd) # get the sd values at one probe position across all probe sets
  }
    
  mns.orig <- mns # store the original mns data matrix
  mn <- mns[, 1] # select values in the first probe position
  mns <- sweep(mns, 1, mn) # adjust for the intensity at the first probe position
  mns <- mns/(sds/sqrt(N)) # adjust for standard error
  lm.stats <- function(x) {
    index <- 0:(length(x) - 1)
    ans <- summary(lm(x ~ index))$coefficients[2, c(1, 4)] # use linear model fit the relationship between intensity and probe position
    return(ans)
  }
  stats <- apply(mns, 1, lm.stats)
  answer <- list(N, names, mns.orig, sds/sqrt(N), stats[1,], stats[2, ])
  names(answer) <- c("N", "sample.names", "means.by.number","ses", "slope", "pvalue")
  return(answer)
}

# The RNAdeg_func function generates RNA degradation plots
# return a logical variable whether this array type can be read by affy.
RNAdeg_func <- function() {
  # 1. Read in raw data as an AffyBatch object
  library(affy) # for Affymetrix microarray-specific QC analysis
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  # 2. Obtain a list of probe sets with a matrix of oligos (probes) by samples as an input and compute statistics of the mean PM intensities from 5' to 3' probe positions. 
  PM_list <- affy::pm(raw.data.affy,LIST=T) 
  PM_list <- lapply(PM_list,log2)
  raw.data.rnadeg <- RNAdegaffy_func(PM_list) # Compute mean PM intensity for probes following 5' to 3' order.
  # 3. Plot 5' to 3' mean PM intensity
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  plotAffyRNAdeg(raw.data.rnadeg,cols=status.cols)
  legend("topleft",legend=names(colour_list),fill=colour_list,cex=0.6)
  detach("package:affy", unload=TRUE) # detach the affy package
}
```

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {RNAdeg_func()}
}
```

### Distribution of Perfect Match (PM) and Mismatch (MM)

```{r, eval=T, echo=F}
PMMM_func <- function() {
  if (class(raw.data)=="GeneFeatureSet") {
    message("GeneFeatureSet does not have MM probes. No plots will be generated.")
  } else {
    PM <- log2(pm(raw.data))
    MM <- log2(mm(raw.data))
    if(nrow(PM) != nrow(MM)) {
      message("This might be a PM-only array. No plots will be generated.")
      rm(PM,MM)
    } else {
      subsample=20000
      if(nrow(PM)>subsample) { # randomly select 20000 probe sets
        sel = sample(nrow(PM), subsample)
        sPM = PM[sel, ]
        sMM = MM[sel, ]
      } else {
        sPM = PM
        sMM = MM
      }
      rm(PM,MM) 
      
      df <- data.frame(
        values=c(as.numeric(sPM),as.numeric(sMM)),
        types=c(rep("PM",each=length(as.numeric(sPM))),rep("MM",each=length(as.numeric(sMM))))
      )
      cols=colours[1:2]
      ggplot(df,aes(x=values,colour=types)) + geom_line(aes(group=types),stat="density") +
        theme_bw() +
        xlab("Intensity") +
        ylab("Density") +
        scale_color_manual(values=cols) +
        theme(legend.title=element_blank())
    }
  }
}
```

```{r, eval=T, echo=F}
if (platform=="Affymetrix"&suppldata) {PMMM_func()}
```

### MA Plots

```{r, eval=T, echo=F}
# The MAcal_func function computes M and A matrices, while use the intensity of 20000 randomly selected probes
MAcal_func <- function(x) { # matrix (row: probe intensities, col: array (samples)
  medArray = rowMedians(x, na.rm=TRUE)
  M =  x - medArray
  A = (x + medArray)/2
  subsample=20000
  if(nrow(M)>subsample) {
    set.seed(12345)
    sel = sample(nrow(M), subsample)
    sM = M[sel, ]
    sA = A[sel, ]
  } else {
    sM = M
    sA = A
  }
  list(M=sM,A=sA) # return a list with M and A data matrices
}

# The outlier_MA_func function computes the Hoeffding's statistic (Da) statistics for outlier detection
outlier_MA_func <- function(exprs) { # list with M and A data matrices
  M=exprs$M
  A=exprs$A
  Dstats = sapply(1:ncol(M), function(x){hoeffd(A[,x], M[,x])$D[1,2]})
  names(Dstats) <- colnames(M)
  Dthresh = 0.15
  list(threshold=Dthresh, stats=Dstats, outlier = which(Dstats > Dthresh))
}

# The MAplot_func function plots samples with the first 4 highest and lowest values of Da. The value of Da for each sample is shown in the panel headings. Outliers marked with * have Da values >0.15.
MAplot_func <- function(sMA, outlier_res) {
# select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(sMA$M)-3):ncol(sMA$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  scandate_sel <- pData(raw.data)[,varuse][column_sel]
  M_sel <- sMA$M[,column_sel]
  A_sel <- sMA$A[,column_sel]
  # use * to mark the outliers
  array_name <- shortname_func(colnames(M_sel))
  outlier_MA=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_MA] <- paste0("*",array_name[array_name%in%outlier_MA])
  array_name <- paste0(array_name," (D=",stats_sel,")") # add D statistics to corresponding samples
  # create data frame for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    scandate=rep(scandate_sel,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    A=as.numeric(A_sel)
  )
  # MA plots
  ggplot(df,aes(x=A,y=M,color=scandate)) + geom_point(alpha=0.1) + theme_bw() +
    scale_color_manual(varuse,values=colour_list) +
    facet_wrap(~sample_id,ncol=2)
}

# The MA_func function outputs MA metrics
MA_func <- function(){
  # Compute M-A metrics
  if (!normdata) {
    sMA <- MAcal_func(log2(exprs(raw.data)))
  } else {
    sMA <- MAcal_func(exprs(raw.data))
  }
  outlier_res <- outlier_MA_func(exprs=sMA)
  outlier <- names(outlier_res$outlier)
  plot <- MAplot_func(sMA=sMA, outlier_res=outlier_res)
  return(list(outlier=outlier, plot=plot))
}
```

1. Outlier detection for MA plots

```{r, eval=T, echo=F, message=F, warning=F}
res_MA=MA_func()
outlier_MA=res_MA$outlier
cat(length(outlier_MA), "outliers are detected in the MA metrics.\n")
if (length(outlier_MA)>0) {cat("They are: ", shortname_func(outlier_MA))}
```

2. MA plots

```{r, eval=T, echo=F, message=F, warning=F, fig.height=10, fig.width=7}
res_MA$plot
```

### Spatial Distribution

```{r, eval=T, echo=F}
# The affyspatial_func function computes spatial x- and y-coordinate using raw data object classed as AffyBatch
affyspatial_func <- function() {
  library(affy)
  raw.data.affy <- read.affybatch(rawall_func(),compress=T)
  maxc = ncol(raw.data.affy) # number of probes in x-coordinate
  maxr = nrow(raw.data.affy) # number of probes in y-coordinate
  sx = rep(seq_len(maxc), each = maxr) ## spatial x-coordinate
  sy = rep(seq_len(maxr), maxc) ## spatial y-coordinate
  M = log2(affy::exprs(raw.data.affy))
  detach("package:affy", unload=TRUE)
  numArrays = dim(M)[2]
  return(list(M=M,numArrays=numArrays,sx=sx,sy=sy))
}

# The outlier_spatial_func function computes the Fourier coefficients for outlier detection
outlier_spatial_func <- function(affy_spatial_list) {
  sx=affy_spatial_list$sx # spatial x-coordinate
  sy=affy_spatial_list$sy # spatial y-coordinate
  M=affy_spatial_list$M
  numArrays=affy_spatial_list$numArrays
  maxx = max(sx, na.rm=TRUE)
  maxy = max(sy, na.rm=TRUE)
  stat_spatial = numeric(numArrays)
  for(a in seq_len(numArrays)) {
    mat = matrix(NA_real_, nrow=maxy, ncol=maxx)
    mat[cbind(sy, sx) ] = M[, a]
    pg  = fft(mat) ## periodogram, computes the discrete fourier transform
    npg = Re(pg*Conj(pg))
    npg[1,1] = 0 ## drop the constant component
    stat_spatial[a] = sqrt(sum(npg[1:4, 1:4]) / sum(npg)) # low frequency power
  }
  names(stat_spatial)=colnames(M)
  stats = stats::fivenum(stat_spatial, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, stats=stat_spatial, outlier = which(stat_spatial > th))
}

# The spatplot_func function plots samples with the first 4 highest and lowest values of Fa. The value of Fa for each sample is shown in the panel headings.
spatplot_func <- function(raw.data.spatial,outlier_res) {
  # select arrays with top 4 highest and lowest Da
  stats_order <- order(outlier_res$stats)
  column_sel <- stats_order[c(1:4,(ncol(raw.data.spatial$M)-3):ncol(raw.data.spatial$M))]
  stats_sel <- round(outlier_res$stats[column_sel],2)
  M_sel <- raw.data.spatial$M[,column_sel]
  # apply rank to expression data
  M_sel = apply(M_sel, 2, rank)
  # use * to mark the outliers
  array_name=shortname_func(colnames(M_sel))
  outlier_spatial=shortname_func(names(outlier_res$outlier))
  array_name[array_name%in%outlier_spatial] <- paste0("*",array_name[array_name%in%outlier_spatial])
  array_name <- paste0(array_name," (F=",stats_sel,")") # add F statistics to corresponding samples
  # create variables for plot
  df <- data.frame(
    sample_id=rep(array_name,each=nrow(M_sel)),
    M=as.numeric(M_sel),
    row=rep(raw.data.spatial$sy,ncol(M_sel)),
    column=rep(raw.data.spatial$sx,ncol(M_sel))
  )
  # spatial distribution plots
  ggplot(df,aes(x=row,y=column,fill=M)) + geom_tile() + 
    theme_bw() +
    xlab("Raw Probe Intensiry in X") + ylab("Raw Probe Intensiry in Y") +
    scale_fill_gradientn(name="Ranked Intensity",colours=viridis(256,option="B")) +
    facet_wrap(~sample_id,ncol=2)
}

# The spatial_func function outputs spatial metrics
spatial_func <- function() {
  raw.data.spatial=affyspatial_func()
  outlier_res=outlier_spatial_func(affy_spatial_list=raw.data.spatial)
  outlier=names(outlier_res$outlier)
  plot=spatplot_func(raw.data.spatial=raw.data.spatial,outlier_res=outlier_res)
  return(list(outlier=outlier,plot=plot))
}
```


1. Outlier detection for spatial plots

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial=spatial_func()
    outlier_spatial=res_spatial$outlier
    cat(length(outlier_spatial), "outlier(s) are detected in the spatial metrics.\n")
    if (length(outlier_spatial)>0) {cat("They are: ", shortname_func(outlier_spatial))}
  }
}
```
  
2. Spatial distribution plots

```{r, eval=T, echo=F, fig.height=10, fig.width=7}
if (platform=="Affymetrix"&suppldata) {
    if (grepl('hta.2.0',annotation(raw.data))) {cat("The affy package is not designed for this array type.\n")} else {
    res_spatial$plot
  }
}
```

### Relative Log Expression (RLE) Distribution

```{r, eval=T, echo=F, message=F, warning=F}
# The fitPLM_func function generates RLE and NUSE matrices
fitPLM_func <- function(raw.data) {
  exprs(raw.data) <- log2(exprs(raw.data)) # The fitProbeLevelModel function needs ExpressionFeatureSet object as an input. Assign log transformed expression values to a new object
  fitPLM <- fitProbeLevelModel(raw.data)
  # RLE
  M_RLE <- RLE(fitPLM, type="values") # generate RLE matrix
  Mss_RLE <- subsamp(M_RLE,seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  # NUSE
  M_NUSE <- NUSE(fitPLM, type="values") # generate NUSE matrix
  Mss_NUSE <- subsamp(M_NUSE, seed=1234) # use the subsamp function to reduce RLE data with randomly selected 20000 probes
  return(list(Mss_RLE=Mss_RLE,Mss_NUSE=Mss_NUSE))
}
# The RLE_func function outputs RLE metrics
RLE_func <- function(Mss) {
  outlier_res=outlier_KS_func(Mss) # compute KS statistics to detect outliers
  outlier=names(outlier_res$outlier)
  plot=boxplot_func(Mss,outlier,"RLE")
  return(list(outlier=outlier,plot=plot))
}
```

1. Outlier detection for RLE

```{r, eval=T, echo=F, message=F, warning=F}
if (platform=="Affymetrix"&suppldata) {
  fitPLM=fitPLM_func(raw.data)
  res_RLE=RLE_func(Mss=fitPLM$Mss_RLE)
  outlier_RLE=res_RLE$outlier
  cat(length(outlier_RLE), "outlier(s) are detected in RLE metrics.\n")
  if (length(outlier_RLE)>0) {cat("They are: ", shortname_func(outlier_RLE))}
}
```

2. Boxplot for RLE

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_RLE$plot}
```

### Normalized Unscaled Standard Error (NUSE) Outlier Detection and Plots

```{r, eval=T, echo=F, message=F, warning=F}
# The function outlier_upperquartile_func function computes upper 75% quantile for outlier detection
outlier_upperquartile_func <- function(exprs) { # matrix (row: NUSE values, col: array (e.g. sample))
  upperquartile = apply(exprs, 2, quantile, na.rm=TRUE, probs=0.75)
  stats = stats::fivenum(upperquartile, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(upperquartile > th))
}

# The NUSE_func function outputs the NUSE metrics
NUSE_func <- function(Mss) {
  outlier_res = outlier_upperquartile_func(Mss)
  outlier=names(outlier_res$outlier)
  boxplot=boxplot_func(Mss,outlier,"NUSE")
  return(list(outlier=outlier,boxplot=boxplot))
}
```

1. Outlier detection for NUSE

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
if (platform=="Affymetrix"&suppldata) {
  res_NUSE <- NUSE_func(Mss=fitPLM$Mss_NUSE)
  outlier_NUSE = res_NUSE$outlier # compute upper 75% quantile statistics to detect outliers
  cat(length(outlier_NUSE), "outlier(s) are detected in NUSE metrics.\n")
  if (length(outlier_NUSE)>0) {cat("They are: ", shortname_func(outlier_NUSE))}
}
```

2. Boxplot for NUSE

```{r, eval=T, echo=F, message=F, warning=F, fig.height=8, fig.width=6}
if (platform=="Affymetrix"&suppldata) {res_NUSE$boxplot}
```

### Distance between Samples and Outlier Detection

```{r, eval=T, echo=F, warning=F}
# The dist2 estimates distance between samples
dist2 <- function (x,fun = function(a, b) mean(abs(a - b), na.rm = TRUE),diagonal = 0) {
  if (!(is.numeric(diagonal) && (length(diagonal) == 1)))
    stop("'diagonal' must be a numeric scalar.")

  if (missing(fun)) {
    res = apply(x, 2, function(w) colMeans(abs(x-w), na.rm=TRUE))
  } else {
    res = matrix(diagonal, ncol = ncol(x), nrow = ncol(x))
    if (ncol(x) >= 2) {
      for (j in 2:ncol(x))
        for (i in 1:(j - 1))
          res[i, j] = res[j, i] = fun(x[, i], x[, j])
    } # if
  } # else
  colnames(res) = rownames(res) = colnames(x)
  return(res)
}

# The outlier_dist_func function computes the sum of all distance of one sample to other samples for outlier detection
outlier_dist_func <- function(exprs) { # matrix (row: distance to each sample, col: array (e.g. sample))
  sum = colSums(exprs, na.rm=TRUE) # sum the total distance
  stats = stats::fivenum(sum, na.rm = TRUE) # Tukey's five number summary (minimum, lower-hinge, median, upper-hinge, maximum)
  iqr = diff(stats[c(2, 4)]) # lagged difference between the lower-hinge and upper-hinge
  coef = 1.5
  th = (stats[4] + coef * iqr)
  list(threshold = th, outlier = which(sum > th))
}

# The displot_func function plots distance between samples
distplot_func <- function(m,outlier) {
  dend = as.dendrogram(hclust(as.dist(m), method = "single"))
  ord = order.dendrogram(dend)
  array_name=shortname_func(colnames(m))
  outlier=shortname_func(outlier)
  array_name[array_name%in%outlier] <- paste0("*",outlier)
  array_name <- shortname_func(array_name) # shorten the sample id
  status.cols <- unlist(lapply(pData(raw.data)[,varuse],function(x)colour_list[x])) # colour list to corresponding scan date list
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256, option="B"),ColSideColors=status.cols,RowSideColors=status.cols,
    labCol=array_name,labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_list),fill=colour_list,cex=0.6)
}

# The dist_func function outputs distance metrics
dist_func <- function() {
  if (!normdata) {
    m <- dist2(log2(exprs(raw.data)))
  } else {
    m <- dist2(exprs(raw.data))
  }
  
  outlier_res=outlier_dist_func(m)
  outlier=names(outlier_res$outlier)
  return(list(outlier=outlier,m=m))
}
```

1. Outlier detection for sample distance

```{r, eval=T, echo=F}
res_dist=dist_func()
outlier_dist=res_dist$outlier
cat(length(outlier_dist), "outlier(s) are detected in sample distance metrics.\n")
if (length(outlier_dist)>0) {cat("They are: ", shortname_func(outlier_dist))}
```

2. Plot distance between samples
```{r, eval=T, echo=F, fig.height=10, fig.width=12}
distplot_func(m=res_dist$m,outlier=res_dist$outlier)
```

### Principal Component Analysis (PCA)

```{r, eval=T, echo=F}
# The pcastat_func function computes principal components
pcastat_func <- function() {
  # obtain original expression data
  if (!normdata) {
    raw.data.pca <- na.omit(log2(exprs(raw.data)))
  } else {
    raw.data.pca <- na.omit(exprs(raw.data))
  } # remove NAs
 
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(pc, group_var,legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(raw.data)[,group_var]
  )
  i=length(levels(pData(raw.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(raw.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(pc) {
  group_vars=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  legends=c("ScanDate_Group", "Disease", "Treatment", "Tissue", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(raw.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    nlevel=nlevels(pData(raw.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=20)) {
      plot_list[[group_var]]=pcaplot_func(pc, group_var=group_var,legend=legend)
    }
  }
  return(plot_list)
}
```


1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
res_pca <- pcastat_func()
pandoc.table(res_pca$tb,split.tables=Inf, caption="Variance explained")
```

2. PCA plots

```{r, eval=T, echo=F}
plot_list=pca_func(pc=res_pca$pc)
for (i in plot_list) {print(i)}
```


### QC Summary

```{r, eval=T, echo=F}
# The outlier_summ_func function outputs a summary table of outlier and the detected frequency
outlier_summ_func <- function() {
  outlier_all <- c("outlier_intensity","outlier_MA","outlier_spatial","outlier_RLE","outlier_NUSE","outlier_dist") # all outliers
  outlier_env=ls(envir=.GlobalEnv, pattern="outlier_") # "outlier_" enviromental variables
  outlier=outlier_env[outlier_env%in%outlier_all]
  method=gsub("outlier_","",outlier)
  outliers=unlist(lapply(1:length(outlier),function(x){get(outlier[x],envir=.GlobalEnv)}))
  if (length(outliers)==0) {
    cat("No outlier was detected\n")
    res <- data.frame() # create an empty data frame
  } else {
    methods=unlist(lapply(1:length(outlier),function(x){n=length(get(outlier[x]));rep(method[x],n)}))
    outlier_list=list()
    for (x in 1:length(outliers)){outlier=outliers[x];method=methods[x];outlier_list[[outlier]]=append(outlier_list[[outlier]],method)}
    # summary table
    Frequency <- sapply(outlier_list,length) # times to detect
    Method <- unlist(lapply(names(outlier_list),function(x){paste0(outlier_list[[x]],collapse=", ")}))
    res <- data.frame(Frequency,Method)
    res <- res[order(res$Frequency),]
  }
  return(res)
}

# The tbQC_func function
tbQC_func <- function(outliers) { # define outliers
  tb=pData(raw.data)
  tb$QC_Pass=1
  if (missing(outliers)) { # if outliers are not defined, use those detected more than twice
    tb$QC_Pass[rownames(tb)%in%rownames(outlier_tb)[outlier_tb$Frequency>2]]<-0 # assign 0 to outliers detected more than twice
  } else {
    tb$QC_Pass[rownames(tb)%in%outliers]<-0
  }
  tb$Filename <- rownames(tb) # add filename in a new column
  # save in a new phenotype file
  write.table(tb,pheno_fn_withQC,col.names=T,row.names=F,sep="\t",quote=F)
  # defined outliers
  outlier=as.character(tb$GEO_ID)[which(tb$QC_Pass==0)]
  # summary of phenotype information before QC
  vars=c("Tissue","Treatment","Disease","QC") # variables of interest
  # before QC
  tb_withoutQC=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb_withoutQC)[ncol(tb_withoutQC)]="Counts"
  # after QC
  tb_withQC=as.data.frame(table(tb[which(tb$QC==1),names(tb)%in%vars]))
  names(tb_withQC)[ncol(tb_withQC)]="Counts"
  return(list(outlier=outlier, tb_withoutQC=tb_withoutQC, tb_withQC=tb_withQC))
}
```

```{r, eval=T, echo=F, results="asis"}
outlier_tb=outlier_summ_func()
if (nrow(outlier_tb)>0) {
  pandoc.table(outlier_tb,caption="Outlier Summary",split.tables=Inf)
}
```

```{r, eval=T, echo=F}
res_tbQC=tbQC_func()
outlier=res_tbQC$outlier
cat(length(outlier), "outlier(s) are defined.\n")
if (length(outlier)>0) {cat("They are: ", outlier)}
```

```{r, eval=T, echo=F, results="asis"}
pandoc.table(res_tbQC$tb_withoutQC, split.tables=Inf, caption="Summary of samples without QC")
pandoc.table(res_tbQC$tb_withQC, split.tables=Inf, caption="Summary of samples with QC")
```

> Differential Gene Expression Analysis for GSE95233

```{r, eval=T, echo=T}
# GEO id
geo_id="GSE95233"
# tissue
tissue="Blood"
# reference condition
con0="Control"
# altered condition
con1="Shock"
# treatment. Assign "comparison" if this column is used for DE.
treatment="24hr"
# disease. Assign "comparison" if this column is used for DE.
disease=c(con0,con1)
```

```{r, eval=T, echo=T}
platform="Affymetrix"
geo_GPL=""
usesuppl=TRUE
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*).(cel|CEL).gz","\\1",x)} # remove .cel.gz or .CEL.gz from sample
```

```{r, eval=T, echo=F}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
```

```{r pheno_fn_show, eval=T, echo=F}
cat(paste0("pheno_fn = '", pheno_fn,"'"))
```

```{r, eval=T, echo=F, message=F, warning=F}
library(GEOquery)
library(oligo)
library(limma)
library(sva)
library(annotate)
library(viridis)
library(ggplot2)
library(gplots)
library(devtools)
library(preprocessCore)
library(pander)
```

## Obtain Phenotype and GEO Data

### Phenotype data preparation

```{r, eval=T, echo=F}
# The phenosub_func function subsets phenotypes based on the user defined variables
phenosub_func <- function(){
  pheno.sub=subset(pheno,(Tissue%in%tissue)&(Treatment%in%treatment)&(Disease%in%disease))
  pheno.sub=droplevels(pheno.sub)
  # assign comparison to "Status" column
  if (length(treatment)==2) {
    if (identical(sort(levels(pheno.sub$Treatment)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Treatment} else {stop("Assigned treatment variables are not included in the Treatment column")}
  } else if (length(disease)==2) {
    if (identical(sort(levels(pheno.sub$Disease)),sort(c(con0,con1)))) {
      pheno.sub$Status=pheno.sub$Disease} else {stop("Assigned treatment variables are not included in the Disease column")}
  }
  pheno.sub$Status <-factor(pheno.sub$Status,levels=c(con0,con1))
  return(pheno.sub)
}

# The phenoqc_func function excludes outliers from phenotype file 
phenoqc_func <- function(outlier,pheno) {
  if (missing(outlier)) {pheno=subset(pheno, QC_Pass==1)} else {pheno=subset(pheno, Filename%in%outlier)}
  droplevels(pheno)
}

# The phenopair_func function excludes unpaired donor from analysis
phenopair_func <- function(dat) {
  unpaired_samp=names(which(table(dat$Donor)==1))
  dat=dat[which(!dat$Donor%in%unpaired_samp),]
  droplevels(pheno)
  if (length(unpaired_samp)>0) {
    cat(paste0(length(unpaired_samp)," sample(s) with unpaired donor are excluded from analysis\n"))
    cat(paste(unpaired_samp,collapse=", "),"\n")
  }
  return(dat)
}

# The tbsum_func function generates summary of variables of interest
tbsum_func <- function(tb) {
  vars=c("Status", "ScanDate_Group") # variables of interest
  tb=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb)[ncol(tb)]="Counts"
  return(tb)
}

# The infosumm_function generates summary of the comparison
infosumm_func <- function(pheno) {
  N_Condition0 <- sum(pheno$Status==con0) # count number of samples under condition 0
  N_Condition1 <- sum(pheno$Status==con1) # count number of samples under condition 1
  if (identical(sort(levels(pheno$Treatment)),sort(c(con0,con1)))) {
    App="GC"
    if (geo_GPL=="") {name=paste(geo_id,tissue,disease,con1,"vs",con0, sep="_")} else {{name=paste(geo_id,geo_GPL,tissue,disease,con1,"vs",con0, sep="_")}}
    Disease=disease
    Treatment=con1
  } else {
    App="Asthma"
    if (geo_GPL=="") {name=paste(geo_id,tissue,treatment,con1,"vs",con0, sep="_")} else {name=paste(geo_id,geo_GPL,tissue,treatment,con1,"vs",con0, sep="_")}
    Disease=con1
    Treatment=treatment
  }
  
  df <- data.frame(
    GEO_ID=geo_id,
    Tissue=tissue,
    App=App,
    Disease=Disease,
    Treatment=Treatment,
    N_Condition0=N_Condition0,
    N_Condition1=N_Condition1,
    Total=N_Condition0+N_Condition1,
    Unique_ID=name
  )
  return(list(df=df,name=name))
}
```

```{r, eval=T, echo=F}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
# read in the pre-prepared phenotype data
if (!file.exists(pheno_fn)) {stop("The phenotype file does not exist. Please check!")} else {pheno <- read.table(pheno_fn, header=TRUE, sep="\t")}
```

```{r, eval=T, echo=F}
pheno.sub=phenosub_func()
outlier=as.character(pheno.sub$Filename)[pheno.sub$QC_Pass==0]
if (length(outlier)>0) {
  cat("Remove outlier(s)", outlier, "from phenotype file\n")
  pheno.of.interest=phenoqc_func(pheno=pheno.sub)
} else {pheno.of.interest=pheno.sub}
```

Define paired variable.

```{r, eval=T, echo=F, results="asis"}
if (length(disease)==2) {
  paired=FALSE
} else if (length(disease)==1) {
  if (all((pheno.sub$Donor)==1)) {paired=FALSE} # if treatment is in different donors
  else {paired=TRUE} # if treatment is in samd donors
}
```

```{r, eval=T, echo=F}
cat("paired =",as.character(paired))
```

Exclude samples missing the other paired donors in treatment comparisons
```{r, eval=T, echo=F, results="asis"}
if (paired) {
  pheno.of.interest <- phenopair_func(pheno.of.interest)
}
```

```{r, eval=T, echo=F, results="asis"}
if (nrow(pheno.sub)!=nrow(pheno.of.interest)) {
  pandoc.table(tbsum_func(tb=pheno.sub), split.tables=Inf, caption="Summary of subsetted samples without QC")
  pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples with QC")
} else {pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples")}

# create a summary table for this comparison
pandoc.table(t(infosumm_func(pheno=pheno.of.interest)$df),split.tables=Inf, caption="Summary of the comparison")
```

```{r, eval=T, echo=F}
# assign colours to comparison status
colour_status <- c("navy","red")
names(colour_status) <- c(con0,con1) # assign red to condition 1 and navy to condition 2
colour_status_list <- unlist(lapply(pheno.of.interest$Status,function(x){colour_status[x]}))
# assign colours to scan date
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
if ("ScanDate_Group"%in%names(pheno)) {
  i=nlevels(pheno.of.interest$ScanDate_Group)
  colour_scandate <- colours[1:i]
  names(colour_scandate) <- levels(pheno.of.interest$ScanDate_Group) # colour to corresponding scan date
  colour_scandate_list <- unlist(lapply(pheno.of.interest$ScanDate_Group,function(x){colour_scandate[x]}))
}
```

### Gene expression data preparation

```{r, eval=T, echo=F, message=F, warning=F, results="hide"}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and unextract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

# If supplementary data is available, download supplimentary raw data files
if (usesuppl) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno$Filename))}

  # The existall_func function check whether all supplementary files in GEO phenotype exist in the data directory
  existall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # check if all supplementary_file name from GEO phenotype are within the downloaded folder
    return(all(sapply(sampall_func(),function(x)x%in%raw_fn)))
  }

  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {
    raw_fn=list.files(path=paste0(datadir,"/",geo_id,"/data"))
    # obtain supplementary data with path
    paste0(datadir,"/",geo_id,"/data/",raw_fn[which(raw_fn%in%sampall_func())])
  }

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=existall_func()

  if (!samp_exist) {
    suppldownload_func()
  }
  samp_exist=existall_func() # updated the existing samples
  if (!samp_exist) {stop("The .cel files obtained from GEO do not include all the samples of interest")}

  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)
}
```

```{r, eval=T, echo=F, message=F, warning=F}
if (!usesuppl) {
  # check if GEO matrix file exists
  geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))] # check if GEO matrix file exists
  if (length(geo_fn)==0) { # # GEO matrix file is not downloaded
    gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
    if (length(gselms)>1) {  # multiple platform
      gpls=sapply(gselms,annotation)
      cat("This study was performed in multiple platforms:\n")
      cat(unname(gpls),"\n")
      cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
      if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); idx=which(grepl(geo_GPL,gpls))}
    } else {idx=1}
    gse <- gselms[[idx]]
  } else if (length(geo_fn)==1) { # GEO matrix file is alreadly downloaded and only has one platform
    gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
  } else { # GEO matrix file is alreadly downloaded and has multiple platforms
    cat("This study was performed in multiple platforms:\n")
    cat(geo_fn)
    cat("Samples from same platform shoud be analyzed together. Assign a platform to the variable geo_GPL in the session coding.\n")
    if (geo_GPL=="") {stop("This study has multiple platforms. Please assign the platform to the variable geo_GPL in the session coding.")} else {cat("Use platform", geo_GPL, "\n"); geo_fn <-geo_fn[grep(geo_GPL,geo_fn)];gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)}
  }
  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.data=gse
}
```

```{r, eval=T, echo=F}
# The subdat_func function subsets data based on the phenotype of interest
subdat_func <- function(raw.data, pheno) {
  # subset raw.data based on the phenotype of interest
  raw.data=raw.data[,colnames(raw.data)%in%pheno$Filename]
  # assign phenotype data to raw expression data
  pData(raw.data) <- pheno
  row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
  # check if the sample names derived from expression data match those in phenotype file
  if (usesuppl) {matching=mapply(identical,row.names(pData(raw.data)),as.character(pheno$Filename))}
  else {matching=mapply(grepl,row.names(pData(raw.data)),as.character(pheno$Filename))}
  if (!all(matching)) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
  return(raw.data)
}
raw.data.of.interest=subdat_func(raw.data=raw.data, pheno=pheno.of.interest)
```

Show expression dataset features
```{r, eval=T, echo=F}
raw.data.of.interest
```

## Differential Gene Expression Analysis

### Normalize raw gene expression data

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data.of.interest),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data.of.interest)=apply(exprs(raw.data.of.interest),2,function(x){replace(x,which(x<=0),NA)})
```

```{r, eval=T, echo=F, message=F, results="hide"}
if (usesuppl) {
  rma.data.of.interest = rma(raw.data.of.interest)
  cat("RMA normalization is used.\n")
} else {
  rma.data.of.interest=raw.data.of.interest
  if (!normdata) {exprs(rma.data.of.interest)=normalize.quantiles(log2(exprs(rma.data.of.interest)))
  cat("Quantile normalization and log2 transformation is used.\n")
  }
}
```

```{r, eval=T, echo=F}
cols=colour_status_list
boxplot(raw.data.of.interest,target="core",col=cols,main="Raw Probe Intensities",xaxt="n") # view raw data
legend("topright",legend=names(colour_status),fill=colour_status)

if (!normdata) {
  boxplot(rma.data.of.interest,col=cols,main="Normalized Probe Intensities",xaxt="n") # view RMA-adjusted data
  legend("topright",legend=names(colour_status),fill=colour_status)
} else {cat("The raw data is already normalized")}
```


### Pairwise Comparison between Status

```{r, eval=T, echo=F, results="asis"}
limma_func <- function(paired=FALSE) { # here only con0, con1 are used in comparisons. use a function to reduce the factor levels
  if (paired) {
    cat("Donor is adjusted in this regression\n")
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$Donor)) # create design model matrix
    colnames(design) = c(levels(factor(rma.data.of.interest$Status)),levels(factor(rma.data.of.interest$Donor))[-1])
  } else {
    # Create a design model matrix for linear model. Fit a linear model using design matrix model.
    design = model.matrix(~ -1+factor(rma.data.of.interest$Status)) # create design model matrix
    colnames(design) = levels(factor(rma.data.of.interest$Status))
  }
  fit = lmFit(rma.data.of.interest, design) # fit a linear model to estimate the fold changes and standard error
  # Create a contrast group and fit it in a linear model
  data.contrast = makeContrasts(contrasts=paste(c(con1,con0),collapse="-"),levels = design) # create a contrast group by comparing con1 vs con0
  fit2 = contrasts.fit(fit, data.contrast) # get the contrasts for samples of interest
  fit2 = eBayes(fit2) # adjust fit coefficients using an empirical Bayes moderation of standard errors
  return(list(design=design,data.contrast=data.contrast,fit2=fit2))
}
```

```{r, eval=T, echo=F, message=F, warning=F, results="asis"}
res_DE=limma_func(paired=paired)
fit2=res_DE$fit2
pandoc.table(data.frame(Sample=rma.data.of.interest$Sample,res_DE$design), split.tables=Inf, caption="A design model matrix for linear model")
pandoc.table(as.data.frame(res_DE$data.contrast), caption="A contract matrix for comparison")
contrast_table <- topTable(fit2, adjust="BH",num=Inf) # get full set of results for each hypothesis test
col.sel=c("logFC","AveExpr","t","P.Value","adj.P.Val","B") # select the columns of DE results
contrast_table <- data.frame(ID=row.names(contrast_table), contrast_table[,col.sel])
```

### Adjusting for Batch Effect

```{r, eval=T, echo=F}
# The nbatch_func function obtains number of batches (scan date) in the data
nbatch_func <- function() {
  if (!"ScanDate_Group"%in%names(pData(rma.data.of.interest))) {nbatch=0} else {nbatch=nlevels(rma.data.of.interest$ScanDate_Group)}
}

# The svamod_func function creates full and null models, and Checks if the batch and comparison status are confounded
svamod_func <- function(paired=FALSE) {
  # Create a full model
  modBatch = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)) # full model (adjusted variables and variables of interest)
  # Create a null model only including batch variables
  nullBatch =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)) # null model (adjusted variables only)
  # Check if the scan date and comparison status are confounded
  if (class(try(solve(t(modBatch)%*%modBatch),silent=T))=="matrix") {batchadj=TRUE} else {batchadj=FALSE; message("The scan date and comparison status are highly confounded")}
  # summary of the full model
  tb.fullmod <- as.data.frame(modBatch)
  names(tb.fullmod) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])
  # summary of the null model
  tb.nullmod <- as.data.frame(nullBatch)
  names(tb.nullmod) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])

  donoradj=NULL # assign variable is donor is adjusted
  tb.nullmod1=NULL # assign null matrix for donor adjustment
  if ((paired)&(batchadj)) { # same donor treatment adjust for donor
    # Test if donor and scandate are correlated
    modBatch1 = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # full model including donor
    nullBatch1 =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)+factor(rma.data.of.interest$Donor)) # null model including donor
    # summary of the full model
    tb.fullmod1 <- as.data.frame(modBatch1)
    names(tb.fullmod1) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
    # summary of the null model
    tb.nullmod1 <- as.data.frame(nullBatch1)
    names(tb.nullmod1) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1],levels(droplevels(rma.data.of.interest$Donor))[-1])
      
    # check if scandate correlated with donor
    if (class(try(solve(t(modBatch1)%*%modBatch1),silent=T))=="matrix") {
      donoradj="yes"
      modBatch=modBatch1
      nullBatch=nullBatch1
      tb.fullmod=tb.fullmod1
      tb.nullmod=tb.nullmod1
    }
  }

  return(list(modBatch=modBatch, nullBatch=nullBatch, tb.fullmod=tb.fullmod, tb.nullmod=tb.nullmod, batchadj=batchadj, donoradj=donoradj, tb.nullmod_donor=tb.nullmod1))
}

# The batcherror_func function assigns a variable batcherror to decide whether to adjust for batch effect under various scenarios
batcherror_func <- function() {
  if (nbatch==0) {
    batcherror="zero"
  } else if (nbatch==1) {
    batcherror="one"
  } else {
    if (batchadj) {batcherror="no"} else {batcherror="correlate"}
  }
  return(batcherror)
}

# The batchadj_func function outputs table with batch effects adjusted p-values
batchadj_func <- function(batcherror=batcherror, contrast_table=contrast_table, paired=paired) {
  if (batcherror=="no") {
    modBatch=svamod_func(paired=paired)$modBatch
    nullBatch=svamod_func(paired=paired)$nullBatch
    pValuesBatch=f.pvalue(exprs(rma.data.of.interest), modBatch, nullBatch) # get batch effect-adjusted p-values
    qValuesBatch=p.adjust(pValuesBatch, method="BH") # get q-values
    tb.sva <- data.frame(ID=names(pValuesBatch),pValuesBatch,qValuesBatch)
    contrast_table <- merge(contrast_table, tb.sva, by="ID", all=TRUE)
  } else if (batcherror=="correlate") {
    contrast_table$pValuesBatch=contrast_table$qValuesBatch=rep(NA,nrow(contrast_table))
  } else {
    contrast_table$pValuesBatch=contrast_table$P.Value
    contrast_table$qValuesBatch=contrast_table$adj.P.Val
  }
  return(contrast_table)
}
```

```{r, eval=T, echo=F}
nbatch=nbatch_func()
if (nbatch>1) {res_svamod=svamod_func(paired=paired);batchadj=res_svamod$batchadj}
batcherror=batcherror_func()
if (batcherror=="zero") {cat("No scan date is present in the data.")} else if (batcherror=="one") {cat("Only one batch is present in the data.")} else if (batcherror=="correlate") {cat("The scan date and the comparison status are highly confounded (See the model matrix). Cannot ajust for batch effect.")}
```

```{r, eval=T, echo=F, results="asis"}
if (nbatch>1) {
  if (paired) {
    if (is.null(res_svamod$donoradj)) {
      cat("Scan date and donor are highly confounded. See the matrix below.\n")
      pandoc.table(res_svamod$tb.nullmod_donor, split.tables=Inf, caption="Null model matrix with scan date and donor")
      cat("Only adjust for scan date.\n")
    } else {cat("Both scan date and donor are adjusted.\n")}
  }
  pandoc.table(res_svamod$tb.fullmod, split.tables=Inf, caption="Full model matrix")
  pandoc.table(res_svamod$tb.nullmod, split.tables=Inf, caption="Null model matrix")
}
```

```{r, eval=T, echo=F, results="asis"}
contrast_table=batchadj_func(batcherror=batcherror, contrast_table=contrast_table, paired=paired)
pandoc.table(summary(contrast_table), split.tables=Inf, caption=paste0(con1, " vs. ", con0, " summary"))
```


### Assign Official Gene Symbol

```{r, eval=T, echo=F}
anno_list=list()
# Affymetrix
anno_list[["pd.hg.u133.plus.2"]]="hgu133plus2.db"
```

```{r, echo=F}
# glpanno_func creates anntoation vector based on GPL annotation from GEO
glpanno_func <- function(GPL_ID){
  gpl <- Table(getGEO(GPL_ID, destdir = "data"))
  if (GPL_ID%in%names(symbol_list)) {anno_vect <- gpl[,symbol_col]} else {anno_vect <- gpl[,"gene name"]}
  names(anno_vect) <- gpl[,"ID"]
  return(anno_vect)
}

# ranno_func creates anntoation vector based on R annotation database
ranno_func <- function(anno_lib){
  # check if the annotation database is installed
  if (!anno_lib%in%installed.packages()[,1]){source("http://bioconductor.org/biocLite.R"); biocLite(anno_lib)}
  library(anno_lib, character.only=T)
  anno_symbol=gsub(".db","SYMBOL",anno_lib) # The name of the R object mapping between probe id and gene symbol
  x=get(anno_symbol)
  # Get the probe identifiers that are mapped to a gene symbol
  mapped_probes <- mappedkeys(x)
  # Convert to a list
  xx <- as.list(x[mapped_probes])
  # Convert list to annotation vector
  anno_vect <- sapply(xx,function(x){x})
  return(anno_vect)
}

# geneannot_func annotates gene symbol to DE result table
geneannot_func <- function(tb, anno_vect) {
  remove.pm <- function(x) {gsub("_PM", "", x)} # Assign official gene symbol using hgu133plus2.db package if anntoation is based on pd.hg.u133.plus.2. Note that the probe names have additional "PM"s in the results will be removed to match the names in the gene symbol package.
  if (exists("anno_lib")) {
    if (anno_lib=="hgu133plus2.db") {tb$ID=sapply(as.character(tb$ID), remove.pm)}
  }
  tb$ID=as.character(tb$ID)
  tb$SYMBOL=sapply(as.character(tb$ID), function(x){if (x%in%names(anno_vect)){anno_vect[x]} else {"NA"}})
  tb$SYMBOL[which(tb$SYMBOL=="")]="NA"
  # remove probes with NA in logFC column
  tb <- tb[!is.na(tb$logFC),]
  tb[order(tb$P.Value),]
}
```

```{r, eval=T, echo=F, warning=F, message=F}
# install corresponding annotation database if it is not installed
anno_array=annotation(rma.data.of.interest)
cat("The platform used is", anno_array, "\n")
if (!anno_array%in%names(anno_list)) {
  cat("Annotate using GPL annotation in GEO\n")
  anno_vect=glpanno_func(GPL_ID=anno_array)
} else {
  anno_lib=anno_list[[anno_array]] # use the annotation database
  cat("The corresponding R annotation database package is", anno_lib,"\n")
  anno_vect <- ranno_func(anno_lib=anno_lib)
}
```

```{r, eval=T, echo=F}
contrast_name=infosumm_func(pheno=pheno.of.interest)$name # adopt Unique_ID created in the information summary table
contrast_fn=paste0(resdir,"/", contrast_name, ".csv")
```

```{r, eval=T, echo=F, warning=F, message=F}
contrast_table <- geneannot_func(tb=contrast_table, anno_vect=anno_vect)
write.csv(contrast_table, file=contrast_fn, row.names = FALSE)
```

```{r, eval=T, echo=F}
if (file.exists(contrast_fn)) {contrast_fn=paste0(resdir,"/", contrast_name, ".csv")}
res=read.csv(contrast_fn)
```

## Gene Expression Results Visualization

### Volcano Plots

```{r, eval=T, echo=F}
# The volplot_func function generates volcano plots
volplot_func <- function(df,qval_column,title) {
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else {          
    df <- df[!is.na(qval),] # remove NA values
    qval <- df[,qval_column]
    if (min(df[,qval_column])>=0.05) {
      df$sig <- "black" # assign colors to DE and non-DE genes
    } else {
      # assign colors to DE and non-DE genes
      df$sig <- rep(NA,nrow(df))
      df$sig[qval<0.05] <- "red"
      df$sig[qval>=0.05] <- "black"
    }
    df$sig <- as.factor(df$sig)
    color <- levels(df$sig)
    # log10 transformed q values
    df$logqval <- -log10(qval)
    diffgenes <- df$ID[qval<0.05] #Create list of all DEG's
    signum = paste0(length(diffgenes), " significant genes based on ", qval_column)
    if (missing(title)) {title=signum}
    print(
    ggplot(df, aes(x = logFC, y = logqval, color=sig)) + geom_point() +
      theme_bw() +
      labs(title=title,x="logFC",y=paste0("-log10(",qval_column,")")) +
      scale_color_manual(values=color) +
      theme(legend.position="none")
    )
  }
}
```

Volcano plot (probes with a q-value <0.05 are present in red)

```{r, eval=T, echo=F, fig.height=4, fig.width=4.5}
for (qval in c("adj.P.Val","qValuesBatch")) {volplot_func(res, qval)}
```


### Histograms

```{r, eval=T, echo=F}
# The histplot_func function generates histogram for p-value distributions
histplot_func <- function(df,qval_column,title) {
  if (missing(title)) {title=""}
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else{hist(qval,main=title,xlab=qval_column)}
}
```

Histograms of p-value distributions

```{r, eval=T, echo=F, fig.width=4.5, fig.height=4}
for (pval in c("P.Value","pValuesBatch")) {histplot_func(res, pval)}
for (qval in c("adj.P.Val","qValuesBatch")) {histplot_func(res, qval)}
```

### Top 20 Differentially Expression Results

```{r, eval=T, echo=F}
# The datreform_func function reformats the DE table
datreform_func <- function(dt,topnum=200) {
  dt=dt[order(dt$P.Value),]
  dt=dt[1:topnum,]
  round2 <- function(x){round(x,2)}
  dt[,c("logFC","AveExpr","t","B")] <- sapply(dt[,c("logFC","AveExpr","t","B")],round2)
  sciform <- function(x){format(x,scientific=TRUE,digits =2)}
  dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")] <- sapply(dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")],sciform)
  dt
}
```

Show top 20 probes sorted by un-adjusted p-values

```{r, eval=T, echo=F, results="asis"}
res <- datreform_func(dt=res)
rownames(res) <- NULL
pandoc.table(res[1:20,],split.tables=Inf)
```

### Boxplots for Top 6 Differentially Expressed Genes

This step helps to visualize and check the effect direction in the comparison.

```{r, eval=T, echo=F}
# function for top gene boxplot
topgene_boxplot_func <- function(tb,colour,comp) { # comp: comparison status
  for (i in 1:nrow(tb)) {# top i probe in res
    if (missing(comp)) {comp=""}
    if (missing(colour)) {colour=colours[1]}
    probe_top <- tb$ID[i]
    gene_top <- tb$SYMBOL[i]
    row.names(rma.data.of.interest) <- gsub("_PM","",row.names(rma.data.of.interest))
    values=exprs(rma.data.of.interest)[row.names(rma.data.of.interest)%in%probe_top, ]
    status=rma.data.of.interest$Status
    df <- data.frame(values=values,status=status)
    title=paste0(comp," top ",i," probe ", probe_top, " gene ", gene_top)
    print(
      ggplot(df,aes(x=status,y=values)) +
        geom_boxplot(outlier.colour=NA,color="grey18",fill=colour) +
        stat_boxplot(geom ='errorbar', color="grey18") +
        geom_jitter(size=1,position = position_jitter(width=0.3)) +
        labs(title=title) +
        theme_bw() +
        theme(legend.position="none",axis.title=element_blank())
    )
  }
}
```

```{r, eval=T, echo=F, message=F, warning=F, fig.height=4, fig.width=4.5}
topgene_boxplot_func(tb=res[1:6,])
```


### Heatmap for Top 200 Differentially Expressed Genes

```{r, eval=T, echo=F}
# The heatmap_topgene_func function for top gene heatmap plots
heatmap_topgene_func <- function(tb, topnum=200, colour_status_list, colour_status, main="") { # colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  top.rma <- rma.data.of.interest[row.names(rma.data.of.interest)%in%tb[1:topnum,"ID"],] # plot heatmap for top 200 genes
  array_name <- shortname_func(colnames(exprs(top.rma))) # shorten the sample id
  heatmap.2(na.omit(exprs(top.rma)), col=viridis(256, option="B"),
    ColSideColors=colour_status_list, # use predefined colour_status_list, assign colors to status
    labCol=array_name,labRow = "", # take out gene probe id
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow=1,cexCol=1,
    keysize=1.5,key.title=NA,key.xlab="Gene Expression Values",key.ylab="Counts",
    main=main)
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.8) # use predifined colour_status
}
```


```{r, eval=T, echo=F, fig.height=10, fig.width=12}
heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_status_list, colour_status=colour_status, main="Gene expression heatmap by comparison status")
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Gene expression heatmap by scan date")
}
```

### Heatmap for Sample Correlation

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
# The corplot_func function plots correlation between samples
corplot_func <- function(m, colour_status_list, colour_status, main="") {  # m: correlation matrix, colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  m <- cor(na.omit(m)) # compute correlation matrix
  # compute distance based on 1-correlation efficient
  dend = as.dendrogram(hclust(as.dist(1-m), method = "single"))
  ord = order.dendrogram(dend)
  array_name <- shortname_func(colnames(m)) # shorten the sample id
  # heatmap plot
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256,option="B"), ColSideColors=colour_status_list, RowSideColors=colour_status_list,
    labCol=array_name, labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.6)
}
```


```{r, eval=T, echo=F, fig.height=10, fig.width=12}
corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_status_list, colour_status=colour_status, main="Correlation heatmap by comparison status")
```

```{r, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Correlation heatmap by scan date")
}
```

### Principal Component Analysis (PCA)

```{r, eval=T, echo=F, warning=F, message=F, results="asis"}
# The pcastat_func function computes principal components
pcastat_func <- function(m) {
  # obtain original expression data
  raw.data.pca <- na.omit(apply(m,2,function(x)replace(x,is.infinite(x),NA))) # replace infinite values to NAs and omit NAs
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(oligo.data, pc, group_var, legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(oligo.data)[,group_var]
  )
  i=length(levels(pData(oligo.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(oligo.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and Donor
pca_func <- function(oligo.data, pc) {
  group_vars=c("ScanDate_Group", "Status", "Donor")
  legends=c("ScanDate_Group", "Status", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(oligo.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    pData(oligo.data)[,group_var]=as.factor(as.character(pData(oligo.data)[,group_var])) # convert to factor
    nlevel=nlevels(pData(oligo.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=10)) {
      if (group_var=="Status") {
        plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)+scale_color_manual(legend,values=colour_status,na.value="grey") # assign colour to comparison stauts
      } else {plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)}
    }
  }
  return(plot_list)
}
```

1. Compute PCs and variance explained by the first 10 PCs

```{r, eval=T, echo=F, warning=F, message=F, results="asis"}
res_pca <- pcastat_func(m=exprs(rma.data.of.interest))
pandoc.table(res_pca$tb, split.tables=Inf, caption="Variance explained")
```

2. PCA plots

```{r, eval=T, echo=F, message=F, warning=F}
plot_list=pca_func(oligo.data=rma.data.of.interest, pc=res_pca$pc)
for (i in plot_list) {print(i)}
```

## Meta-Analysis

Meta-analysis performed utilizing python and R files developed by Mengyuan Kan and run through the PMACS HPC command terminal.  Files were altered in order to run the appropriate analysis on the .csv files obtained from each differential expression analysis as described above.  Two additional .csv files containing information for each of the datasets previously analyzed were also prepared.  The files used are as follows:

csvrrds.R
meta_analysis_geneexpr.py
integration_utility.R
meta_analysis_geneexpr.R
meta_analysis_RankProd.R
study.rankprod.combine.R
mk_bsub.py
Microarray_data_infosheet_R #This is the pediatric sample information
Microarray_data_infosheet_R2 #This is the adult sample information; change name to Microarray_data_infosheet_R when preparing to run the adult meta-analysis

The output of these files was two text files containing the differentially expressed genes for the pediatric datasets (Sepsis_peds.metaranef.txt) and for the adult datasets (Sepsis_structural.metaranef.txt).  These files have also been uploaded to Gethub.

## Analysis of Results

Each of the datasets has now undergone quality control and differential gene expression analysis.  The genes which have reached a threshold of an adjusted p value of < 0.05 and a fold change of > 1.5 will now be selected. 

```{r, eval=TRUE}
Peds <- read.table("/home/bonkmp/Sepsis_peds/Sepsis_peds.metaranef.txt", header=T)
Adult <- read.table("/home/bonkmp/Sepsis_structural.metaranef.txt", header=T)
```

Returns the top 20 differentially expressed genes in the pediatric meta analysis by adjusted p value.

```{r, eval=TRUE}
head(Peds, n = 20)
```

Return the top 20 differentially expressed genes in the pediatric meta analysis by adjusted p value.

```{r, eval=TRUE}
head(Adult, n = 20)
```

Select only the genes from each dataset which met the significance threshold (adjusted p value < 0.05 and FC > 1.5)

```{r, eval=TRUE}
library(dplyr)
Peds_P <- filter(Peds, qval < 0.05)
Peds_P_FC <- filter(Peds_P, logFC < -0.585 | logFC > 0.585)
Adult_P <- filter(Adult, qval < 0.05)
Adult_P_FC <- filter(Adult_P, logFC < -0.585 | logFC > 0.585)
```

Create a dataframe of only the differentially expressed pediatric gene names and a dataframe of the differentially expressed adult genes.  Create new dataframes of the commonly expressed genes, unique pediatric expressed genes, and unique adult expressed genes.  

```{r, eval=TRUE}
Peds_genes <- select(Peds_P_FC, Gene)
Adult_genes <- select(Adult_P_FC, Gene)
Common_genes <- intersect(Peds_genes, Adult_genes)
Peds_genes_unique <- setdiff(Peds_genes, Adult_genes)
Adult_genes_unique <- setdiff(Adult_genes, Peds_genes)
```

Display the top 10 commonly expressed genes
```{r, eval=TRUE}
header(Common_genes, n = 10)
```

Display the top 10 unique pediatric expressed genes
```{r, eval=TRUE}
header(Peds_genes_unique, n = 10)
```

```{r, eval=TRUE}
header(Adult_genes_unique)
```

Export txt files of common and unique gene sets to be entered into DAVID database for functional annotation analysis.

```{r, eval=TRUE}
write.table(Peds_genes_unique, file="Peds_genes_unique.csv", sep=",")
write.table(Adult_genes_unique, file="Adult_genes_unique.csv", sep=",")
write.table(Common_genes, file="Common_genes.csv", sep=",")
```

The gene sets were then entered into DAVID.  The top 10 functional gene annotion enrichment analysis results by p-value were extracted into .csv files and displayed below.  

```{r, eval=TRUE}
Comon_DAVID <- read.csv("/home/bonkmp/Common_functional.csv", header=T) # Change pathway to file location
Peds_DAVID <- read.csv("/home/bonkmp/Peds_unique_functional", header=T) # Change pathway to file location
Adult_DAVID <- read.csv("/home/bonkmp/Adult_unique_functional", header=T) # Change pathway to file location
```

**Top Common Funtional Annotation Results**
```{r, eval=TRUE}
Common_DAVID
```

**Top Pediatric Funtional Annotation Results**
```{r, eval=TRUE}
Peds_DAVID
```

**Top Adult Funtional Annotation Results**
```{r, eval=TRUE}
Adult_DAVID
```

### Results

Since each gene expression dataset utilized the same microarray (Affymetrix Human Genome U133 Plus 2.0 array), each analysis was performed on the same 20,192 probes.  The pediatric meta-analysis identified 7,955 expressed genes.  1,798 genes were identified as differentially expressed by the threshold of adjusted p value < 0.05 and a fold change of > 1.5.  The adult meta-analysis identified 10,508 expressed genes, with 3,961 genes identified as differentially expressed.  The adult and pediatric lists of differentially expressed genes included 1,401 transcripts in common.  The unique pediatric and unique adult differentially expressed gene lists contained 397 and 2,560 transcripts, respectively.  

Functional gene annotation enrichment analysis of the shared differentially expressed gene list demonstrated significant regulation of adaptive and innate immune response, as well as T cell activation and function. The unique pediatric enrichment analysis emphasized a variety of cellular processes, including those related to active infection such as inflammatory response and viral response. The unique adult enrichment analysis displayed many cellular mechanisms and pathways related to cellular repair and division. 

The current study has several limitations. Although this is a meta-analysis, there is a lack of diversity in the study databases used. The pediatric studies are all from Hector Wong’s lab at the University of Cincinnati. Only two adult databases met the criteria for inclusion. The inclusion of two additional larger adult datasets, UK GAinS and the MARS consortium, would improve the diversity and sample sizes of the adult meta-analysis. Another limitation is the use of only effect size based integration for the meta-analyses.  One way to improve this would be to perform the meta-analyses using p-value based and effect size based integration as well, and compare the results.  The current study also has limitations associated with using microarray analysis. Microarrays are unable to detect novel transcripts and may miss transcripts with low levels of expression. The inclusion of RNA sequencing studies could help to address these limitations.

In conclusion, through the use of RAVED and previously developed meta-analysis tools, lists of differentially expressed genes unique to pediatric and adult patients as well as shared in common were able to be identified.  DAVID was utilized to perform functional gene annotation enrichment analysis.  Immune system activation and T cell function were the most significant pathways regulated in the common gene set.  In the adult gene set, an emphasis on cellular repair and division was found.  One potential explanation for these findings in the adult meta-analysis is the potential higher prevalence of comorbidities and the result of aging in the adult patient population.  Further evaluation, including meta-analysess with more diverse datasets and additional forms of data integration, will need to be performed to evaluate these findings further.

# References

1. Van der Poll T, van de Veerdonk FL, Scicluna BP, &amp; Netea MG. The immunopathology of sepsis
and potential therapeutic targets. Nat Rev Immunol 2017;17:407-420.
2. Rhee C, Dantes R, Epstein L, et al. Incidence and trends of sepsis in US hospitals using clinical vs
claims data, 2009-2014. JAMA 2017;18(13):1241-1249.
