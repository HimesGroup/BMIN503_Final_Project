---
title: "Blood Cultures Utilization at HUP"
author: "Annie Chen"
output: 
  html_document:
    self_contained: no
    toc: false 
    depth: 3 
    theme: paper 
    highlight: tango
---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 400)
```  
***
Use this template to complete your project throughout the course. Your Final Project presentation in class will be based on the contents of this document. Replace the title/name and text below with your own, but leave the headers.

### Overview
In this section, give a brief a description of your project and its goal, what data you are using to complete it, and what three faculty/staff in different fields you have spoken to about your project with a brief summary of what you learned from each person. Include a link to your final project GitHub repository.

The goal of my project is to characterize the use and effectiveness of blood cultures for detecting bloodstream infections in patients at the Hospital for the University of Pennsylvania (HUP). I will be using data from monthly reports of blood cultures at HUP for FY2015.

### Introduction 
In the first paragraph, describe the problem addressed, its significance, and some background to motivate the problem.

In the second paragraph, explain why your problem is interdisciplinary, what fields can contribute to its understanding, and incorporate background related to what you learned from meeting with faculty/staff.

Blood cultures are frequently used and are important for detecting the presence of microbes in the bloodstream. However, excessive use of blood cultures can be detrimental to patients and may not significantly contribute to patient care. Furthermore, there are different guidelines for blood culture utilization, and it is unclear to what extent health professionals are aware of these guidelines. Investigating blood culture utilization is critical for improving the practice of blood cultures, their effectiveness in detecting bloodstream infections, and patient care management. In addition, analyzing blood cultures data may reveal information on the frequency of false positives due to contamination and the prevalence of bacteremia in different patient populations. In addiiton, analysis of blood cultures utilization data may result in the dentification of low-risk populations for bacteremia, which may will help reduce unnecessary use of blood cultures. Finally, analysis of high-utilizers of blood cultures may also be useful for addressing the practice of blood cultures utilization.

This is an interdisciplinary problem that draws knowledge from data science, clinical microbiology, statistics, and data visualization. I have been working with Dr. Irv Nachamkin, Director of the Divison of Laboratory Medicine at HUP. He has helped direct me to relevant analyses based on his domain knowledge of clinical microbiology. I met with Dr. Rebecca Hubbard, Associate Professor of Biostatistics, to discuss statistical analyses and data visualization. She suggested focusing on the upper tail of my distributions, and she suggested conducting an ANOVA to get a composite p-value for the independent variable of interest. She also suggested making a binary outcome variable to run logistic regressions. In my meeting with Dr. Randy Olson, Senior Data Scientist at IBI, he suggested making a heat map to look at the blood cultures utilization of high utilizers over time. He also suggested doing some category compression to cut down on the number of levels in my variables. He also suggested making violin plots, since traditional boxplots hide the shape of the data. I also met with Dr. Haochang Shou, Assistant Professor of Biostatistics, who gave me advice on dealing with repeated measures and longitudinality. She also gave some suggestions for building longitudinal models.



### Methods
In the first paragraph, describe the data used and general methodological approach. Subsequently, incorporate full R code necessary to retrieve and clean data, and perform analysis. Be sure to include a description of code so that others (including your future self) can understand what you are doing and why. 

I will be using monthly reports of blood cultures utilization at HUP for FY2015. This is a record that includes information for each patient who had blood drawn for a blood culture test. The report shows the number of sets of blood cultures taken per day, the location by hospital floor, whether a phlebotomist drew the culture, and the final result (ex. no growth or the name of the microbial species isolated). 

I will first use descriptive statistics to look at the distribution of sets of blood cultures taken per patient and by hospital floor. I will also look at the distribution of pathogens isolated. Then, I will analyze the number of follow-up cultures taken after a positive identification to test the hypothesis that the number of sets of blood cultures taken is linked to the organism identified. I will also analyze the high utilizers to see what floors they are coming from and whether there is an association.

```{r Load libraries and read in data}
library(ggplot2)
library(dplyr)
library(magrittr)
library(gdata)
library(lubridate)

getwd()
inFile <- "FY15_deidentified_data-2015-11-22-revised.txt"
FY15_deID <- read.table(inFile,header=T, sep="\t", quote="",na.strings="")

str(FY15_deID)

#change Study_ID from integers to factors
FY15_deID$Study_ID <- factor(FY15_deID$Study_ID)

sum(complete.cases(FY15_deID))
#11 not complete cases. 8 have abnormal results (ex. test reordered). 2 are missing location.
#View(FY15_deID[!complete.cases(FY15_deID),])
#1 is aerobic gram pos rods not listeria. Final_report should be "GPR NLIS".

FY15_deID[10875,"Final_Report"] <- "GPR NLIS"

#only use complete cases in analyses. 45757 cases
FY15_deIDcomplete <- FY15_deID[complete.cases(FY15_deID),]

#change Julian date so that day 1 is July 1st.
FY15_deIDcomplete %<>%
  mutate(Julian = ifelse(Julian >=182,Julian-181,Julian+184))

#sort by Study_ID and then Julian so that it's in chronological order for each patient
FY15_deIDcomplete %<>% arrange(Study_ID,Julian)

length(unique(FY15_deIDcomplete$Final_Report)) #168 (167 for FY15_deIDcomplete)
length(unique(FY15_deIDcomplete$Isolate)) #173 (only 165 for FY15_deIDcomplete)

#clean up entries for results on pathogen identification
cultures <- FY15_deIDcomplete %>%
  filter(!is.na(Final_Report)) %>%
  filter(Final_Report != "Dead") %>%
  filter(Final_Report != "See C A-BC") %>%
  filter(Final_Report != "See C-NBC") %>%
  filter(Final_Report != "Corr Rpt") %>%
  filter(Final_Report != "Dup")

length(unique(cultures$Final_Report)) #162

length(unique(cultures$Isolate)) #160. Bacspe and Bacil are both abbreviations for "Bacillus species". Nicrospe and Micro are both abbreviations for "Micrococcus species".
x = 1:162
d <- data.frame(x,unique(factor(cultures$Final_Report)))
#write.table(d,"finalreportvalues.txt",sep="\t")

x = 1:160
d <- data.frame(x,unique(factor(cultures$Isolate)))
#write.table(d,"isolate.txt",sep="\t")

x=1:173
d <- data.frame(x,unique(factor(FY15_deID$Isolate)))
#write.table(d,"orig_isolate.txt",sep="\t")

#Group certain species together based on Irv's suggestions
cultures$Final_Report[cultures$Final_Report=="MRSA"] <- "SA"
cultures$Final_Report[cultures$Final_Report=="Acispe" || cultures$Final_Report=="Actodo" || cultures$Final_Report=="Actspe"] <- "Actinomy"
cultures$Final_Report[cultures$Final_Report=="Bacfra"] <- "BacfraG"
cultures$Final_Report[cultures$Final_Report=="Bacil"] <- "Bacspe"
cultures$Final_Report[cultures$Final_Report=="Gorspu"] <- "Gordo"
cultures$Final_Report[cultures$Final_Report=="Kocrhizo"] <- "Kochrizo"
cultures$Final_Report[cultures$Final_Report=="SalGD" || cultures$Final_Report=="SalspD"] <- "Salmo"
cultures$Final_Report[cultures$Final_Report=="Stahomhom"] <- "Stahom"
cultures$Final_Report[cultures$Final_Report=="Staintergp"] <- "Staint"
cultures$Final_Report[cultures$Final_Report=="Strsalsal"] <- "Strsal"
cultures$Final_Report[cultures$Final_Report=="Triasa"] <- "Trichosp"
cultures$Final_Report[cultures$Final_Report=="Veill"] <- "Veillspe"

length(unique(cultures$Final_Report)) #152

```


### Results
Describe your results and include relevant tables, plots, and code/comments used to obtain them. End with a brief conclusion of your findings related to the question you set out to address. You can include references if you'd like, but this is not required.

I am first looking at the overall distribution of number of blood cultures taken per patient and by location. This is a highly skewed distribution. Of 45,767 sets of blood cultures taken in FY2015, there were 11,737 different patients (based on MRN). I will be using the 45,757 complete cases (11,735 patients) for subsequent analyses. The number of sets taken ranged from 1 to 90, with a median of 2 and a mean of 3.899 sets. The number of days in between sets ranged from 0 to 364, with a median of 0 and a mean of 30.82. This is because some patients had multiple hospital visits within FY2015. Of 125 locations where patients had blood cultures taken in FY2015, the number of sets ranged from 1 to 4531, with a median of 17 and a mean of 366.1.

```{r Descriptive statistics on entire dataset}
#gives the number of sets of bc/patient and the period of time during which blood cultures were taken during the year.
by_ID <- FY15_deIDcomplete %>%
  group_by(Study_ID) %>%
  summarise(count=n(),
            Range=diff(range(Julian))) %>%
  arrange(desc(count))

nrow(by_ID)
head(by_ID)

summary(by_ID$count)
summary(by_ID$Range)

fig1 <- ggplot(by_ID, aes(x=count)) +
  geom_histogram(binwidth=1) +
  theme_bw() +
  theme(text=element_text(size=14)) +
  scale_y_continuous(expand=c(0,0)) +
  scale_x_continuous(expand=c(0,0)) +
  labs(x="Number of blood cultures/patient", y="Count",
       title="Total number of sets taken per patient") +
  geom_vline(xintercept=median(by_ID$count),colour="red")

ggsave(file="Figures/fig1-freqdist.pdf",plot=fig1)

by_IDtop <- by_ID %>%
  filter(count>=quantile(count,0.99))

ggplot(by_IDtop, aes(x=count)) +
  geom_histogram(binwidth=1) +
  theme_bw() + 
  scale_y_continuous(expand=c(0,0)) +
  scale_x_continuous(expand=c(0,0)) +
  labs(x="Number of blood cultures/patient", y="Count",
       title="Total number of sets for patients with at least 20 sets") +
  geom_vline(xintercept=median(by_ID20$count),colour="red")

#Look at the distribution of total # of bc by location
by_loc <- FY15_deIDcomplete %>%
  filter(!is.na(Location)) %>%
  group_by(Location,Study_ID) %>%
  summarise(count=n()) %>%
  arrange(Location)

#use n() to count number of rows for each Location
by_loc_avg <- by_loc %>%
  group_by(Location) %>%
  summarise(avg=sum(count)/n())

nrow(by_loc)
head(by_loc)
summary(by_loc$count)

fig2 <- ggplot(by_loc, aes(reorder(Location,-count),count)) +
  geom_boxplot() +
  theme_bw() + 
  theme(panel.grid.major=element_line(colour="gray")) +
  theme(text=element_text(size=14),
        axis.text.x = element_text(colour="black",angle=90, hjust=1)) +
  scale_y_continuous(expand=c(0,0),limit=c(0,80)) +
  labs(x="Location", 
       y="Number of sets/patient")
ggsave(file="Figures/fig2-freqdistloc.pdf",plot=fig2,width=8,height=6)


#frequency distribution by Julian day
by_day <- FY15_deIDcomplete %>%
  group_by(Julian) %>%
  summarise(count=n())
by_day$Julian <- as.factor(by_day$Julian)

summary(by_day$count)

#sets taken seem to be evenly spread out throughout the year
ggplot(by_day,aes(Julian,count)) +
  geom_bar(stat="identity") +
  theme_bw() + 
  theme(panel.grid.major=element_line(colour="gray")) +
  theme(text=element_text(size=14),
        axis.text.x = element_blank()) +
  scale_y_continuous(expand=c(0,0),limit=c(0,200)) +
  labs(x="Julian day", 
       y="Number of sets")

#rate of blood drawn by phlebotomist. 19079/(26678+19079)=41.7%
table(FY15_deIDcomplete$Phleb)
```

Since we don't have information on the length of each patient's hospital encounter, I will split the bc into 30-day periods, which is a reasonable amount of time to clear an infection and probably accounts for the duration of most hospital stays. After splitting into 30-day periods, the number of bc taken ranged from 1 to 52, with a median of 2 and a mean of 3.084.

```{r Split # of bc per patient into 30d periods}
by_Jul <- FY15_deIDcomplete %>%
  group_by(Study_ID,Julian,Location) %>%
  summarise(num_set=n()) 

by_Jul <- droplevels(by_Jul)

subsets <- split(by_Jul,by_Jul$Study_ID)

#for each Study_ID, count the number of sets in 30d periods
split30days <- function(df){
  c <- cumsum(diff(df$Julian))
  ref=1 #ref index for counting 30day periods
  max=30 #30days from ref. initial max would be 30
  vec = rep(0,length(c))
  g=0
  if (length(c)>=1){
     for (i in 1:length(c)){
       if (c[i]<=max) {
         vec[i] = g
         } else {
           ref=i+1 #set reference for next 30day period
           max=c[i]+30 #next 30day period
           g = g+1
           vec[i]=g
         }
     }
  }
  df$group_30 <- 1+c(0,vec)
  return(df)
}
#test <- subsets[4080:4085]
#get error because Study_ID 4085 is not there. the location was missing so I removed it but somehow R still thinks this is one of the levels for Study_ID. Use droplevels() to drop factor levels in a subsetted data frame
bc_30d <- lapply(subsets,split30days)
bc_30d <- as.data.frame(do.call("rbind",bc_30d)) 
bc_30d %<>%
  arrange(Study_ID,Julian)
bc_30d$group_30 <- as.factor(bc_30d$group_30)

#look at distribution of bc for patients after splitting up into 30d periods
bc_30d_ID <- bc_30d %>%
  group_by(Study_ID,group_30) %>%
  summarise(count=sum(num_set),
            Range=diff(range(Julian))) %>%
  arrange(desc(count))

summary(bc_30d_ID$count)
quantile(bc_30d_ID$count,c(.1,.2,.3,.4,.5,.6,.7,.8,.95))

ggplot(bc_30d_ID, aes(x=count)) +
  geom_histogram(binwidth=1) +
  theme_bw() + 
  scale_y_continuous(expand=c(0,0)) +
  scale_x_continuous(expand=c(0,0)) +
  labs(x="Number of sets of blood cultures per patient", y="Count",
       title="Distriution of sets taken per patient within a 30d period") +
  geom_vline(xintercept=median(bc_30d_ID$count),colour="red")

bc_30d_ID20 <- bc_30d_ID %>%
  filter(count>=20) %>%
  arrange(Study_ID)

ggplot(bc_30d_ID20, aes(x=count)) +
  geom_histogram(binwidth=1) +
  theme_bw() + 
  scale_y_continuous(expand=c(0,0)) +
  scale_x_continuous(expand=c(0,0)) +
  labs(x="Number of sets of blood cultures/patient", y="Count",
       title="Distribution of sets taken for patients with at least 20 sets within a 30d period") +
  geom_vline(xintercept=median(bc_30d_ID20$count),colour="red")

by_Jul_isolate <- cultures %>%
  group_by(Study_ID,Julian,Location,Final_Report) %>%
  summarise(num_set=n()) 

by_Jul_isolate <- droplevels(by_Jul_isolate)

subsets_isolate <- split(by_Jul_isolate,by_Jul_isolate$Study_ID)

bc_30d_isolate <- lapply(subsets_isolate,split30days)
bc_30d_isolate <- as.data.frame(do.call("rbind",bc_30d_isolate)) 
bc_30d_isolate %<>%
  arrange(Study_ID,Julian)

by_loc_isolate <- bc_30d_isolate %>%
  filter(!is.na(Location)) %>%
  group_by(Location,Study_ID,group_30) %>%
  summarise(count=sum(num_set)) %>%
  arrange(desc(count))

by_loc_avg_isolate <- by_loc_isolate %>%
  group_by(Location) %>%
  summarise(min=min(count),
            avg=sum(count)/n(),
            max=max(count))

#freq dist of sets/patient in a 30d period by location
ggplot(by_loc_isolate,aes(reorder(Location,-count),count)) +
  geom_boxplot() +
  theme_bw() +
  theme(panel.grid.major=element_line(colour="gray")) +
  theme(axis.text.x = element_text(colour="black",angle=90, hjust=1)) +
  scale_y_continuous(expand=c(0,0)) +
  labs(x="Location", 
       y="Number of sets of blood cultures per patient in a 30-day period",
       title="Distribution of sets/patient in a 30-day period by location")

```


Next, I will characterize the rate of contamination and of positive identification. I will also look at the distribution of pathogens isolated.

Of 45,767 sets taken, there are 45,752 sets included in this analysis after cleaning up the data. 426 sets were contaminated, which gives a contamination rate of 0.93%. 3,484 cultures yielded a positive identification, which gives a rate of 7.6%. There were 151 different pathogens identified (after grouping some species). The number of times a pathogen was identified ranged from 1 to 763, with a median of 3 and a mean of 22.65.

```{r Descriptive statistics on isolation of pathogens}
#Look at the frequency of contamination and of positive identification. Look at distribution of pathogens isolated.
#I will be using the dataframe cultures, since that has been cleaned up. I will be using the Final_Report column for ease of readability, since this contains abbreviations of the isolates, and some of the species have been grouped together for ease of analysis.
table(cultures$Contam)

#rate of contam is 426/(45324+426)=0.93%

#rate of positive identification. 7.6%
sum(cultures$Final_Report!="Ng")/length(cultures$Final_Report)

#df of positive cultures only that are not contamination
cultures.pos <- cultures %>%
  filter(Final_Report!="Ng") %>%
  filter(Contam=="no")

#135 unique cultures
length(unique(cultures.pos$Final_Report))

#lump sum of sets where a pathogen was identified
by_isolate <- cultures.pos %>%
  group_by(Final_Report) %>%
  summarise(count=n()) %>%
  arrange(desc(count))

head(by_isolate$count)
summary(by_isolate$count)

fig3 <- ggplot(by_isolate,aes(reorder(Final_Report,-count),count)) +
  geom_bar(stat="identity") +
  theme_bw() +
  theme(text=element_text(size=14),
        axis.text.x = element_text(colour="black",angle=90, hjust=1)) +
  scale_y_continuous(expand=c(0,0),limits = c(0,800)) +
  scale_x_discrete(expand=c(0,0)) +
  labs(x="Isolate", y="Count") +
  geom_vline(xintercept=median(by_isolate$count),colour="red")

ggsave(file="Figures/fig3-freqdistpath.pdf",plot=fig3,width=8,height=6)


#count number of pathogens by Study_ID and Julian to parse out repeated measures
isolate_perIDday <- cultures.pos %>%
  group_by(Study_ID, Julian, Final_Report) %>%
  summarise(count=n()) %>%
  arrange(desc(count))

isolate <- isolate_perIDday %>%
  group_by(Final_Report) %>%
  summarise(count=n())

ggplot(isolate,aes(reorder(Final_Report,-count),count)) +
  geom_bar(stat="identity") +
  theme_bw() +
  theme(text=element_text(size=14),
        axis.text.x = element_text(colour="black",angle=90, hjust=1)) +
  scale_y_continuous(expand=c(0,0),limits = c(0,600)) +
  scale_x_discrete(expand=c(0,0)) +
  labs(x="Isolate", y="Count") +
  geom_vline(xintercept=median(isolate$count),colour="red")


hist(isolate$count,breaks=100)
quantile(isolate$count,c(0.1,.2,.3,.4,.5,.6,.7,.8,.9)) 
#only 14 pathogens in top 10th percentile

barplot(prop.table(table(isolate_perIDday$Final_Report)))

#geom_histogram is for continuous data, geom_bar is for discrete data
ggplot(by_isolate, aes(reorder(Final_Report,-count),count)) +
  geom_bar(stat="identity") +
  theme_bw() + 
  scale_y_continuous(expand=c(0,0)) +
  theme(text=element_text(size=10),
        axis.text.x = element_text(colour="black",
                                   angle=90,hjust=1)) +
  labs(x="Isolate", 
       y="Count",
       title="Frequency distribution of pathogen identification") +
  geom_vline(xintercept=median(by_isolate$count),colour="red")

#only 20 pathogens were isolated at least 20 times.
by_isolate20 <- by_isolate %>%
  filter(count>=20)

ggplot(by_isolate20, aes(reorder(Final_Report,-count),count)) +
  geom_bar(stat="identity") +
  theme_bw() + 
  scale_y_continuous(expand=c(0,0)) +
  theme(text=element_text(size=10),
        axis.text.x = element_text(colour="black",
                                   angle=90,hjust=1)) +
  labs(x="Isolate", 
       y="Count",
       title="Pathogens that were isolated at least 20 times") +
  geom_vline(xintercept=median(by_isolate20$count),colour="red")



```



```{r Look at number of bc after positive identification}
cultures.pos.loc <- cultures.pos %>%
  group_by(Study_ID,Julian,Location,Final_Report) %>%
  summarise(count=n()) %>%
  ungroup()

cultures.pos.loc <- droplevels(cultures.pos.loc)

cultures.pos.loc_subsets <- split(cultures.pos.loc,
                                  cultures.pos.loc$Study_ID)

#use split30days to group sets taken within 30d of each other

cultures.pos.loc_30d <- lapply(cultures.pos.loc_subsets,split30days)
cultures.pos.loc_30d <- as.data.frame(do.call("rbind",cultures.pos.loc_30d))
cultures.pos.loc_30d %<>%
  arrange(Study_ID,Julian)

#get full record of bc taken for the Study_ID's with pos ID
bc_30d_posID <- bc_30d %>%
  filter(Study_ID %in% cultures.pos.loc_30d$Study_ID)

bc_30d_posID <- droplevels(bc_30d_posID)

for (i in 1:nrow(cultures.pos.loc_30d)){
  #subset by_Jul_posID so I only get the rows associated with Study_ID for the i-th row
  x<-bc_30d_posID[bc_30d_posID$Study_ID==cultures.pos.loc_30d[i,"Study_ID"],]
  #get Julian date associated with pos ID
  date <- cultures.pos.loc_30d[i,"Julian"]
  #get group associated with the Julian date assoc with pos ID
  #get rows where Julian dates are greater than the specified Julian date within the grouping made by splitDates
  y <- x[x$Julian>date,]
  g <- x[x$Julian==date,"group_30"][1] #there are multiple entries if it's polymicrobial but the group should be the same
  z <- y[y$group_30==g,]
  #add up the number of bc taken during that period
  s <- sum(z$num_set)
  #want to keep track of no follow-up's too.
  if (nrow(z)==0) {
    s <- 0
    days <- 0
  }
  days <- nrow(z)
  cultures.pos.loc_30d[i,"num_set_postPosID"] <- s
  cultures.pos.loc_30d[i,"num_days_postPosID"] <- days
}
#test <- culturesbyLoc_30d[1:6,]


#make new df so I see number of cultures after 1st pos ID within a 30d period rather than for each subsequent day.
cultures.pos.loc_30d_subsets <- split(cultures.pos.loc_30d,
                                   cultures.pos.loc_30d$Study_ID)


getFollowUpSets <- function(df){
  #make sure data is sorted by Study_ID and Julian day
  df %<>% arrange(Study_ID,Julian)
  df_sub <- split(df,df$group_30)
  df_sub <- lapply(df_sub,function(df){
    minDate <- min(df$Julian)
    return(df[df$Julian==minDate,]) #get row with min Julian date for that grouping
    #may be 2 rows if there was a polymicrobial infection
  })
  newDF <- as.data.frame(do.call("rbind",df_sub))
  return(newDF)
}

numFollowUpCultures <- lapply(cultures.pos.loc_30d_subsets,
                              getFollowUpSets)
numFollowUpCultures <- as.data.frame(do.call("rbind",numFollowUpCultures)) 
numFollowUpCultures %<>%
  arrange(Study_ID,Julian)


#test whether number of follow-up cultures is linked to pathogen identified.
numCulturesbyOrg <- numFollowUpCultures %>%
  group_by(Final_Report) %>%
  summarise(min=min(num_set_postPosID),
            avg=mean(num_set_postPosID),
            max=max(num_set_postPosID),
            sd=sd(num_set_postPosID))

fit_bc <- glm(num_set_postPosID ~ Final_Report + Location,data=numFollowUpCultures)
summary(fit_bc)


fit_isolate <- aov(num_set_postPosID ~ Final_Report,
                   data=numFollowUpCultures)
summary(fit_isolate)

#look at avg # follow-up cultures based on pathogen
ggplot(numFollowUpCultures,aes(reorder(Final_Report,-num_set_postPosID),num_set_postPosID)) +
  geom_boxplot() +
  theme_bw() +
  theme(text=element_text(size=10),
        axis.text.x = element_text(colour="black",
                                   angle=90,hjust=1)) +
  labs(x="Isolate", 
       y="Number of follow-up cultures",
       title="Distribution of follow-up cultures by isolate")

fit_loc <- glm(count ~ Location,data=by_loc)
summary(fit_loc)

fit_loc_aov <- aov(count ~ Location,data=by_loc)
summary(fit_loc_aov)


#Characterize distribution of follow-up sets
qplot(data=numFollowUpCultures,y=num_set_postPosID)
summary(numFollowUpCultures$num_set_postPosID)
summary(numFollowUpCultures$num_days_postPosID)
quantile(numFollowUpCultures$num_set_postPosID,.9) #11
quantile(numFollowUpCultures$num_days_postPosID,.9) #7

#Distribution of follow-up days and sets
pdf("Figures/fig4a-followupsets.pdf")
hist(numFollowUpCultures$num_set_postPosID,breaks=100,xlab="Number of follow-up sets",
     ylab="Count",main="Number of follow-up sets")
dev.off()

pdf("Figures/fig4b-followupdays.pdf")
hist(numFollowUpCultures$num_days_postPosID,breaks=30,xlab="Number of follow-up days",
     ylab="Count",main="Number of follow-up days")
dev.off()

#make binary variable for num follow-up sets and days: 
mean(numFollowUpCultures$num_set_postPosID)
numFollowUpCultures %<>%
  mutate(highSets = factor(ifelse(num_set_postPosID<11,0,1),levels=c(0,1),labels=c("low","high")),
         highDays = factor(ifelse(num_days_postPosID<7,0,1),levels=c(0,1),labels=c("low","high")))
```


```{r Category compression}
#63 levels for Location, 128 levels for Final_Report
#do some data compression
nLoc <- numFollowUpCultures %>%
  group_by(Location) %>%
  summarise(num=n()) %>%
  arrange(desc(num))

hist(nLoc$num,breaks=50)
summary(nLoc$num)
quantile(nLoc$num,.75)

nLoc_top <- nLoc %>%
  slice(1:16) #take top 25%

topLocNames <- droplevels(nLoc_top$Location)

nLoc_top <- numFollowUpCultures %>%
  filter(numFollowUpCultures$Location %in% nLoc_top$Location)
nLoc_top <- droplevels(nLoc_top)

other <- numFollowUpCultures %>%
  filter(!(numFollowUpCultures$Location %in% nLoc_top$Location))
other <- droplevels(other)
#combine levels
levels(other$Location) <- rep("Other",nlevels(other$Location))

nLoc_top <- rbind(nLoc_top,other)

nLoc_top %<>%
  mutate(sqrt_sets = sqrt(num_set_postPosID),
         sqrt_days = sqrt(num_days_postPosID))

fig5a <- ggplot(nLoc_top,aes(reorder(Location,-num_set_postPosID),num_set_postPosID)) +
  #geom_jitter(width=0.3) +
  geom_violin() +
 # geom_boxplot() +
  theme_bw() +
  theme(text=element_text(size=10),
        axis.text.x = element_text(colour="black",angle=90,hjust=1),
        axis.line = element_line(0.75)) +
  labs(x="Location", 
       y="Number of follow-up sets")

ggsave(file="Figures/fig5a.pdf",plot=fig5a,width=5)

fig5b <- ggplot(nLoc_top,aes(reorder(Location,-num_days_postPosID),num_days_postPosID)) +
  #geom_jitter(width=0.1) +
  geom_violin() +
  #geom_boxplot() +
  theme_bw() +
  theme(text=element_text(size=10),
        axis.text.x = element_text(colour="black",angle=90,hjust=1),
        axis.line = element_line(0.75)) +
  labs(x="Location", 
       y="Number of days of follow-up")

ggsave(file="Figures/fig5b.pdf",plot=fig5b,width=5)

#category compression for pathogens
nPath <- numFollowUpCultures %>%
  group_by(Final_Report) %>%
  summarise(num=n()) %>%
  arrange(desc(num))

hist(nPath$num,breaks=50)
summary(nPath$num)
quantile(nPath$num,.75)

nPath_top <- nPath %>%
  arrange(desc(num)) %>%
  slice(1:30) #take top 25%

topPathNames <- droplevels(nPath_top$Final_Report)

nPath_top <- numFollowUpCultures %>%
  filter(numFollowUpCultures$Final_Report %in% nPath_top$Final_Report)
nPath_top <- droplevels(nPath_top)

other <- numFollowUpCultures %>%
  filter(!(numFollowUpCultures$Final_Report %in% nPath_top$Final_Report))
#combine levels
levels(other$Final_Report) <- rep("Other",nlevels(other$Final_Report))

nPath_top <- rbind(nPath_top,other)

fig6a <- ggplot(nPath_top,aes(reorder(Final_Report,-num_set_postPosID),num_set_postPosID)) +
  #geom_jitter(width=0.3) +
  #geom_violin() +
  geom_boxplot() +
  theme_bw() +
  theme(text=element_text(size=10),
        axis.text.x = element_text(colour="black",angle=45,hjust=1),
        axis.line = element_line(0.75)) +
  labs(x="Isolate", 
       y="Number of follow-up sets")
ggsave(file="Figures/fig6a.pdf",plot=fig6a,width=5)

fig6b <- ggplot(nPath_top,aes(reorder(Final_Report,-num_days_postPosID),num_days_postPosID)) +
  #geom_jitter(width=0.1) +
  #geom_violin() +
  geom_boxplot() +
  theme_bw() +
  theme(text=element_text(size=10),
        axis.text.x = element_text(colour="black",angle=45,hjust=1),
        axis.line = element_line(0.75)) +
  labs(x="Isolate", 
       y="Number of days of follow-up")
ggsave(file="Figures/fig6b.pdf",plot=fig6b,width=5)

#Combined category compression for Locations and pathogens
nLocPath_top <- numFollowUpCultures %>%
  filter(Location %in% topLocNames) %>%
  filter(Final_Report %in% topPathNames)
nLocPath_top <- droplevels(nLocPath_top)

```


Objective: Conduct statistical tests to determine whether follow-up is associated wtih the pathogen identified or hospital location.
```{r Statistical Tests}
#1. Number of follow up sets ~ Location (all)
#should I run a linear regression?
#no significant results
lm_loc <- lm(num_set_postPosID ~ Location,data=numFollowUpCultures)
summary(lm_loc)

#Hosmer Lemeshow goodness of fit test
library(ResourceSelection)
hoslem.test(numFollowUpCultures$num_set_postPosID,fitted(lm_loc))

aov_loc <- aov(num_set_postPosID ~ Location,data=numFollowUpCultures)
summary(aov_loc)

#2. Number of follow up sets ~ Location (compressed)
#MICA, RP3, RP6, RP7, S10 significant when there's only 10
#S10 is the only significant one. D6S was missing in summary. I always get n-1 locations in the summary...
#number of locations that are significant differs depending on the number I include.
#R-squared value is really low
lm_loc <- lm(num_set_postPosID ~ Location,data=nLoc_top)
summary(lm_loc)

aov_loc <- aov(num_set_postPosID ~ Location,data=nLoc_top)
summary(aov_loc)

#3. number of follow up days ~ Location
#Location S4S Silver 4 is significant
fit_loc <- lm(num_days_postPosID ~ Location,data=numFollowUpCultures)
summary(fit_loc)

#4. number of follow up days ~ Location (compressed)
#S10, RP6 significant. R-squared value is really low
fit_loc <- lm(num_days_postPosID ~ Location,data=nLoc_top)
summary(fit_loc)

#5. binary outcome low/high number of follow up sets ~ Location (compressed)
#PCH2 HemOnc2, RP6, RP7, S10 significant. 
#Only S10 is significant when aboveAverage is changed to >=11 (90th percentile)
fit_loc <- glm(highSets ~ Location,nLoc_top,family="binomial")
summary(fit_loc)
#goodness of fit. model fits. 
with(fit_loc, cbind(res.deviance = deviance, df = df.residual,
  p = pchisq(deviance, df.residual, lower.tail=FALSE)))

#6. binary outcome for low/high number of follow up days ~ Location (compressed)
#only S10 is significant
fit_loc <- glm(highDays ~ Location,nLoc_top,family="binomial")
summary(fit_loc)

library(randomForest)
nLoc_top.rf <- randomForest(highDays~Location, data=nLoc_top, ntree=100, importance=TRUE)
#not a good model. misclassified all of the high's.
nLoc_top.rf

#check how good the model is
glm.pred <- predict(fit_loc, nLoc_top, type="response")
#K-Fold Cross Validation
N = nrow(nLoc_top)
K = 10
set.seed(1234)
#assign each value in dataset into 1 of 10 groups
s = sample(1:K, size=N, replace=T)
#make vectors of length N
pred_outputs.glm <- vector(mode="numeric", length=N)
#pred_outputs.rf <- vector(mode="numeric", length=N)
obs_outputs <- vector(mode="numeric", length=N)
offset <- 0
#put i=1 in console then run through for loop each command at a time.
for(i in 1:K){
	train <- filter(nLoc_top, s != i) #return rows in remaining 9 groups other than those in group i
	test <- filter(nLoc_top, s == i) #test set is group i
	#put survived status for those in group i into obs_outputs.
  obs_outputs[1:length(s[s==i]) + offset] <- test$highDays
    
    #GLM train/test
	glm <- glm(highDays~Location, data=train, family=binomial(logit))
    glm.pred.curr <- predict(glm, test, type="response")
    #put predicted glm outputs into vector
    pred_outputs.glm[1:length(s[s==i]) + offset] <- glm.pred.curr

    #RF train/test
    #rf <- randomForest(survived~., data=train, ntree=100)
#	rf.pred.curr <- predict(rf, newdata=test, type="prob") #gives matrix for prediction error estimate of dying/living. want column 2 because that corresponds to the prediction error estimates for surviving.
#	pred_outputs.rf[1:length(s[s==i]) + offset] <- rf.pred.curr[,2]
  #offset by length of group i so that you add the data in the right spots in the vectors.
	offset <- offset + length(s[s==i])
}

library(pROC)
#glm.pred was the logistic regression model
plot.roc(nLoc_top$highDays, glm.pred, ci=TRUE) #Fitted logistic regression
plot.roc(obs_outputs, pred_outputs.glm, ci=TRUE, col="darkblue", add=TRUE) #Cross-validation of glm

#7. var(nLoc_top$num_set_postPosID) is 27, and mean is 4.9
var(nLoc_top$sqrt_sets)
mean(nLoc_top$sqrt_sets)
summary(m1 <- glm(sqrt_sets ~ Location, 
                    family="poisson", data=nLoc_top))
#now Poisson model is a good fit. but since I did sqrt, maybe I should just do a linear regression
with(m1, cbind(res.deviance = deviance, df = df.residual,
  p = pchisq(deviance, df.residual, lower.tail=FALSE)))
#Poisson regression
nLoc_top$Location <- relevel(nLoc_top$Location,"Other")
summary(m1 <- glm(num_set_postPosID ~ Location, 
                    family="poisson", data=nLoc_top))
#goodness of fit test for the model. if not significant, model fits well
#model does not fit well
with(m1, cbind(res.deviance = deviance, df = df.residual,
  p = pchisq(deviance, df.residual, lower.tail=FALSE)))

summary(m1 <- glm(num_days_postPosID ~ Location, 
                    family="poisson", data=nLoc_top))

library(pscl)
mp <- glm(num_days_postPosID~Location, family=poisson, data=nLoc_top)
summary(mp)
zobs <- nLoc_top$num_days_postPosID == 0
zpoi <- exp(-exp(predict(mp))) # or dpois(0,exp(predict(mp)))
c(obs=mean(zobs), poi=mean(zpoi)) #13.4% had 0 follow up days, but Poisson model only predicts 6.4%


with(nLoc_top,table(num_days_postPosID,Location))
m1 <- zeroinfl(num_days_postPosID ~ Location+Final_Report,
  data = nLoc_top,dist="negbin")
summary(m1)

#8 linear reg 
lm_loc <- lm(sqrt_sets ~ Location,data=nLoc_top)
summary(lm_loc)
```

```{r Statistical tests for association with pathogen}
#1. number of follow up sets ~ Pathogen
#Acispe, Bacova, Cankru, Cantro, Raoorn, Rhoequ, SA, SerliqStacapi, Stalug, Stawar, Sv are significant
fit_path <- lm(num_set_postPosID ~ Final_Report,data=numFollowUpCultures)
summary(fit_path)

#2. number of follow up sets ~ Pathogen (compressed)
#Cantro, SA, and Stacapi are significant
fit_path <- lm(num_set_postPosID ~ Final_Report,data=nPath_top)
summary(fit_path)

aov_path <- aov(num_set_postPosID ~ Final_Report,data=nPath_top)
summary(aov_path)

#3. number of follow-up days ~ Pathogen (comopressed)
#Cantro, Entfaeca, Entfaeci, SA, Stacapi, Staepi are significant
fit_path <- lm(num_days_postPosID ~ Final_Report,data=nPath_top)
summary(fit_path)

#4. binary outcome for follow up sets ~ Pathogen (compressed)
#nothing was significant
fit_path <- glm(highSets ~ Final_Report,data=nPath_top,family="binomial")
summary(fit_path)

#5. binary outcome for follow up days ~ Pathogen (compressed)
#nothing was significant
fit_path <- glm(highDays ~ Final_Report,data=nPath_top,family="binomial")
summary(fit_path)

```

```{r Statistical Tests to look at Location and Pathogen in same model}
#Combined category compression for Locations and pathogens
nLocPath_top <- numFollowUpCultures %>%
  filter(Location %in% topLocNames) %>%
  filter(Final_Report %in% topPathNames)
nLocPath_top <- droplevels(nLocPath_top)

other <- numFollowUpCultures %>%
  filter(!(Location %in% topLocNames) | !(Final_Report %in% topPathNames))
levels(other$Final_Report) <- rep("Other",nlevels(other$Final_Report))
levels(other$Location) <- rep("Other",nlevels(other$Location))

nLocPath_top <- rbind(nLocPath_top,other)
nLocPath_top <- droplevels(nLocPath_top)

#1. number of follow up sets ~ Location + Pathogen
fit <- glm(num_set_postPosID ~ Location + Final_Report,data=nLocPath_top)
summary(fit)

fit <- aov(num_set_postPosID ~ Location + Final_Report,data=nLocPath_top)
summary(fit)


#2. binary highDays ~ Location + Pathogen
#nothing was significant
fit <- glm(highDays ~ Location + Final_Report,data=nLocPath_top,family="binomial")
summary(fit)
confint(fit)

```

```{r Identify variables of interest in predicting high follow up}
N=ncol(numFollowUpCultures)-1
pvalues <- data.frame(colnames(numFollowUpCultures)[-1],rep(0,N))
colnames(pvalues) <- c("variable","pvalue")
for (i in 2:(ncol(numFollowUpCultures))){
  variable=numFollowUpCultures[,i]
  numFollowUpCultures.glm <- glm(numFollowUpCultures$highDays~variable,family="binomial")
  pvalues[i-1,2] <- coef(summary(numFollowUpCultures.glm))[2,4]
}

sig_pvalues <- pvalues %>%
  filter(pvalue<0.05) %>%
  arrange(pvalue)

sig_pvalues
#highSets, num_set_postPosID, count are significant
#highDays is highly correlated with highSets and num_set_postPosID
#only one of interest is count I think.


#check with compressed Location and Final_Report values
N=ncol(nLocPath_top)-1
pvalues <- data.frame(colnames(nLocPath_top)[-1],rep(0,N))
colnames(pvalues) <- c("variable","pvalue")
for (i in 2:(ncol(nLocPath_top))){
  variable=nLocPath_top[,i]
  nLocPath_top.glm <- glm(nLocPath_top$highDays~variable,family="binomial")
  pvalues[i-1,2] <- coef(summary(nLocPath_top.glm))[2,4]
}

sig_pvalues <- pvalues %>%
  filter(pvalue<0.05) %>%
  arrange(pvalue)

sig_pvalues #got same results
```


Based on a linear regression, the following pathogens are statistically significant in the model: Sv, Stawar,STACAPI, Serliq, SA, Rhoequ, Raoorn, CANTRO, Cankru, Bacova,ACISPE.

Based on  a linear regression, the following locations are statistically significant in a model for predicting number of bc in a 30-day period: MICB, RP6, RP7, SICA, SICB, SINA, SINB, SIRA, SIRB


Look at just the pathogens that were statistically significantly associated with number of follow-up cultures.
```{r Analysis of blood cultures for statistically significant pathogens }
sigIsolate <- numFollowUpCultures %>%
  filter(Final_Report=="Sv" | Final_Report=="Stawar" | Final_Report=="Stacapi" | Final_Report=="Serliq" | Final_Report=="SA" | Final_Report=="Rhoequ" | Final_Report=="Raoorn" | Final_Report=="Cantro" | Final_Report=="Cankru" | Final_Report=="Bacova" | Final_Report=="Acispe")

ggplot(sigIsolate,aes(reorder(Final_Report,-num_set_postPosID),num_set_postPosID)) +
  geom_boxplot() +
  theme_bw() +
  theme(text=element_text(size=10),
        axis.text.x = element_text(colour="black",
                                   angle=90,hjust=1)) +
  labs(x="Isolate", 
       y="Number of follow-up cultures",
       title="Distribution of follow-up cultures for significant pathogens in model")

top20 <- cultures.pos.loc_30d %>%
  filter(Final_Report %in% by_isolate20$Final_Report)

fit_top20_aov <- aov(num_set_postPosID ~ Final_Report,data=top20)
summary(fit_top20_aov)

#Only EC is statistically significant but it doesn't have the highest average or the highest max...is this giving me what I think it is??
fit_top20 <- glm(num_set_postPosID ~ Final_Report,data=top20)
summary(fit_top20)

ggplot(top20,aes(reorder(Final_Report,-num_set_postPosID),num_set_postPosID)) +
  geom_boxplot() +
  theme_bw() +
  theme(text=element_text(size=10),
        axis.text.x = element_text(colour="black",
                                   angle=90,hjust=1)) +
  labs(x="Isolate", 
       y="Number of follow-up cultures",
       title="Distribution of follow-up cultures for top 20 pathogens")


```


263 out of 11,737 patients had more than 20 blood cultures taken, which is 2.46% of the population. For this subpopulation, the number of sets taken ranged from 20 to 90, with a median of 26 and a mean of 30.86.

```{r Identify high utilisers}
hist(by_ID$count,breaks=100)
quantile(by_ID$count,c(.1,.2,.3,.4,.5,.6,.7,.8,.9,.95)) #95th percentile is 13 sets.

#get ID's for patients with more than 13 bc for FY2015
ID_highuse <- by_ID %>%
  filter(count>20)
ID_highuse <- as.data.frame(ID_highuse)

#263 patients with more than 20 bc taken.
nrow(ID_highuse)
summary(ID_highuse$count)

#subset FY15_deID by these ID's so that I have the Julian information
by_ID_highuse <- FY15_deIDcomplete[FY15_deIDcomplete$Study_ID %in% ID_highuse$Study_ID,]
  
by_ID_highuse %<>%
  group_by(Study_ID,Julian) %>%
  summarise(count=n())

#calculate number of days for high utilizers for the year
highuse_Jul <- by_ID_highuse %>%
  group_by(Study_ID) %>%
  summarise(days=n())
str(highuse_Jul)
hist(highuse_Jul$days,breaks=30)
summary(highuse_Jul$days)

#Compare followup cultures for high utilizers
hu_followup <- numFollowUpCultures %>%
  filter(numFollowUpCultures$Study_ID %in% highuse_Jul$Study_ID)
summary(hu_followup$num_set_postPosID)

#number of followup cultures is greater for high utilizers by 5 sets
t.test(hu_followup$num_set_postPosID,numFollowUpCultures$num_set_postPosID,alternative="two.sided")
plot(density(hu_followup$num_set_postPosID))
plot(density(numFollowUpCultures$num_set_postPosID))

#number of days of follow up is greater by about 2 days
t.test(hu_followup$num_days_postPosID,numFollowUpCultures$num_days_postPosID,alternative="two.sided")
plot(density(hu_followup$num_days_postPosID))
plot(density(numFollowUpCultures$num_days_postPosID))


#look at high utilizers for those with at least 20 bc in a 30day period
#use bc_30d_ID20
#108 different Study_IDs, 116 entries total.
bc_30d_ID20 <- as.data.frame(bc_30d_ID20)

List <- list()
#get entries within 30d for highuse patients
for (i in 1:nrow(bc_30d_ID20)){
  #which() gives which indices are true
  x <- bc_30d[bc_30d$Study_ID %in% bc_30d_ID20[i,"Study_ID"],]
  #get only the rows within the same 30d grouping
  y <- x[which(x[,"group_30"] %in% bc_30d_ID20[i,"group_30"]),]
  List[[i]] <- y
}

bc_30d_ID20_highuse = do.call(rbind, List)
bc_30d_ID20_highuse <- droplevels(bc_30d_ID20_highuse)

#change Julian days so it goes from 1 to 30 for each of the high utilizers
highuse_subset <- split(bc_30d_ID20_highuse,bc_30d_ID20_highuse$Study_ID)
lst <- lapply(highuse_subset,function(df){
  if(nlevels(df$group_30)>1){
    df <- droplevels(df)
    lst <- split(df,df$group_30)
    return(lst)
  }
  else return(df)
})

lst <- unlist(lst,recursive=FALSE)
normalizeDate <- function(df) {
  Jul <- df$Julian
  ref <- Jul[1]
  vec=sapply(Jul,function(x) x-ref+1)
  df$Julian <- vec
  return(df)
}
highuse <- lapply(lst,normalizeDate)
highuse <- as.data.frame(do.call("rbind",highuse)) 
highuse %<>%
  arrange(Study_ID,Julian)

#calculate number of days that blood was taken for high utilizers within 30d
highuse_Jul_30d <- highuse %>%
  group_by(Study_ID,group_30) %>%
  summarise(days=n())
str(highuse_Jul_30d)
hist(highuse_Jul_30d$days,breaks=30)
summary(highuse_Jul_30d$days)

hu_followup_30d <- numFollowUpCultures %>%
  filter(numFollowUpCultures$Study_ID %in% highuse_Jul_30d$Study_ID)
summary(hu_followup_30d$num_days_postPosID)

not_hu <- numFollowUpCultures %>%
  filter(!(numFollowUpCultures$Study_ID %in% highuse_Jul_30d$Study_ID))

v <- numFollowUpCultures$Study_ID %in% highuse_Jul_30d$Study_ID
numFollowUpCultures %<>%
  mutate(highuse=ifelse(v,"highuse","not_highuse"))

#number of followup cultures is greater for high utilizers by about 10 sets
t.test(hu_followup_30d$num_set_postPosID,not_hu$num_set_postPosID,alternative="two.sided")

fig7a <- ggplot(numFollowUpCultures,aes(highuse,
                                        num_set_postPosID)) +
  geom_boxplot() +
  theme_bw() +
  theme(text=element_text(size=14),
        axis.text.x = element_text(colour="black"),
        axis.line = element_line(0.75)) +
  labs(x="High utilizer", 
       y="Number of follow-up sets")

ggsave(file="Figures/fig7a.pdf",plot=fig7a)


#number of days of follow up is greater by about 5 days
t.test(hu_followup_30d$num_days_postPosID,numFollowUpCultures$num_days_postPosID,alternative="two.sided")

fig7b <- ggplot(numFollowUpCultures,aes(highuse,
                                        num_days_postPosID)) +
  geom_boxplot() +
  theme_bw() +
  theme(text=element_text(size=14),
        axis.text.x = element_text(colour="black"),
        axis.line = element_line(0.75)) +
  labs(x="High utilizer", 
       y="Number of days of follow-up")

ggsave(file="Figures/fig7b.pdf",plot=fig7b)


#make heatmap to look for patterns
ggplot(highuse, aes(Julian, Study_ID)) + 
  geom_tile(aes(fill = num_set),colour = "lightblue") + 
  scale_fill_gradient(low = "lightblue",high = "steelblue") +
  scale_x_continuous(expand=c(0,0),breaks=c(1:31))



#randomly sample 50 at a time
s <- sample(highuse$Study_ID,50,replace=FALSE)
df <- highuse[highuse$Study_ID %in% s,]
fig8 <- ggplot(df, aes(Julian, Study_ID,fill=num_set)) + 
  geom_tile() + 
  scale_fill_gradient(low = "#deebf7",high = "#3182bd") +
  scale_x_continuous(expand=c(0,0),breaks=c(1:31)) +
  scale_y_discrete(expand = c(0, 0))

ggsave(file="Figures/fig8.pdf",plot=fig8)

#compare to random sample of non high-utilizers
lowuse <- bc_30d_ID %>%
  filter(count<20) %>%
  arrange(Study_ID)
lowuse <- as.data.frame(lowuse)

List <- list()
#get entries within 30d for low-use patients
for (i in 1:nrow(lowuse)){
  #which() gives which indices are true
  x <- bc_30d[bc_30d$Study_ID %in% lowuse[i,"Study_ID"],]
  #get only the rows within the same 30d grouping
  y <- x[which(x[,"group_30"] %in% lowuse[i,"group_30"]),]
  List[[i]] <- y
}

lowuse = do.call(rbind, List)
lowuse <- droplevels(lowuse)

lowuse_subset <- split(lowuse,lowuse$Study_ID)
test <- lapply(lowuse_subset,function(df){
  if(nlevels(df$group_30)>1){
    df <- droplevels(df)
    lst <- split(df,df$group_30)
    return(lst)
  }
  else return(df)
})

test <- unlist(test,recursive=FALSE)
lowuse <- lapply(test,normalizeDate)
lowuse <- as.data.frame(do.call("rbind",lowuse)) 
lowuse %<>%
  arrange(Study_ID,Julian)

s <- sample(lowuse$Study_ID,50,replace=FALSE)
df <- lowuse[lowuse$Study_ID %in% s,]
fig9 <- ggplot(df, aes(Julian, Study_ID,fill=num_set)) + 
  geom_tile() + 
  scale_fill_gradient(low = "#deebf7",high = "#3182bd") +
  scale_x_continuous(expand=c(0,0),breaks=c(1:31)) +
  scale_y_discrete(expand = c(0, 0))

ggsave(file="Figures/fig9.pdf",plot=fig9)

#calculate waiting times?



#look at distribution of locations for high utilizers to determine whether they are clustered on a certain floor. Divide by the total number of patients on that floor.
#by_loc has number of patients by location
#bc_30d_ID20_highuse shows the location for each high utilizer

#get total number of patients per location
by_loc_numpat <- by_loc %>%
  group_by(Location) %>%
  summarise(num_pat=n())

#locations of high utilizers
#total count 176...
highuse_loc <- bc_30d_ID20_highuse %>%
  group_by(Location) %>%
  summarise(count=n_distinct(Study_ID,group_30))

a <- bc_30d_ID20_highuse %>%
  group_by(Study_ID,group_30) %>%
  summarise(a=n())
nrow(a) #120

b <- bc_30d_ID20 %>%
  group_by(Study_ID,group_30) %>%
  summarise(a=n())

nrow(b) #120 rows. 7 had multiple entries for group_30 (mostly 2, 1 had 3)

c <- anti_join(b,a,by=c("Study_ID","group_30"))

#calculate proportion of high utilizers/total for each location
highuse_loc <- inner_join(highuse_loc,by_loc_numpat) 
highuse_loc %<>%
  mutate(prop_highuse = count/num_pat)

ggplot(highuse_loc,aes(reorder(Location,-prop_highuse),
                       prop_highuse)) +
  geom_bar(stat="identity") +
  theme_bw() +
  theme(text=element_text(size=10),
        axis.text.x = element_text(colour="black",
                                   angle=90,hjust=1)) +
  labs(x="Location", 
       y="Propotion of high utilizers",
       title="Distribution of high utilizers") 

```

```{r Deleted code}

#I don't think this graph is informative
ggplot(by_loc, aes(x=count)) +
  geom_histogram(binwidth=1) +
  theme_bw() + 
  theme(panel.grid.major=element_line(colour="gray")) +
  theme(axis.text.x = element_text(colour="black", hjust=1)) +
  scale_y_continuous(expand=c(0,0)) +
  scale_x_continuous(expand=c(0,0)) +
  labs(x="Number of blood cultures/location", 
       y="Count",
       title="Distribution of number of sets/patient by location") +
  geom_vline(xintercept=median(by_loc$count),colour="red")


#randomly sample 10 at a time from high utilisers and plot days when bc were taken
s <- sample(by_ID_highuse$Study_ID,10,replace=F)
df <- by_ID_highuse[by_ID_highuse$Study_ID %in% s,]

ggplot(df,aes(Julian,Study_ID)) +
  theme_bw() + 
  labs(x="Julian day", 
       y="Study_ID",
       title="Sets of bc taken per day for high utilizers") +
  geom_point(aes(alpha=count)) +
  scale_x_continuous(breaks=c(0,50,100,150,200,250,300,350,400))


fit_loc <- glm(num_set_postPosID ~ Location,data=nLoc_10)
summary(fit_loc)

fit_loc_aov <- aov(num_set_postPosID ~ Location,data=nLoc_10)
summary(fit_loc_aov)


fit_loc <- glm((aboveAverage=="high") ~ Location,data=numFollowUpCultures,family="binomial")
summary(fit_loc) #none of the locations are significant



#why does this give me a significant result??
chisq.test(table(loc=numFollowUpCultures$Location,followUp=numFollowUpCultures$aboveAverage))

ggplot(numFollowUpCultures,aes(Location)) +
  geom_bar(aes(fill=aboveAverage),position="dodge")

chisq.test(table(loc=nLoc_top$Location,followUp=nLoc_top$aboveAverage))

fit_loc <- glm(aboveAverage ~ Location,data=nLoc_top,family="binomial")
#RP3, RP6, RP7,S10, and Other are significant. doesn't look like it should be though.
summary(fit_loc)

ggplot(nLoc_top,aes(Location))+
  geom_bar(aes(fill=aboveAverage),position="dodge")

ggplot(nLoc_topPath,aes(Final_Report)) +
  geom_bar(aes(fill=aboveAverage),position="dodge")

fit_path <- glm((aboveAverage=="low") ~ (Final_Report=="SA"),data=nLoc_topPath,family="binomial")
summary(fit_path)
#EC is significant. I think in having lower follow-ups.

fit_path <- glm(num_set_postPosID ~ Final_Report,data=nLoc_topPath)
summary(fit_path) #SA is significant

fit_path <- glm(num_days_postPosID ~ Final_Report,data=nLoc_topPath)
summary(fit_path) #SA is even more significant

fit_path <- glm((aboveAverage=="high")~Final_Report,
                 data=nLoc_top,family="binomial")
summary(fit_path)

chisq.test(table(aboveAvg=nLoc_topPath$aboveAverage,path=nLoc_topPath$Final_Report))

#randomly sample 10 at a time from high utilisers and plot days when bc were taken
s <- sample(bc_30d_ID20_highuse$Study_ID,10,replace=F)
df <- bc_30d_ID20_highuse[bc_30d_ID20_highuse$Study_ID %in% s,]
ggplot(df,aes(Julian,Study_ID)) +
  theme_bw() +
  geom_point(aes(alpha=num_set)) +
  labs(x="Julian day", 
       y="Study_ID",
       title="Sets of bc taken within 30-day period for high utilizers") +
  scale_x_continuous(breaks=c(0,50,100,150,200,250,300,350,400))

```




