---
title: "BMIN503/EPID600 Project Template"
author: "Godefroy Chery"
output: 
  html_document:
    theme: paper 
    highlight: tango
---


***
Use this template to complete your project throughout the course. Your Final Project presentation will be based on the contents of this document. Replace the title/name above and text below with your own, but keep the headers. Feel free to change the theme and other display settings, but this is not required.

### Overview
For this project, we are seeking to determine the feasibility, diagnostic and predictive power of unstructured text data (from medical notes) to diagnose heart failure with reduced ejection fraction (HFrEF). We are using the Medical Information Mart for Intensive Care (MIMIC)-III dataset for this project. Specifically, we are seeking to determine the feasibility of extracting pertinent components of the unstructured text of medical note (e.g. discharge summary) using natural language processing (NLP) methods to assist in making a heart failure diagnosis. Secondarily, we aim to compare the diagnostic and predictic power of the unstructured text to conventional factors in making a heart failure diagnosis. 

### Introduction 
Heart failure (HF) is a progressive clinical syndrome resulting from any structural or functional cardiac disorder that impairs ability of the ventricle to fill or eject blood. It carries a poor prognosis with 50% mortality within the first 5 years of diagnosis, and is associated with significant co-morbidity and remarkable decrease in quality of life and functional status. Unfortunately, recent data suggest HF-associated mortality and morbidity are on the rise. While the reason for the HF-related poor outcomes is multifactorial, underdiagnosis and time-sensitive diagnosis play a significant contributory role leading to poor cardiovascular outcomes. This is mainly because the diagnosis of heart failure is a clinical and thus, it requires compilation of various data points including detailed and thorough history and physical exam.


### Methods
For this project, we are using MIMIC-III which is a large, freely-available database comprising deidentified health-related data associated with over forty thousand patients who stayed in critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012. This is a vast dataset with many variables and limited access. It comes in form of various datasets which were then cleaned. Datatables containing basic demographics, ICD codes and note events were then merged. Heart failure with reduced ejection fraction (HFrEF) definition (using definition from https://phekb.org/  was used to define case and control populations. 

#Retrieving datatables
```{r eval = TRUE}
library(data.table)
library(ggplot2)
library(dplyr)
library(magrittr)
library(pROC)
NOTEEVENTS <- read.csv("~/Downloads/NOTEEVENTS.csv", comment.char="#")
PATIENTS <- read.csv("~/Downloads/PATIENTS.csv")
DIAGNOSES_ICD <- read.csv("~/Downloads/DIAGNOSES_ICD_3.csv", header=TRUE)
ADMISSIONS <- read.csv("~/Downloads/ADMISSIONS.csv", header=TRUE)
```

#Query the data, QI and cleaning
```{r eval = TRUE}
#Quering the dataset
head(PATIENTS)
head(DIAGNOSES_ICD)
head(NOTEEVENTS)

#uniquea <-length(unique(ADMISSIONS$SUBJECT_ID)) #46,520 unique subject IDs
#uniqued <-length(unique(DIAGNOSES_ICD$SUBJECT_ID)) #46,520 unique subject IDs
#uniquep <-length(unique(PATIENTS$SUBJECT_ID)) #46,520 unique subject IDs
#uniquens <-length(unique(NOTEEVENTS$SUBJECT_ID)) #46146 unique subject IDs

#Duplicates in subject ID for patient dataset. 
library(dplyr)
PATIENTS %>% 
group_by(SUBJECT_ID) %>% 
  filter(n()>1) #There is no duplicate. 

#First let's look at the various types of notes in category 
#unique_c <-unique(NOTEEVENTS$CATEGORY) 
#unique_nd <-unique(NOTEEVENTS$DESCRIPTION)
#NoteSum <-sum(NOTEEVENTS$CATEGORY == "Discharge summary")
```

##Results
#Creating a basic demographic datasets
```{r eval = TRUE}
library(dplyr)
library(plyr)
#Joining datasets PATIENTS with ADMISSIONS which contain demographics including ethnicity, insurance, etc. 
Demographic<- dplyr::inner_join(PATIENTS, ADMISSIONS, by = "SUBJECT_ID")
Demographic <-select(Demographic, SUBJECT_ID, GENDER, ADMISSION_TYPE, ETHNICITY, MARITAL_STATUS, INSURANCE) 

#Removing duplicate rows by subject_ID. This was done after querying the data to visualize what constitutes duplicated rows and what data is contained within those rows. 
Demographic <- Demographic[!duplicated(Demographic$SUBJECT_ID), ]
```

#Creating a basic demographic tables
```{r eval = TRUE}
#Table 1. Basic demographic of the cohort
library (gtsummary)
Demographic  %>% gtsummary::tbl_summary()

#Table 2. Basic demographic of the cohort by gender
Demographic %>% gtsummary::tbl_summary(by = GENDER)

#Table 3. Basic demographic of the cohort by insurance status 
Demographic %>% gtsummary::tbl_summary(by = INSURANCE)
```

#Visualizing our cohort dataset
```{r eval = TRUE}
#Visualizing the data
library(ggplot2)

#Figure 1.Visualizing Insurance status in cohort
ggplot(data = Demographic, aes(x = INSURANCE)) +
    geom_bar()

#Figure 2. Visualizing Insurance status across age in cohort 
ggplot(data = Demographic, aes(x =INSURANCE, fill = GENDER)) +
    geom_bar(position = "dodge")
    geom_bar()
    
#Figure 3. Visualizing marital status across age in cohort
ggplot(data = Demographic, aes(x =  MARITAL_STATUS, fill = GENDER)) +
    geom_bar(position = "dodge")
    geom_bar()
    
#Figure 4. Visualizing Ethnicity breakdown in cohort
ggplot(data = Demographic, aes(x = ETHNICITY)) + 
    geom_bar()

#Figure 5. Visualizing various demographics in one chart
ggplot(data = Demographic, aes(x = ADMISSION_TYPE, fill = (GENDER))) + 
    geom_bar(position = "dodge") +
    facet_grid(. ~INSURANCE) + #Split by another variable
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#Creating a new heart failure status variable. 
```{r eval = TRUE}
#Creating a new binary column called HF Status indicative of heart failure (HF) or non-HF (noHF)
DIAGNOSES_ICD<- DIAGNOSES_ICD %>%
  mutate(HF_Status = ifelse(ICD9_CODE == 42840 | ICD9_CODE == 42841 | ICD9_CODE == 42842, "HF", "noHF"))

#Pulling ICD codes from Diagnoses table for case/cohort definition.
HF_ICD9 <- filter(DIAGNOSES_ICD, HF_Status == "HF")

#Pulling ICD codes from Diagnoses table for case/cohort definition.
nHF_ICD9 <- filter(DIAGNOSES_ICD, HF_Status == "noHF")

#Table 4. Heart failure vs non-heart failure cohort. 
print(table(DIAGNOSES_ICD$HF_Status))

```


#Creating the heart failure case cohort (NOTEEVENTS_ICD9_HF)
#Joining tables NOTEEVENTS data to ICD codes
```{r eval = TRUE}
#Dropping row_id as it is not needed. 
library(dplyr)
library(plyr) 
HF_ICD9 <- select(HF_ICD9, select = -ROW_ID)
nHF_ICD9 <- select(nHF_ICD9, select = -ROW_ID)

#Defining case cohort
#Joining by unique hospital admission ID aka HADM_ID. That is we are joining a specific ICD9 code of an encounter to that same encounter in the NOTEEVENTS
NOTEEVENTS_ICD9_HF <- dplyr::inner_join(NOTEEVENTS, HF_ICD9, by = "HADM_ID")

#Selecting for encounters with discharge summary and echo reports.  
NOTEEVENTS_ICD9_HF<- filter(NOTEEVENTS_ICD9_HF, CATEGORY == 'Discharge summary'| CATEGORY == 'Echo' )

#Dropping a few more variables (charttime, storetime and iserror) which are not needed
NOTEEVENTS_ICD9_HF <- dplyr::select(NOTEEVENTS_ICD9_HF, -CHARTTIME, -STORETIME, -ISERROR)
NOTEEVENTS_ICD9_HF<- filter(NOTEEVENTS_ICD9_HF, DESCRIPTION != 'Addendum')

#Characteristics of heart failure cohort
HF_demo <- dplyr::inner_join (Demographic, HF_ICD9, by = "SUBJECT_ID") 

#Figure 6. Visualizing the heart failure cohort 
ggplot(data = HF_demo, aes(x =INSURANCE, fill = GENDER)) +
    geom_bar(position = "dodge")
    geom_bar()

```

#Joining table to create our our overall cohort (both case and control)
```{r eval = TRUE}
#Herein, we want to create a dataset including the patient ID, note type (discharge summary, echoreport), unique note ID, HADM_ID, column text, HF_case (1 or 0, 1 for case, 0 for cohort), column text. 

#Joining notevents with icd9 codes
DIAGNOSES_ICD_n <- select(DIAGNOSES_ICD, -ROW_ID)
NOTEEVENTS_ICD9 <- dplyr::inner_join(NOTEEVENTS, DIAGNOSES_ICD_n, by = "HADM_ID")

#Removing obs or noted encounters without associated discharge summaries or echo reports
NOTEEVENTS_ICD9 <- filter(NOTEEVENTS_ICD9, CATEGORY == 'Discharge summary'| CATEGORY == 'Echo') #large datset as one patient or one admission will have 7-8 different ICD9 codes for billing. 

#Turning the HF_status into a factor (0= noHF, 1 = HF)
NOTEEVENTS_ICD9$HF_Status <- ifelse(NOTEEVENTS_ICD9$HF_Status == "HF", 1,0)
table(NOTEEVENTS_ICD9$HF_Status)
  
#Dropping a few more variables (charttime, storetime and iserror) which are not needed
NOTEEVENTS_ICD9 <- dplyr::select(NOTEEVENTS_ICD9, -CHARTTIME, -STORETIME, -ISERROR)
NOTEEVENTS_ICD9 <- filter(NOTEEVENTS_ICD9, DESCRIPTION != 'Addendum') #removing discharge with addendum as not needed.
```

#Creating the heart failure control cohort (NOTEEVENTS_ICD9_nHF)
```{r eval = TRUE}
#Joining by unique hospital admission ID aka HADM_ID. That is we are joining a specific ICD9 code of an encounter to that same encounter in the NOTEEVENTS
NOTEEVENTS_ICD9_nHF <- dplyr::inner_join(NOTEEVENTS, nHF_ICD9, by = "HADM_ID")

#Selecting for encounters with discharge summary and echo reports.  
NOTEEVENTS_ICD9_nHF<- filter(NOTEEVENTS_ICD9_nHF, CATEGORY == 'Discharge summary'| CATEGORY == 'Echo' )

#Dropping a few more variables (charttime, storetime and iserror) which are not needed
NOTEEVENTS_ICD9_nHF <- dplyr::select(NOTEEVENTS_ICD9_nHF, -CHARTTIME, -STORETIME, -ISERROR)
NOTEEVENTS_ICD9_nHF <- filter(NOTEEVENTS_ICD9_nHF, DESCRIPTION != 'Addendum')

#Characteristics of heart failure cohort
nHF_demo <- dplyr::inner_join (Demographic, nHF_ICD9, by = "SUBJECT_ID") 

#Figure 7. Visualizing the heart failure cohort 
ggplot(data = nHF_demo, aes(x =INSURANCE, fill = GENDER)) +
    geom_bar(position = "dodge")
    geom_bar()
```


#create a text file to be used in Python and cTakes for NLP text analysis.
```{r eval = TRUE}

#Selecting for specific variables needed for the text file analysis.
HF_Sub <- dplyr::select(NOTEEVENTS_ICD9_HF, SUBJECT_ID.x, HADM_ID, ROW_ID, CATEGORY, HF_Status, TEXT)
nHF_Sub <- dplyr::select(NOTEEVENTS_ICD9_nHF, SUBJECT_ID.x, HADM_ID, ROW_ID, CATEGORY, HF_Status, TEXT)

#Will create two subcohorts with 100 patients each for the text file analysis (100 pts in case subcohort, 100 pts in control subcohort). 
HF_Sub <- NOTEEVENTS_ICD9_HF [ 1:25, ]
nHF_Sub <-NOTEEVENTS_ICD9_nHF [1:50, ]

#Now creating separate text files for case cohort and saving them "HF case" folder  
for (row in 1:nrow(HF_Sub)) {
    A <- HF_Sub[row, "SUBJECT_ID.x"]
    B  <- HF_Sub[row, "HADM_ID"] 
    C  <- HF_Sub[row, "ROW_ID"] 
    D <- HF_Sub[row, "CATEGORY"]
    E <- HF_Sub[row, "HF_Status"]
    G <- HF_Sub [row, "TEXT"]
    Filename <-paste(A,B,C,D,E,".txt", sep = "_") 

    write.table(G, file = file.path("/Users/godefroychery/BMIN503_Final_Project/HF_case/", Filename), sep = "\t",
            row.names = TRUE, col.names = TRUE)
}


#Now creating separate text files for case cohort and saving them "HF control" folder  
for (row in 1:nrow(nHF_Sub)) {
    A <- nHF_Sub[row, "SUBJECT_ID.x"]
    B  <- nHF_Sub[row, "HADM_ID"] 
    C  <- nHF_Sub[row, "ROW_ID"] 
    D <- nHF_Sub[row, "CATEGORY"]
    E <- nHF_Sub[row, "HF_Status"]
    G <- nHF_Sub [row, "TEXT"]
    Filename <-paste(A,B,C,D,E,".txt", sep = "_") 

    write.table(G, file = file.path("/Users/godefroychery/BMIN503_Final_Project/HF_control/", Filename), sep = "\t",
            row.names = TRUE, col.names = TRUE)
}
```

#Apply open-source NLP tools to encode variables for your study 
```{r eval = TRUE}
#We will be applying applying open-source NLP tools to encode variables for the study. For this study, we are using cTakes. More on cTakes can be found at doi: 10.1136/jamia.2009.001560. PMID: 20819853; PMCID: PMC2995668.
```

#Develop and apply logic to features that are indicative to HFrEF definition from notes to predict case label


#Evaluate how well the predictive power of rule logic for phenotyping HFrEF (extrinsic evaluation) and areas for improvement based on errors in NLP and rules (intrinsic evaluation)
