---
title: "BMIN503/EPID600 Project Template"
author: "Godefroy Chery"
output: 
  html_document:
    theme: paper 
    highlight: tango
---


***
Use this template to complete your project throughout the course. Your Final Project presentation will be based on the contents of this document. Replace the title/name above and text below with your own, but keep the headers. Feel free to change the theme and other display settings, but this is not required.

### Overview
For this project, we are seeking to determine the feasibility, diagnostic and predictive power of unstructured text data (from medical notes) to diagnose heart failure with reduced ejection fraction (HFrEF). We are using the Medical Information Mart for Intensive Care (MIMIC)-III dataset for this project. Specifically, we are seeking to determine the feasibility of extracting pertinent components of the unstructured text of medical note (e.g. discharge summary) using natural language processing (NLP) methods to assist in making a heart failure diagnosis. Secondarily, we aim to compare the diagnostic and predictic power of the unstructured text to conventional factors in making a heart failure diagnosis. 

### Introduction 
Heart failure (HF) is a progressive clinical syndrome resulting from any structural or functional cardiac disorder that impairs ability of the ventricle to fill or eject blood. It carries a poor prognosis with 50% mortality within the first 5 years of diagnosis, and is associated with significant co-morbidity and remarkable decrease in quality of life and functional status. Unfortunately, recent data suggest HF-associated mortality and morbidity are on the rise. While the reason for the HF-related poor outcomes is multifactorial, underdiagnosis and time-sensitive diagnosis play a significant contributory role leading to poor cardiovascular outcomes. This is mainly because the diagnosis of heart failure is a clinical and thus, it requires compilation of various data points including detailed and thorough history and physical exam.


### Methods
For this project, we are using MIMIC-III which is a large, freely-available database comprising deidentified health-related data associated with over forty thousand patients who stayed in critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012. This is a vast dataset with many variables and limited access. It comes in form of various datasets which were then cleaned. Datatables containing basic demographics, ICD codes and note events were then merged. Heart failure with reduced ejection fraction (HFrEF) definition (using definition from https://phekb.org/  was used to define case and control populations. 

#Retrieving datatables
```{r eval = TRUE}
library(data.table)
library(ggplot2)
library(dplyr)
library(magrittr)
library(pROC)
NOTEEVENTS <- read.csv("~/Downloads/NOTEEVENTS.csv", comment.char="#")
PATIENTS <- read.csv("~/Downloads/PATIENTS.csv")
#Diagnoses_icd_2 <- read.csv("~/Downloads/DIAGNOSES_ICD (1).csv", header=TRUE)
DIAGNOSES_ICD_3 <-  read.csv("~/Downloads/DIAGNOSES_ICD_3.csv", header=TRUE)
DIAGNOSES_ICD <- DIAGNOSES_ICD_3
ADMISSIONS <- read.csv("~/Downloads/ADMISSIONS.csv", header=TRUE)
```

#Query the data, QI and cleaning
```{r eval = TRUE}
#Quering the dataset
head(PATIENTS)
head(DIAGNOSES_ICD)
head(NOTEEVENTS)

length(unique(DIAGNOSES_ICD$SUBJECT_ID)) #46,520 unique subject IDs
length(unique(PATIENTS$SUBJECT_ID)) #46,520 unique subject IDs
length(unique(NOTEEVENTS$SUBJECT_ID)) #46146 unique subject IDs

#Duplicates in subject ID for patient dataset. 
library(dplyr)
PATIENTS %>% 
  group_by(SUBJECT_ID) %>% 
   filter(n()>1) #There is no duplicate. 

#For our project, we are interested in unstructured text data. As such, we will drop observations without discharge summaries. 

#First let's look at the various types of notes in category 
unique(NOTEEVENTS$CATEGORY) #type of notes listed in category including discharge summary
unique(NOTEEVENTS$DESCRIPTION)
sum(NOTEEVENTS$CATEGORY == "Discharge summary")

#Now, creating new subset of data with only discharge summaries. 
NOTEEVENTS %>% group_by(CATEGORY) %>% filter (CATEGORY == 'Discharge summary')
NOTEEVENTS_DC <- filter(NOTEEVENTS, CATEGORY == 'Discharge summary') 
length(unique(NOTEEVENTS_DC$SUBJECT_ID)) #41,127 unique subject IDs
Subject_ID_Dup <- data.frame(table(NOTEEVENTS_DC$SUBJECT_ID))

#Of note, Diagnoses_ICD dataset contain the patients with the ICD diagnosis codes. D_ICD_diagnoses is a data dictionary.Also, one may consider pulling echo reports as well using this code 'NOTEEVENTS_DC_ECHO <- filter(NOTEEVENTS, CATEGORY == 'Discharge summary' & 'Echo')' 
```


#Joining the tables Will set to join tables by the variable SUBJECT_ID which is unique. 
```{r eval = TRUE}

#Joining tables containing patients' discharge summaries (NOTEEVENTS_DC) with table containing patients' basic demographics (PATIENTS). Performing a left join to join patients with discharge summary to patients' demographic in PATIENTS table
library(dplyr)
library(plyr) 
NOTEEVENTS_DC_PATIENTS <- dplyr::left_join(NOTEEVENTS_DC, PATIENTS, by = "SUBJECT_ID")
dim(NOTEEVENTS_DC_PATIENTS)
tail(NOTEEVENTS_DC_PATIENTS)
length(unique(NOTEEVENTS_DC_PATIENTS$SUBJECT_ID)) #41127 unique subject IDs

#Joining the newly created table with ICD9 codes table. 
NOTEEVENTS_DC_PATIENTS_ICD <- dplyr::left_join(NOTEEVENTS_DC_PATIENTS, DIAGNOSES_ICD, by = "SUBJECT_ID")
length(unique(NOTEEVENTS_DC_PATIENTS_ICD$SUBJECT_ID)) #41127 unique subject IDs

#The new table 'NOTEEVENTS_DC_PATIENTS_ICD$SUBJECT_ID' contains observations with discharge summaries, patients' demographics and ICD codes (keep in mind that one patient often have more than one ICD code that it is dependent on billing). 

#Joining the table 'NOTEEVENTS_DC_PATIENTS_ICD$SUBJECT_ID' with admissions data which contain admission date. 
NOTEEVENTS_DC_PATIENTS_ICD_ADM <- dplyr::left_join(NOTEEVENTS_DC_PATIENTS_ICD, ADMISSIONS, by = "SUBJECT_ID")
length(unique(NOTEEVENTS_DC_PATIENTS_ICD_ADM$SUBJECT_ID)) #41,127 unique subject IDs
summary(ADMISSIONS$SUBJECT_ID)


#Herein will, we will drop variables that are not needed for our project.
MIMICIII = select(NOTEEVENTS_DC_PATIENTS_ICD_ADM, -ROW_ID.x, -ROW_ID.x.x, -HADM_ID.x, -HADM_ID.y, -ROW_ID.y.y, -HADM_ID, -DEATHTIME, -ADMISSION_LOCATION, -DISCHARGE_LOCATION, -LANGUAGE, -RELIGION, -MARITAL_STATUS, -EDREGTIME, -EDOUTTIME, -HOSPITAL_EXPIRE_FLAG, -HAS_CHARTEVENTS_DATA, -CHARTDATE, -CHARTTIME, -STORETIME, -ISERROR, -ROW_ID.y, -EXPIRE_FLAG, -ADMITTIME, -ADMISSION_TYPE, -DOD_HOSP, -DOD_SSN)

#Removing obs with "addendum" description as they are not needed
unique(MIMICIII$DESCRIPTION)
MIMICIII <- filter(MIMICIII, DESCRIPTION != 'Addendum')
which(is.na(MIMICIII$DESCRIPTION))

#Now finding overlapping subject IDs in control cohort that were listed in case cohort but with a different ICD9_code. Once that list of subject IDs, then remove that list from the control cohort.
HF_cs <-unique(MIMICIII_case$SUBJECT_ID)

#Find a way to drop all of those subject ID from the control cohort.
#MIMICIII_control_1 <-subset(MIMICIII_control, SUBJECT_ID!=9801, SUBJECT_ID!=30213) ***

#MIMICIII_control[MIMICIII_control$SUBJECT_ID == 9801 | MIMICIII_control$SUBJECT_ID == 30213,]


```

##Results
#Creating a basic demographic table 
```{r eval = TRUE}
#Pulling pertinent dataset to create demographic table. 
Demographic <- select(MIMICIII, GENDER, ETHNICITY, INSURANCE, DIAGNOSIS)
Demographic %>% gtsummary::tbl_summary()


```

#Creating case and control cohorts. 
```{r eval = TRUE}
#Control cohort
#Creating a new dataset which contains control (aka where HF is not listed as a ICD diagnosis code)
MIMICIII_control <- MIMICIII[(MIMICIII$ICD9_CODE != "42840") & (MIMICIII$ICD9_CODE != "42841") & (MIMICIII$ICD9_CODE != "42842"), ]
class(MIMICIII$ICD9_CODE)
unique(MIMICIII$ICD9_CODE)
 #Control cohort has 7633150 obs (which + case of 6286 give the initial total of 7639436)

#Case cohort
#Of note, this case cohort has the similar subject IDs as the case cohort that was pulled from Bigquery Google. 
MIMICIII_case <- filter(MIMICIII, ICD9_CODE == "42840" | ICD9_CODE == "42841" | ICD9_CODE == "42842") #Case cohort has 6286 obs

```


#Apply open-source NLP tools to encode variables for your study 


#Develop and apply logic to features that are indicative to HFrEF definition from notes to predict case label


#Evaluate how well the predictive power of rule logic for phenotyping HFrEF (extrinsic evaluation) and areas for improvement based on errors in NLP and rules (intrinsic evaluation)
