---
title: "BMIN503/EPID600 Final Project"
author: "Willem van der Mei"
output: 
  html_document:
    theme: paper 
    highlight: tango
---
```{r set-options, echo=FALSE, cache=FALSE, message=FALSE}
options(width = 400)
finalData <- readr::read_csv("./finalData.csv")
```  
***


### Overview

The main goal of this project is to find area-level predictors of fatal cocaine overdoses. I additionally aim to build and test some preliminary predictive models. I am using data on fatal cocaine overdoses from the CDC and covariates from the Census and teh Vera Institute of Justice.

Final Repository Link: https://github.com/wvdmei/BMIN503_Final_Project


### Introduction 

Overdoses are an increasing burden cause of mortality in the United States. However, the majority of the research has focused on opioid overdoses. Stimulant overdoses, and specifically cocaine for the purposes of this project, have not received as much attention, despite their increases over time, and therefore there is less literature on its prediction. This project hopes to fill in that gap, just a bit, so that future projects can build upon it and build strong conceptual and predictive models of stimulant overdoses. Hopefully with these models, interventions to reduce fatal overdoses can be developed to combat this growing problem.

This project draws from a couple areas of epidemiology, such as social epidemiology and psychiatric epidemiology. However, over the course of meetings with faculty, it became apparent that concepts from the fields of spatial data analysis and machine learning were also needed for this project. Firstly, due to the geographic clustering of the counties, it may be necessary to account for potential non-independence. Secondly, the project will also draw from machine learning in order to try to build predictive models of fatal cocaine overdoses.

### Methods

#### Source of Data

The data used for this project has been procured from two sources. The first is PolicyMap which aggregates geographic data from various sources. For this project, fatal cocaine overdose data was obtained from the Centers for Disease Control through PolicyMap. Data for covariates, except total jail admissions, was obtained from the U.S. Census Bureau through PolicyMap. Data on total jail admissions was obtained from the Vera Institute of Justice. For data from the Census Bureau, 5-year estimates from 2010-2014 and 2015-2019 were used, since those were the most available for the covariates. For data on outcomes and jail admissions, annual estimates were combined into 5-year estimates, or if less than 5 years of data were available were imputed based on the average of the years of data available. Commented code for data processing can be found in the DataProcessing.R script in the repository. All data were collected on the county-level. 

#### Covariates

Covariates were selected based on a previous literature review of predictors of stimulant and opioid overdoses. Covariates selected included county level information on the following: mean household size, mean age, race and ethnicity, sex, rent burden ,disability, income inequality (measured by Gini index), Medicaid coverage, education (proportion of population with at least a bachelors), poverty, per capita income, proportion of households without a motor vehicle, and jail admissions per 100 people. More information can be found in the Conceptual Model document.

#### Outcome

The number of fatal cocaine overdoses in a county was calculated by the CDC based on the number of death certificates, which listed drug poisoning as the primary cause of death and cocaine use as an additional cause of death.

#### Statistical Analysis

For continuous variables, descriptive statistics include mean, standard deviation, median, minimum ,and maximum. These data will be reported in Table 1. To find predictors for the number of cocaine overdoses in a US county, poisson linear mixed effect models were chosen for a few of reasons. First, they allow for longitudinal analysis. Second, they can be used to model clustered data, which is useful in this scenario, where counties are clustered in states. Lastly, they allow for random effects. The 5-year population estimate was used as an offset term for the regression model. To build predictive models, elastic net regression and random forest models were used.

### Results

#### Table 1. Descriptive Statistics

```{r}
# Load Table1
library(table1)
library(dplyr)

# Create Other Race Variable
finalData$otherRace <- 100 - finalData$prevBlack - finalData$prevWhite - finalData$prevHispanic

# Create labels so that the rows in the table look nice
label(finalData$meanHouseholdSize) <- "Mean Household Size"
label(finalData$prevDisabled) <- "Proportion of Population with a Disability"
label(finalData$gini) <- "Gini Coefficient"
label(finalData$medianAge) <- "Median Age"
label(finalData$prevMedicaid) <- "Proportion of Population on Medicaid"
label(finalData$prevMinBachelors) <- "Proportion of Population with at least a Bachelors"
label(finalData$prevBlack) <- "Proportion of Population that is Non-Hispanic Black Only"
label(finalData$prevWhite) <- "Proportion of Population that is Non-Hispanic White Only"
label(finalData$prevHispanic) <- "Proportion of Population that is Hispanic of All Races"
label(finalData$otherRace) <- "Proportion of Population that is in an Other Race Group"
label(finalData$perCapIncome) <- "Per Capita Income"
label(finalData$prevMen) <- "Proportion of the Population that is Male"
label(finalData$prevPoverty) <- "Proportion of Population in Poverty"
label(finalData$medianRentCostBurden) <- "Median Rent Burden"
label(finalData$prevNoCar) <- "Proportion of Population with No Car"
label(finalData$jailAdmit100) <- "Jail Admissions per 100 People"

# Create table and pass it to kable, which makes it pretty
table1::table1(~meanHouseholdSize + prevDisabled + gini  + medianAge + prevMedicaid + prevMinBachelors + prevBlack + prevWhite + prevHispanic + otherRace + perCapIncome + prevMen + prevPoverty + medianRentCostBurden + prevNoCar + jailAdmit100, data = finalData) %>% kableExtra::kable()
```

#### Predictive Model

Convergence issues have been solved, but models are still being built.

```{r, eval=FALSE}
library(glmnet)
elasticModel <- glmnet::cv.glmnet(x = as.matrix(select(finalData, prevPoverty, prevDisabled, prevHispanic, prevBlack, prevWhite, prevMinBachelors, prevMen, jailAdmit100)), y = as.matrix(finalData$cocaineDeath), offset = as.matrix(log(finalData$nPop)), family = "poisson", alpha = 0.5)
```

#### Risk Factor Model

```{r, eval=FALSE}
library(lme4)

finalDataRescaled <- finalData
finalDataRescaled[,c(6:16,18:22)] <- scale(finalDataRescaled[,c(6:16,18:22)])

poissonModelRandom <- lme4::glmer(formula = round(cocaineDeath, 0) ~ year +  meanHouseholdSize + prevDisabled + prevHispanic + medianAge + prevMedicaid + prevMinBachelors + prevBlack + prevWhite + perCapIncome + prevMen + prevPoverty + prevNoCar + jailAdmit100 + offset(log(nPop)) + (1 | state), family = poisson(link = "log"), data = finalDataRescaled2))

poissonModelRandomSummary <- summary(poissonModelRandom)
zScore <- coef(poissonModelRandomSummary)[, 1] / (coef(poissonModelRandomSummary)[, 2]*sqrt(dp))
pvals <- ifelse(zScore <= 0, pnorm(q = zScore)*2, pnorm(q = zScore, lower.tail = FALSE)*2)

modelSummary <- data.frame(Estimate = coef(poissonModelRandomSummary)[, 1], RateRatio = exp(coef(poissonModelRandomSummary)[, 1]), StdError = (coef(poissonModelRandomSummary)[, 2]*sqrt(dp)),zScore = zScore, pvals = pvals) %>% mutate(lowerCiRR = exp(Estimate - 1.96*StdError), upperCiRR = exp(Estimate + 1.96*StdError))

pvals[which(pvals < 0.05)]

dp = sum(residuals(poissonModelRandom,type ="pearson")^2)/486

nBinomModelRandom <- lme4::glmer(formula = round(cocaineDeath, 0) ~ year +  meanHouseholdSize + prevDisabled + gini + medianAge + prevMedicaid + prevMinBachelors + prevBlack + prevWhite + prevHispanic + perCapIncome + prevMen + prevPoverty + medianRentCostBurden + prevNoCar + jailAdmit100 + offset(log(nPop)) + (1 | state), family = negative.binomial(link = "log", theta = 1/dp), data = finalDataRescaled)

nBinomModelRandom@

summary(poissonModelRandom)

poissonModel <- glm(formula = round(cocaineDeath, 0) ~  perCapIncome + jailAdmit100 + medianAge + gini, offset = log(nPop) , family = poisson(link = "log"), data = finalData)
summary(poissonModel)
```

