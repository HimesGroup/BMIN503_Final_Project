---
title: "Predicting statin response using machine learning (simulated data!)"
author: "Jason E. Miller"
output:
  html_document:
    depth: 3
    highlight: tango
    theme: paper
    toc: no
  pdf_document:
    toc: no
---
```{r  }
knitr::opts_chunk$set( echo=TRUE, cache=FALSE, results='hide',message=FALSE ,warning=FALSE)

```  
***

### THIS FILE IS PURELY JUST TO SHOW THE CODE WORKS, AS I USED SIMULATED DATA. THE RESULTS AND DESCRIPTIONS REFLECT THE USE OF REAL DATA FROM THE final_project_temp_Miller_git_v3.Rmd FILE.


### Overview
 Plasma lipid levels are highly heritable and associated with coronary artery disease (CAD). Statins make up a class of drugs that can reduce cholesterol levels however it is unclear if genes expression levels are most predictive of a strong response relative to phenotypes and demographics. As a preliminary study to determine how well baseline measurements can predict phenotypic information, phenotypic and demographic data will be used to predict whether or not an individual has a weak or strong response to statins.

### What I learned from interviewing others

Shefali Verma, Phd

Project lead/Staff Scientist

Department of Genetics

When using randomForest, tuning the parameters  is very important. Typically you can perform a simulation to have some understanding of how the parameters  may affect the results, but that doesn't always generalize to real data. SVM can be difficult to interpret as it will provide a result using all features. Thus, a feature selection step preceding SVM can help so you know the features that are most relevant and this will help with interpretation.

Anurag Verma, PhD

Project lead/Staff Scientist

Department of Genetics

It's important to investigate the data structure using some exploratory data analysis before performing any complex analyses. During EDA it is important to quantify the missingness to see if there are any variables that may need to be excluded or imputed. A feature selection step can be useful to improve accuracy and efficiency. There are autoML methods that can be used to test multiple algorithms at once, but that might be a future direction. 

Anastacia Lucas

Data Analyst

Department of Genetics

Using an ROC curve is useful when comparing ML methods. Interpretation is important after evaluating methods to make sure that if you do get really good predictions they make sense in the context of the dataset. http://colorbrewer2.org has optimized color schemes for geographic data but can be used in other contexts. 


https://github.com/git-jemiller/BMIN503_Final_Project

### Introduction 

  
  Plasma lipid levels can be used to identify risk of CAD. In order to reduce the likelihood of developing the disease, patients are often prescribed statins, a lipid lowering medication. While statins are effective, there can be significant variability between how patients respond. Though previous studies have focused on performing association studies, there has yet to be work that has tested how machine learning can be used to make predictions based on gene expression levels as a means to identify individuals who will respond well to statins. Furthermore, it remains unclear what features would be best suited for making said predictions.


  The problem being addressed in this work is inherently multi-disciplinary. The data being used is from the CAP study (Theusch et al., 2016) which is focused on the pharmacogenomics of statins. Therefore, knowledge of biology and pharmacology are at the basis of the questions being addressed. Furthermore, machine-learning methods are being applied to the data which comes from computer science. In order to apply machine learning in this context, it will be important to first perform exploratory data analysis to have a good idea of what the data looks like. It will also be useful to test multiple parameters to make sure the most robust results are found. And results can be interpreted using AUC and/or ROC curves.



### Methods

The data used for this analysis has come from the Cholesterol and Pharmacogenomics (CAP) study. Between 2002 and 2004, 944 African American and European-American men and women were recruited to participate in a research project to study their lipids in response to statins. In addition to demographic information, RNA-seq and limited metabolomic data was also generated pre and post-statin exposure for over 400 individuals. In this study, I am interested in understanding which demographics and lab measures are most predictive for a weak or strong statin response. In other words which features predict if someone has a small or large decrease in LDL. To carry out such an analysis I will first test how well demographic and lab measures perform using correlations and visual inspection through exploratory data analysis mostly using functions from tidyverse. I will then use multivariable linear regression to predict statin response as a binary outcome followed by training models using machine learning methods such as SVM (e1071 package) and random forest (randomForest package). I will test four different kernels in SVM incase the relationship does not follow a linear trend. Finally, the models will be evaluated using 10-fold cross-validation. 

### Results


In this first part I have cleared the environment and have loaded all the necessary libraries to run the Rmd file. 
```{r }


#BMIN503
#Generates fake results
#Upload RmD file but not data

rm(list=ls())

#Test update


#Load libraries


library(GGally)
library(reshape2)
library(tidyverse)
library(gplots)
library(pROC)
library(DAAG)
library(randomForest)
library(sensitivity)
library(randomForest)
library(e1071)
library(pROC)
library(Hmisc)
library(RColorBrewer)

```

In the following section, I have loaded the data, selected 420 samples, and averaged the two pre-statin and post-statin values. I then calculated the change in LDL, which is what will be predicted for the final analysis.

```{r }

###Phenotypic data

########################################################################################
###Phenotypic data (real data)
########################################################################################

###########Phenotypic data
#Load phenotype cholesterol data


#lcl.pheno <- read.table(file = "~/Desktop/ritchie_group/penn/class/BMIN503_EPID600/final_project/BMIN503_Final_Project/N426CAPphenosToShare.txt", header = TRUE,sep = "\t")

#Columns with missing data
#lcl.pheno_w_na <- lcl.pheno %>% select(2:6,SelfReported.Race, 35:50, 158:161 )
#Columns with NAs
#colnames(lcl.pheno_w_na)[colSums(is.na(lcl.pheno_w_na)) > 0]

#Select columns of interest
#lcl.pheno.sel_noNA <- na.omit(lcl.pheno %>% select(2:6,SelfReported.Race, 35:50, 158:161 )  )

#After omitting NAs there are 423 samples.
#dim(lcl.pheno.sel_noNA)


########################################################################################################################
########################################################################################################################
###############MAKE FAKE DATA
########################################################################################################################
########################################################################################################################

#Make continuous data
mat1 <- matrix(data = rexp(426, rate = 100), nrow = 426, ncol = 23)*10000
#Add noise
mat2 <- apply(mat1, 2, function(x) x + rnorm(426))
#Make data with strings
Sex <- as.data.frame(c(rep("Female", 213), rep("Male", 213)))
Smoker <- as.data.frame(c(rep("Yes", 213), rep("No", 213)))
Race <- as.data.frame(c(rep("Afri", 213), rep("Cauc", 213)))

#Combine fake discrete and continuous data
fakedata1 <- cbind(Sex, mat1[,1:2], Smoker, mat1[,3], Race, mat1[,4:23]    )
dim(fakedata1)

#Shuffle data
set.seed(1)
fakedata1[] <- lapply(fakedata1, sample)

#add column names
colnames(fakedata1) <- c("Sex"     ,          "Age"     ,          "BMI"      ,         "Smoker"    ,        "waist"     ,        "SelfReported.Race" , "Tg.SV"       ,      "Tg.EV"  ,          
                                    "Tg.V2"         ,    "Tg.V3"     ,        "TC.SV"     ,         "TC.EV"     ,        "TC.V2"      ,       "TC.V3"     ,        "LDLC.SV"  ,         "LDLC.EV"     ,     
                                    "LDLC.V2"         ,  "LDLC.V3"      ,     "HDLC.SV"   ,        "HDLC.EV"  ,         "HDLC.V2" ,          "HDLC.V3"     ,      "DeltaLnTg"     ,    "DeltaLnTC"  ,      
                                    "DeltaLnLDLC" ,      "DeltaLnHDLC")

lcl.pheno.sel_noNA <- fakedata1

########################################################################################################################
########################################################################################################################



#Sample 420 samples randomly
set.seed(1234)
lcl.pheno.sel <- lcl.pheno.sel_noNA[sample(nrow(lcl.pheno.sel_noNA), 420), ]

#head(lcl.pheno.sel)
#dim(lcl.pheno.sel)

####################################################################################
#calculating average lipid pre/post statin
####################################################################################

lcl.pheno.sel$tg.pret.mean <-  (lcl.pheno.sel$Tg.EV + lcl.pheno.sel$Tg.SV)/2
lcl.pheno.sel$tg.post.mean <-  (lcl.pheno.sel$Tg.V2 + lcl.pheno.sel$Tg.V3)/2

lcl.pheno.sel$tc.pret.mean <- (lcl.pheno.sel$TC.EV + lcl.pheno.sel$TC.SV)/2
lcl.pheno.sel$tc.post.mean <- (lcl.pheno.sel$TC.V2 + lcl.pheno.sel$TC.V3)/2

lcl.pheno.sel$ldl.pret.mean <-  (lcl.pheno.sel$LDLC.EV + lcl.pheno.sel$LDLC.SV)/2
lcl.pheno.sel$ldl.post.mean <-  (lcl.pheno.sel$LDLC.V2 + lcl.pheno.sel$LDLC.V3)/2

lcl.pheno.sel$hdl.pret.mean <-  (lcl.pheno.sel$HDLC.EV + lcl.pheno.sel$HDLC.SV)/2
lcl.pheno.sel$hdl.post.mean <-  (lcl.pheno.sel$HDLC.V2 + lcl.pheno.sel$HDLC.V3)/2

#LDL pre - post treatment = (+) decrease in lipid, (-) increase in lipids 
lcl.pheno.sel$ldl.dcr.mean <- lcl.pheno.sel$ldl.pret.mean - lcl.pheno.sel$ldl.post.mean

#keep average results, remove individual time points
lcl.pheno.sel2 <- lcl.pheno.sel[,-c(7:22)]
#colnames(lcl.pheno.sel2)
#summary(lcl.pheno.sel2)



```


In the next sections I defined LDL status as weak responder (LDL change is less than median) and strong responder (LDL change in greater than median). I then graphed the distribution of age, BMI, and waist data which appear to be fairly normally distributed. This was followed up by looking at the relationship between race or sex and CAD risk factors. I used ggpair plots to visualize the correlations between traits with respect to sex or race. Total cholesterol (TC) and low-density lipoprotein (LDL) levels correlated with both sexes. High-density lipoprotein (HDL), triglycerides (TG), and TC were significantly associated with sex (p < 0.05). TC and LDL were also consistently correlated among both races. TG and TC were significantly associated with race (p < 0.05). Sex and race were associated with BMI and waist size (p < 0.05). It should be noted that "associated with" should be interpreted  as male and female or white and African-American individuals were significantly different with respect to the risk factor.
```{r }
#Create LDL response categories


#1 = strong responder
#0 = weak responder
lcl.pheno.sel2$ldl.status <- ifelse(lcl.pheno.sel2$ldl.dcr.mean > median(lcl.pheno.sel2$ldl.dcr.mean, na.rm = TRUE), 1, 0 )

#head(lcl.pheno.sel2)
#summary(lcl.pheno.sel2)
#table(lcl.pheno.sel2$ldl.status)
colnames(lcl.pheno.sel2)

#Rename lipids
colnames(lcl.pheno.sel2)[c(11,13,15,17)] <- c( "TG"  ,"TC",  "LDL", "HDL")

#Prep dataframe for boxplot
lcl.pheno.sel2_bp <- lcl.pheno.sel2
lcl.pheno.sel2_bp$ldl.status <- as.factor(lcl.pheno.sel2_bp$ldl.status)
lcl.pheno.sel2_bp$ID <- seq(1,length(lcl.pheno.sel2_bp$ldl.status))
lcl.pheno.sel2_all_melt <- melt(lcl.pheno.sel2_bp,id.vars=c('ID'), measure.vars=c('Age','BMI','waist'))

#Hist age, bmi, waist

# you start here...
ggplot(lcl.pheno.sel2_all_melt, aes(x=value))+
  geom_histogram(aes(y=..density..,fill=variable),color="grey80")+
  facet_grid(variable~.)




#ggplot(lcl.pheno.sel2_all_melt) +geom_boxplot(aes(x=variable, y=value))


#ggpairs(lcl.pheno.sel2, mapping = aes(col=as.factor(Sex)), columns= c(  'Age','BMI','waist' ))


lcl.pheno.sel2_lm <- lcl.pheno.sel2
lcl.pheno.sel2_lm$sex <- ifelse(lcl.pheno.sel2_lm$Sex == "Female", 0, 1)

#Looking at individual demographics/traits association with sex
summary(glm(as.factor(Sex)~BMI  , data=lcl.pheno.sel2_lm, family=binomial(logit)))#0.013*
summary(glm(as.factor(Sex)~Age  , data=lcl.pheno.sel2, family=binomial(logit)))#0.0706
summary(glm(as.factor(Sex)~waist  , data=lcl.pheno.sel2, family=binomial(logit)))#0.0029*


#Looking at individual lipid traits association with sex
summary(glm(as.factor(Sex)~HDL  , data=lcl.pheno.sel2, family=binomial(logit)))#3.36e-12*
summary(glm(as.factor(Sex)~LDL  , data=lcl.pheno.sel2, family=binomial(logit)))#0.960
summary(glm(as.factor(Sex)~TC  , data=lcl.pheno.sel2, family=binomial(logit)))#0.0136*
summary(glm(as.factor(Sex)~TG  , data=lcl.pheno.sel2, family=binomial(logit)))#0.00743*


#Looking at individual demographics/traits association with race
summary(glm(as.factor(SelfReported.Race)~Age , data=lcl.pheno.sel2, family=binomial(logit)))#0.848
summary(glm(as.factor(SelfReported.Race)~BMI  , data=lcl.pheno.sel2, family=binomial(logit)))#0.000551*
summary(glm(as.factor(SelfReported.Race)~waist  , data=lcl.pheno.sel2, family=binomial(logit)))#0.00574*
#Looking at individual lipid traits association with race
summary(glm(as.factor(SelfReported.Race)~HDL  , data=lcl.pheno.sel2, family=binomial(logit)))#0.963
summary(glm(as.factor(SelfReported.Race)~LDL  , data=lcl.pheno.sel2, family=binomial(logit)))#0.138
summary(glm(as.factor(SelfReported.Race)~TC  , data=lcl.pheno.sel2, family=binomial(logit)))#0.016*
summary(glm(as.factor(SelfReported.Race)~TG  , data=lcl.pheno.sel2, family=binomial(logit)))#0.00199*

ggpairs(lcl.pheno.sel2, mapping = aes(col=as.factor(Sex)), columns= c(  'Age','BMI','waist' ))

ggpairs(lcl.pheno.sel2, mapping = aes(col=as.factor(SelfReported.Race)), columns= c(  'Age','BMI','waist' ))

ggpairs(lcl.pheno.sel2, mapping = aes(col=as.factor(Sex)), columns= c(  'TG','TC','HDL','LDL'))

ggpairs(lcl.pheno.sel2, mapping = aes(col=as.factor(SelfReported.Race)), columns= c(  'TG','TC','HDL','LDL' ))
```






I then investigated overall relationships between sex and race along with smoking status. There are fewer African-Americans (AA) and the ratio of female to male samples is slightly higher in AA samples. Smoking status appears to be similar across race and sex. 

```{r }

#Histogram of individual features
##ggplot(lcl.pheno.sel2, aes(Age)) + geom_histogram(bins = 300) + geom_vline(xintercept = median(lcl.pheno.sel2$ldl.dcr.mean, na.rm = TRUE), linetype="dashed", color = "red", size=2)

#Investigating Smoking status
lcl.pheno.sel2_sex <- lcl.pheno.sel2 %>% group_by(SelfReported.Race, Sex) %>% summarise(count = n())

ggplot(data=lcl.pheno.sel2_sex, aes(x=SelfReported.Race, y=count,fill = Sex )) +
    geom_bar(stat="identity", position=position_dodge())

ggpairs(lcl.pheno.sel2, mapping = aes(col=as.factor(Sex)), columns= c(   "Smoker"  ,"SelfReported.Race" ))


#Checking distributions before sampling
#ggpairs(lcl.pheno.sel2, mapping = aes(col=as.factor(ldl.status)), columns= c(   "hdl.pret.mean",     "tg.pret.mean"  ,"tc.pret.mean"  ,"ldl.pret.mean") , title = "All Samples")
#ggpairs(lcl.pheno.sel2, mapping = aes(col=as.factor(ldl.status)), columns= c(   "Sex" ,   "Smoker"  ,   "Age"     ,      "BMI"      ,     "waist"  ), title = "All Samples")




```


I next visualized the distribution of the change in LDL. All but one individuals had a decrease in LDL upon statin treatment. The data was scaled and centered to make sure all variables that have differnt magnitudes and measurements did not bias the results. The heatmap illustrates LDL, TC, TG, and age are positively correlated with having a stronger response to statin therapy (FDR < 0.05). Additionally, smoking is anti-correlated with having a stronger response to statin therapy (FDR < 0.05). The final table from this chunk contains the significant correlations. 

```{r, results='markup' }
######### Create full multivariable phenotype model for lipid
########################################################################################################################
##Before we start doing multivarible analysis, the data needs to be normalized. 

#Make sure NA's are omitted
dim(na.omit(lcl.pheno.sel2))
lcl.pheno.sel2na <- na.omit(lcl.pheno.sel2)

#colnames(lcl.pheno.sel2na)

#Select 420 samples randomly and sepcific columns of interest
lcl.pheno.sel2_del_LDL <- lcl.pheno.sel2na[, c(20,1,4,2,3,5,11,13,15,17,6,19 ) ]
#set.seed(1234)
#lcl.pheno.sel2_del_LDL <- lcl.pheno.sel2na[sample(nrow(lcl.pheno.sel2na), 420), c(20,1,4,2,3,5,11,13,15,17,6,19 ) ]

#Check 420 rows are present
dim(lcl.pheno.sel2_del_LDL)
summary(lcl.pheno.sel2_del_LDL)

###Fraction and count
##Histogram
ggplot(lcl.pheno.sel2_del_LDL, aes(ldl.dcr.mean)) + geom_histogram(bins = 300) + geom_vline(xintercept = median(lcl.pheno.sel2$ldl.dcr.mean, na.rm = TRUE), linetype="dashed", color = "red", size=2) + xlab("Mean starting LDL - mean post statin LDL")+ ylab("Sample count") + ggtitle("Change in LDL (i.e. decrease)")



######Box plots
lcl.pheno.sel2_del_LDL_bp <- lcl.pheno.sel2_del_LDL
lcl.pheno.sel2_del_LDL_bp$ldl.status <- as.factor(lcl.pheno.sel2_del_LDL_bp$ldl.status)
lcl.pheno.sel2_del_LDL_bp$ID <- seq(1,length(lcl.pheno.sel2_del_LDL_bp$ldl.status))

#graph distributions of data
lcl.pheno.sel2_del_LDL_melt <- melt(lcl.pheno.sel2_del_LDL_bp,id.vars=c('ID','ldl.status'), measure.vars=c('Age','BMI','waist', 'TG','TC','HDL','LDL'))
ggplot(lcl.pheno.sel2_del_LDL_melt) +
      geom_boxplot(aes(x=variable, y=value, fill=ldl.status))+ ggtitle("Continous data") + scale_x_discrete(labels = c('Age','BMI','Waist', 'TG','TC','HDL','LDL'))



##############

#Scale age, waist, bmi, and lipids data
#colnames(lcl.pheno.sel2_del_LDL)
lcl.pheno.sel2_del_LDL_z <- cbind(lcl.pheno.sel2_del_LDL[,c(1:3,11)], as.data.frame(apply(lcl.pheno.sel2_del_LDL[,4:10], 2, function(x) scale(x, center = TRUE, scale = TRUE))))
colnames(lcl.pheno.sel2_del_LDL_z)[c(1,2,3,4)] <- c("ldl.status","sex","smoker","sr.race")
#head(lcl.pheno.sel2_del_LDL_z)
#dim(lcl.pheno.sel2_del_LDL_z)
#table(lcl.pheno.sel2_del_LDL_z$ldl.status)

#Rename dataframe before stats
ldl.df <- lcl.pheno.sel2_del_LDL_z


######Box plots
lcl.pheno.sel2_del_LDL_bp_norm <- ldl.df
lcl.pheno.sel2_del_LDL_bp_norm$ldl.status <- as.factor(lcl.pheno.sel2_del_LDL_bp_norm$ldl.status)
lcl.pheno.sel2_del_LDL_bp_norm$ID <- seq(1,length(lcl.pheno.sel2_del_LDL_bp_norm$ldl.status))


lcl.pheno.sel2_del_LDL_norm_melt <- melt(lcl.pheno.sel2_del_LDL_bp_norm,id.vars=c('ID','ldl.status'), measure.vars=c('Age','BMI','waist', "TG"  ,"TC",  "HDL", "LDL"))




###Graph rescaled and centered boxplot results
ggplot(lcl.pheno.sel2_del_LDL_norm_melt) +
      geom_boxplot(aes(x=variable, y=value, fill=ldl.status)) + ggtitle("Continous data after being scaled") + scale_x_discrete(labels = c('Age','BMI','Waist', 'TG','TC','HDL','LDL'))

##############
#Rename columns
#colnames(ldl.df)
colnames(ldl.df) <- c("ldl.status" ,"sex", "smoker" , "race" ,"age"  , "BMI" , "waist" , "TG"  ,"TC",  "LDL", "HDL")





#Checking distributions AFTER sampling
#Can look at pairwise ggpair results again if necessary
##ggpairs(ldl.df, mapping = aes(col=as.factor(ldl.status)), columns= c(   "HDL",     "TG"  ,"TC"  ,"LDL"))
##ggpairs(ldl.df, mapping = aes(col=as.factor(ldl.status)), columns= c(   "sex" ,   "smoker"  ,"race",   "age"     ,      "BMI"      ,     "waist" ))
##ggpairs(ldl.df, mapping = aes(col=as.factor(ldl.status)), columns= c(   "HDL",     "TG"  ,"TC"  ,"LDL"),title = "400 samples")


ldl.df_matrix <- ldl.df
ldl.df_matrix$Sex <- as.numeric(ifelse(ldl.df_matrix$sex == "Female", 0, 1))
ldl.df_matrix$Smoker <- as.numeric(ifelse(ldl.df_matrix$smoker == "No", 0, 1))
ldl.df_matrix$Race <- as.numeric(ifelse(ldl.df_matrix$race == "Afri", 0, 1))
#colnames(ldl.df_matrix)

###Generate heatmap
heatmap.2(cor(as.matrix(ldl.df_matrix[,c(1,5:14)]) , use = "na.or.complete", method = "spearman"),symbreaks = FALSE,cellnote = round(cor(as.matrix(ldl.df_matrix[,c(1,5:14)])),2),notecex = .7, notecol = "black", trace= 'none',margins = c(7,7))

########################################################
#Identifying significant correlations
########################################################

ldl.df_matrix2 <- ldl.df_matrix[,c(1,5:14)]
#colnames(ldl.df_matrix)


ldl.df_matrix2_cor <- rcorr(as.matrix(ldl.df_matrix2),type = "spearman")

flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}

ldl.df_matrix2_cor_flat <- flattenCorrMatrix(ldl.df_matrix2_cor$r, ldl.df_matrix2_cor$P)
ldl.df_matrix2_cor_flat$fdr <- p.adjust(ldl.df_matrix2_cor_flat$p, method = "fdr")

#FDR < 0.05 correlations with LDL status
subset(ldl.df_matrix2_cor_flat, fdr < 0.05 & row == "ldl.status")

```





After controlling for all risk factors using multivariable logistic regression, age is associated with strong statin response (p < 0.001), and to a lesser extent LDL pre-statin levels were also associated with a strong response (p < 0.05).
```{r, results='markup' }
##perform regression, SVM, and randomforest using all samples.


#GLM logistic
#############################################################################

ldl.glm.all <- glm(as.factor(ldl.status)~., data=ldl.df, family=binomial(logit))

ldl.glm.all_sum <- summary(ldl.glm.all)
#round(ldl.glm.all_sum$coefficients,3)
ldl.glm.all.pred <- predict(ldl.glm.all, ldl.df, type="response")
#Age is strongly associated with statin response after controlling for all variables.
#TG,TC,LDL, and HDL are weakly associated after controlling for other variables. 

summary(ldl.glm.all)

```

I then used SVM to generate a predictive model for statin response using all the risk factors. Predictions all had a good AUC. The AUC for Linear, radial, and polynomial are ~0.88 while sigmoid was 0.81. In each of the plots, the ability of SVM to classify strong and weak statin response is seen using age and LDL levels. Grey (0) is weak responder prediction, white is strong responder prediction (1), blue were actual weak responders, red were actual strong responders, and "x" data points were support vectors. Finally, random forest was used to generate a classifier model. LDL and TC have the biggest impact on accuracy if left out of the model (left). LDL and TC also have the purest nodes at the end of the tree (right).

```{r, results='markup' }


#SVM
#############################################################################
#provide probabilities (lin)
set.seed(1234)
ldl.svm.lin <- svm(as.factor(ldl.status) ~ ., data=ldl.df, scale=TRUE, kernel="linear", probability = TRUE)
ldl.svm.pred.lin <- predict(ldl.svm.lin, ldl.df,probability = TRUE)
ldl.svm.pred.lin.prb <- attr(ldl.svm.pred.lin, "probabilities")[, 1]

#Prediction of LDL status
table(ldl.df$ldl.status, ldl.svm.pred.lin)

roc(ldl.df$ldl.status, ldl.svm.pred.lin.prb, col = 1) 

plot(ldl.svm.lin, ldl.df, age ~ LDL, symbolPalette = c("blue", "red"), col = c(gray(0.5),"white"))

#X's = support vectors
#o's = other data points
#purple/blue  = predicted classifier
#black = actual group 0
#red = actual group 1

#provide probabilities (rad)
set.seed(1234)
ldl.svm.rad <- svm(as.factor(ldl.status) ~ ., data=ldl.df, scale=TRUE, kernel="radial", probability = TRUE)
ldl.svm.pred.rad <- predict(ldl.svm.rad, ldl.df,probability = TRUE)
ldl.svm.pred.rad.prb <- attr(ldl.svm.pred.rad, "probabilities")[, 1]
table(ldl.df$ldl.status, ldl.svm.pred.rad)

roc(ldl.df$ldl.status, ldl.svm.pred.rad.prb, col = 1) 

plot(ldl.svm.rad, ldl.df, age ~ LDL, symbolPalette = c("blue", "red"), col = c(gray(0.5),"white"))


#provide probabilities (polynomial)
set.seed(1234)
ldl.svm.pol <- svm(as.factor(ldl.status) ~ ., data=ldl.df, scale=TRUE, kernel="polynomial", probability = TRUE)
ldl.svm.pred.pol <- predict(ldl.svm.pol, ldl.df,probability = TRUE)
ldl.svm.pred.pol.prb <- attr(ldl.svm.pred.pol, "probabilities")[, 1]

table(ldl.df$ldl.status, ldl.svm.pred.pol)

roc(ldl.df$ldl.status, ldl.svm.pred.pol.prb, col = 1) 

plot(ldl.svm.pol, ldl.df,  age ~ LDL, symbolPalette = c("blue", "red"), col = c(gray(0.5),"white"))


#sigmoid
#provide probabilities (sigmoid)
set.seed(1234)
ldl.svm.sig <- svm(as.factor(ldl.status) ~ ., data=ldl.df, scale=TRUE, kernel="sigmoid", probability = TRUE)
ldl.svm.pred.sig <- predict(ldl.svm.sig, ldl.df,probability = TRUE)
ldl.svm.pred.sig.prb <- attr(ldl.svm.pred.sig, "probabilities")[, 1]
table(ldl.df$ldl.status, ldl.svm.pred.sig)

roc(ldl.df$ldl.status, ldl.svm.pred.sig.prb, col = 1) 

plot(ldl.svm.sig, ldl.df,  age ~ LDL, symbolPalette = c("blue", "red"), col = c(gray(0.5),"white"))


#RandomForest
#############################################################################


ldl.df.rf <- randomForest(as.factor(ldl.status) ~ ., data=ldl.df, ntree=100, importance=TRUE)
ldl.df.rf
#sort(ldl.df.rf$importance)
varImpPlot(ldl.df.rf,main = "Random forest results")


ldl.df.rf.pred <- predict(ldl.df.rf, ldl.df, type="prob")
rf.pred.strong <- ldl.df.rf.pred[, 2]



```

All methods were then evaluated using 10-fold cross-validation. 

```{r}


#Cross validation
#############################################################################

N = nrow(ldl.df)
K = 10
#Class version
#set.seed(1234)
#s = sample(1:K, size=N, replace=T)
#My version
#400v 
reps <- rep(1:10, each=42)
#reps <- rep(1:10, each=10)
set.seed(1234)
s = sample(reps)

table(s)

pred.outputs.svm.lin <- vector(mode="numeric", length=N)
pred.outputs.svm.rad <- vector(mode="numeric", length=N)
pred.outputs.svm.pol <- vector(mode="numeric", length=N)
pred.outputs.svm.sig <- vector(mode="numeric", length=N)

pred.outputs.rf <- vector(mode="numeric", length=N)

pred.outputs.glm <- vector(mode="numeric", length=N)

obs.outputs <- vector(mode="numeric", length=N)
offset <- 0
for(i in 1:K){
  train <- filter(ldl.df, s != i)
  test <- filter(ldl.df, s == i)
  obs.outputs[1:length(s[s==i]) + offset] <- as.factor(test$ldl.status)
  
  #SVM train/test (lin)
  svm.m.lin <- svm(as.factor(ldl.status) ~ ., data=train, scale=TRUE, kernel="linear", probability=TRUE)
  svm.pred.curr.lin <- predict(svm.m.lin, test, probability=TRUE) 
  pred.outputs.svm.lin[1:length(s[s==i]) + offset] <- attr(svm.pred.curr.lin, "probabilities")[,1]
  
  #SVM train/test (rad)
  svm.m.rad <- svm(as.factor(ldl.status) ~ ., data=train, scale=TRUE, kernel="radial", probability=TRUE)
  svm.pred.curr.rad <- predict(svm.m.rad, test, probability=TRUE) 
  pred.outputs.svm.rad[1:length(s[s==i]) + offset] <- attr(svm.pred.curr.rad, "probabilities")[,1]
  
  #SVM train/test (pol)
  svm.m.pol <- svm(as.factor(ldl.status) ~ ., data=train, scale=TRUE, kernel="polynomial", probability=TRUE)
  svm.pred.curr.pol <- predict(svm.m.pol, test, probability=TRUE) 
  pred.outputs.svm.pol[1:length(s[s==i]) + offset] <- attr(svm.pred.curr.pol, "probabilities")[,1]
  
  #SVM train/test (sig)
  svm.m.sig <- svm(as.factor(ldl.status) ~ ., data=train, scale=TRUE, kernel="sigmoid", probability=TRUE)
  svm.pred.curr.sig <- predict(svm.m.sig, test, probability=TRUE) 
  pred.outputs.svm.sig[1:length(s[s==i]) + offset] <- attr(svm.pred.curr.sig, "probabilities")[,1]
  
  
  #RF train/test
  rf <- randomForest(as.factor(ldl.status) ~ ., data=train, ntree=100)
  rf.pred.curr <- predict(rf, newdata=test, type="prob") 
  pred.outputs.rf[1:length(s[s==i]) + offset] <- rf.pred.curr[,2]
  
  #GLM train/test
  glm <- glm(as.factor(ldl.status)~., data=train, family=binomial(logit))
  glm.pred.curr <- predict(glm, test, type="response")
  pred.outputs.glm[1:length(s[s==i]) + offset] <- glm.pred.curr
  
  offset <- offset + length(s[s==i])
}




roc(obs.outputs, pred.outputs.svm.lin, ci=TRUE)
roc(obs.outputs, pred.outputs.svm.rad, ci=TRUE)
roc(obs.outputs, pred.outputs.svm.pol, ci=TRUE)
roc(obs.outputs, pred.outputs.svm.sig, ci=TRUE)
roc(obs.outputs, pred.outputs.glm, ci=TRUE)
roc(obs.outputs, pred.outputs.rf, ci=TRUE)

colorRampPalette(c('dark red','white','dark blue'), 
                 space = "Lab") 


##PLOTTING BOTH TESTING AND TRAINING (optional)

#Linear

##plot.roc(ldl.df$ldl.status, ldl.svm.pred.lin.prb, col = 1) ;par(new=TRUE)
##plot.roc(obs.outputs, pred.outputs.svm.lin, ci=TRUE, col=2) ;par(new=TRUE)

##plot.roc(ldl.df$ldl.status, ldl.svm.pred.lin.prb, col = 1) ;par(new=TRUE)
##plot.roc(obs.outputs, pred.outputs.svm.lin, ci=TRUE, col=2) ;par(new=TRUE)

#Radial
##plot.roc(ldl.df$ldl.status, ldl.svm.pred.rad.prb,col = 3) ;par(new=TRUE)
##plot.roc(obs.outputs, pred.outputs.svm.rad, ci=TRUE, col=4) ;par(new=TRUE)
#Polynomial
##plot.roc(ldl.df$ldl.status, ldl.svm.pred.pol.prb,  col = 5) ;par(new=TRUE)
##plot.roc(obs.outputs, pred.outputs.svm.pol, ci=TRUE, col= 6 ) ;par(new=TRUE)
#Sigmoid
##plot.roc(ldl.df$ldl.status, ldl.svm.pred.sig.prb,  col = 7) ;par(new=TRUE)
##plot.roc(obs.outputs, pred.outputs.svm.sig, ci=TRUE, col= 8) ;par(new=TRUE)

#Random forst
##plot.roc(ldl.df$ldl.status, rf.pred.strong, col = 9) ;par(new=TRUE)
##plot.roc(obs.outputs, pred.outputs.rf, ci=TRUE, col=10) ;par(new=TRUE)

#GLM
##plot.roc(ldl.df$ldl.status,ldl.glm.all.pred,  col = 11) ;par(new=TRUE)
##plot.roc(obs.outputs, pred.outputs.glm, ci=TRUE, col=12) ;par(new=TRUE)



```



All methods did fairly well at making predictions (AUC 0.76-0.85). Changing kernel had modest impact on prediction accuracy. Logistic regression had the best predictions, Random Forest did about as well, and SVM was not far behind. 

```{r, results='markup' }

svm.lin.roc <- roc(obs.outputs, pred.outputs.svm.lin, ci=TRUE)
svm.lin.roc
svm.rad.roc <- roc(obs.outputs, pred.outputs.svm.rad, ci=TRUE)
svm.rad.roc
svm.pol.roc <- roc(obs.outputs, pred.outputs.svm.pol, ci=TRUE)
svm.pol.roc
svm.sig.roc<- roc(obs.outputs, pred.outputs.svm.sig, ci=TRUE)
svm.sig.roc
glm.log.roc <- roc(obs.outputs, pred.outputs.glm, ci=TRUE)
glm.log.roc
rf.roc <- roc(obs.outputs, pred.outputs.rf, ci=TRUE)
rf.roc

#rf .81 -.77.81
#Linear
plot.roc(obs.outputs, pred.outputs.svm.lin, ci=TRUE, col=1 );par(new=TRUE)
#Radial
plot.roc(obs.outputs, pred.outputs.svm.rad, ci=TRUE, col=2) ;par(new=TRUE)
#Polynomial
plot.roc(obs.outputs, pred.outputs.svm.pol, ci=TRUE, col= 3 ) ;par(new=TRUE)
#Sigmoid
plot.roc(obs.outputs, pred.outputs.svm.sig, ci=TRUE, col= 4) ;par(new=TRUE)
#RF
plot.roc(obs.outputs, pred.outputs.rf, ci=TRUE, col=5) ;par(new=TRUE)
#GLM
plot.roc(obs.outputs, pred.outputs.glm, ci=TRUE, col= 6) ;par(new=TRUE)




legend("bottomright", title = "Method: Testing AUC (95%CI)", 
       legend=c(paste("SVM-linear:", round(svm.lin.roc$auc[1],2), "(",round(svm.lin.roc$ci[1],2),"-",round(svm.lin.roc$ci[3],2),")"),
                paste("SVM-radial:", round(svm.rad.roc$auc[1],2), "(",round(svm.rad.roc$ci[1],2),"-",round(svm.rad.roc$ci[3],2),")"),
                paste("SVM-polynomial:", round(svm.pol.roc$auc[1],2), "(",round(svm.pol.roc$ci[1],2),"-",round(svm.pol.roc$ci[3],2),")"),
                paste("SVM-sigmoid:", round(svm.sig.roc$auc[1],2), "(",round(svm.sig.roc$ci[1],2),"-",round(svm.sig.roc$ci[3],2),")"),
                paste("RandomForest:", round(rf.roc$auc[1],2), "(",round(rf.roc$ci[1],2),"-",round(rf.roc$ci[3],2),")"),
                paste("GLM-logistic:", round(glm.log.roc$auc[1],2), "(",round(glm.log.roc$ci[1],2),"-",round(glm.log.roc$ci[3],2),")")), col=c(1:6),lwd=1)





```


In conclusion, LDL, TC, TG, and age positively correlate stronger statin response. Statin response is associated with age and to a lesser extent lipid levels using multivariable logistic regression. All models did well at making predictions, but logistic regression did the best. Overall, the CAP study provides a useful dataset for investigating CAD and statins. Future directions including breaking up the status into more than two subgroups, investigating hwo sex and/or ancesrtry impacts the associations and predictions. Utilzing genetic and gene expression data could also be a useful predictor and characterize the molecular underpinnings of CAD. Furthermore, this strategy could also be applied to other phenortypes and diseases. 

