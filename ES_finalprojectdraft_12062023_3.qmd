---
title: "My Final Project"
subtitle: "BMIN503/EPID600 Final Project"
author: "Elaine Sang"
format: 
  html:
    toc: true
    toc-location: left
editor: visual
theme: united
embed-resources: true
editor_options: 
  chunk_output_type: inline
execute: 
  warning: false
  message: false
---

------------------------------------------------------------------------

## Overview {#sec-overview}

This project explores whether random forest modeling can be used to predict whether a random forest model using age, insurance status, gender, and race/ethnicity, etc. can predict 30-day readmissions, in-patient mortality, and discharge among patients with pulmonary hypertension receiving ICU-level care. Both training data only and 10-fold CV were used. I included all predictors and top 5 predictors. I conducted data analysis using the MIMIC-IV dataset.

## Introduction {#sec-introduction}

Pulmonary hypertension (PH) is a chronic disease characterized by having a mean pulmonary arterial pressure (mPAP) of at least 25 mmHg at rest (Maron, 2023). The World Health Organization classifies PH into five different groups: pulmonary arterial hypertension (PAH), PH due to chronic lung disease, chronic thromboembolic PH, PH from unknown source, and PH due to left-sided heart disease (Mandras et al., 2020; Mullin & Ventetuolo, 2021). Regardless, the higher mPAP characterized within PH contributes to increase strain within the heart as it pumps blood to the lungs via the left pulmonary artery. As this chronic disease is progressive and does not have a cure, PH will eventually lead to right-sided heart failure and hemodynamic collapse.

Naturally, patients with PH have poor morbidity and mortality. They experience debilitating signs and symptoms such as shortness of breath, chest pain, cardiac arrhythmias, syncope, and fluid retention, all of which negatively impact one's ability to participate in activities of daily living (Mandras et al., 2020). One study found that the 30-day readmission rate for patients with PH is 19%, which is higher than that of the general hospitalized population (Bhattacharya et al., 2020). Another study estimated that 50% of adult patients with PH will due within 7 years, most of them within the intensive care unit (ICU) (Gall et al., 2017). In fact, the PH mortality rate within the ICU is between 32% to 41% (Poor & Ventetuolo, 2012). Despite these poor health outcomes, the patient population with PH is seriously understudied, leading to deficiencies in care.

Machine learning approaches have been used to improving diagnosing PH. However, none have focused on predicting in-hospital mortality, discharge to hospice, and 30-day readmissions. Evidence to fill these knowledge gaps may inform future policies, individualized care plans, precision medicine, and clinical practice guidelines to improve care among patients with pulmonary hypertension. For instance, predicting patients with PH receiving ICU care who likely to die in the hospital or be discharged to hospice may improve palliative care utilization within this patient population. Predicting 30-day readmissions may lead to quality care initiatives for this patient population.

### Project Objectives

For this project, I conducted an exploratory study using random forest to:

1.  Predict 30-day readmissions vs. not among adult PH patients within the ICU

2.  Predict in-hospital mortality or discharge to hospice vs. not to hospice among adult PH patient within the ICU.

I used 1000 trees, with and without 10-fold cross validation, all predictors and top 5 predictors for random forest modeling.

## Methods {#sec-methods}

### About MIMIC-IV Dataset

The Medical Information Mart for Intensive Care IV (MIMIC-IV) dataset was used for this project as it contains de-identified data from patients admitted to the intensive care units (ICU) of Beth Israel Deaconess Medical Center from 2008 to 2019 (Johnson et al., 2023). This dataset contains data from 299,712 patients (subject_id) and 431,231 hospital encounters (hadm_id). There are more admission encounters than patients because some patients may be readmitted multiple times between 2008 to 2019. In this project, I only considered the patients' characteristics from the first admission encounter. In other words: if patient A was admitted on 1/1/2008 and then readmitted on 1/20/2008, only the characteristics from patient A's hospital encounter for 1/1/2008 will be considered in predicting 30-day readmission and in-hospital mortality/discharge to hospice. The MIMIC-IV dataset contains data coded with ICD-9 and ICD-10. The data user agreement was signed and the downloaded from PhysioNet, which is organized by MIT. The link to the dataset is [here](https://physionet.org/content/mimiciv/2.2/).

### Inclusion and Exclusion Criteria

+--------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Inclusion Criteria                                                                                                       | Exclusion Criteria                                                                                                                                                                                                             |
+==========================================================================================================================+================================================================================================================================================================================================================================+
| 1.  Adult patients (age 18+ years old)                                                                                   | 1.  Observation status (length of stay less than 2 days)                                                                                                                                                                       |
| 2.  Diagnosed with PH according to the ICD-9 or ICD-10 code                                                              | 2.  Discharged to psych facility, other facility, or other healthcare facility as unable to confirm whether they were truly discharged alive to home or post-acute care or if they transferred to another acute care hospital. |
| 3.  Received ICU level care                                                                                              | 3.  For predicting 30-day readmission only: Died within the hospital or discharged to hospice.                                                                                                                                 |
| 4.  Discharge to home, against medical advice, home health, rehab, skilled nursing facility, or long term care facility. |                                                                                                                                                                                                                                |
+--------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

### Data Cleaning

#### Loading R Packages

The R packages below were loaded to complete this project:

```{r}
#| label: load-packages
library(dplyr) #to clean the data
library(naniar) #convert blank data into NAs
library(comorbidity) # to calcuate get comorbidity scores
library(gtsummary) # for descriptive data analysis 
library(ggplot2) # to make plots
library(kernlab) # for Support Vector Machine (SVM) 
library(randomForest) # for random forest
library(tidymodels) #machine learning 
tidymodels_prefer()
library(vip) #to get the most important predictors
library(RColorBrewer) #to make colorful graphs
library(cowplot) # to arrange plots
```

#### Loading MIMIC-IV Files

The following files from the MIMIC-IV dataset were imported into R:

```{r}

#file with the ICD-9 and ICD-10 codes and corresponding diagnoses. Not be directly used in data analysis but is needed to identify pulmonary hypertension (PH) patients. 
ICD_code_diagnosis <- read.csv("/Users/esang/Desktop/Upenn courses/fall 2023/BMIN 503/final project/mimic-iv-2.2/hosp/d_icd_diagnoses.csv.gz",header = TRUE, sep = ",")

#file with each patient's diagnoses and comorbidities 
all_patient_diagnoses <- read.csv("/Users/esang/Desktop/Upenn courses/fall 2023/BMIN 503/final project/mimic-iv-2.2/hosp/diagnoses_icd.csv.gz",header = TRUE, sep = ",")

#file with each patient's admissions information, which includes admission encouter (hadm_id), admit and discharge time, admission type (urgent, ER, observation, etc), discharge location (home, hospice, home health care, etc.), insurance (other, medicaid, medicare),language, martial status, race, etc. 
pt_admission_info <- read.csv("/Users/esang/Desktop/Upenn courses/fall 2023/BMIN 503/final project/mimic-iv-2.2/hosp/admissions.csv.gz",header = TRUE, sep = ",")

#file with each patients' personal characteristics, such as gender and age
pt_gender_age <- read.csv("/Users/esang/Desktop/Upenn courses/fall 2023/BMIN 503/final project/mimic-iv-2.2/hosp/patients.csv.gz",header = TRUE, sep = ",")

#file with patient service information
services <- read.csv("/Users/esang/Desktop/Upenn courses/fall 2023/BMIN 503/final project/mimic-iv-2.2/hosp/services.csv.gz")

```

#### MIMIC-IV File Cleaning and Data Manipulation

After importing the MIMIC-IV files above, I used the package `dplyr` to clean the files and selected variables for this project. In addition, I used the package `naniar` to convert blank data into NAs to assess for missing data later.

```{r}

#pt_admission_info
pt_admission_info_2 <- pt_admission_info |>
  select("subject_id", "hadm_id", "admittime", "dischtime", "admission_type", "insurance", "marital_status", "race", "hospital_expire_flag", "discharge_location")

pt_admission_info_2 <- replace_with_na(pt_admission_info_2, replace = list(subject_id = ""))
pt_admission_info_2 <- replace_with_na(pt_admission_info_2, replace = list(hadm_id = ""))
pt_admission_info_2 <- replace_with_na(pt_admission_info_2, replace = list(admittime = ""))
pt_admission_info_2 <- replace_with_na(pt_admission_info_2, replace = list(dischtime = ""))
pt_admission_info_2 <- replace_with_na(pt_admission_info_2, replace = list(admission_type = ""))
pt_admission_info_2 <- replace_with_na(pt_admission_info_2, replace = list(insurance = ""))
pt_admission_info_2 <- replace_with_na(pt_admission_info_2, replace = list(marital_status = ""))
pt_admission_info_2 <- replace_with_na(pt_admission_info_2, replace = list(race = ""))
pt_admission_info_2 <- replace_with_na(pt_admission_info_2, replace = list(hospital_expire_flag = ""))
pt_admission_info_2 <- replace_with_na(pt_admission_info_2, replace = list(discharge_location = ""))

#pt_gender_age
pt_gender_age_2 <- pt_gender_age |>
  select("subject_id", "gender", "anchor_age")

pt_gender_age_2 <- replace_with_na(pt_gender_age_2, replace = list(subject_id = ""))
pt_gender_age_2 <- replace_with_na(pt_gender_age_2, replace = list(gender = ""))
pt_gender_age_2 <- replace_with_na(pt_gender_age_2, replace = list(anchor_age = ""))


#services
services_2 <- services |>
  select("subject_id", "hadm_id", "curr_service", "transfertime")

services_2 <- replace_with_na(services_2, replace = list(subject_id = ""))
services_2 <- replace_with_na(services_2, replace = list(hadm_id = ""))
services_2 <- replace_with_na(services_2, replace = list(curr_service = ""))
services_2 <- replace_with_na(services_2, replace = list(transfertime = ""))

#all_patient_diagnoses
all_patient_diagnoses_2 <- all_patient_diagnoses |>
  select("subject_id", "hadm_id", "icd_code", "icd_version", "seq_num")

all_patient_diagnoses_2 <- replace_with_na(all_patient_diagnoses_2, replace = list(subject_id = ""))
all_patient_diagnoses_2 <- replace_with_na(all_patient_diagnoses_2, replace = list(hadm_id = ""))
all_patient_diagnoses_2 <- replace_with_na(all_patient_diagnoses_2, replace = list(icd_code = ""))
all_patient_diagnoses_2 <- replace_with_na(all_patient_diagnoses_2, replace = list(icd_version = ""))
all_patient_diagnoses_2 <- replace_with_na(all_patient_diagnoses_2, replace = list(seq_num = ""))

```

A new file, PH_sample, was created specifically for patients diagnosed with PH. Specifically, it was created from all_patient_diagnoses_2 to only include those specifically diagnosed with PH. This file was created by first retrieving the ICD-9 and ICD-10 codes for PH. One of the retrieved ICD-10 codes is P2930, which references "pulmonary hypertension of newborn". Given that this project's focus is on adults, I did not move forward with this ICD code.

```{r}

ICD_PH <- ICD_code_diagnosis |>
  filter(grepl("pulmonary.*hypertension", long_title, ignore.case = TRUE))

#print(ICD_PH)

PH_sample <- all_patient_diagnoses_2 |>
  filter(
    (icd_version == 9 & icd_code == '4160') | 
      (icd_version == 10 & icd_code %in% c('I270', 'I272', 'I2720', 'I2721', 'I2722', 'I2723', 'I2724', 'I2729'))
  )
```

Data manipulation on the files were done to categorize existing variables and add new variables. Existing variables were renamed for data management purposes.

Data manipulation for pt_admission_info_2:

```{r}
#pt_admission_info_2
#First, look at pt_admission_info_2: I want to get length of stay, whether the patient died, martial status, and race/ethnicity

#calcuate length of stay using admittime and dischtime

pt_admission_info_2$admission_time <- as.POSIXct(pt_admission_info_2$admittime)
pt_admission_info_2$discharge_time <- as.POSIXct(pt_admission_info_2$dischtime)

#create new variable and calcuate length of stay 

pt_admission_info_2$length_of_stay <- as.numeric(difftime(pt_admission_info_2$discharge_time, pt_admission_info_2$admission_time, units = "days"))

#only include those with in-patient status, meaning that the patients were hospitalized for at least 2 days. Those who were admitted for less than 2 days are considered as observation status. 
pt_admission_info_2 <- pt_admission_info_2 |>
  filter(length_of_stay >= 2)

#examine admission type and dichotomize the variables
#contains AMBULATORY OBSERVATION, EU OBSERVATION, URGENT, DIRECT EMER., EW EMER., DIRECT OBSERVATION, OBSERVATION ADMIT, ELECTIVE , and SURGICAL SAME DAY ADMISSION. Dichotomize to elective or emergency 

pt_admission_info_2$admit_category <- ifelse(pt_admission_info_2$admission_type %in% c("AMBULATORY OBSERVATION", "EU OBSERVATION", "URGENT", "DIRECT EMER.", "EW EMER.", "DIRECT OBSERVATION", "OBSERVATION ADMIT"), "emergency", ifelse(pt_admission_info_2$admission_type %in% c("ELECTIVE", "SURGICAL SAME DAY ADMISSION"), "elective", NA))

#examine marital_status and dichotomize the variables DIVORCED, MARRIED, SINGLE, WIDOWED to not_married or married. 

pt_admission_info_2$married_or_not <- ifelse(pt_admission_info_2$marital_status %in% c("DIVORCED", "WIDOWED", "SINGLE"), "not_married", ifelse(pt_admission_info_2$marital_status == "MARRIED", "married", NA))

#examine race and categorize the variables into unknown, asian, black, hispanic/latino, white, and other. 

pt_admission_info_2$race_category <- ifelse(pt_admission_info_2$race %in% c("UNKNOWN", "PATIENT DECLINED TO ANSWER", "UNABLE TO OBTAIN"), "unknown", ifelse(pt_admission_info_2$race %in% c("ASIAN", "ASIAN - CHINESE", "ASIAN - SOUTH EAST ASIAN", "ASIAN - ASIAN INDIAN", "ASIAN - KOREAN"), "asian", ifelse(pt_admission_info_2$race %in% c("BLACK/AFRICAN", "BLACK/CAPE VERDEAN", "BLACK/AFRICAN AMERICAN", "BLACK/CARIBBEAN ISLAND"), "black", ifelse(pt_admission_info_2$race %in% c("HISPANIC OR LATINO", "HISPANIC/LATINO - COLUMBIAN", "HISPANIC/LATINO - DOMINICAN", "HISPANIC/LATINO - HONDURAN", "HISPANIC/LATINO - PUERTO RICAN", "HISPANIC/LATINO - CENTRAL AMERICAN", "HISPANIC/LATINO - CUBAN", "HISPANIC/LATINO - GUATEMALA", "HISPANIC/LATINO - MEXICAN", "HISPANIC/LATINO - SALVADORAN", "HISPANIC/LATINO - GUATEMALAN"), "hispanic/latino", ifelse(pt_admission_info_2$race %in% c("WHITE", "WHITE - EASTERN EUROPEAN", "WHITE - RUSSIAN", "WHITE - BRAZILIAN", "WHITE - OTHER EUROPEAN"), "white", ifelse(pt_admission_info_2$race %in% c("AMERICAN INDIAN/ALASKA NATIVE", "MULTIPLE RACE/ETHNICITY", "OTHER", "PORTUGUESE", "NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER", "SOUTH AMERICAN"), "other", NA))))))

#sum(is.na(pt_admission_info_2$race_category))#no missing values                                                                                                                   #pt_admission_info_2$discharge_location, also consider expired flag

#examine discharge location and hospital_expire_flag and categorize variables 
#only interested in those who were discharged home or assisted living, long term care or snf, home health, rehab, hospice, or against medical advice. This is because I am unable to confirm whether those discharged to psych facility, other healthcare facility, or other facilities were truly discharged to home or post-acute care.   

pt_admission_info_2 <- pt_admission_info_2 %>%
  filter((discharge_location %in% c("CHRONIC/LONG TERM ACUTE CARE", "HOME HEALTH CARE", "REHAB", "DIED", "HOSPICE", "SKILLED NURSING FACILITY", "ASSISTED LIVING", "HOME", "AGAINST ADVICE")))

#categorize discharge_location by died or hospice, long-term, skilled nursing, rehab care, home health, home or assisted living, or against medical advice
pt_admission_info_2$discharge_category <- ifelse(
  pt_admission_info_2$discharge_location %in% c("DIED", "HOSPICE") |
    pt_admission_info_2$hospital_expire_flag == 1,
  "died or hospice",
  ifelse(
    pt_admission_info_2$discharge_location %in% c("CHRONIC/LONG TERM ACUTE CARE", "REHAB", "SKILLED NURSING FACILITY"),
    "long-term, skilled nursing, rehab care",
    ifelse(
      pt_admission_info_2$discharge_location == "HOME HEALTH CARE", "home health",
      ifelse(pt_admission_info_2$discharge_location %in% c("HOME", "ASSISTED LIVING"),
             "home or assisted living",
             ifelse(pt_admission_info_2$discharge_location %in% c("AGAINST ADVICE"),
                    "against medical advice", NA )))))


#sum(is.na(pt_admission_info_2$discharge_category)) #ensure that none within discharge_category were coded as zero. 


#create new column for died/hospice vs. not. This variable is important when predicting in-patient/hospital death or discharge to hospice vs. discharged alive. 

pt_admission_info_2$died_hospice <- ifelse(pt_admission_info_2$discharge_category == "died or hospice", "yes", "no")


#examine insurance and categorize insurance by Medicaid and Medicare or Other. This is so that social determinants of health (Medicaid) can be included in the random forest models. 

#categorize insurance by Medicaid and Medicare or Other, new variable: insurance_category
pt_admission_info_2$insurance_category <- ifelse(pt_admission_info_2$insurance == "Medicaid", "Medicaid", ifelse(pt_admission_info_2$insurance %in% c("Medicare", "Other"), "Medicare or Other", NA))


```

Data manipulation for pt_gender_age_2:

```{r}
#look at gender 
pt_gender_age_2$gender_category <- ifelse(pt_gender_age_2$gender == "F", "female", ifelse(pt_gender_age_2$gender == "M", "male", NA))

#pt_gender_age_2$age
pt_gender_age_2$age <- pt_gender_age_2$anchor_age

#I am only including those that have an age of 18 or older. This is because I am interested in adults with PH. 
pt_gender_age_2 <- pt_gender_age_2 |>
  filter(age >= 18)

#As there are no hadm_id in pt_gender_age_2 to reflect admission encounter, see if there are any duplicate subject IDs. 

#length(unique(pt_gender_age_2$subject_id)) == nrow(pt_gender_age_2)

#both of them are 299712, which suggest each subject id in pt_gender_age_2 is unique

```

Data manipulation for services_2:

```{r}


#see how many hospital encounters have duplicate services and then only keeping the first one. This is to ensure that only the first admission encounter is included. 
#sum(duplicated(services_2$hadm_id)) #36798 duplicated 

#remove duplicates
services_2 <- services_2 |>
  group_by(hadm_id) |>
  arrange(hadm_id, transfertime) |>   
  distinct(hadm_id, .keep_all = TRUE) 

#Create a new variable named current_service_cat which has medicine, surgery or trauma, and other
services_2$current_service_cat <- ifelse(services_2$curr_service %in% c("CMED", "MED", "NMED", "OMED"), "medicine", ifelse(services_2$curr_service %in% c("CSURG", "NSURG", "ORTHO", "PSURG", "SURG", "TRAUM", "TSURG", "VSURG", "DENT", "ENT", "EYE", "GU", "GYN", "OBS", "PSYCH"), "other", NA))

#sum(is.na(services_2$current_service_cat))#no missing values   

```

Data manipulation for PH_sample:

```{r}

#sum(duplicated(PH_sample$hadm_id)) # 38 duplicates, meaning that 38 are actually the same hospital encounter and pulmonary hypertension was actually coded twice. These patients may have different ICD-9 or ICD-10 codes representing different types of PH. 

#Of the duplicates, I only kept the hadm_id with the highest seq_num.Seq_num is the rank of the diagnosis. Lower seq_num means higher rank. Thus, I wanted to include only the highest rank ICD-9/ICD-10 for PH for these 38 duplicates. 

PH_sample_1 <- PH_sample |>
  group_by(hadm_id) |>
  filter(seq_num == min(seq_num)) 

#sum(duplicated(PH_sample_1$hadm_id)) #0 duplicates of hadm_id. 

#As mentioned previously, different pulmonary hypertension ICD codes mean different types of pulmonary hypertension. After consulting with Dr. Lea Ann Matura, I decided divide the different PH into two categories: 1. Pulmonary arterial hypertension and 2. Other pulmonary hypertension. 

#Use ICD codes to seperate the different types of pulmonary hypertension
PH_sample_1$PH_type <- ifelse(PH_sample_1$icd_code %in% c('4160', 'I270', '12721'), "Pulmonary arterial hypertension ", "Other pulmonary hypertension")

#sum(is.na(PH_sample_1$PH_type)) #no missing values, ensures that the PH_type has been coded to all. 

```

Data manipulation for all_patient_diagnosis_2 is below. I separated ICD-9 and ICD-10 and calculated Elixhauser comorbidity score accordingly using the `comorbidity` package.

```{r}
#I seperated all_patient_diagnoses_2 based on whether ICD-9 or ICD-10 was used.

ICD_9_sample <- all_patient_diagnoses_2 |>
  filter(
    (icd_version == 9))

ICD_10_sample <- all_patient_diagnoses_2 |>
  filter((icd_version == 10))

#Then I collapsed all the icd_codes into one row alongside their respective subject_id and hadm_id and calcuated Elixhauser comorbidity scores. Start with ICD_9_sample
patient_diagnoses_9 <- ICD_9_sample |>
  group_by(subject_id, hadm_id) |>
  dplyr::summarize(icd_code = paste(icd_code, collapse = " "))

#used the comorbidity package. 
icd9_como <- comorbidity(x = patient_diagnoses_9, id = "hadm_id", code = "icd_code", map = "elixhauser_icd9_quan", assign0 = FALSE, labelled = TRUE, tidy.codes = TRUE)

#Calcuate Elxihauser score per hadm_id and added it to patient_diagnoses_9

patient_diagnoses_9$elixhauser_score <- score(icd9_como, weights = "vw", assign0 = FALSE)

#Next is ICD_10_sample
patient_diagnoses_10 <- ICD_10_sample |>
  group_by(subject_id, hadm_id) |>
  dplyr::summarize(icd_code = paste(icd_code, collapse = " "))

icd10_como <- comorbidity(x = patient_diagnoses_10, id = "hadm_id", code = "icd_code", map = "elixhauser_icd10_quan", assign0 = FALSE, labelled = TRUE, tidy.codes = TRUE)

patient_diagnoses_10$elixhauser_score <- score(icd10_como, weights = "vw", assign0 = FALSE)

#combine the ICD-9 and ICD-10 back together. 
patient_comorbidity_scores <- rbind(patient_diagnoses_10, patient_diagnoses_9)

```

After completing data manipulation, I joined the files for data analysis purposes. The R code `inner_join` was used for this purpose.

Joined PH_sample_1 and patient_comorbidity_scores

```{r}

#join PH_sample_1 with patient_comorbidity_scores using inner_join 

PH_comorbidity <- inner_join(PH_sample_1, patient_comorbidity_scores, by = c("hadm_id"))
#head(PH_comorbidity)

#sum(duplicated(PH_comorbidity$hadm_id)) #no duplicate hadm_id or hospital encounters.

#PH_comorbidity represents those with pulmonary hypertension and their comorbidities. 
```

Joined PH_comorbidity with services_2:

```{r}

PH_comorbidity_service <- inner_join(PH_comorbidity, services_2, by = c("hadm_id"))
#head(PH_comorbidity_service)
#sum(duplicated(PH_comorbidity_service$hadm_id))#no duplicate hadm_id or hospital encounters.
#PH_comorbidity_services adds the service caring for those with PH. 

```

I joined PH_comorbidity_service and pt_admission_info_2. I also calculated 30-day readmissions (yes or no) using the joined file.

```{r}


#join PH_sample (dataset with all with PH) and pt_admission_info_2
PH_como_service_admission <- inner_join(PH_comorbidity_service, pt_admission_info_2, by = c("hadm_id"))

#I received the admission information for those with pulmonary hypertension. Thus, I calcuated 30 day readmissions- or whether patients were readmitted within 30 days or after 30 days. 

PH_como_service_admission_30day <- PH_como_service_admission |>
  group_by(subject_id.x) |>
  arrange(admission_time) |>
  mutate(time_to_readmission = abs((difftime(dplyr::lag(discharge_time), admission_time, units="days")))) |>
  mutate(readmision30days = ifelse(is.na(time_to_readmission) | time_to_readmission > 30, "No", "Yes")) # Yes are for those that were readmitted within 30 days, No are for those that were readmitted after 30 days or never readmitted. 

#get the subject_ids who were readmitted within 30 days
readmit_ids <- PH_como_service_admission_30day |>
  filter(readmision30days == "Yes") |>
  pull(subject_id.x) |>
  unique()

#Ensure that subject_ids who are readmitted within 30 days will have a yes for the variable readmision30days, even for the first hospital encounter.
PH_como_service_admission_30day <- PH_como_service_admission_30day |>
  mutate(readmision30days = ifelse(subject_id.x %in% readmit_ids, "Yes", "No"))

##As there are multiple hadm_ids per subject_id, I kept the earliest admission and remove the rest. This is to avoid duplicate patients. I used admittime instead of admission_time to filter because the filter must contain a logical vector (which is admittime), not a <POSIXct/POSIXt> object (which is admission_time) I also dropped -subject_id.y and -time_to_readmission to avoid confusion. 
PH_como_service_admission30_no_dup <- PH_como_service_admission_30day |>
  group_by(subject_id.x) |>
  filter(admittime == min(admittime))|>
  select(-subject_id.y, -time_to_readmission) 

#sum(duplicated(PH_como_service_admission30_no_dup$subject_id.x))#ensure that there are no duplicate subject_ids. This means means that each row within the file represents a unique patient.  

```

Joined PH_como_service_admission_no_dup and pt_gender_age_2. I joined these files last as pt_gender_age_2 does not contain hadm_id.

```{r}

#join PH_como_service_admission30_no_dup and pt_gender_age_2

PH_como_service_admission_gender_age <- inner_join(PH_como_service_admission30_no_dup, pt_gender_age_2, by = c("subject_id.x" = "subject_id"))

```

Further data cleaning was done after joining all the tables. Specifically, I kept the variables needed for analysis and removed the rest to avoid confusion and stay organized.

```{r}

#get all the variables of PH_admission_names_characteristics
#colnames(PH_como_service_admission_gender_age)

final_variables_subjects <- PH_como_service_admission_gender_age |>
  select("subject_id.x", "elixhauser_score", "current_service_cat", "admit_category", "length_of_stay", "discharge_category", "died_hospice", "PH_type", "married_or_not", "gender_category", "race_category", "insurance_category","age", "readmision30days") 

#head(final_variables_subjects)

#Subject_id.x is not used for analysis. Before getting rid of subject_id.x, ensure one more time that the rows represent different subject_id.x. This was done by ensuring that there are no duplicate subject_id.x

#sum(duplicated(final_variables_subjects$subject_id.x)) #no duplicates. 

#now remove subject_id.x from the analysis 

final_variables <- final_variables_subjects[, !names(final_variables_subjects) %in% "subject_id.x"]

#head(final_variables)# no more subject_id.x

#remove rows with missing values 
final_variables_no_na <- na.omit(final_variables) 

```

The structure of final_variables_no_na was examined.

```{r}
str(final_variables_no_na)
```

As one can see from the structure above, numeric variables include age, elixhauser_score, and length_of_stay. Categorical variables include current_service_cat, admit_category, discharge_category, PH_type, married_or_not, gender_category, race_category, insurance_category, readmision30days, and died_hospice. This is important to remember for descriptive data analysis.

The file, final_variables_no_na, was divided into two files: **1.)** readmit_30 and **2.)** hospital_death_hospice. The file readmit_30 was used to predict patients likely to be readmitted within 30 days vs. not. It excluded those who died or were discharged to hospice. The outcome variable for **readmit_30** was **readmission30days**. The other file, hospital_death_hospice, was used to predict in-hospital mortality or discharge to hospice vs. not. The variables, discharge_category and readmission30days, were removed from hospital_death_hospice was they are not needed to predict patients in-hospital death and/or discharge to hospice. The outcome variable for **hospital_death_hospice** was **died_hospice**.

```{r}
#making the file readmit_30.

readmit_30 <- final_variables_no_na[final_variables_no_na$discharge_category != "died or hospice" | final_variables_no_na$died_hospice != "yes", ]

#make sure the answer is 0, patients who died or were transfered to hospice should be excluded.
sum(readmit_30$discharge_category == "died or hospice" | readmit_30$died_hospice == "yes") == 0

#now drop the variable died_hospice as all the remaining patients in readmit_30 have "no" for this. 
readmit_30 <- readmit_30 |>
  select(-died_hospice) 

#making the file hospital_death_hospice
hospital_death_hospice <- final_variables_no_na |>
  select(-discharge_category, -readmision30days)
```

#### Factoring Variables

Most variables in readmit_30 and hospital_death_hospice were factored in preparation for random forest analysis. In both files, age, length_of_stay, and elixhauser_score were not factored as they were already numeric and integers. This was evident when I analyzed the structure of final_variables_no_na via `str(final_variables_no_na)`. As previously mentioned, readmit_30 and hospital_death_hospice were directly derived from final_variables_no_na.

Below is the code I used to factor variables in readmit_30. I copied readmit_30 into readmit_30_factor and used the file, readmit_30_factor, for factoring.

```{r}
#first factor readmit_30
readmit_30_factor <- readmit_30


readmit_30_factor$PH_type <- as.factor(readmit_30_factor$PH_type)
#readmit_30_factor$PH_type <- as.numeric(readmit_30_factor$PH_type) - 1

table(readmit_30$married_or_not)
#married_or_not         
readmit_30_factor <- readmit_30_factor |>
  mutate(married_or_not = factor(married_or_not, levels = c("not_married", "married"), labels = c(0,1)))

#race_category
readmit_30_factor <- readmit_30_factor |>
  mutate(race_category = factor(race_category, levels = c("white", "black", "hispanic/latino", "asian", "other", "unknown"), labels = c(0, 1, 2, 3, 4, 5)))

#discharge_category
readmit_30_factor <- readmit_30_factor |>
  mutate(discharge_category = factor(discharge_category, levels = c("home or assisted living", "home health", "long-term, skilled nursing, rehab care", "against medical advice"), labels = c(0, 1, 2, 3)))

#insurance_category
readmit_30_factor <- readmit_30_factor |>
  mutate(insurance_category = factor(insurance_category, levels = c("Medicare or Other", "Medicaid"), labels = c(0,1)))

#current_service_cat
readmit_30_factor <- readmit_30_factor |>
  mutate(current_service_cat = factor(current_service_cat, levels = c("other", "medicine"), labels = c(0,1)))

#gender
readmit_30_factor <- readmit_30_factor |>
  mutate(gender_category = factor(gender_category, levels = c("male", "female"), labels = c(0,1)))

#admit_category
readmit_30_factor <- readmit_30_factor |>
  mutate(admit_category = factor(admit_category, levels = c("elective", "emergency"), labels = c(0, 1)))

#readmision30days
readmit_30_factor <- readmit_30_factor |>
  mutate(readmision30days = factor(readmision30days, levels = c("No","Yes"), labels = c(0, 1)))


#sum(is.na(readmit_30_factor)) #insure that there are no NAs throughout factoring readmit_30_factor 

#head(readmit_30_factor)
```

Below is the code I used to factor variables in hospital_death_hospice. I copied hospital_death_hospice into hospital_death_hospice_factor and used the file, hospital_death_hospice_factor, for factoring.

```{r}
#then factor hospital_death_hospice
hospital_death_hospice_factor <- hospital_death_hospice

#PH type 
hospital_death_hospice_factor$PH_type <- as.factor(hospital_death_hospice_factor$PH_type)

#married_or_not         
hospital_death_hospice_factor <- hospital_death_hospice_factor |>
  mutate(married_or_not = factor(married_or_not, levels = c("not_married", "married"), labels = c(0,1)))


#race_category
hospital_death_hospice_factor <- hospital_death_hospice_factor |>
  mutate(race_category = factor(race_category, levels = c("white", "black", "hispanic/latino", "asian", "other", "unknown"), labels = c(0, 1, 2, 3, 4, 5)))

#insurance_category
hospital_death_hospice_factor <- hospital_death_hospice_factor |>
  mutate(insurance_category = factor(insurance_category, levels = c("Medicare or Other", "Medicaid"), labels = c(0,1)))

#current_service_cat
hospital_death_hospice_factor <- hospital_death_hospice_factor|>
  mutate(current_service_cat = factor(current_service_cat, levels = c("other", "medicine"), labels = c(0,1)))

#gender
hospital_death_hospice_factor <- hospital_death_hospice_factor |>
  mutate(gender_category = factor(gender_category, levels = c("male", "female"), labels = c(0,1)))

#admit_category
hospital_death_hospice_factor <- hospital_death_hospice_factor |>
  mutate(admit_category = factor(admit_category, levels = c("elective", "emergency"), labels = c(0, 1)))

#died_hospice
hospital_death_hospice_factor <- hospital_death_hospice_factor |>
  mutate(died_hospice = factor(died_hospice, levels = c("no", "yes"), labels = c(0, 1)))


#sum(is.na(hospital_death_hospice_factor)) #insure that there are no NAs while factoring hospital_death_hospice_factor

#head(hospital_death_hospice_factor)
```

### Descriptive Data Analysis

Mean, standard deviation, and median were calculated for numeric variables. Frequencies were calculated for categorical variables. The total number of patients was also calculated Frequencies for readmission30days were calculated later, after I created a subset file to exclude patients who died or went to hospice. The package `gtsummary` was used for descriptive data analysis. Meanwhile, the package `ggplot2` was used for creating descriptive plots. The package `cowplot` was used to arrange the plots.

Below, I calculated and stored descriptive statistics for all patients within this project.

```{r}

#final_variables_no_na was used for descriptive data analysis for all patients within this project. This includes patients for predicting 30 day readmissions vs. not and patients for predicting in-hospital death and/or discharge to hospice vs. not. 
descriptive_statistics <- final_variables_no_na |> 
  select (-readmision30days) |>
  tbl_summary() 


```

More detailed descriptive statistics were calculated for both files: **1.)** readmit_30 and **2.)** hospital_death_hospice

Below is the descriptive data analysis code for readmit_30, which is the file used to predict 30 day readmissions vs. not. Box plots and bar-charts were also made and stored to visualize the distribution.

```{r}

#readmit_30
descriptive_30dayreadmission <- readmit_30 |> 
  tbl_summary(by = readmision30days) |>
  add_p()

#how many patients, 3124
number_readmit <- nrow(readmit_30)

#get percentage of PH patients readmitted within 30 days. In this dataset, it is 10.97951%
percent30day <- prop.table(table(readmit_30$readmision30days)) * 100

#discharge_category
readmit30_discharge_category <- ggplot(data = readmit_30, aes(x = readmision30days, fill = discharge_category)) +
  geom_bar(position = "dodge") +
  labs(title = "Initial Discharge Disposition", x = "30-day Readmit", y = "Frequency of PH Patients")

#race_category
readmit30_race_category <- ggplot(data = readmit_30, aes(x = readmision30days, fill = race_category)) +
  geom_bar(position = "dodge") +
  labs(title = "Race/Ethnicity", x = "30-day Readmit", y = "Frequency of PH Patients")


#current_service_cat
readmit30_current_service_cat <- ggplot(data = readmit_30, aes(x = readmision30days, fill = current_service_cat)) +
  geom_bar(position = "dodge") +
  labs(title = "Hospital Service", x = "30-day Readmit", y = "Frequency of PH Patients")

#PH_type
readmit30_PH_type <- ggplot(data = readmit_30, aes(x = readmision30days, fill = PH_type)) +
  geom_bar(position = "dodge") +
  labs(title = "PH type", x = "30-day Readmit", y = "Frequency of PH Patients")

#insurance_category
readmit30_insurance_category <- ggplot(data = readmit_30, aes(x = readmision30days, fill = insurance_category)) +
  geom_bar(position = "dodge") +
  labs(title = "Insurance Category", x = "30-day Readmit", y = "Frequency of PH Patients")

#admit_category
readmit30_admit_category <- ggplot(data = readmit_30, aes(x = readmision30days, fill = admit_category)) +
  geom_bar(position = "dodge") +
  labs(title = "Admit Category", x = "30-day Readmit", y = "Frequency of PH Patients")

#gender_category
readmit30_gender_category <- ggplot(data = readmit_30, aes(x = readmision30days, fill = gender_category)) +
  geom_bar(position = "dodge") +
  labs(title = "Gender Category", x = "30-day Readmit", y = "Frequency of PH Patients")

#Find mean, median, and SD for numeric variables
#elixhauser_score
meanmedianSD_30comorbidity <- summary(readmit_30$elixhauser_score)

comorbidity_30sd <- sd(readmit_30$elixhauser_score)

# boxplot for elixhauser_score
boxplot_30day_comorbidity <- ggplot(readmit_30, aes(x = readmision30days, y = elixhauser_score)) +
  geom_boxplot() +
  labs(title = "Elixhauser Score by 30-day Readmission", x = "30-day Readmission", y = "Elixhauser Comorbidity Score") +
  theme_minimal()

#age
meanmedianSD_30age <- summary(readmit_30$age)

comorbidity_30age <- sd(readmit_30$age)

# boxplot for age
boxplot_30day_age <- ggplot(readmit_30, aes(x = readmision30days, y = age)) +
  geom_boxplot() +
  labs(title = "Age by 30-day Readmission", x = "30-day Readmission", y = "Age") +
  theme_minimal()

#length_of_stay
meanmedianSD_30LOS <- summary(readmit_30$length_of_stay)

LOS_30age <- sd(readmit_30$length_of_stay)

# boxplot for length_of_stay
boxplot_30day_length_of_stay <- ggplot(readmit_30, aes(x = readmision30days, y = length_of_stay)) +
  geom_boxplot() +
  labs(title = "Length of Stay by 30-day Readmission", x = "30-day Readmission", y = "Length of Stay") +
  theme_minimal()



```

Below is the descriptive analysis for hospital_death_hospice, which is the file used to predict in-hospital death or discharge to hospice vs. not. Box plots and bar-charts were also made and stored to visualize distributions.

```{r}

#hospital_death_hospice
descriptive_died_hospice <- hospital_death_hospice |> 
  tbl_summary(by = died_hospice) |>
  add_p()

#how many patients, 3419
number_death_hospice <- nrow(hospital_death_hospice)

#race_category
died_hospice_race_category <- ggplot(data = hospital_death_hospice, aes(x = died_hospice, fill = race_category)) +
  geom_bar(position = "dodge") +
  labs(title = "Race/Ethnicity", x = "Died/Hospice", y = "Frequency of PH Patients")

#current_service_cat
died_hospice_current_service_cat <- ggplot(data = hospital_death_hospice, aes(x = died_hospice, fill = current_service_cat)) +
  geom_bar(position = "dodge") +
  labs(title = "Hospital Service", x = "Died/Hospice", y = "Frequency of PH Patients")


#PH_type
died_hospice_PH_type <- ggplot(data = hospital_death_hospice, aes(x = died_hospice, fill = PH_type)) +
  geom_bar(position = "dodge") +
  labs(title = "PH type", x = "Died/Hospice", y = "Frequency of PH Patients")

#insurance_category
died_hospice_insurance_category <- ggplot(data = hospital_death_hospice, aes(x = died_hospice, fill = insurance_category)) +
  geom_bar(position = "dodge")+
  labs(title = "Insurance Category", x = "Died/Hospice", y = "Frequency of PH Patients")

#admit_category
died_hospice_admit_category <- ggplot(data = hospital_death_hospice, aes(x = died_hospice, fill = admit_category)) +
  geom_bar(position = "dodge") +
  labs(title = "Admit Category", x = "Died/Hospice", y = "Frequency of PH Patients")

#gender_category
died_hospice_gender_category <- ggplot(data = hospital_death_hospice, aes(x = died_hospice, fill = gender_category)) +
  geom_bar(position = "dodge") +
  labs(title = "Gender Category", x = "Died/Hospice", y = "Frequency of PH Patients")  


#Find mean, median, and SD for numeric variables
#elixhauser_score
meanmedianSD_diedcomorbidity <- summary(hospital_death_hospice$elixhauser_score)

comorbidity_diedsd <- sd(hospital_death_hospice$elixhauser_score)

# boxplot for elixhauser_score
boxplot_died_comorbidity <- ggplot(hospital_death_hospice, aes(x = died_hospice, y = elixhauser_score)) +
  geom_boxplot() +
  labs(title = "Elixhauser Score by Died/Hospice or Discharged Alive", x = "Died/Hospice", y = "Elixhauser Comorbidity Score") +
  theme_minimal()

#age
meanmedianSD_diedage <- summary(hospital_death_hospice$age)

comorbidity_diedage <- sd(hospital_death_hospice$age)

# boxplot for age
boxplot_died_age <- ggplot(hospital_death_hospice, aes(x = died_hospice, y = age)) +
  geom_boxplot() +
  labs(title = "Age by Died/Hospice or Discharged Alive", x = "Died/Hospice", y = "Age") +
  theme_minimal()


#length_of_stay
meanmedianSD_diedLOS <- summary(hospital_death_hospice$length_of_stay)

LOS_diedage <- sd(hospital_death_hospice$length_of_stay)

# boxplot for length_of_stay
boxplot_died_length_of_stay <- ggplot(hospital_death_hospice, aes(x = died_hospice, y = length_of_stay)) +
  geom_boxplot() +
  labs(title = "Length of Stay by Died/Hospice or Discharged Alive", x = "Died/Hospice", y = "Length of Stay") +
  theme_minimal()

```

### Inferential Analysis: Random Forest Analyses (multiple)

I did random forest with 1000 trees both with and without 10-fold cross validation (CV) for readmit_30_factor and hospital_death_hospice_factor. I duplicated these two files for random forest analyses to better organize myself. The packages `kernlab` and `randomForest` were used to conduct random forest analyses. Packages `tidymodels`, `tidymodels_prefer()`, and `library(vip)` were used to find the top predictors. I used `ggplot2` and `RColorBrewer` for plotting ROC curves. For all random forest modeling, I set seed, used 1000 trees, stored AUC values, and stored ROC curves.

| Original File                 | Random Forest no 10-fold CV (training data) | Random Forest with 10-fold CV |
|-------------------------------|---------------------------------------------|-------------------------------|
| readmit_30_factor             | readmit_30_factor_RF_training               | CV_readmit_30_factor          |
| hospital_death_hospice_factor | death_hospice_RF_training                   | CV_death_hospice_RF_training  |

```{r}

#using dataset readmit_30_factor and copied it to readmit_30_factor_RF_training, Random forest without 10-fold CV (training data only)

readmit_30_factor_RF_training <- readmit_30_factor

#using dataset readmit_30_factor and copied it to CV_readmit_30_factor, Random forest with 10-fold CV

CV_readmit_30_factor <- readmit_30_factor


#using dataset hospital_death_hospice_factor and copied it to hospital_death_hospice_factor_RF_training, Random forest without 10-fold CV (training data only)

death_hospice_RF_training <- hospital_death_hospice_factor

#using dataset hospital_death_hospice_factor and copied it to CV_hospital_death_hospice_factor, Random forest with 10-fold CV

CV_death_hospice_RF_training <- hospital_death_hospice_factor

#colnames(CV_death_hospice_RF_training )
```

#### Using All Predictors for PH 30-Day Readmissions Vs. Not : Without 10-fold CV (Training Data Only)

Random forest without 10-fold CV was done to predict whether patients with PH would be readmitted within 30 days vs. not. I used readmit_30_factor_RF_training for this analysis.

```{r}

#Set seed and create random forest with 1000 trees 
set.seed(1234)
rf_cls_spec <- 
  rand_forest(trees = 1000, min_n = 5) |>
  set_engine("randomForest") |>
  set_mode("classification")

#use the dataset readmit_30_factor_RF_training

RF_no_10_readmit30_training <- rf_cls_spec |>
  fit(readmision30days  ~ ., data = readmit_30_factor_RF_training)
#colnames(RF_no_10_readmit30_training)
#print(RF_no_10_readmit30_training)


#head(readmit_30_factor_RF_training)
#find most important predictors for future use 
important_readmit_1 <- RF_no_10_readmit30_training |>
  extract_fit_engine() |>
  importance()

important_readmit_2 <- RF_no_10_readmit30_training |>
  extract_fit_engine() |>
  vip()

#Store the predicted values of the training data into a variable called rf.predicted.
rf.predicted_readmit30  <- bind_cols(
  truth = readmit_30_factor_RF_training$readmision30days,
  predict(RF_no_10_readmit30_training, readmit_30_factor_RF_training), 
  predict(RF_no_10_readmit30_training, readmit_30_factor_RF_training, type = "prob"))

#AUC value
no_10_AUC_readmit30 <- roc_auc(rf.predicted_readmit30, 
                                  truth, .pred_1, event_level = "second") #readmision30days "yes" was factored as 1 and "no" was factored as 0

#ROC curve
no_10_ROCplot_readmit30 <- autoplot(roc_curve(rf.predicted_readmit30, 
                   truth, .pred_1, event_level = "second"))
```

#### Using All Predictors for PH 30-Day Readmissions Vs. Not : With 10-fold CV

Random forest with 10-fold CV was done to predict whether these patients would be readmitted within 30 days vs. not. I used CV_readmit_30_factor for this analysis.

```{r}
set.seed(1234)
CV_readmit_30_factor <- vfold_cv(CV_readmit_30_factor, 10) #split into 10 groups

rf_workflow_10_cv <-
  workflow() |>
  add_model(rf_cls_spec) |>
  add_formula(readmision30days ~ .)

set.seed(1234)

fit_randomforest_ten <-
  rf_workflow_10_cv |>
  fit_resamples(CV_readmit_30_factor, 
                control = control_resamples(save_pred = TRUE))

#AUC value
AUC_CV_readmit30 <- collect_metrics(fit_randomforest_ten)

#ROC curve
ROC_CV_readmit30 <- fit_randomforest_ten |>
  collect_predictions() |>
  roc_curve(readmision30days, .pred_1, event_level = "second") |>
  autoplot()
```

#### Finding Top 5 Predictors for PH 30-Day Readmissions Vs. Not

I found the top five top predictors for 30-day readmissions vs. not. They are age, length_of_stay, elixhauser_score, race_category, and discharge_category . These top five predictors were then used to refit the random forest models above.

```{r}
#print the important predictors as indicated by MeanDecreaseGini within random forest.  
print(important_readmit_1)
print(important_readmit_2)

```

#### Using Top 5 Predictors for PH 30-Day Readmissions Vs. Not : Without 10-fold CV (Training Data Only)

As mentioned previously, I reconstructed my random forest models using these top five predictors. AUC estimates and ROC curves were also created to be stored. Below is the random forest without 10-fold CV using only the top five predictors: age, length_of_stay, elixhauser_score, race_category, and discharge_category.

```{r}

#Set seed and create random forest with 1000 trees 
set.seed(1234)
rf_cls_spec <- 
  rand_forest(trees = 1000, min_n = 5) |>
  set_engine("randomForest") |>
  set_mode("classification")

#use readmit_30_factor_RF_training file 
top_RF_no_10_readmit30 <- rf_cls_spec |>
  fit(readmision30days  ~ age + length_of_stay + elixhauser_score + race_category + discharge_category , data = readmit_30_factor_RF_training)

#colnames(top_RF_no_10_readmit30)
print(top_RF_no_10_readmit30)
#OOB estimate of  error rate: 11.01%

#Store the predicted values of the training data into a variable called top_rf.readmit30_top5.
top_rf.readmit30_top5  <- bind_cols(
  truth = readmit_30_factor_RF_training$readmision30days,
  predict(top_RF_no_10_readmit30, readmit_30_factor_RF_training), 
  predict(top_RF_no_10_readmit30, readmit_30_factor_RF_training, type = "prob"))

#head(top_rf.readmit30_top5)

#Store AUC value
top_no_10_AUC_readmit30 <- roc_auc(top_rf.readmit30_top5, 
                                  truth, .pred_1, event_level = "second") 

#readmission30days "yes" was factored as 1 and "no" was factored as 0
top_no_10_ROCreadmit30 <- autoplot(roc_curve(top_rf.readmit30_top5, 
                   truth, .pred_1, event_level = "second"))

```

#### Using Top 5 Predictors for PH 30-day Readmissions Vs. Not : With 10-fold CV

Next, I repeated the process but used 10-fold CV for the top five predictors: age, length_of_stay, elixhauser_score, race_category, and discharge_category.

```{r}


# 10-fold cross validation classification vectors for random forest
set.seed(1234)

#no need to split CV_readmit_30_factor into 10 groups because already done that when doing 10-fold CV with all predictors. 


top_rf_workflow_10_cv <-
  workflow() |>
  add_model(rf_cls_spec) |>
  add_formula(readmision30days ~ age + length_of_stay + race_category + discharge_category + elixhauser_score)

set.seed(1234)

top_fit_randomforest_ten <-
  top_rf_workflow_10_cv |>
  fit_resamples(CV_readmit_30_factor , 
                control = control_resamples(save_pred = TRUE))

#Store AUC value
top_5_10CV_AUC_readmit30 <- collect_metrics(top_fit_randomforest_ten)

#Store ROC curve
top_10_CV_ROC_readmit30 <- top_fit_randomforest_ten |>
  collect_predictions() |>
  roc_curve(readmision30days, .pred_1, event_level = "second") |>
  autoplot()

```

#### Combining ROC Plots: 30-Day Readmission Vs. Not Predictions

Here I combined and stored the ROC plots of random forests predicting 30-day readmissions vs. not. This included those with and without 10-fold CV. They included all predictors and the top 5 predictors.

```{r}

# Combine the ROC data
combined_ROC_plots_readmit_top <- rbind(
  data.frame(method = "Random Forest: No 10-fold cross validation, all predictors",
             no_10_ROCplot_readmit30$data),
  data.frame(method = "Random Forest: 10-fold cross validation, all predictors", ROC_CV_readmit30$data),
  data.frame(method = "Random Forest: No 10-fold cross validation, top five predictors", top_no_10_ROCreadmit30$data), 
  data.frame(method = "Random Forest: 10-fold cross validation, top five predictors", top_10_CV_ROC_readmit30$data)
)


# Create a ggplot for the combined data and store
ROC_Curve_30_day <- ggplot(combined_ROC_plots_readmit_top, aes(1 - specificity, sensitivity, color = method)) +
  geom_line() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  scale_color_brewer(palette = "Set1") + 
  labs(
    title = "ROC: 30-day readmission prediction ",
    x = "1-Specificity ",
    y = "Sensitivity",
    color = "Method"
  )


```

#### Using All Predictors for PH In-Hospital Mortality or Discharge to Hospice Vs. Not : Without 10-fold CV (Training Data Only)

After predicting 30-day readmissions vs. not, I used random forest without 10-fold CV to predict death and/or hospice vs. not within patients with PH. The file I used was death_hospice_RF_training.

```{r}


#created random forest without 10-fold CV to see if the variables I selected can predict died or hospice vs. not 

#Set seed and create random forest with 1000 trees 
set.seed(1234)
rf_cls_spec_died <- 
  rand_forest(trees = 1000, min_n = 5) |>
  set_engine("randomForest") |>
  set_mode("classification")


#use file death_hospice_RF_training
RF_no_10_diedhospice_RF_training <- rf_cls_spec_died |>
  fit(died_hospice  ~ ., data = death_hospice_RF_training)
#colnames(RF_no_10_diedhospice_RF_training)
print(RF_no_10_diedhospice_RF_training)
#OOB estimate of  error rate: 8.75%

#find most important predictors for future use 
important_died_1 <- RF_no_10_diedhospice_RF_training |>
  extract_fit_engine() |>
  importance()

important_died_2 <- RF_no_10_diedhospice_RF_training |>
  extract_fit_engine() |>
  vip()

#Store the predicted values of the training data into a variable called rf.predicted_hospice_died.
rf.predicted_hospice_died  <- bind_cols(
  truth = death_hospice_RF_training$died_hospice,
  predict(RF_no_10_diedhospice_RF_training, death_hospice_RF_training), 
  predict(RF_no_10_diedhospice_RF_training, death_hospice_RF_training, type = "prob"))

#AUC value
no_10_AUC_hospice_died <- roc_auc(rf.predicted_hospice_died, 
                                  truth, .pred_1, event_level = "second") #died_hospice "yes" was factored as 1 and "no" was factored as 0

#ROC curve
no_10_ROCplot_hospice_died <- autoplot(roc_curve(rf.predicted_hospice_died, 
                   truth, .pred_1, event_level = "second"))
```

#### Using All Predictors for PH In-Hospital Mortality or Discharge to Hospice Vs. Not : With 10-fold CV

Next, I used random forest with 10-fold CV to predict death and/or hospice vs. not within these patients. I used the file named CV_death_hospice_RF_training.

```{r}
#I created random forest with 10-fold CV to see if the variables I selected can predict died or hospice vs. not, use CV_death_hospice_RF_training

# 10-fold cross validation classification vectors for random forest
set.seed(1234)
CV_death_hospice_RF_training <- vfold_cv(CV_death_hospice_RF_training, 10) #split into 10 groups

rf_workflow_10_cv_died <-
  workflow() |>
  add_model(rf_cls_spec) |>
  add_formula(died_hospice ~ .)

set.seed(1234)

fit_randomforest_ten_died <-
  rf_workflow_10_cv_died |>
  fit_resamples(CV_death_hospice_RF_training, 
                control = control_resamples(save_pred = TRUE))

#AUC value
ten_CV_hospice_died_AUC <- collect_metrics(fit_randomforest_ten_died)

#ROC curve
ten_CV_hospice_died_RF <- fit_randomforest_ten_died |>
  collect_predictions() |>
  roc_curve(died_hospice, .pred_1, event_level = "second") |>
  autoplot()
```

#### Finding Top 5 Predictors for PH In-Hospital Mortality or Discharge to Hospice Vs. Not

I found the top five top predictors for in-hospital mortality or discharge to hospice vs. not. They are age, length_of_stay, elixhauser_score, race_category, and married_or_not. These top five predictors were then used to refit the random forest models to predict in-hospital mortality or discharge to hospice vs. not.

```{r}
print(important_died_1) 
print(important_died_2) 
```

#### Using Top 5 Predictors for PH In-Hospital Mortality or Discharge to Hospice Vs. Not : Without 10-fold CV (Training Data Only)

I reconstructed my random forest models using these top five predictors for in-hospital mortality or discharge to hospice vs. not. Below is the random forest without 10-fold CV using only the top five predictors.

```{r}
#Set seed and create random forest with 1000 trees 
set.seed(1234)
rf_cls_spec_top5_died <- 
  rand_forest(trees = 1000, min_n = 5) |>
  set_engine("randomForest") |>
  set_mode("classification")

top_RF_no_10_death_hospice <- rf_cls_spec_top5_died |>
  fit(died_hospice  ~ length_of_stay + age + race_category + elixhauser_score + married_or_not, data = death_hospice_RF_training)

#print(top_RF_no_10_death_hospice)
#OOB estimate of  error rate: 8.75%

#Store the predicted values of the training data into a variable called top_rf.predicted_hospice_died.
top_rf.predicted_hospice_died  <- bind_cols(
  truth = death_hospice_RF_training$died_hospice,
  predict(top_RF_no_10_death_hospice, death_hospice_RF_training), 
  predict(top_RF_no_10_death_hospice, death_hospice_RF_training, type = "prob"))

#AUC value
top_no_10_AUC_hospice_died <- roc_auc(top_rf.predicted_hospice_died, 
                                  truth, .pred_1, event_level = "second") #died_hospice "yes" was factored as 1 and "no" was factored as 0

#ROC curve
top_no_10_ROCplot_hospice_died <- autoplot(roc_curve(top_rf.predicted_hospice_died, 
                   truth, .pred_1, event_level = "second"))
```

#### Using Top 5 Predictors for PH In-Hospital Mortality or Discharge to Hospice Vs. Not : With 10-fold CV

Random forest with 10-fold CV using only the top five predictors to predict in-hospital mortality and/or hospice vs. not within patients with PH:

```{r}


# 10-fold cross validation classification vectors for random forest
set.seed(1234)

#no need to split CV_death_hospice_RF_training into 10 groups because already done that when doing 10-fold CV with all predictors. 

top_rf_workflow_10_cv_top5_died <-
  workflow() |>
  add_model(rf_cls_spec) |>
  add_formula(died_hospice  ~ length_of_stay + age + race_category + elixhauser_score + married_or_not)

set.seed(1234)

top_fit_randomforest_ten_top5_died <-
  top_rf_workflow_10_cv_top5_died |>
  fit_resamples(CV_death_hospice_RF_training, 
                control = control_resamples(save_pred = TRUE))

#AUC value
top_5_10CV_AUC_died_hospice <- collect_metrics(top_fit_randomforest_ten_top5_died)

#ROC curve
top_10_CV_ROC_died_hospice <- top_fit_randomforest_ten_top5_died |>
  collect_predictions() |>
  roc_curve(died_hospice, .pred_1, event_level = "second") |>
  autoplot()

```

#### Combining ROC plots: In-Hospital Mortality or Discharge to Hospice Vs. Not Predictions

Here I combined and stored the ROC plots of random forests predicting in-hospital mortality or discharge to hospice vs. not. This included those with and without 10-fold CV. They included all predictors and the top 5 predictors.

```{r}

# Combine the ROC data
combined_ROC_plots_diedhospice <- rbind(
  data.frame(method = "Random Forest: 10-fold cross validation, all predictors",
             ten_CV_hospice_died_RF$data),
  data.frame(method = "Random Forest: no 10-fold cross validation, all predictors", no_10_ROCplot_hospice_died$data),
  data.frame(method = "Random Forest: no 10-fold cross validation, top five predictors", top_no_10_ROCplot_hospice_died$data), 
  data.frame(method = "Random Forest: 10-fold cross validation, top five predictors", top_10_CV_ROC_died_hospice$data)
)


# Create a ggplot for the combined data
ROC_Curve_death_hospice <- ggplot(combined_ROC_plots_diedhospice, aes(1 - specificity, sensitivity, color = method)) +
  geom_line() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  scale_color_brewer(palette = "Dark2") +  
  labs(
    title = "My ROC Curves : random forest predicting ICU death or discharge to hospice",
    x = "1-Specificity",
    y = "Sensitivity",
    color = "Method"
  )

```

## Results {#sec-results}

### Descriptive Data Analysis

A total of 3419 ICU patients with PH were included in this project. Median and IQR are displayed for elixhauser_score, length_of_stay, and age. Frequencies and percentages are displayed for the other variables. The large majority of the patients were in the medicine service, admitted under emergency, have other PH types, and have either Medicare or other insurance. 8.6% of the patients died in the hospital or were discharged to hospice. Most patients were white, discharged with home health, and were not married. There were slightly more females and males. Only a few left against medical advice. The median length of stay was 7 days.

```{r}
#descriptive analysis for all PH paitents
descriptive_statistics

```

Below are the descriptive analysis results and graphs for the file, readmit_30 - used to predict 30-day readmissions vs. not among those discharged alive and not to hospice. There were a total of 3124 patients within readmit_30. The readmission rate for this file is 10.97951%. The length of stay was significantly greater among those who were readmitted within 30 days compared to those who were not. Bar graphs and bar plots for readmit_30 are displayed below to visualize distributions.

|                              | Mean   | SD       | Median | IQR             |
|------------------------------|--------|----------|--------|-----------------|
| Elixhauser Comorbidity Score | 0.9481 | 2.768909 | 0.0000 | 0.0000 - 0.0000 |
| Age                          | 68.93  | 14.62213 | 71.00  | 60.00 - 80.00   |
| Length of Stay               | 8.97   | 8.916452 | 7.000  | 4.000 - 11.000  |

```{r}
#readmit_30
descriptive_30dayreadmission

#how many patients, 3124
print(number_readmit)

#get percentage of PH patients readmitted within 30 days. In this dataset, it is 10.97951%
print(percent30day)

#bargraph discharge_category
print(readmit30_discharge_category) 

#bargraph PH_type
print(readmit30_PH_type) 

ggdraw() +
  draw_plot(readmit30_race_category, x=0, y=0, width = 0.5, height = 1)+
  draw_plot(readmit30_current_service_cat, x=0.5, y=0, width=0.5, height=1)

ggdraw() +
  draw_plot(readmit30_insurance_category, x=0, y=0.5, width = 0.5, height = 0.5) + 
  draw_plot(readmit30_admit_category, x=0.5, y=0.5, width = 0.5, height = 0.5) + 
  draw_plot(readmit30_current_service_cat, x=0, y=0, width = 0.5, height = 0.5) +
  theme_minimal()


#Find mean, median, and SD for numeric variables
#elixhauser_score
print(meanmedianSD_30comorbidity) 
#  Min.   1st Qu.  Median   Mean   3rd Qu.    Max. 
# -7.0000  0.0000  0.0000  0.9481  0.0000 12.0000 

print(comorbidity_30sd) 
#2.768909


#age
print(meanmedianSD_30age)
#   Min. 1st Qu.  Median   Mean   3rd Qu.   Max. 
#  18.00   60.00   71.00   68.93   80.00   91.00

print(comorbidity_30age) 
#14.62213

#length_of_stay
print(meanmedianSD_30LOS)
#Min.    1st Qu. Median. Mean  3rd Qu.  Max. 
#2.000   4.000   7.000   8.97  11.000 192.96

print(LOS_30age) 
#8.916452

ggdraw() +
  draw_plot(boxplot_30day_age, x=0, y=0.5, width = 0.5, height = 0.5) + 
  draw_plot(boxplot_30day_comorbidity, x=0.5, y=0.5, width = 0.5, height = 0.5) + 
  draw_plot(boxplot_30day_length_of_stay, x=0, y=0, width = 0.5, height = 0.5) +
  theme_minimal()

```

Below are the descriptive analysis results and graphs for the file, descriptive_died_hospice - used to predict in-hospital mortality or discharge to hospice vs. not. There were total of 3419 patients in descriptive_died_hospice. Length of stay and age was significantly higher among patients who died or were discharged to hospice compared to those who were not. Significantly more white patients were discharged alive and not to hospice. Bar graphs and bar plots for descriptive_died_hospice are displayed below to visualize distributions.

|                              | Mean   | SD       | Median | IQR             |
|------------------------------|--------|----------|--------|-----------------|
| Elixhauser Comorbidity Score | 0.9336 | 2.762277 | 0.0000 | 0.0000 - 0.0000 |
| Age                          | 69.31  | 14.45223 | 71.00  | 61.00 - 91.00   |
| Length of Stay               | 9.362  | 9.314404 | 7.000  | 4.000 - 12.000  |

```{r}
#hospital_death_hospice
descriptive_died_hospice

#how many patients, 3419
print(number_death_hospice)

ggdraw() +
  draw_plot(died_hospice_race_category, x=0, y=0, width = 0.5, height = 1)+
  draw_plot(died_hospice_current_service_cat, x=0.5, y=0, width=0.5, height=1)+
  theme_minimal()

ggdraw() +
  draw_plot(died_hospice_admit_category, x=0, y=0, width = 0.5, height = 1) +
  draw_plot(died_hospice_gender_category, x=0.5, y=0, width=0.5, height=1) +
  theme_minimal()


#PH_type
died_hospice_PH_type

#insurance_category
print(died_hospice_insurance_category) 

print(meanmedianSD_diedcomorbidity) 
#  Min.   1st Qu.  Median   Mean   3rd Qu.    Max. 
# -7.0000  0.0000  0.0000  0.9336  0.0000 12.0000 

print(comorbidity_diedsd) 
#2.762277


#age
print(meanmedianSD_diedage) 
#   Min. 1st Qu.  Median   Mean   3rd Qu.   Max. 
#  18.00   61.00   71.00   69.31   80.00   91.00

print(comorbidity_diedage) 
#14.45223

#length_of_stay
print(meanmedianSD_diedLOS) 
#Min.    1st Qu. Median. Mean  3rd Qu.  Max. 
#2.000   4.000   7.000   9.362 12.000 192.958

print(LOS_diedage) 
#9.314404

# boxplot for elixhauser_score
print(boxplot_died_comorbidity) 

# boxplot for age
print(boxplot_died_age) 

# boxplot for length_of_stay
print(boxplot_died_length_of_stay) 
```

### Random Forest Predicting 30-Day Readmission for PH Vs. Not.

Below displays the AUC values and ROC curves of the random forests predicting 30-day readmissions vs. not among patients with PH. These random forests are with and without 10-fold CV and with all predictors and the top 5 predicts. The AUC values and ROC curves are much higher among the random forest models using only training data compared to those of models using 10-fold CV. This is true for random forest models using all predictors and the top five predictors: age, length_of_stay, elixhauser_score, race_category, and discharge_category. This suggests that over-fitting is present.

The OOB estimate of error rate is 11.01% for the random forest model using training data (not 10-fold CV) and all predictors to predict 30-day readmissions vs. not.

Similarly, the random forest model using training data (not 10-fold CV) and the top five predictors to predict 30-day readmissions vs. not has an OOB estimate of error rate is 11.01%.

| Model                                                                   | AUC       |
|-------------------------------------------------------------------------|-----------|
| Random Forest without 10-fold CV (training data only), All Predictors   | 0.9702993 |
| Random Forest with 10-fold CV, All Predictors                           | 0.4903993 |
| Random Forest without 10-fold CV (training data only), Top 5 Predictors | 0.9310801 |
| Random Forest with 10-fold CV, Top 5Predictors                          | 0.4887786 |

```{r}

#AUC for predicting 30-day readmission without 10-fold CV, All Predictors
print(no_10_AUC_readmit30)

#AUC for predicting 30-day readmission with 10-fold CV, All Predictors
print(AUC_CV_readmit30)

#AUC for predicting 30-day readmission without 10-fold CV, Top 5 Predictors
print(top_no_10_AUC_readmit30)

#AUC for predicting 30-day readmission with 10-fold CV, Top 5 Predictors
print(top_5_10CV_AUC_readmit30)

# OOB estimate of  error rate: 11.01%, random forest without 10-fold CV, all predictors 
print(RF_no_10_readmit30_training)

# OOB estimate of  error rate: 11.01%, random forest without 10-fold CV, top 5 predictors 
print(top_RF_no_10_readmit30)

#ROC Curves for predicting 30-day readmission without and with 10-fold CV
print(ROC_Curve_30_day)

```

### Random Forest Predicting PH In-Hospital Mortality or Discharged to Hospice Vs. No.

Below displays the AUC values and ROC curves of the random forests predicting in-hospital mortality or discharged to hospice vs. not among patients with PH. These random forests are with and without 10-fold CV and with all predictors and the top 5 predicts. Similar to that of predicting 30-day readmissions vs. not, the AUC values and ROC curves are much higher among the random forest models using only training data compared to those of models using 10-fold CV for both all predictors and the top five predictors: age, length_of_stay, elixhauser_score, race_category, and married_or_not. The comparisons of AUC values and the ROC curves between the random forest using only training data and those with the 10-fold CV suggest that overfitting is present.

The OOB estimate of error rate is 8.75% for the random forest model using training data (not 10-fold CV) and all predictors to predict in-hospital death or discharged to hospice vs. not.

Similarly, the random forest model using training data (not 10-fold CV) and the top five predictors to predict in-hospital mortality or discharged to hospice has an OOB estimate of error rate is 8.75%.

| Model                                                                   | AUC       |
|-------------------------------------------------------------------------|-----------|
| Random Forest without 10-fold CV (training data only), all predictors   | 0.961298  |
| Random Forest with 10-fold CV, all predictors                           | 0.6072309 |
| Random Forest without 10-fold CV (training data only), Top 5 predictors | 0.9365226 |
| Random Forest with 10-fold CV (training data only), Top 5 predictors    | 0.5856270 |

```{r}

#AUC for predicting hospice or death vs. not without 10-fold CV, all predictors
print(no_10_AUC_hospice_died)

#AUC for predicting hospice or death vs. not with 10-fold CV, all predictors
print(ten_CV_hospice_died_AUC)

#AUC for predicting hospice or death vs. not without 10-fold CV, Top 5 predictors
print(top_no_10_AUC_hospice_died)

#AUC for predicting hospice or death vs. not with 10-fold CV, Top 5 predictors
print(top_5_10CV_AUC_died_hospice) 

# OOB estimate of  error rate: 8.75%, random forest without 10-fold CV, all predictors
print(RF_no_10_diedhospice_RF_training)

# OOB estimate of  error rate: 8.75%, random forest without 10-fold CV, Top 5 predictors
print(top_RF_no_10_death_hospice)

print(ROC_Curve_death_hospice)


```

## Conclusion, Limitations, and Future Directions

This project explores using random forest to predict **1.)** 30-day readmissions vs. not and **2.)** in-hospital mortaltiy or discharge to hospice vs. not among patients with PH receiving ICU-level care. Overfitting was present when using this machine learning approach regardless of whether I included all predictors or just the top five.

There are additional machine learning approaches that may be a better fit to predict 30-day readmissions, in-hospital death, or discharge to hospice. These approaches include, but are not limited to, logistic regression, X-G boost, and Recurrent Neural Networks.

Future projects may consider modifying or adding predictors to the model. This includes lab values, such as sodium (Na) and B-type natriuretic peptide (BNP), and additional social determinants of health. A dataset, named MIMIC-IV-SDOH, could be used to additional variables representing social determinants of health (Yang et al., 2023). These include social vulnerability, environment, and education. The MIMIC-IV-SDOH would be uploaded to PhysioNet when the researchers can ensure that it will not increase the risk of patient reidentification. Natural language processing could be used to extract data from the MIMIC-IV-Note dataset, which contains deidentified free-text patient notes. This data could then be integrated as predictors to the model. EEG readings will be included in the MIMIC-IV-Note dataset at a later date. Thus, EEG readings may be included as a predictor to the model. This is particular relevant to patients with PH as they may have cardiac arrhythmias.

There are limitations regarding the generalizability of these findings as the data comes from only one hospital. Future studies may consider using the All of Us and Patient Registry for Primary Pulmonary Hypertension datasets supported by the NIH.

## References

Bhattacharya, P. T., Hameed, A. M. A., Bhattacharya, S. T., Chirinos, J. A., Hwang, W. T., Birati, E. Y., Menachem, J. N., Chatterjee, S., Giri, J. S., Kawut, S. M., Kimmel, S. E., & Mazurek, J. A. (2020). Risk factors for 30-day readmission in adults hospitalized for pulmonary hypertension. *Pulmonary circulation*, *10*(4), 2045894020966889. https://doi.org/10.1177/2045894020966889

Gall, H., Felix, J. F., Schneck, F. K., Milger, K., Sommer, N., Voswinckel, R., Franco, O. H., Hofman, A., Schermuly, R. T., Weissmann, N., Grimminger, F., Seeger, W., & Ghofrani, H. A. (2017). The Giessen Pulmonary Hypertension Registry: Survival in pulmonary hypertension subgroups. *The Journal of heart and lung transplantation : the official publication of the International Society for Heart Transplantation*, *36*(9), 957--967. https://doi.org/10.1016/j.healun.2017.02.016

Johnson, A. E. W., Bulgarelli, L., Shen, L., Gayles, A., Shammout, A., Horng, S., Pollard, T. J., Hao, S., Moody, B., Gow, B., Lehman, L. H., Celi, L. A., & Mark, R. G. (2023). MIMIC-IV, a freely accessible electronic health record dataset. *Scientific data*, *10*(1), 1. https://doi.org/10.1038/s41597-022-01899-x

Mandras, S. A., Mehta, H. S., & Vaidya, A. (2020). Pulmonary Hypertension: A Brief Guide for Clinicians. *Mayo Clinic proceedings*, *95*(9), 1978--1988. https://doi.org/10.1016/j.mayocp.2020.04.039

Maron B. A. (2023). Revised Definition of Pulmonary Hypertension and Approach to Management: A Clinical Primer. *Journal of the American Heart Association*, *12*(8), e029024. https://doi.org/10.1161/JAHA.122.029024

Mullin, C. J., & Ventetuolo, C. E. (2021). Critical Care Management of the Patient with Pulmonary Hypertension. *Clinics in chest medicine*, *42*(1), 155--165. https://doi.org/10.1016/j.ccm.2020.11.009

Poor, H. D., & Ventetuolo, C. E. (2012). Pulmonary hypertension in the intensive care unit. *Progress in cardiovascular diseases*, *55*(2), 187--198. https://doi.org/10.1016/j.pcad.2012.07.001

Yang, M.Y., Kwak, G.H., Pollard, T., Celi, L.A, & Ghassemi, M. (2023). Evaluating the Impact of Social Determinants on Health Prediction in the Intensive Care Unit. *AIES '23: Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society,* 333-350. https://doi.org/10.1145/3600211.3604719
