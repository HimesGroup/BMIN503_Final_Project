---
title: "Exploring Countermovement Jump (CMJ) Scan Movement Signatures in Men's Collegiate Lacrosse Athletes"
author: "Bernadette D'Alonzo"
output: 
  html_document:
    toc: false 
    depth: 3 
    theme: paper 
    highlight: tango
---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 400)
```  
***

### Overview
Members of Penn Athletics, Penn Sports Medicine, and the Penn Injury Science Center are collaborating on a large study titled “Force Plate Analysis in Collegiate Athletes: An Epidemiologic and Injury Prevention Study,” to evaluate a program that has been active at Penn over the last 5 years. The overarching goal of that study is to investigate whether force plate measurements can predict injuries, and performance outcomes, and whether (and how) measurements vary across sports and sex. Exploring this may identify sport-specific profiles that may inform customized strength and conditioning injury prevention programs. The objective of this class project is to take a step back from prediction to first answer the question of whether and how these measurements vary between athletes from the same sport compared to within one athlete over time, and I examine this in the context of men’s lacrosse players. For this project, I worked with a large interdisciplinary team including: Dr. Doug Wiebe, Professor of Epidemiology and Director of the Penn Injury Science Center (PISC), Dr. Abby Bretzin, Postdoctoral Fellow at PISC, Dr. Jeremy Weeks, Associate Director of Penn Strength & Conditioning (and Director of Research), and Dr. Brian Sennett, Chair of Athletic Medicine at Penn.


### Introduction 
The specific problem that this project addresses, is that the field currently does not have a strong understanding of how and the extent to which force plate measurements vary across collegiate athletes in the larger study playing the same sport, and within an athlete over time. This is a key concept to explore prior to estimating or predicting injury. Penn Athletics in particular is interested in this issue, having used force plates for 5 years, yet lacking evidence of the utility of what they are measuring. Ultimately, by identifying individuals who may be at increased risk of injury, we may be able to inform the development of targeted injury prevention programs, thereby improving countermeasure effectiveness. Sparta Science is a sports performance and injury evaluation tool utilized by multiple human movement-based industries, with significant use in military, athletic, and clinical settings. Sparta Science has been described as having a technology that may enable identifying athletes at-risk for sustaining an injury. To lay the groundwork for next studies on injury prediction, this project investigates some of the metrics that force plates measure.

The collaborative nature of the team involved in this study is a strength and critical to the success of any of our projects. Penn’s Strength & Conditioning leadership and staff bring expertise in research utilizing force plates to date and Penn’s utilization and implementation of Sparta Science assessments. Penn Sports Medicine and Athletic Training contribute knowledge regarding the appropriateness and application of findings related to injury. Finally, Epidemiologists and Data Scientists provide support for study design, identify opportunities for natural and planned experiments, and interpretation of results.

From meetings with Strength & Conditioning, we have learned that the technology used in the Sparta Science system consists of a force plate, proprietary software, and a dataset projected to consist of data captured from more than 1,500,000 assessments. Current Sparta Science set-up at Penn consists of force plates with dedicated computers and software, and it is used with athletes across all years and varsity sports. Athletes begin with a standardized warm up that is completed just prior to the assessments; counter movement jump (CMJ); single leg balance scan, and single arm plank scan. The results of each assessment are computed by the software and converted to T-scores, by comparing to the Sparta Science dataset. For the CMJ assessment, the system generates industry-standard variables of force/time including Load, Explode, and Drive, which we will examine in this project. These scores represent an individual's ability to Create, Transfer, and Apply force efficiently and are referred to by Sparta as the individual's Movement Signature™. We have also learned that men’s lacrosse coaches have utilized the software most consistently in recent years, and at the encouragement of the Epidemiologists providing guidance on this project, I focus on those athletes here. From Sports Medicine and Athletic Training, we have learned that lower-extremity injuries (LEIs) have been common among men’s lacrosse players at Penn, further underscoring this population as an ideal one to first explore patterns in CMJ scan measurements among team members and over time.


### Methods
The data utilized in this analysis were extracted from the Sparta Science platform and are part of a larger project, as discussed above. The main goal of this class project was to use descriptive analyses and data visualization to explore and present the data in a meaningful way, and to aid in hypothesis generation.

To begin, I loaded the appropriate tidyverse packages and read in the Sparta Science scan data file (containing all sports). I used the package gtsummary to create the summary tables below.

```{r, results=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(gtsummary)
```

```{r}
sparta.scans <- read.csv("U:/PhD program/600 Data Science_Final proj_Sparta/sparta_scan_summaries.csv", header = TRUE)
```


I aimed to focus on a single sport for this project, and so I first examined the total number of scans that we have access to in the Sparta dataset. There are 21,143 scans total, roughly half (54%) are scans of Penn Varsity athletes with complete data. I confirmed that among Penn teams, Men's Varsity Lacrosse has the most number of scans (Note, we suspected this following conversations with the Strength & Conditioning group due to this team's frequent utilization of Sparta and buy-in from coaches, etc.).
```{r, message=FALSE}
#ID sport with most number of scans - we see that it's Men's Lacrosse.
scans.by.sport <- sparta.scans %>%
  group_by(Group.s.) %>%
  summarise(n()) %>%
  arrange(desc(`n()`))

sparta.scans %>% 
  select(Group.s.) %>%
  tbl_summary(
    sort = list(everything() ~ "frequency"),
    label = Group.s. ~ "Penn sport team and other") %>%
  modify_header(label ~ "Total Number of Scans") %>%
  bold_labels()

```


Next, I cleaned the dataset, removing identifiers. I restricted the sample to Men's Lacrosse and to Counter Movement Jump (CMJ) scan only. I assigned a new unique ID to each athlete (id.new):
```{r}
#Cleaning up dataset here - removing identifiers, new labels, Men's Lax only, Jump scan only.
sparta.scans.clean <- sparta.scans %>%
  select(Unique.ID, Group.s., Date, Time, Scan.Type, Load.t.score, Explode.t.score, Drive.t.score, Jump.height..in., Weight..lb., Injury.risk) %>%
  rename(id = Unique.ID, sport = Group.s., date.scan = Date, time.scan = Time, scan.type = Scan.Type, load.tscore = Load.t.score, explode.tscore = Explode.t.score, drive.tscore = Drive.t.score, jump.ht.in = Jump.height..in., jump.wt.lb = Weight..lb., injury.riskscore = Injury.risk) %>%
  filter(sport == "Lacrosse (M)") %>%
  filter(scan.type == "Jump")

#Check if missing - none.
#sapply(sparta.scans.clean, function(x) length(x[is.na(x)]))

#Assigning new unique ID (pre-assigned from software is very long).
sparta.scans.clean <- sparta.scans.clean %>%
  group_by(id) %>%
  mutate(id.new = row_number())
#Removing old ID
sparta.scans.clean <- sparta.scans.clean[-c(1)]

#More cleaning - make new ID class character.
sparta.scans.clean$id.new <- as.character(sparta.scans.clean$id.new)
#Creating new variable, id.new as a factor
sparta.scans.clean <- sparta.scans.clean %>%
  mutate(id.new_factor = factor(id.new, levels = unique(id.new)))
#Remove old ID from software.
sparta.scans.clean <- sparta.scans.clean[-c(1)]
#Make injury risk score a factor (1-5) from numeric.
sparta.scans.clean$injury.riskscore <- as.factor(sparta.scans.clean$injury.riskscore)

```

The final dataset here:
```{r}
#Cleaned dataset here.
str(sparta.scans.clean)
```

### Results
I looked at 35 Men's lacrosse players with 852 jump scans from 2016-2020 (athletes with complete data).

```{r, message=FALSE}
#Men's lacrosse - we have 35 players, 852 jump scans
#length(unique(sparta.scans.clean$id.new))

#This table shows the number of scans per athlete, range 49-1
scans.per.athlete <- sparta.scans.clean %>%
  group_by(id.new) %>%
  summarise(n()) %>%
  arrange(desc(`n()`))

sparta.scans.clean %>% 
  select(id.new) %>%
  tbl_summary(
    sort = list(everything() ~ "frequency"),
    label = id.new ~ "ID") %>%
  modify_header(label ~ "Number of Scans per Athlete") %>%
  bold_labels()

```


I explored "Injury Risk Score" first, which ranges from 0-low to 5-high risk of injury. We see that for the majority of scans (47%; almost half) Injury Risk Score was reported to be 1, followed by 3, then 0. 
```{r}
#Shows frequencies of scans by injury risk score (scale range 0-5, no 4)
scans.injury.riskscore <- sparta.scans.clean %>% count(injury.riskscore)
#print(scans.injury.riskscore)

sparta.scans.clean %>% 
  select(injury.riskscore) %>%
  tbl_summary(label = injury.riskscore ~ "(0-5)") %>%
  modify_header(label ~ "Injury Risk Score")

#This shows that the most common injury risk score is 1 (then 3, 0, 2, 5)
ggplot(data = sparta.scans.clean, aes(x = injury.riskscore)) +
  geom_bar() +
  labs(y = "Scans (count)",
     x = "Injury Risk Score (0-5)") +
  ggtitle("Number of Scans by Injury Risk Score")

```

We can further observe that Injury Risk Score varies greatly both across the 35 lacrosse athletes and within a given athlete here. Almost all athletes experienced each Injury Risk Score at one point in time. A next step in the larger study will be to explore whether an increase (or change) in Injury Risk Score for a given athlete coincides with an actual injury occurring by combining this dataset with medical/athletic training records containing injuries.

```{r}
#This shows the variability in scans by injury risk score both within the same athlete and across the 35 M lacrosse athletes. 
ggplot(data = sparta.scans.clean, aes(y = id.new_factor, fill = injury.riskscore)) +
  geom_bar() +
  labs(y = "Athlete ID (1-35)",
     x = "Scans (counts)",
     fill = "Injury Risk Score(0-5)") +
  ggtitle("Variability in Injury Risk Score within and across athletes")

```


To explore another facet of the Counter Movement Jump (CMJ), I looked at Injury Risk Score and Jump Height below. We see that in general, higher jumps seem to coincide with lower Injury Risk Scores; 0 and 2. We may have expected to see some sort of dose response relationship, however, Jump Height seems to be fairly consistent across all Injury Risk Scores.

```{r}
#Jump height and injury risk score
#ggplot(data = sparta.scans.clean, aes(x = jump.ht.in, y = injury.riskscore)) +
  #geom_point()
ggplot(data = sparta.scans.clean, aes(x = jump.ht.in, y = injury.riskscore)) +
  geom_boxplot() +
  labs(y = "Injury Risk Score",
        x = "Jump height (in)") +
  ggtitle("Jump height by Injury Risk Score")
```


After Injury Risk Score, I explored the 3 variables that make up the Sparta Movement Signature; LOAD, EXPLODE, and DRIVE (expressed as tscores). Looking across all 35 athletes, we see that most athletes' median scores in all 3 measures center around 50, however, we see consistent variability within a given athlete's scores. This is additional motivation for future studies to determine what factors may be contributing to a change in score over time.
```{r, message=FALSE}
library(gridExtra)
```


```{r}
#This shows median, IQR of LOAD, EXPLODE, DRIVE tscores within and across all M lacrosse athletes
#LOAD
#ggplot(data = sparta.scans.clean, aes(x = load.tscore, y = id.new)) +
  #geom_point()
box.loadt <- ggplot(data = sparta.scans.clean, aes(x = load.tscore, y = id.new_factor)) +
  geom_boxplot() +
  labs(y = "Athlete ID",
         x = "Load t-score") +
  ggtitle("Load")

#EXPLODE
#ggplot(data = sparta.scans.clean, aes(x = explode.tscore, y = id.new)) +
  #geom_point()
box.explodet <- ggplot(data = sparta.scans.clean, aes(x = explode.tscore, y = id.new_factor)) +
  geom_boxplot() +
  labs(y = ".",
       x = "Explode t-score") +
  ggtitle("Explode")

#DRIVE
#ggplot(data = sparta.scans.clean, aes(x = drive.tscore, y = id.new)) +
  #geom_point()
box.drivet <- ggplot(data = sparta.scans.clean, aes(x = drive.tscore, y = id.new_factor)) +
  geom_boxplot() +
  labs(y = ".",
       x = "Drive t-score") +
  ggtitle("Drive")

grid.arrange(box.loadt, box.explodet, box.drivet, ncol = 3)

```

I then examined the relationship between LOAD, EXPLODE, DRIVE scores and Injury Risk Score. We see below that low Injury Risk Score (0,1) seems to coincide with tscores primarily between 45-60, while higher Injury Risk Scores are clustered at tscores below 45 and above 60, resembling a U-shape relationship.
```{r}
#Scatterplots - LOAD, EXPLODE, DRIVE and injury.riskscore

scatter.explode.drivet <- ggplot(sparta.scans.clean, aes(x = explode.tscore, y = drive.tscore,)) +
  geom_point(aes(color=factor(injury.riskscore)), show.legend = FALSE) +
  labs(y = "Drive t-score",
         x = "Explode t-score")
  

scatter.load.drivet <- ggplot(sparta.scans.clean, aes(x = load.tscore, y = drive.tscore,)) +
  geom_point(aes(color=factor(injury.riskscore)), show.legend = FALSE) +
  labs(y = "Drive t-score",
        x = "Load t-score")

scatter.load.explodet <- ggplot(sparta.scans.clean, aes(x = load.tscore, y = explode.tscore,)) +
  geom_point(aes(color=factor(injury.riskscore))) +
  labs(y = "Explode t-score",
        x = "Load t-score") +
  theme(legend.position = "bottom")

grid.arrange(scatter.explode.drivet, scatter.load.drivet, scatter.load.explodet, nrow = 3)

```

Despite being 3 distinct measures, as discussed above, LOAD, EXPLODE, DRIVE can really be thought of together as one overall summary measure. So, in order to better conceptualize LOAD, EXPLODE, and DRIVE scores as one measure, I generated a variable similar to Sparta Science's Movement Signature. I split each variable LOAD, EXPLODE, and DRIVE into tertiles and classified each scan according to "High," "Medium," "Low" on each measure. I then concatenated them, creating a "Jump Profile" for each jump scan.

```{r}
#Splitting LOAD, EXPLODE, DRIVE tscores into tertiles - low, med, high and added these columns to df
sparta.scans.clean <- sparta.scans.clean %>%
  mutate(load.tert = ntile(load.tscore, 3)) %>%
  mutate(load.tert = if_else(load.tert == 1, 'Low', if_else(load.tert == 2, 'Medium', 'High'))) %>%
  mutate(explode.tert = ntile(explode.tscore, 3)) %>%
  mutate(explode.tert = if_else(explode.tert == 1, 'Low', if_else(explode.tert == 2, 'Medium', 'High'))) %>%
  mutate(drive.tert = ntile(drive.tscore, 3)) %>%
  mutate(drive.tert = if_else(drive.tert == 1, 'Low', if_else(drive.tert == 2, 'Medium', 'High'))) %>%
  arrange(id.new)
#concatenate their "movement signature" into a "jump profile"
sparta.scans.clean$jump.profile <- paste(sparta.scans.clean$load.tert,sparta.scans.clean$explode.tert,sparta.scans.clean$drive.tert)

head(sparta.scans.clean)

```

Below, the bar graphs show the proportion of each athlete's scans where LOAD, EXPLODE, DRIVE were classified as Low, Medium, High. We see a lot of variability within each athlete's LOAD, EXPLODE, DRIVE profiles (which, at this point in this class project, wasn't so surprising). Across the board, athletes had scans that could be classified as Low, Medium, and High, consistently across all 3 measures, and even athletes with only a handful of scans had this. We expected there to be maybe some variation in scores across athletes based on individual characteristics, but we were surprised to see such variation within an athlete over time. Again, as discussed above in the section on tscores, a next step in this project will be to see if these changes in Jump Profile coincide with actual injury based on injury records.

```{r}
#This shows variability in LOAD, EXPLODE, DRIVE within and across athletes
#Load
bar.loadprofile <- ggplot(data = sparta.scans.clean, aes(y = id.new_factor, fill = load.tert)) +
  geom_bar(show.legend = FALSE) +
  labs(y = "Athlete ID",
       x = "Scans (count)",
       fill = "Load tertiles") +
  ggtitle("Load")

#Explode
bar.explodeprofile <- ggplot(data = sparta.scans.clean, aes(y = id.new_factor, fill = explode.tert)) +
  geom_bar() +
  labs(y = ".",
       x = "Scans (count)",
       fill = "Tertiles") +
  ggtitle("Explode") +
  theme(legend.position = "bottom")

#Drive
bar.driveprofile <- ggplot(data = sparta.scans.clean, aes(y = id.new_factor, fill = drive.tert)) +
  geom_bar(show.legend = FALSE) +
  labs(y = ".",
       x = "Scans (count)",
       fill = "Drive tertiles") +
  ggtitle("Drive") 


```


```{r}
grid.arrange(bar.loadprofile, bar.explodeprofile, bar.driveprofile, ncol = 3)
```


```{r}
```

Putting these pieces together, I then looked at jump profile within an athlete and across our 35 Men's Lacrosse players, and saw a lot of variability here as well.
```{r}
#This shows the variability in jump profile within and across athletes
ggplot(data = sparta.scans.clean, aes(y = id.new_factor, fill = jump.profile)) +
  geom_bar() +
  labs(y = "Athlete ID",
       x = "Scans (counts)",
       fill = "Jump profile - LOAD, EXPLODE, DRIVE") +
  ggtitle("Variability in jump profile within and across athletes")

```

Finally, I was interested in examining how these LOAD, EXPLODE, DRIVE variables were associated with Injury Risk Score as an outcome variable. Below, I plot each measure by Injury Risk Score. Here, we expected to see some type of dose response relationship between all or some of the measures and Injury Risk Score. We do not see this.
```{r}

boxplot.load.injury <- ggplot(sparta.scans.clean, aes(x = load.tscore, y = injury.riskscore)) +
  geom_boxplot() +
  labs(y = "Injury risk score",
        x = "Load t-score")

boxplot.explode.injury <- ggplot(sparta.scans.clean, aes(x = explode.tscore, y = injury.riskscore)) +
  geom_boxplot() +
  labs(y = "Injury risk score",
        x = "Explode t-score")

boxplot.drive.injury <- ggplot(sparta.scans.clean, aes(x = drive.tscore, y = injury.riskscore)) +
  geom_boxplot() +
  labs(y = "Injury risk score",
        x = "Drive t-score")

grid.arrange(boxplot.load.injury,boxplot.explode.injury,boxplot.drive.injury, nrow = 3)

```

As a first (somewhat preliminary) pass, I performed bivariate analysis, using linear(OLS) regression to look at the pairwise relationships between:
1) Load tscore -> Injury Risk Score
2) Explode tscore -> Injury Risk Score
3) Drive tscore -> Injury Risk Score

I then fit a multivariate linear regression model:
4) Load, Explode, Drive as predictors of Injury Risk Score
```{r}

sparta.scans.clean$injury.riskscore.cont <- as.numeric(sparta.scans.clean$injury.riskscore)

#Examining correlation between LOAD, EXPLODE, DRIVE and Injury Risk Score
cor(sparta.scans.clean$load.tscore, sparta.scans.clean$injury.riskscore.cont)
cor(sparta.scans.clean$explode.tscore, sparta.scans.clean$injury.riskscore.cont)
cor(sparta.scans.clean$drive.tscore, sparta.scans.clean$injury.riskscore.cont)

#Linear regression - bivariate
summary(lm(injury.riskscore.cont ~ load.tscore, data = sparta.scans.clean))

summary(lm(injury.riskscore.cont ~ explode.tscore, data = sparta.scans.clean))

summary(lm(injury.riskscore.cont ~ drive.tscore, data = sparta.scans.clean))

#Multivariate linear regression
injury.riskscore.cont.lm <- lm(injury.riskscore.cont ~ load.tscore + explode.tscore + drive.tscore, data = sparta.scans.clean)
summary(injury.riskscore.cont.lm)


```

We see here that neither LOAD, EXPLODE, nor DRIVE correspond to Injury Risk Score in a linear fashion. 

### Conclusion/Next steps:
I concluded this class project by determining whether the Load or Expload or Drive score(s) corresponds to Injury Risk Score in a linear fashion, and found that they do not (so, at least based on evidence here, a score on those measures isn't associated with a higher Injury Risk Score). I could (and will) examine appropriate cut-points, split Injury Risk Score into levels as an ordinal variable, and repeat the analysis as a logistic regression.
However, ultimately, we are likely getting ahead of ourselves here with regard to prediction. What the field really needs to explore first is the variability that we see in these measures within an athlete. So, thinking back to the earlier parts of this project, the next best step is to examine this variability as it relates to actual injury occurrence over time, which we will do.
