---
title: "EPID 600 Project Template"
author: "Amrom Obstfeld"
output: 
  html_document:
    toc: false 
    depth: 3 
---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 400)
```  
***

# Predicting Screening Coagulation Studies Using Coagulation Factor Results

### By Amrom Obstfeld

## Overview
The interpretation of coagulation studies in clinical practice can be hampered by lack of understanding of the relationship between screening coagulation studies and followup coagulation factor results that are ordered in order to expain abnormalities in these studies. In order to allucidate these relationships I will acquire deideintified laboratory results from CHOP and HUP data warehouses and use statistical and machine learning tools. My ultimate goal is to use these tools in clinical practice to guide clinicians towards appropriate coagulation tests.

## Introduction
Screening coagulation studies such as the partial thromboplastin time (PTT) and the prothrombin time (PT) are used to assess the risk of bleeding patients. When abnormalities are seen in one or both of these, additional testing is performed to identify the specific blood  coagulation factors that are abnormal. The univariate relationships between the screening studies and the specific factors have been elucidated using empiric laboratory evidence. However these relationships have not been validated using real patient data. Furthermore the multivariate relationships are more difficult to assess in the laboratory. Using accurate real-world models will allow hematologists and coagulation laboratories to better assess the bleeding risk of patients and suggest additional studies when screening results are inconsistent with the results of the coagulation factor levels.

Addressing this problem requires a multidisciplinary approach. Specifically, in depth knowledge of the pathophysiology of several hematological disorders is necessary in order to steer clear of patients with data that wouuld obscure this relationship. For instance, patients with elevated PTT levels as a results of anti-phospholipid antibodies would confound results due to the kinetics of the antibodies present in this situation. Input from pathology and laboratory medicine brings an in depth knowledge of the way the data was generated and allows the project to avoid additional potential confounding variables. For instance, the precise relationship between screening studies and coagulation factor levels may be impacted by changes in reagent manufactururers, changes in lots, or changes in instrumentation. Finally, data scientists provide insight into the process of exploring data and using knowledge of the data, such as its size, quality, and nature, to inform the classifier development approach. 


### Methods
In the first paragraph, describe the data used and general methodological approach. Subsequently, incorporate full R code necessary to retrieve and clean data, and perform analysis. Be sure to include a description of code so that others (including your future self) can understand what you are doing and why. 

Two independent datasets containing results from coagulation testing were obtained. The first of these data sets was obtained from a clinical laboratory data repository maintained by the Department of Pathology at Penn Medicine. The second of these datasets was exported out of the CHOP Data warehouse. 

```{r}
library(readr)
# penn <- read_csv(
#   "~/Rprojects/EPID600_Final_Project/coag_res.csv",
#   col_types = cols(
#     drawn_date = col_datetime(format = "%m/%d/%Y %H:%M"),
#     ord_date = col_datetime(format = "%m/%d/%Y %H:%M"),
#     pat_adm_dt = col_datetime(format = "%m/%d/%Y %H:%M"),
#     result = col_character()
#   )
# )

penn <-
  read_csv(
    "~/Rprojects/EPID600_Final_Project/coag_res.v2.csv.gz",
    col_types = cols(
      drawn_date = col_datetime(format = "%m/%d/%Y %H:%M"),
      ord_date = col_datetime(format = "%m/%d/%Y %H:%M"),
      pat_adm_dt = col_datetime(format = "%m/%d/%Y %H:%M"),
      result = col_character()
    )
  )

```

Summary views of the data were reviewed

```{r}
str(penn)
summary(penn)
#May want to explore how NA's are correlate, may want to see how the two value fields relate to each other and to the result.
```
Columns of relavence were selected
```{r}
library(dplyr)
cols<-c(5,17,21,7,12,14,15)
penn<-penn%>%select(cols)
```
Task_name is the variable that holds the test name. Need to filter dataset to tests relavent to the PT and PTT screening tests

```{r}
table(penn$task_name)
#filter out extraneous testing pulled out of warehouse
penn<-penn%>%filter(!task_name %in% c('Factor XIII', 'PT 0 Patient',  'PT 30 Patient','PT TEMP','PTT 0 Patient', 'PTT 30 Patient','PTT 60 Patient','TTI','PT WB','PTT WB','DTT','PT 60 Patient'))
```


All 'result' values should be numeric, need to explore results that are non-numeric.
```{r}
#Index by na's introduced by as.numeric coercion
penn%>%select(2,4)%>%filter(is.na(as.numeric(result)))%>%table
```
All textbased comments in the result field indicate fundamental issues with the result and should be filtered out. Many of the remainder are due to a measurement being out of range high or low. most of these can be kept and replaced with the numeric value indicated in the field for the purposes of this analysis
```{r}
#Explore weird results
#Replace with NA those results without numbers
penn$result[grepl("[:alpha:]",penn$result)]<-NA
penn$result[grepl("[:a-z:]",penn$result)]<-NA
penn$result[grepl("[:A-Z:]",penn$result)]<-NA
#Results that are 'greater than' a number (such as 150, 90, etc) should be replaced with that number. 
penn$result<-gsub(">", "", penn$result) 
#Less than with a small number should be replaced by 0. 
penn$result<-gsub("<", "", penn$result)
#Text results should be filtered out of dataset.
penn<-penn%>%filter(!is.na(result))
#Convert result variable to numeric
penn$result<-as.numeric(penn$result)
#confirm removal of all non-numeric results
penn%>%filter(is.na(result))%>%count%>%as.numeric

```

A histogram was created in order to see the amount  of each kind of result in the dataset. The plot demonstrates that the vast majority of tests included only screening tests and not individuals factors. These will have to be filtered from the data set (see below).

```{r}
library(knitr)
library(ggplot2)
ggplot(penn)+
  geom_bar(aes(x=task_name))+
  scale_y_log10()
knitr::kable(penn%>%group_by(task_name)%>%summarise(n=n())%>%arrange(desc(n)))

```



The accession number is essentially the order number. This number groups labs that were performed on the same sample. This is the unit upon which we will group the dependent and independent variables. The 'empi' is also important as it represents the patient identifier in this de-identified data set.
To facilitate analysis, the data was reshaped to a spread format, such that the independent and dependent variables now present in the 'task_name' variables are spread out in there own columns. Results are grouped by accession number. Before doing so, data cleaning was performed.

```{r}
library(tidyr)
library(lubridate)
#Before spreading data need to ensure that all entries are unique
dblresults<-penn%>%group_by(accession,task_name)%>%summarise(n=n())%>%ungroup()%>%filter(n>1)
dupresults<-penn%>%group_by(accession,task_name,result)%>%summarise(n=n())%>%select(1,2,4)%>%ungroup()%>%filter(n>1)
```

There were `r nrow(dupresults)` entries with duplicated data. There were `r nrow(dblresults)-nrow(dupresults)` with two results for the same test in the same accession. The accessions with two different result values for the same test were further evaluated.

```{r}
acc<-left_join(dblresults,penn, by=c('accession' = 'accession', 'task_name' = 'task_name'))
```

Overall the number of duplications are fairly small. This appears to be due to duplication of a screening test (PT, PTT, or fibrinogen) off of an identical draw time. The percent difference between these was calculated. 

```{r}

acc%>%group_by(accession,task_name)%>%summarise(n=n(),mean=mean(result),stdev=sd(result),cv=sd(result)/mean(result))%>%filter(n>1)

acc.rm<-acc%>%group_by(accession,task_name)%>%summarise(n=n(),mean=mean(result),stdev=sd(result),cv=sd(result)/mean(result))%>%filter(n>1)%>%filter(cv>.2)
```

Nine of these differences were greater than 20%. As a result the agreement was considered close enough for the analysis in this project and these values were replaced with the average of these two results. The following dataframe accounts for this correction and spreads variables within task_name across new column fields with values coming from 


```{r}
penndf<-anti_join(penn,acc.rm,by=c('accession' = 'accession', 'task_name' = 'task_name'))%>%
  group_by(empi,accession,task_name)%>%summarise(result=mean(result))%>%spread(task_name,result)
str(penndf)
summary(penndf)
```

Most of these orders only have PT or PTT, the screening test and the dependent variables in this analysis, as such these need to be filtered out since they will not contribute to the analysis. 

```{r}
#The following lines labels all rows with NAs in every independent predicting variable as a '10', any number less than 10 means that there is at least one 
penndf[,15]<-as.numeric()
names(penndf)[15]<-"allna"

penndf$allna<-rowSums(apply(is.na(penndf[,c(3:11,14)]), 2, as.numeric))


#Plot distribution of number of results for each acccession
ggplot(penndf)+
  geom_bar(aes(x=allna))+
  scale_y_log10()+
  ggtitle("Distribution of number of missing data per entry")+
  labs(x="Number of factor assays missing",y="Number of entries (log)",title="Distribution of number of missing data per entry")
```

As a result of the uselessness of having numerous accessions with dependent vairables but without the predictors these have been dropped. 
```{r}

#create final dataset with filtering. Rename variables to remove spaces

names(penndf)<-gsub(" ","",names(penndf))
penndf<-penndf%>%filter(allna<10)
summary(penndf)
str(penndf)
```

### Results
Describe your results and include relevant tables, plots, and code/comments used to obtain them. End with a brief conclusion of your findings related to the question you set out to address. You can include references if you'd like, but this is not required.

It is helpful when performing regression analysis to have a distribution of results. The Distributions of results were explored with histograms of screening lab results and specific coagulation factors (Figure 1). 

```{r}
library(gridExtra)

myplots <- list()  # new empty list
for (i in 1:length(colnames(penndf))) {
    p1 <- eval(substitute(
        ggplot(data=data.frame(penndf),aes(x=penndf[,i]))+ 
          geom_histogram(fill="grey") +
          xlab(colnames(penndf)[ i])
    ,list(i = i)))
    #print(i)
    #print(p1)
    myplots[[i]] <- p1  # add each plot into plot list
}


grid.arrange(myplots[[3]], 
             myplots[[4]],
             myplots[[5]],
             myplots[[6]],
             myplots[[7]],
             myplots[[8]],
             myplots[[9]],
             myplots[[10]],
             myplots[[11]],
             myplots[[12]],
             myplots[[13]],
             myplots[[14]],
             nrow=3, ncol=4,top="Distribution of lab results in data set",  bottom="Figure 1")
#In the future suggest adding normal range vertical bars

```
The data demonstrates that there is a relatively evenly distributed set of results for predictors lab values. Dependent lab results had a unimodal gaussian distribution, centered around the normal range for these measures (?).

```{r}
library(gtools)

bxpt <- list()  # new empty list
for (i in c(3:11,14)) {
    p1 <- eval(substitute(
        ggplot(penndf)+
          geom_boxplot(aes(x=quantcut(as.numeric(unlist(penndf[,i])),na.rm = TRUE),y=PT)) +
          xlab(colnames(penndf)[ i]) +
          ylim(0,25)
    ,list(i = i)))
    #print(i)
    #print(p1)
    bxpt[[i]] <- p1  # add each plot into plot list
}


grid.arrange(bxpt[[3]], 
             bxpt[[4]],
             bxpt[[5]],
             bxpt[[6]],
             bxpt[[7]],
             bxpt[[8]],
             bxpt[[9]],
             bxpt[[10]],
             bxpt[[11]],
             bxpt[[14]],
             nrow=3, ncol=4,top="Box plots depicting relationship of coagulation factor quantiles and Prothrombin Time",  bottom="Figure 2")


bxptt <- list()  # new empty list
for (i in c(3:11,14)) {
    p1 <- eval(substitute(
        ggplot(penndf)+
          geom_boxplot(aes(x=quantcut(as.numeric(unlist(penndf[,i])),na.rm = TRUE),y=PTT)) +
          xlab(colnames(penndf)[ i])
    ,list(i = i)))
    #print(i)
    #print(p1)
    bxptt[[i]] <- p1  # add each plot into plot list
}

grid.arrange(bxptt[[3]], 
             bxptt[[4]],
             bxptt[[5]],
             bxptt[[6]],
             bxptt[[7]],
             bxptt[[8]],
             bxptt[[9]],
             bxptt[[10]],
             bxptt[[11]],
             bxptt[[14]],
             nrow=3, ncol=4,top="Box plots depicting relationship of coagulation factor quantiles and partial thromboplastin time",bottom="Figure 3")



```



To further explore the relationships amongst these measures, bivariate plots were created.
```{r}

mypts <- list()  # new empty list
for (i in c(3:11,14)) {
    p1 <- eval(substitute(
        ggplot(data=data.frame(penndf),aes(y=PT, x=penndf[,i]))+ 
          geom_point(fill="grey") +
          xlab(colnames(penndf)[ i]) +
          ylim(0,25)
    ,list(i = i)))
    #print(i)
    #print(p1)
    mypts[[i]] <- p1  # add each plot into plot list
}


grid.arrange(mypts[[3]], 
             mypts[[4]],
             mypts[[5]],
             mypts[[6]],
             mypts[[7]],
             mypts[[8]],
             mypts[[9]],
             mypts[[10]],
             mypts[[11]],
             mypts[[14]],
             nrow=3, ncol=4,top="Scatterplots of independent variables vs Prothrombin Time",  bottom="Figure 4")
#In the future suggest adding normal range vertical bars
```

```{r}

myptts <- list()  # new empty list
for (i in c(3:11,14)) {
    p1 <- eval(substitute(
        ggplot(data=data.frame(penndf),aes(y=PTT, x=penndf[,i]))+ 
          geom_point(fill="grey") +
          xlab(colnames(penndf)[ i])
    ,list(i = i)))
    #print(i)
    #print(p1)
    myptts[[i]] <- p1  # add each plot into plot list
}


grid.arrange(myptts[[3]], 
             myptts[[4]],
             myptts[[5]],
             myptts[[6]],
             myptts[[7]],
             myptts[[8]],
             myptts[[9]],
             myptts[[10]],
             myptts[[11]],
             myptts[[14]],
             nrow=3, ncol=4,top="Scatterplots of independent variables vs Prothrombin Time",  bottom="Figure 5")
#In the future suggest adding normal range vertical bars
```

A seperate analysis was performed specifically on the reptilase time as it itself is considered a screen for a fibrinogen abnormality. This was again performed using boxplots and bivariate scatterplots.

```{r}

p1<-ggplot(penndf)+
  geom_boxplot(aes(y=`Reptilase Test`, x=quantcut(penndf$Fibrinogen,na.rm = TRUE)))

p2<-ggplot(penndf)+
  geom_point(aes(y=`Reptilase Test`, x=penndf$Fibrinogen))

grid.arrange(p1,p2,nrow=1)

```

```{r}
attach(penndf)

#perofrm lm and store as list
pt.lm<-lapply( penndf[,-1], function(x) summary(lm(penndf$PT ~ x)) )
#Extract relavent parameters and store as dataframe lmresults.pt
variable<-names(pt.lm)
cols<-as.list(c(1:14))
beta.f<-function(x){
  pt.lm[x][[1]][[4]][2,1]
}

pvalue.f<-function(x){
  pt.lm[x][[1]][[4]][2,4]
}

arsquared.f<-function(x){
  pt.lm[x][[1]][[9]]
}

beta<-lapply(cols, beta.f)
pvalue<-lapply(cols, pvalue.f)
arsquare<-lapply(cols, arsquared.f)

lmresults.pt<-as.data.frame(cbind(variable=unlist(variable),beta=unlist(beta),pvalue=unlist(pvalue),arsquare=unlist(arsquare),log='linear'),stringsAsFactors = FALSE)
lmresults.pt[2:4]<-sapply(lmresults.pt[2:4],as.numeric)


#perofrm lm for pt on log of dependent variable and store as list
ptlg.lm<-lapply( penndfx[,-1], function(x) summary(lm(penndf$PT ~ log(x))))
#Extract relavent parameters and store as dataframe lmresults.pt
variable<-names(ptlg.lm)
cols<-as.list(c(1:14))
beta.f<-function(x){
  ptlg.lm[x][[1]][[4]][2,1]
}

pvalue.f<-function(x){
  ptlg.lm[x][[1]][[4]][2,4]
}

arsquared.f<-function(x){
  ptlg.lm[x][[1]][[9]]
}

beta<-lapply(cols, beta.f)
pvalue<-lapply(cols, pvalue.f)
arsquare<-lapply(cols, arsquared.f)

lmresultslg.pt<-as.data.frame(cbind(variable=unlist(variable),beta=unlist(beta),pvalue=unlist(pvalue),arsquare=unlist(arsquare),log='log'),stringsAsFactors = FALSE)
lmresultslg.pt[2:4]<-sapply(lmresultslg.pt[2:4],as.numeric)
lmresults.pt<-bind_rows(lmresults.pt,lmresultslg.pt)

knitr::kable(lmresults.pt)
```

The results of the univariate regression support much of the information and conventional wisdom in the literature. The most significant predictor of the prothrombin time are common pathway and extrinsic pathway coagulation factors (Factors X,II,VII). Interestingly, the logarithmic model produces the most robust predictors. Unexpectadly, two common pathway factors had little impact on the Prothrombin time, Factor V and Fibrinogen. The literature suggests that biologically, very little  Factor V activity is required for coagulation, which supports the results of this analysis. The lack of association with fibrinogen is somewhat surprusing given thatn the Reptilase time, which is solely dependent on fibrinogen is correlated with Prothrombin time. This may be because the fibrinogen quantification, which is assayed in diluted plasma, is less sensitivie to the inhibitors, such as fibrin split products, than the reptilase time, which is performed undiluted.  


```{r}
attach(penndf)

#perofrm lm and store as list
ptt.lm<-lapply( penndf[,-1], function(x) summary(lm(penndf$PTT ~ x)) )
#Extract relavent parameters and store as dataframe lmresults.ptt
variable<-names(ptt.lm)
cols<-as.list(c(1:14))
beta.f<-function(x){
  ptt.lm[x][[1]][[4]][2,1]
}

pvalue.f<-function(x){
  ptt.lm[x][[1]][[4]][2,4]
}

arsquared.f<-function(x){
  ptt.lm[x][[1]][[9]]
}

beta<-lapply(cols, beta.f)
pvalue<-lapply(cols, pvalue.f)
arsquare<-lapply(cols, arsquared.f)

lmresults.ptt<-as.data.frame(cbind(variable=unlist(variable),beta=unlist(beta),pvalue=unlist(pvalue),arsquare=unlist(arsquare),log='linear'),stringsAsFactors = FALSE)
lmresults.ptt[2:4]<-sapply(lmresults.ptt[2:4],as.numeric)


#perofrm lm for ptt on log of dependent variable and store as list
pttlg.lm<-lapply( penndfx[,-1], function(x) summary(lm(penndf$PTT ~ log(x))))
#Extract relavent parameters and store as dataframe lmresults.ptt
variable<-names(pttlg.lm)
cols<-as.list(c(1:14))
beta.f<-function(x){
  pttlg.lm[x][[1]][[4]][2,1]
}

pvalue.f<-function(x){
  pttlg.lm[x][[1]][[4]][2,4]
}

arsquared.f<-function(x){
  pttlg.lm[x][[1]][[9]]
}

beta<-lapply(cols, beta.f)
pvalue<-lapply(cols, pvalue.f)
arsquare<-lapply(cols, arsquared.f)

lmresultslg.ptt<-as.data.frame(cbind(variable=unlist(variable),beta=unlist(beta),pvalue=unlist(pvalue),arsquare=unlist(arsquare),log='log'),stringsAsFactors = FALSE)
lmresultslg.ptt[2:4]<-sapply(lmresultslg.ptt[2:4],as.numeric)
lmresults.ptt<-bind_rows(lmresults.ptt,lmresultslg.ptt)
knitr::kable(lmresults.ptt)

```

```{r}

#Two plots to look at the distribution of the lm statistics
lmresults.pt%>%filter(!variable %in% c('PT','PTT','accession','allna'))%>%
ggplot()+
  geom_bar(stat='identity',aes(x=variable,y=pvalue,fill=log),position='dodge')+
  geom_hline(yintercept=0.05)+
  theme(axis.text.x = element_text(angle=60, hjust=1))

lmresults.ptt%>%filter(!variable %in% c('PT','PTT','accession','allna'))%>%
ggplot()+
  geom_bar(stat='identity',aes(x=variable,y=pvalue,fill=log),position='dodge')+
  geom_hline(yintercept=0.05)+
  theme(axis.text.x = element_text(angle=60, hjust=1))

```


Like the results of the linear regression models for the prothrombin time, the results for the partial thromboplastin time confirm many common assumptions about the relationships between these factors and provide some surprising results. By far the best predictors are factors VIII and XI, particularly the log transformed values. THese are both coagulation factors in the intrinsic pathway that are known to have a strong impact partial thromboplastin times. Amongst the factors that were not found to be associated with PTT were the common pathway factors, despite the fact that the common pathway is required for coagulation testing using the PTT. This result is most likely due to a combination of a relatively weak impact of these factors on PTT clotting times as well as the limitations in the number of datapoints in the dataset.    

```{r}
#LIkely having problem with multivariate analysis as a result of missing data. Will need to analyse missing data, consider imputation and or regression that can deal with missing data.
mlm.pt<-lm(PT~log(FactorVII)+log(FactorX)+Fibrinogen+ReptilaseTest)
summary(mlm.pt)

mlm.ptt<-lm(PTT~log(FactorVIII)+log(FactorXI)+Fibrinogen+ReptilaseTest)
summary(mlm.ptt)

```
```{r}
#impute data for multivariate regression
library('mice')
penndf.pt<-penndf%>%select(3,6,8,11,12)
imp.pt <- mice(penndf.pt, m=5, maxit = 50, method = 'pmm', seed = 500)
fit.imp.pt <- with(data = imp.pt, exp = lm(PT ~ log(FactorII) + log(FactorVII) + log(FactorX)+Fibrinogen)) 

#combine results of all 5 models
combine.pt <- pool(fit.imp.pt)
summary(combine.pt)


penndf.ptt<-penndf%>%select(4,8,10,14)
imp.ptt <- mice(penndf.ptt, m=5, maxit = 50, method = 'pmm', seed = 500)
fit.imp.ptt <- with(data = imp.ptt, exp = lm(PTT ~ log(FactorIX)+(FactorVIII)+log(FactorXI))) 

#combine results of all 5 models
combine.ptt <- pool(fit.imp.ptt)
summary(combine.ptt)


```

The results indicate an association of the predictor variables that were identified in univariate analysis, however the multivariate will likely require additional data without as many missing values. 
