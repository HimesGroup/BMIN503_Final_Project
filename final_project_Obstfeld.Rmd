---
title: "EPID 600 Project Template"
author: "Amrom Obstfeld"
output: 
  html_document:
    toc: false 
    depth: 3 
---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 400)
```  
***

# Predicting Screening Coagulation Studies Using Coagulation Factor Results

### By Amrom Obstfeld

## Overview
The interpretation of coagulation studies in clinical practice can be hampered by lack of understanding of the relationship between screening coagulation studies and followup coagulation factor results that are ordered in order to expain abnormalities in these studies. In order to allucidate these relationships I will acquire deideintified laboratory results from CHOP and HUP data warehouses and use statistical and machine learning tools. My ultimate goal is to use these tools in clinical practice to guide clinicians towards appropriate coagulation tests.

## Introduction
Screening coagulation studies such as the partial thromboplastin time (PTT) and the prothrombin time (PT) are used to assess the risk of bleeding patients. When abnormalities are seen in one or both of these, additional testing is performed to identify the specific blood  coagulation factors that are abnormal. The univariate relationships between the screening studies and the specific factors have been elucidated using empiric laboratory evidence. However these relationships have not been validated using real patient data. Furthermore the multivariate relationships are more difficult to assess in the laboratory. Using accurate real-world models will allow hematologists and coagulation laboratories to better assess the bleeding risk of patients and suggest additional studies when screening results are inconsistent with the results of the coagulation factor levels.

Addressing this problem requires a multidisciplinary approach. Specifically, in depth knowledge of the pathophysiology of several hematological disorders is necessary in order to steer clear of patients with data that wouuld obscure this relationship. For instance, patients with elevated PTT levels as a results of anti-phospholipid antibodies would confound results due to the kinetics of the antibodies present in this situation. Input from pathology and laboratory medicine brings an in depth knowledge of the way the data was generated and allows the project to avoid additional potential confounding variables. For instance, the precise relationship between screening studies and coagulation factor levels may be impacted by changes in reagent manufactururers, changes in lots, or changes in instrumentation. Finally, data scientists provide insight into the process of exploring data and using knowledge of the data, such as its size, quality, and nature, to inform the classifier development approach. 


### Methods
In the first paragraph, describe the data used and general methodological approach. Subsequently, incorporate full R code necessary to retrieve and clean data, and perform analysis. Be sure to include a description of code so that others (including your future self) can understand what you are doing and why. 

Two independent datasets containing results from coagulation testing were obtained. The first of these data sets was obtained from a clinical laboratory data repository maintained by the Department of Pathology at Penn Medicine. The second of these datasets was exported out of the CHOP Data warehouse. 

```{r}
library(readr)
penn <- read_csv("~/Rprojects/EPID600_Final_Project/coag_res.csv", 
     col_types = cols(drawn_date = col_datetime(format = "%m/%d/%Y %H:%M"), 
         ord_date = col_datetime(format = "%m/%d/%Y %H:%M"), 
         pat_adm_dt = col_datetime(format = "%m/%d/%Y %H:%M"), 
         result = col_character()))
```

Summary views of the data were reviewed

```{r}
str(penn)
summary(penn)
```
Columns of relavence were selected
```{r}
library(dplyr)
cols<-c(5,7,10:15,17,23,24)
penn<-penn%>%select(cols)
```
task_name represents the variable that holds the test name. Need to filter dataset to tests relavent to the PT and PTT screening tests

```{r}
table(penn$task_name)
#filter out extraneous testing pulled out of warehouse
penn%>%filter(!task_name %in% c('Factor XIII', 'PT 0 Patient',  'PT 30 Patient','PT TEMP','PTT 0 Patient', 'PTT 30 Patient','PTT 60 Patient','TTI','PT WB'))%>%select(task_name)%>%table

```


All 'result' values should be numeric, need to explore results that are non-numeric.
```{r}
#Index by na's introduced by as.numeric coercion
table(penn$result[is.na(as.numeric(penn$result))])

#Explore weird results
penn%>%filter(result=='>1400')#makes sense, Fibringoen gives high results.
penn%>%filter(result=='<150.0')#likely typo
penn$result<-gsub("<150.0", ">150.0", penn$result)
penn%>%filter(result=='<45')#makes sense, Fibringoen low end of AMR is 45.
#Replace with NA those results without numbers
penn$result[grepl("[:alpha:]",penn$result)]<-NA
penn$result[grepl("[:a-z:]",penn$result)]<-NA
penn$result[grepl("[:A-Z:]",penn$result)]<-NA
#Results that are 'greater than' a number (such as 150, 90, etc) should be replaced with that number. 
penn$result<-gsub(">", "", penn$result) 
#Less than with a small number should be replaced by 0. 
penn$result<-gsub("<1", "0", penn$result)
penn$result<-gsub("<5.0", "0", penn$result)
penn$result<-gsub("<45", "45", penn$result)
#Text results should be filtered out of dataset.
penn<-penn%>%filter(!is.na(result))
#Convert result variable to numeric
penn$result<-as.numeric(penn$result)
#confirm removal of all non-numeric results
penn%>%filter(is.na(result))%>%count%>%as.numeric

```







### Results
Describe your results and include relevant tables, plots, and code/comments used to obtain them. End with a brief conclusion of your findings related to the question you set out to address. You can include references if you'd like, but this is not required.