---
title: "BMIN503/EPID600 Project Template"
author: "Your Name"
output: 
  html_document:
    toc: false 
    depth: 3 
    theme: paper 
    highlight: tango
---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 400)
```  


### Overview
In this section, give a brief a description of your project and its goal, what data you are using to complete it, and what three faculty/staff in different fields you have spoken to about your project with a brief summary of what you learned from each person. Include a link to your final project GitHub repository.

This project will be investigating 6 month outcomes in stroke patients who are discharged from the hospital to a nursing home. We will formulate 3 models. One model will address the question: What factors predict if these patients survive to 6 months? The second model will address the question: What factors predict if these patients improve their living situation (either living at home, a relatives or a residential community) or remain in the nursing home? The third model will address the question: What factors predict their level of function? Are they dependent or not-dependent? 

https://github.com/emahannagabrielli/BMIN503_Final_Project

#Discussed with Dr.Kumar and thought since the outcome of survival is in both the final living situation and final functional outcome, we could reframe the research questions to 3.  First: What factor determine if someone who is discharged to the NH will survive to 6 months? If alive, what factors determine if they will remain in the NH or improve there level of living? If alive, what factors determine if they will be dependent or not?

### Introduction 

Acute stroke is a common and highly morbid disease. Worldwide it is the second most common cause of mortality and third most common cause of disability. More than 7 million people in the United States survive a stroke each year. Improvements in acute stroke treatment such as intravenous tPA and thombectomy have greatly decreased stroke mortality and disabilty. However, there are still a large number of patients who are not candidates for these therapies due to timing of stroke onset, medical comorbidities, medications and more. Families often struggle with deciding between full aggressive care and making their loved one hospice care only. Key questions are often, will they be in a nursing home forever or only temporarily?  Will they be dependent on others for their care? If we knew factors associated with these poor outcomes, it would allow physicians to better council families during these goals of care discussions.

This problem requires a bioinformatician, statistical analysis and clinical knowledge of the problem from both neurology and intensive care point of view. As a bioinformatician in training, I have the knowledge on how to access this database in order to perform a novel secondary analysis.  With statistical expertise, our team is able to appropriately model and analyse our data. Along with this we require the clinical knowledge for the scope of the problem, the clinical significance and to help trouble shoot our analysis. For example, it was discovered some final cohorts on functional status at discharge had very small cohorts.  Using expert consultation from a neurologist we determined it is appropriate to group both the recovered patients and the not-recovered but not-dependent patients together. 

### Methods
In the first paragraph, describe the data used and general methodological approach. Subsequently, incorporate full R code necessary to retrieve and clean data, and perform analysis. Be sure to include a description of code so that others (including your future self) can understand what you are doing and why. 

```{r, eval=TRUE}
library(dplyr)
library(tidyr)
library(tidyverse)
IST <- read.csv("IST_corrected.csv", header=TRUE) #Link to websiste with CSV file https://datashare.is.ed.ac.uk/handle/10283/128
class(IST)
names(IST)
head(IST)
str(IST)
dim(IST)
sum(is.na(IST$DPLACE))
IST_nh <- filter(IST, DPLACE=="D") #Filtering patients who were discharged to place "D," which is a nursing home. 
dim(IST_nh) #cohort is now 534 subjects
str(IST_nh) 
#Link to datadictionary: https://datashare.is.ed.ac.uk/bitstream/handle/10283/128/IST_variables.pdf?sequence=10&isAllowed=y
#Discussed with Dr. Hubbard and First step is to figure out how many subjects are in each outcome.  This then allows me to determine how many predictors I can use. 
IST_nh_home <- filter(IST_nh, FPLACE=="A") #subsetting to subjects who were living at home at 6 months
dim(IST_nh_home) #112 subjects at home in 6 months
IST_nh_rel <- filter(IST_nh, FPLACE=="B") #subsetting to subjects who were living at a relatives home at 6 months
dim(IST_nh_rel) #12 subjects at relatives home
IST_nh_rescare <- filter(IST_nh, FPLACE=="C") #subsetting to subjects who were living in residential care at 6 months
dim(IST_nh_rescare) #57 in residential care
IST_nh_improvedliving <- filter(IST_nh, FPLACE=="A"|FPLACE=="B"|FPLACE=="C") #subsetting to subjects who improved to a lower level of care living situation at 6 months. 
dim(IST_nh_improvedliving) #188 improved living condition
IST_nh_nh <- filter(IST_nh, FPLACE=="D") #subsetting to subjects who remained in a nursing home at 6 months
dim(IST_nh_nh) #188 remained in NH
IST_nh_hosptial <- filter(IST_nh, FPLACE=="E") #subsetting to subjects who were in a hospital setting at 6 months.  I discussed with Dr. Hubbard and Dr. Kumar and we will remove these from the dataset. 
dim(IST_nh_hosptial) #10 in hospital
IST_nh_unknown <- filter(IST_nh, FPLACE=="U")
dim(IST_nh_unknown) #1 unknown --> will remove from dataset
IST_nh_dead <- filter(IST_nh, OCCODE=="1") #subsetting subjects who were dead at 6 months
dim(IST_nh_dead) #134 dead
IST_nh_dependent <- filter(IST_nh, OCCODE=="2") #subsetting subjects who were dependent at 6 months
dim(IST_nh_dependent) #326 dependent
IST_nh_notrecovered <- filter(IST_nh, OCCODE=="3") #subsetting subjects who were not recovered at 6 months
dim(IST_nh_notrecovered) #44 not recovered
IST_nh_recovered <- filter(IST_nh, OCCODE=="4") #subsetting subjects who were recovered at 6 months
dim(IST_nh_recovered) #26 recovered
IST_nh_notdependent <- filter(IST_nh, OCCODE=="3"|OCCODE=="4") #combining subset of subjects who were alive and not dependent at 6 months. 
dim(IST_nh_notdependent) #70 nondependent
IST_nh_missingstatus <- filter(IST_nh, OCCODE=="8"|OCCODE=="9")
dim(IST_nh_missingstatus) #1 missing status --> will remove

#Next step is to clean the dataset.
sum(is.na(IST_nh)) #There are 5539 missing values. 

NH_multinom <- IST_nh %>% #Create a new data set for the multinomial logistic regression of 2 research questions.
  #Will make a new column with our Place at 6 months outcome. 
  #This will have 3 outcomes: Improved level of living(home, relative's home ore residential care), Remains in nursing home, and Dead. 
  mutate(final.placeofliving = ifelse(FPLACE=="A"|FPLACE=="B"|FPLACE=="C", "improved",
                                                            ifelse(FPLACE=="D", "remainsNH",
                                                                   ifelse(OCCODE=="1", "dead", NA)))) %>%
```
```{r eval=TRUE}

NH_alive6m <-IST_nh %>% #Create a new data set with outcome variable of alive or dead at 6 months
  dplyr::select(-(HOSPNUM:RDELAY), -(RATRIAL:RCT), -(RDATE:DAYLOCAL), -(DMAJNCHD:DSIDEX), -(DNOSTRKX), -(DRSISCD), -(DRSHD), -(DRSUNKD), -(DPED:DALIVE), -(DPLACE:FPLACE), -(FU1_RECD:NCCODE), -(TD:DEAD8)) %>% #removing columns that are not pertinent to research questions
    drop_na(DIED) %>%
  mutate(alive6m = factor(DIED, levels=c(1,0), labels=c("died", "survived"))) %>%
  mutate(olderperson = )
  dplyr::select(-(DIED)) 
NH_alive6m 
sum(is.na(NH_alive6m)) #no NA values

NH_FLP <- IST_nh %>% #Create a new data set of patients who were discharged to a NH and survived 6m what their final living place (FLP) was in a binomial outcome: NH or improved living
  mutate(FLP = ifelse(FPLACE=="A"|FPLACE=="B"|FPLACE=="C", "improved",
                                                            ifelse(FPLACE=="D", "remainsNH", NA))) %>%
  drop_na(FLP) %>% #remove subjects that don't have outcome variables
  mutate(FLP = factor(FLP, levels=c("improved","remainsNH"), labels=c("improved","remainsNH"))) %>%
  dplyr::select(-(HOSPNUM:RDELAY), -(RATRIAL:RCT), -(RDATE:DAYLOCAL), -(DMAJNCHD:DSIDEX), -(DNOSTRKX), -(DRSISCD), -(DRSHD), -(DRSUNKD), -(DPED:DALIVE), -(DPLACE:FPLACE), -(FU1_RECD:NCCODE), -(DIED:DEAD8))
head(NH_FLP)
sum(is.na(NH_FLP)) #No NA values

NH_FFO <- IST_nh %>% #Create a new data set with binomial final functional outcome (FFO)
  #Will make a new column with Final functional outcomes.
  #This will also have 2 outcomes: Notdependent (not recovered and recovered) and dependent. 
  mutate(FFO = ifelse(OCCODE=="3"|OCCODE=="4", "notdependent",
                                 ifelse(OCCODE=="2", "dependent", NA))) %>%
  drop_na(FFO) %>%
  mutate(FFO = factor(FFO, levels=c("notdependent", "dependent"), labels=c("notdependent", "dependent"))) %>%
  dplyr::select(-(HOSPNUM:RDELAY), -(RATRIAL:RCT), -(RDATE:DAYLOCAL), -(DMAJNCHD:DSIDEX), -(DNOSTRKX), -(DRSISCD), -(DRSHD), -(DRSUNKD), -(DPED:DALIVE), -(DPLACE:FPLACE), -(FU1_RECD:NCCODE), -(DIED:DEAD8))
head(NH_FFO)
sum(is.na(NH_FFO))
```

``` {r eval=FALSE}
install.packages("mlogit")
install.packages("pROC")
install.packages("randomForest")
```
``` {r eval=TRUE}
library(randomForest)
library(mlogit)
library(ggplot2)
library(tidyverse)
#Logistic regression for outcome of 6 months survival of patient dishcarged from the hospital to a nursing home.
#Alive6m.glm <- glm(alive6m~., data=NH_alive6m, family=binomial(logit))
#summary(Alive6m.glm)
#glm.pred <- predict(Alive6m.glm, NH_alive6m, type="response")

#Random forests for outcome of 6 months survival of patients discharged from the hospital to a nursing home.
Alive6m.rf <- randomForest(alive6m ~ ., data=NH_alive6m, ntree=100, importance=TRUE)
Alive6m.rf
imp.alive6m <- Alive6m.rf$importance
head(sort(imp.alive6m[,4], decreasing=TRUE), n=10)
Alive6m.rf.pred <- predict(Alive6m.rf, NH_alive6m, type="prob")
Alive6m.rf.pred

#Model evaluation it K-fold Cross validation
library(dplyr)
N = nrow(NH_alive6m)
K = 10
set.seed(1234)
s = sample(1:K, size=N, replace=T)
#pred_outputs.glm <- vector(mode="numeric", length=N)
pred_outputs.rf <- vector(mode="numeric", length=N)
obs_outputs <- vector(mode="numeric", length=N)
offset <- 0
for(i in 1:K){
    train <- filter(NH_alive6m, s != i)
    test <- filter(NH_alive6m, s == i)
    obs_outputs[1:length(s[s==i]) + offset] <- test$alive6m
    #GLM train/test
    #glm <- glm(status~., data=train, family=binomial(logit))
    #glm.pred.curr <- predict(glm, test, type="response")
    #pred_outputs.glm[1:length(s[s==i]) + offset] <- glm.pred.curr

    #RF train/test
    rf <- randomForest(alive6m ~., data=train, ntree=100)
    rf.pred.curr <- predict(rf, newdata=test, type="prob") 
    pred_outputs.rf[1:length(s[s==i]) + offset] <- rf.pred.curr[,2]

    offset <- offset + length(s[s==i])
}

#ROC curves
library(pROC)
library(ggplot2)
#plot.roc(NH_alive6m$alive6m, glm.pred, ci=TRUE)
#plot.roc(obs_outputs, pred_outputs.glm, ci=TRUE, col="darkblue", add=TRUE)
pROC::plot.roc(NH_alive6m$alive6m, Alive6m.rf.pred[,2], ci=TRUE, col="darkgreen", add=FALSE)
pROC::plot.roc(obs_outputs, pred_outputs.rf, ci=TRUE, col="red", add=TRUE) 
legend("bottomright", legend=c("RF Training", "RF Cross-Validation"), col=c("darkgreen", "red"), lwd=2)
auc(NH_alive6m$alive6m, Alive6m.rf.pred[,2]) #AUC = 1
auc(obs_outputs, pred_outputs.rf) #AUC=0.9943


#GLM with top variables
alive6m.top.glm <-glm(alive6m ~ DALIVED + AGE + RSBP + STYPE + FAP, data= NH_alive6m, family = binomial(logit))
summary(alive6m.top.glm) 
alive6m.top.glm.pred <- predict(alive6m.top.glm, NH_alive6m, type="response")


#Random forests for outcome of 6 month survivavl with top variables.
alive6m.top.rf <- randomForest(alive6m ~ DALIVED + AGE + RSBP + STYPE + FAP, data=NH_alive6m, ntree=100, importance=TRUE)
alive6m.top.rf
imp.alive6m.top <- alive6m.top.rf$importance
head(sort(imp.alive6m.top[,4], decreasing=TRUE), n=10)
alive6m.top.rf.pred <- predict(alive6m.top.rf, NH_alive6m, type="prob")

#Model evaluation it K-fold Cross validation
library(dplyr)
N = nrow(NH_alive6m)
K = 10
set.seed(1234)
s = sample(1:K, size=N, replace=T)
pred_outputs.glm <- vector(mode="numeric", length=N)
pred_outputs.rf <- vector(mode="numeric", length=N)
obs_outputs <- vector(mode="numeric", length=N)
offset <- 0
for(i in 1:K){
    train <- filter(NH_alive6m, s != i)
    test <- filter(NH_alive6m, s == i)
    obs_outputs[1:length(s[s==i]) + offset] <- test$alive6m
   #GLM train/test
    glm <- glm(alive6m ~ DALIVED + AGE + RSBP + STYPE + FAP, data=train, family=binomial(logit))
    glm.pred.curr <- predict(glm, test, type="response")
    pred_outputs.glm[1:length(s[s==i]) + offset] <- glm.pred.curr
    
    #RF train/test
    rf <- randomForest(alive6m ~ DALIVED + AGE + RSBP + STYPE + FAP, data=train, ntree=100)
    rf.pred.curr <- predict(rf, newdata=test, type="prob") 
    pred_outputs.rf[1:length(s[s==i]) + offset] <- rf.pred.curr[,2]
    
    offset <- offset + length(s[s==i])
}

#ROC curves
library(pROC)
library(ggplot2)
plot.roc(NH_alive6m$alive6m, alive6m.top.glm.pred, ci+TRUE, main="Using Top-Ranking Variables")
plot.roc(obs_outputs, pred_outputs.glm, ci+TRUE, col="darkblue", add = TRUE)
plot.roc(NH_alive6m$alive6m, alive6m.top.rf.pred[,2], ci=TRUE, col="darkgreen", add=TRUE)
plot.roc(obs_outputs, pred_outputs.rf, ci=TRUE, col="red", add=TRUE) 
legend("bottomright", legend=c("GLM Training", "GLM Cross-Validation", "RF Training", "RF Cross-Validation"), col=c("black", "darkblue", "darkgreen", "red"), lwd=2)
#AUC 
auc(NH_alive6m$alive6m, alive6m.top.glm.pred) #AUC = 0.9986
auc(obs_outputs, pred_outputs.glm) #AUC=0.9955
auc(NH_alive6m$alive6m, alive6m.top.rf.pred[,2]) #AUC = 1
auc(obs_outputs, pred_outputs.rf) #AUC = 0.9954


#Random forests for outcome of final Living Place of patients discharged from the hospital to the nursing home and alive at 6 months.
FLP.rf <- randomForest(FLP ~ ., data=NH_FLP, ntree=100, importance=TRUE)
FLP.rf
imp.FLP <- FLP.rf$importance
head(sort(imp.FLP[,4], decreasing=TRUE), n=10)
FLP.rf.pred <- predict(FLP.rf, NH_FLP, type="prob")

#Model evaluation it K-fold Cross validation
library(dplyr)
N = nrow(NH_FLP)
K = 10
set.seed(1234)
s = sample(1:K, size=N, replace=T)
#pred_outputs.glm <- vector(mode="numeric", length=N)
pred_outputs.rf <- vector(mode="numeric", length=N)
obs_outputs <- vector(mode="numeric", length=N)
offset <- 0
for(i in 1:K){
    train <- filter(NH_FLP, s != i)
    test <- filter(NH_FLP, s == i)
    obs_outputs[1:length(s[s==i]) + offset] <- test$FLP
   
    #RF train/test
    rf <- randomForest(FLP ~., data=train, ntree=100)
    rf.pred.curr <- predict(rf, newdata=test, type="prob") 
    pred_outputs.rf[1:length(s[s==i]) + offset] <- rf.pred.curr[,2]
    offset <- offset + length(s[s==i])
}

#ROC curves
library(pROC)
library(ggplot2)
#plot.roc(NH_FLP$FLP, glm.pred, ci=TRUE)
#plot.roc(obs_outputs, pred_outputs.glm, ci=TRUE, col="darkblue", add=TRUE)
plot.roc(NH_FLP$FLP, FLP.rf.pred[,2], ci=TRUE, col="darkgreen", add=FALSE)
plot.roc(obs_outputs, pred_outputs.rf, ci=TRUE, col="red", add=TRUE) 
legend("bottomright", legend=c("RF Training", "RF Cross-Validation"), col=c("darkgreen", "red"), lwd=2)
auc(NH_FLP$FLP, FLP.rf.pred[,2]) #AUC= 1
auc(obs_outputs, pred_outputs.rf) #AUC = 0.7397

#GLM with top variables
FLP.top.glm <-glm(FLP ~ DALIVED + AGE + RSBP + STYPE, data= NH_FLP, family = binomial(logit))
summary(NH_FLP.top.glm) #Age, STYPE: TACS, antiplts unknown or yes
FLP.top.glm.pred <- predict(FLP.top.glm, NH_FLP, type="response")


#Random forests for outcome of final Living Place with top variables.
FLP.top.rf <- randomForest(FLP ~ DALIVED + AGE + RSBP + STYPE, data=NH_FLP, ntree=100, importance=TRUE)
FLP.top.rf
imp.FLP <- FLP.top.rf$importance
head(sort(imp.FLP[,4], decreasing=TRUE), n=10)
FLP.top.rf.pred <- predict(FLP.rf, NH_FLP, type="prob")

#Model evaluation it K-fold Cross validation
library(dplyr)
N = nrow(NH_FLP)
K = 10
set.seed(1234)
s = sample(1:K, size=N, replace=T)
pred_outputs.glm <- vector(mode="numeric", length=N)
pred_outputs.rf <- vector(mode="numeric", length=N)
obs_outputs <- vector(mode="numeric", length=N)
offset <- 0
for(i in 1:K){
    train <- filter(NH_FLP, s != i)
    test <- filter(NH_FLP, s == i)
    obs_outputs[1:length(s[s==i]) + offset] <- test$FLP
   
    #GLM train/test
    glm <- glm(FLP ~ DALIVED + AGE + RSBP + STYPE, data=train, family=binomial(logit))
    glm.pred.curr <- predict(glm, test, type="response")
    pred_outputs.glm[1:length(s[s==i]) + offset] <- glm.pred.curr
    
    #RF train/test
    rf <- randomForest(FLP ~DALIVED + AGE + RSBP + STYPE, data=train, ntree=100)
    rf.pred.curr <- predict(rf, newdata=test, type="prob") 
    pred_outputs.rf[1:length(s[s==i]) + offset] <- rf.pred.curr[,2]

    offset <- offset + length(s[s==i])
}

#ROC curves
library(pROC)
library(ggplot2)
plot.roc(NH_FLP$FLP, FLP.top.glm.pred, ci=TRUE)
plot.roc(obs_outputs, pred_outputs.glm, ci=TRUE, col="darkblue", add=TRUE)
plot.roc(NH_FLP$FLP, FLP.top.rf.pred[,2], ci=TRUE, col="darkgreen", add=TRUE)
plot.roc(obs_outputs, pred_outputs.rf, ci=TRUE, col="red", add=TRUE) 
legend("bottomright", legend=c("GLM Training", "GLM Cross-Validation", "RF Training", "RF Cross-Validation"), col=c("black", "darkblue", "darkgreen", "red"), lwd=2)
auc(NH_FLP$FLP, FLP.top.glm.pred) #AUC = 0.736
auc(obs_outputs, pred_outputs.glm) #AUC=0.7139
auc(NH_FLP$FLP, FLP.top.rf.pred[,2]) #AUC = 1
auc(obs_outputs, pred_outputs.rf) #AUC = 0.6645


#Random forests for outcome of final functional outcome (FFO) of patients discharged from the hospital to the nursing home and alive at 6 months
FFO.rf <- randomForest(FFO ~ ., data=NH_FFO, ntree=100, importance=TRUE)
FFO.rf
imp.FFO <- FFO.rf$importance
head(sort(imp.FFO[,4], decreasing=TRUE), n=10)
FFO.rf.pred <- predict(FFO.rf, NH_FFO, type="prob")

#Model evaluation it K-fold Cross validation
library(dplyr)
N = nrow(NH_FFO)
K = 10
set.seed(1234)
s = sample(1:K, size=N, replace=T)
#pred_outputs.glm <- vector(mode="numeric", length=N)
pred_outputs.rf <- vector(mode="numeric", length=N)
obs_outputs <- vector(mode="numeric", length=N)
offset <- 0
for(i in 1:K){
    train <- filter(NH_FFO, s != i)
    test <- filter(NH_FFO, s == i)
    obs_outputs[1:length(s[s==i]) + offset] <- test$FFO
   
    #RF train/test
    rf <- randomForest(FFO ~., data=train, ntree=100)
    rf.pred.curr <- predict(rf, newdata=test, type="prob") 
    pred_outputs.rf[1:length(s[s==i]) + offset] <- rf.pred.curr[,2]
    offset <- offset + length(s[s==i])
}

#ROC curves
library(pROC)
library(ggplot2)
#plot.roc(NH_FFO$FFO, glm.pred, ci=TRUE)
#plot.roc(obs_outputs, pred_outputs.glm, ci=TRUE, col="darkblue", add=TRUE)
plot.roc(NH_FFO$FFO, FFO.rf.pred[,2], ci=TRUE, col="darkgreen", add=FALSE)
plot.roc(obs_outputs, pred_outputs.rf, ci=TRUE, col="red", add=TRUE) 
legend("bottomright", legend=c("RF Training", "RF Cross-Validation"), col=c("darkgreen", "red"), lwd=2)
auc(NH_FFO$FFO, FFO.rf.pred[,2]) #AUC= 1
auc(obs_outputs, pred_outputs.rf) #AUC = 0.675

#GLM with top variables
FFO.top.glm <-glm(FFO ~ DALIVED + AGE + RSBP + STYPE, data= NH_FFO, family = binomial(logit))
summary(FFO.top.glm) #Age, STYPE: TACS, antiplts unknown or yes
FFO.top.glm.pred <- predict(FFO.top.glm, NH_FFO, type="response")


#Random forests for outcome of final Living Place with top variables.
FFO.top.rf <- randomForest(FFO ~ DALIVED + AGE + RSBP + STYPE, data=NH_FFO, ntree=100, importance=TRUE)
FFO.top.rf
imp.FFO <- FFO.top.rf$importance
head(sort(imp.FFO[,4], decreasing=TRUE), n=10)
FFO.top.rf.pred <- predict(FFO.rf, NH_FFO, type="prob")

#Model evaluation it K-fold Cross validation
library(dplyr)
N = nrow(NH_FFO)
K = 10
set.seed(1234)
s = sample(1:K, size=N, replace=T)
pred_outputs.glm <- vector(mode="numeric", length=N)
pred_outputs.rf <- vector(mode="numeric", length=N)
obs_outputs <- vector(mode="numeric", length=N)
offset <- 0
for(i in 1:K){
    train <- filter(NH_FFO, s != i)
    test <- filter(NH_FFO, s == i)
    obs_outputs[1:length(s[s==i]) + offset] <- test$FFO
   
    #GLM train/test
    glm <- glm(FFO ~ DALIVED + AGE + RSBP + STYPE, data=train, family=binomial(logit))
    glm.pred.curr <- predict(glm, test, type="response")
    pred_outputs.glm[1:length(s[s==i]) + offset] <- glm.pred.curr
    
    #RF train/test
    rf <- randomForest(FFO ~DALIVED + AGE + RSBP + STYPE, data=train, ntree=100)
    rf.pred.curr <- predict(rf, newdata=test, type="prob") 
    pred_outputs.rf[1:length(s[s==i]) + offset] <- rf.pred.curr[,2]

    offset <- offset + length(s[s==i])
}

#ROC curves
library(pROC)
library(ggplot2)
plot.roc(NH_FFO$FFO, FFO.top.glm.pred, ci=TRUE)
plot.roc(obs_outputs, pred_outputs.glm, ci=TRUE, col="darkblue", add=TRUE)
plot.roc(NH_FFO$FFO, FFO.top.rf.pred[,2], ci=TRUE, col="darkgreen", add=TRUE)
plot.roc(obs_outputs, pred_outputs.rf, ci=TRUE, col="red", add=TRUE) 
legend("bottomright", legend=c("GLM Training", "GLM Cross-Validation", "RF Training", "RF Cross-Validation"), col=c("black", "darkblue", "darkgreen", "red"), lwd=2)
auc(NH_FFO$FFO, FFO.top.glm.pred) #AUC = 0.7309
auc(obs_outputs, pred_outputs.glm) #AUC=0.6884
auc(NH_FFO$FFO, FFO.top.rf.pred[,2]) #AUC = 1
auc(obs_outputs, pred_outputs.rf) #AUC = 0.6311
```
### Results
Describe your results and include relevant tables, plots, and code/comments used to obtain them. End with a brief conclusion of your findings related to the question you set out to address. You can include references if you'd like, but this is not required.
